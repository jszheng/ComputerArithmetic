{"config":{"lang":["ja"],"separator":"[\\s\\-\uff0c\u3002]+","pipeline":["stemmer"]},"docs":[{"location":"","title":"\u5c01\u9762","text":""},{"location":"Appendix/","title":"\u9644\u5f55:\u8fc7\u53bb\u73b0\u5728\u548c\u672a\u6765","text":"<p>Appendix: Past, Present, and Future</p> <p>\u201cWho controls the past controls the future; who controls the present controls the past.\u201d GEORG ORWELL</p> <p>In this appendix, we trace the history of computer arithmetic, from the earliest digital computers to the modern machines that permeate ourdaily lives.We present a few turning points along this amazing chain of events, including the development of early supercomputers,the role played by vector supercomputers (particularly,their contributions to advances in pipelining), the arrival of digital signal processors, and the distillation of all these advanced developments into the tiny processors that power our desktop and laptop computers.We conclude with a discussion of current trends, future outlook, and resources for further study of computer arithmetic.</p>"},{"location":"BackCover/","title":"\u5c01\u5e95","text":""},{"location":"Front/","title":"Computer Arithmetic","text":"<p>Algorithms and Hardware Designs</p> <p>Second Edition</p> <p>2010</p> <p></p> <p></p> <p>by Behrooz Parhami</p> <p>UCSB</p> <p></p>"},{"location":"Preface_1st/","title":"\u7b2c\u4e00\u7248\u5e8f\u8a00","text":""},{"location":"Preface_1st/#_2","title":"\u8ba1\u7b97\u673a\u7b97\u672f\u7684\u80cc\u666f","text":"<p>\u5728\u8fc7\u53bb20\u5e74\u95f4\uff0c\u8ba1\u7b97\u673a\u4f53\u7cfb\u7ed3\u6784\u7684\u8fdb\u6b65\u4f7f\u5f97\u6570\u5b57\u8ba1\u7b97\u673a\u786c\u4ef6\u7684\u6027\u80fd\u6301\u7eed\u5448\u6307\u6570\u7ea7\u589e\u957f\uff0c\u5c3d\u7ba1\u5728\u7535\u8def\u5c42\u63d0\u9ad8\u901f\u5ea6\u7684\u6280\u672f\u96be\u5ea6\u5728\u4e0d\u65ad\u63d0\u9ad8\u3002\u5982\u679c\u6ca1\u6709\u7406\u8bba\u4e0a\u7684\u6d1e\u5bdf\u529b\u3001\u5b9e\u9a8c\u7814\u7a76\u548c\u5de5\u5177\u6784\u5efa\u7684\u52aa\u529b\uff0c\u8fd9\u79cd\u73b0\u8c61\u7ea7\u7684\u589e\u957f\u901f\u5ea6\u662f\u4e0d\u53ef\u80fd\u7684\uff0c\u8fd9\u4e9b\u52aa\u529b\u6709\u52a9\u4e8e\u5c06\u8ba1\u7b97\u673a\u4f53\u7cfb\u7ed3\u6784\u4ece\u4e00\u95e8\u827a\u672f\u8f6c\u53d8\u4e3a\u8ba1\u7b97\u673a\u79d1\u5b66\u548c\u5de5\u7a0b\u4e2d\u6700\u91cf\u5316\u7684\u4e00\u4e2a\u5206\u652f\uff0c\u4e14\u9884\u8ba1\u5728\u4e0d\u4e45\u7684\u5c06\u6765\u4e5f\u4f1a\u7ee7\u7eed\u4e0b\u53bb\u3002\u5bf9\u4e0d\u540c\u5f62\u5f0f\u7684\u5e76\u53d1\u6027\u7684\u7406\u89e3\uff0c\u4ee5\u53ca\u5177\u5907\u5408\u7406\u6709\u6548\u6027\u5e76\u4e14\u7528\u6237\u53cb\u597d\u7684\u7f16\u7a0b\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u662f\u8fd9\u4e00\u6210\u529f\u6545\u4e8b\u7684\u5173\u952e\u63a8\u52a8\u56e0\u7d20\u3002</p> <p>\u5904\u7406\u5668\u6027\u80fd\u6210\u672c\u589e\u957f\u80cc\u540e\u7684\u95ee\u9898\u662f\u786c\u4ef6\u548c\u8f6f\u4ef6\u590d\u6742\u6027\u7684\u7a7a\u524d\u589e\u52a0\u3002\u590d\u6742\u5316\u7684\u8d8b\u52bf\u4e0d\u4ec5\u4e0e\u53ef\u6d4b\u8bd5\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u76f8\u62b5\u89e6\uff0c\u8fd8\u963b\u788d\u4e86\u53ef\u9002\u5e94\u6027\u3001\u6027\u80fd\u8c03\u6574\uff0c\u4ee5\u53ca\u5404\u79cd\u6743\u8861\u7684\u8bc4\u4f30\uff0c\u6240\u6709\u7684\u8fd9\u4e9b\u6700\u7ec8\u5bfc\u81f4\u4e86\u5f00\u53d1\u6210\u672c\u7684\u98d9\u5347\u3002\u5f53\u524d\u548c\u672a\u6765\u7684\u8ba1\u7b97\u673a\u8bbe\u8ba1\u6240\u9762\u4e34\u7684\u4e00\u4e2a\u5173\u952e\u6311\u6218\u662f\uff1a\u9700\u8981\u901a\u8fc7\u53bb\u9664\u4e00\u5c42\u53c8\u4e00\u5c42\u7684\u590d\u6742\u6027\u6765\u626d\u8f6c\u8fd9\u4e00\u8d8b\u52bf\u3002\u5728\u9009\u62e9\u7b80\u6d01\u3001\u7a33\u5065\u3001\u6613\u4e8e\u9a8c\u8bc1\u7684\u8bbe\u8ba1\u540c\u65f6\uff0c\u8fd8\u8981\u7ee7\u7eed\u5c1d\u8bd5\u65b0\u7684\u8bbe\u8ba1\u65b9\u6cd5\u3002\u5e94\u5f53\u4ece\u8f83\u7b80\u5355\u7684\u7535\u8def\u4e2d\u83b7\u5f97\u6027\u80fd\u4e0e\u6613\u7528\u6027\u7684\u597d\u5904\uff0c\u5e76\u80fd\u968f\u65f6\u9002\u5e94\u5e94\u7528\u7684\u9700\u6c42\u3002</p> <p>\u5728\u8ba1\u7b97\u673a\u8bbe\u8ba1\u8005\u5bf9\u7528\u6237\u53cb\u597d\u6027\u3001\u7d27\u51d1\u6027\u3001\u7b80\u5355\u6027\u3001\u9ad8\u6027\u80fd\u3001\u4f4e\u6210\u672c\u548c\u529f\u8017\u7684\u8ffd\u6c42\u4e2d\uff0c\u8ba1\u7b97\u673a\u7b97\u672f\u8d77\u5230\u4e86\u5173\u952e\u4f5c\u7528\u3002\u5b83\u662f\u8ba1\u7b97\u673a\u4f53\u7cfb\u7ed3\u6784\u4e2d\u6700\u53e4\u8001\u7684\u5b50\u9886\u57df\u4e4b\u4e00\u3002\u65e9\u671f\u6570\u5b57\u8ba1\u7b97\u673a\u7684\u5927\u90e8\u5206\u786c\u4ef6\u5f00\u9500\u90fd\u6765\u81ea\u7d2f\u52a0\u5668\u548c\u5176\u5b83\u7b97\u672f/\u903b\u8f91\u7535\u8def\u4e2d\u3002\u56e0\u6b64\uff0c\u7b2c\u4e00\u4ee3\u8ba1\u7b97\u673a\u8bbe\u8ba1\u8005\u7684\u52a8\u673a\u662f\u5728\u53ef\u80fd\u7684\u8303\u56f4\u5185\u5c3d\u53ef\u80fd\u7b80\u5316\u548c\u5171\u4eab\u786c\u4ef6\uff0c\u5e76\u5728\u63d0\u51fa\u65b9\u6848\u524d\u8fdb\u884c\u8be6\u7ec6\u7684\u6027\u4ef7\u6bd4\u5206\u6790\u3002\u6211\u4eec\u4eca\u5929\u4f7f\u7528\u7684\u8bb8\u591a\u5de7\u5999\u7684\u8bbe\u8ba1\u65b9\u6cd5\u5b9e\u9645\u4e0a\u90fd\u6e90\u81ea\u4e8e30\uff5e50\u5e74\u524d\u7b28\u91cd\u3001\u8017\u7535\u7684\u673a\u5668\u4e2d\u3002</p> <p>\u5b9e\u9645\u4e0a\uff0c\u8ba1\u7b97\u673a\u7b97\u672f\u5982\u4eca\u5df2\u7ecf\u975e\u5e38\u6210\u529f\u4e86\uff0c\u4ee5\u81f3\u4e8e\u6709\u65f6\u4f1a\u53d8\u5f97\u975e\u5e38\u900f\u660e\u3002\u5c31\u590d\u6742\u6027\u800c\u8a00\uff0c\u5982\u4eca\u7684\u7b97\u672f\u7535\u8def\u65e9\u5df2\u4e0d\u518d\u5360\u636e\u4e3b\u5bfc\u5730\u4f4d\uff1b\u5bc4\u5b58\u5668\u3001\u5b58\u50a8\u5668\u548c\u7c97\u51fa\u6c14\u7ba1\u7406\u3001\u6307\u4ee4\u53d1\u5c04\u903b\u8f91\u548c\u6d41\u6c34\u7ebf\u63a7\u5236\u903b\u8f91\u624d\u662f\u5f53\u4eca\u5904\u7406\u5668\u82af\u7247\u9762\u79ef\u7684\u4e3b\u8981\u6d88\u8d39\u8005\u3002\u7b97\u672f\u7535\u8def\u7684\u6b63\u786e\u6027\u4e0e\u9ad8\u6027\u80fd\u662f\u4eba\u4eec\u901a\u5e38\u7684\u9884\u671f\uff0c\u50cf1990s\u82f1\u7279\u5c14\u5954\u817e\u7684\u9664\u6cd5\u9519\u8bef\u8fd9\u6837\u7684\u4e8b\u4ef6\u5b9e\u9645\u4e0a\u5f88\u5c11\u53d1\u751f\u3002</p> <p>\u524d\u9762\u6240\u8ff0\u7684\u60c5\u51b5\u6b63\u5728\u8f6c\u53d8\uff0c\u8fd9\u91cc\u6709\u51e0\u4e2a\u539f\u56e0\u3002\u9996\u5148\uff0c\u5728\u6781\u9ad8\u7684\u65f6\u949f\u9891\u7387\u4e0b\uff0c\u7b97\u672f\u7535\u8def\u548c\u5904\u7406\u5668\u5176\u5b83\u90e8\u5206\u95f4\u7684\u63a5\u53e3\u5f00\u59cb\u53d8\u5f97\u975e\u5e38\u5173\u952e\u3002\u7b97\u672f\u5355\u5143\u4e5f\u4e0d\u518d\u80fd\u88ab\u5b64\u7acb\u5730\u8bbe\u8ba1\u548c\u9a8c\u8bc1\u4e86\u3002\u76f8\u53cd\uff0c\u9700\u8981\u8fdb\u884c\u7efc\u5408\u7684\u8bbe\u8ba1\u4e0e\u4f18\u5316\uff0c\u8fd9\u4f7f\u5f97\u5f00\u53d1\u5de5\u4f5c\u53d8\u5f97\u66f4\u52a0\u590d\u6742\u4e14\u6602\u8d35\u3002\u5176\u6b21\uff0c\u8fd8\u8981\u5229\u7528\u65b0\u6280\u672f\u7684\u4f18\u52bf\u4f18\u5316\u7b97\u672f\u7535\u8def\u4ee5\u6ee1\u8db3\u8bbe\u8ba1\u76ee\u6807\uff0c\u5e76\u80fd\u5bb9\u5fcd\u5f31\u70b9\uff0c\u8fd9\u4f7f\u5f97\u6211\u4eec\u9700\u8981\u5bf9\u73b0\u6709\u7684\u8bbe\u8ba1\u6a21\u5f0f\u8fdb\u884c\u91cd\u65b0\u5ba1\u89c6\u3002\u6700\u540e\uff0c\u5c06\u66f4\u9ad8\u7ea7\u522b\u7684\u7b97\u672f\u57fa\u7840\u5355\u5143\u7eb3\u5165\u786c\u4ef6\uff0c\u4f7f\u5f97\u8bbe\u8ba1\u3001\u4f18\u5316\u548c\u9a8c\u8bc1\u5de5\u4f5c\u53d8\u5f97\u9ad8\u5ea6\u590d\u6742\uff0c\u4e14\u76f8\u4e92\u5173\u8054\u3002</p> <p>\u8fd9\u4fbf\u662f\u8ba1\u7b97\u673a\u7b97\u672f\u5728\u5982\u4eca\u4ecd\u5177\u6d3b\u529b\u7684\u539f\u56e0\u3002\u8fd9\u4e2a\u9886\u57df\u7684\u8bbe\u8ba1\u8005\u548c\u7814\u7a76\u4eba\u5458\u4ee5\u60ca\u4eba\u7684\u89c4\u5f8b\u6027\u4ea7\u751f\u4e86\u65b0\u7684\u7ed3\u6784\u3002\u8d85\u524d\u8fdb\u4f4d\u52a0\u6cd5\u5668\u5c31\u662f\u4e00\u4e2a\u5178\u578b\u7684\u4f8b\u5b50\uff1a\u5728\u4e0d\u8fdc\u7684\u8fc7\u53bb\uff0c\u6211\u4eec\u66fe\u8ba4\u4e3a\u6211\u4eec\u77e5\u9053\u6240\u6709\u5173\u4e8e\u8d85\u524d\u8fdb\u4f4d\u52a0\u6cd5\u5668\u7684\u77e5\u8bc6\u3002\u7136\u800c\uff0c\u65b0\u7684\u8bbe\u8ba1\u3001\u6539\u8fdb\u548c\u4f18\u5316\u4ecd\u5728\u4e0d\u65ad\u51fa\u73b0\u3002IEEE 754\u6807\u51c6\u6d6e\u70b9\u683c\u5f0f\u6d88\u9664\u4e86\u8bb8\u591a\u6709\u5173\u6d6e\u70b9\u8ba1\u7b97\u517c\u5bb9\u6027\u4e0e\u8bef\u5dee\u63a7\u5236\u7684\u4f46\u53c8\uff0c\u4ece\u800c\u4ea7\u751f\u4e86\u8bb8\u591a\u5bf9\u5927\u4f17\u5e02\u573a\u5177\u6709\u5438\u5f15\u529b\u7684\u65b0\u8bbe\u8ba1\u4e0e\u4ea7\u54c1\u3002\u9274\u4e8e\u8bb8\u591a\u65b0\u5e94\u7528\u573a\u666f\uff08\u5982\u52a0\u5bc6\u3001\u9519\u8bef\u68c0\u6d4b\u548c\u591a\u5a92\u4f53\uff09\u90fd\u5177\u6709\u7b97\u672f\u5bc6\u96c6\u6027\u7684\u7279\u70b9\uff0c\u8ba1\u7b97\u673a\u7b97\u672f\u5728\u672a\u6765\u51e0\u5e74\u4ecd\u5c06\u7ee7\u7eed\u84ec\u52c3\u53d1\u5c55\u3002</p>"},{"location":"Preface_1st/#_3","title":"\u672c\u4e66\u7684\u76ee\u7684\u4e0e\u7ed3\u6784","text":"<p>\u8ba1\u7b97\u673a\u7b97\u672f\u8fd9\u4e00\u9886\u57df\u5df2\u7ecf\u53d1\u5c55\u6210\u719f\uff0c\u5df2\u7ecf\u6709\u5341\u51e0\u7bc7\u6750\u6599\u548c\u53c2\u8003\u4e66\u88ab\u51fa\u7248\u4e86\u3002\u5176\u4e2d\u4e00\u4e9b\u6d89\u53ca\u8ba1\u7b97\u673a\u7b97\u672f\u7684\u4e00\u822c\u4e66\u7c4d\uff08\u76f8\u5bf9\u4e8e\u7279\u6b8a\u5e94\u7528\u6216\u9ad8\u7ea7/\u975e\u5e38\u89c4\u65b9\u6cd5\uff09\u88ab\u5217\u5728\u4e86\u5e8f\u8a00\u7684\u6700\u540e\uff08\u53c2\u8003\u6587\u732e\u7d22\u5f15\u8bf7\u89c1\u539f\u4e66\u5e8f\u8a00\u672b\uff09\u3002\u8fd9\u4e9b\u4e66\u7684\u6bcf\u4e00\u672c\u90fd\u5177\u6709\u72ec\u7279\u7684\u4f18\u52bf\uff0c\u4e14\u5bf9\u8be5\u9886\u57df\u7684\u5f62\u6210\u548c\u53d1\u5c55\u505a\u51fa\u4e86\u8d21\u732e\u3002\u672c\u4e66\uff0c\u300aComputer Arithmetic: Algorithms and Hardware Designs\u300b\u5c31\u662f\u5750\u7740\u591a\u5e74\u6765\u5f00\u53d1\u5e76\u5b8c\u5584\u7684\u8bb2\u4e49\u7684\u4ea7\u7269\u3002\u4ee5\u4e0b\u662f\u672c\u4e66\u4e0e\u6240\u5217\u4e66\u7c4d\u76f8\u6bd4\uff0c\u6700\u91cd\u8981\u7684\u7279\u70b9\uff1a</p> <ol> <li>**\u6750\u6599\u7ae0\u8282\u6309\u7167\u8bb2\u5ea7\u7684\u89c4\u6a21\u5212\u5206\uff1a**\u5728\u6211\u7684\u6559\u5b66\u65b9\u6848\u4e2d\uff0c\u4e00\u4e2a\u8bb2\u5ea7\u6216\u591a\u6216\u5c11\u662f\u4e00\u4e2a\u72ec\u7acb\u7684\u6a21\u5757\uff0c\u5176\u4e0e\u8fc7\u53bb\u7684\u8bb2\u5ea7\u6709\u8054\u7cfb\uff0c\u4e14\u4f1a\u6307\u51fa\u672a\u6765\u4f1a\u53d1\u751f\u4ec0\u4e48\u3002\u6bcf\u4e2a\u8bb2\u5ea7\u90fd\u5fc5\u987b\u6709\u4e00\u4e2a\u4e3b\u9898\u6216\u6807\u9898\uff0c\u4e14\u5fc5\u987b\u4ece\u52a8\u673a\u5230\u7ec6\u8282\u518d\u5230\u7ed3\u8bba\u3002\u5728\u8bbe\u8ba1\u6587\u672c\u65f6\uff0c\u6211\u52aa\u529b\u5c06\u6750\u6599\u5206\u4e3a\u51e0\u7ae0\uff0c\u6bcf\u7ae0\u90fd\u9002\u5408\u7528\u4e8e\u4e00\u4e2a\u8bb2\u5ea7\uff081\uff5e2\u5c0f\u65f6\uff09\u3002\u7b80\u77ed\u7684\u8bb2\u5ea7\u53ef\u4ee5\u4ec5\u6db5\u76d6\u5176\u4e2d\u524d\u9762\u51e0\u4e2a\u5c0f\u8282\uff0c\u800c\u8f83\u957f\u7684\u8bb2\u5ea7\u5219\u53ef\u5904\u7406\u77e5\u8bc6\u6216\u65b9\u6cd5\u7684\u53d8\u79cd\u3001\u6b21\u8981\u7684\u601d\u60f3\u6216\u63a5\u8fd1\u7ae0\u672b\u65f6\u7684\u9ad8\u7ea7\u6750\u6599\u3002\u4e3a\u4f7f\u7ed3\u6784\u5177\u6709\u5c42\u6b21\u6027\uff08\u800c\u4e0d\u662f\u6241\u5e73\u6216\u7ebf\u6027\u7684\uff09\uff0c\u672c\u4e66\u4e00\u5171\u88ab\u5206\u4e3a\u4e86\u4e03\u4e2a\u90e8\u5206\uff0c\u6bcf\u4e2a\u90e8\u5206\u7531\u56db\u7ae0\u7ec4\u6210\uff0c\u6bcf\u7ae0\u5bf9\u5e94\u4e00\u4e2a\u8bb2\u5ea7\uff0c\u6db5\u76d6\u8be5\u9886\u57df\u7684\u4e00\u4e2a\u65b9\u9762\uff08\u89c1\u56feP.1\uff0c\u5728\u672c\u6587\u540e\u9762\u8bf7\u5f80\u4e0b\u7ffb\uff09\u3002</li> <li>**\u5f3a\u8c03\u57fa\u7840\u7406\u8bba\u4e0e\u786c\u4ef6\u8bbe\u8ba1\uff1a**\u5904\u7406\u590d\u6742\u95ee\u9898\u7684\u80fd\u529b\u65e2\u9700\u8981\u5305\u62ec\u8ba1\u7b97\u673a\u7b97\u672f\u7406\u8bba\u57fa\u7840\u7684\u6df1\u523b\u7406\u89e3\uff0c\u4e5f\u9700\u8981\u5e2e\u52a9\u6211\u4eec\u7406\u89e3\u7406\u8bba\u7684\u8bbe\u8ba1\u5b9e\u4f8b\u3002\u8fd9\u4e9b\u8bbe\u8ba1\u4e5f\u540c\u65f6\u4e3a\u7efc\u5408\u63d0\u4f9b\u4e86\u6784\u5efa\u5757\uff0c\u5e76\u5728 \u6210\u672c-\u6027\u80fd \u6bd4\u8f83\u65b9\u9762\u63d0\u4f9b\u4e86\u53c2\u8003\u70b9\u3002\u8fd9\u79cd\u89c2\u70b9\u53cd\u6620\u5728\uff0c\u4f8b\u5982\uff0c\u901a\u8fc7\u5bf9\u5197\u4f59\u6570\u5b57\u8868\u793a\u548c\u76f8\u5173\u7b97\u672f\u7684\u8be6\u7ec6\u4e86\u89e3\uff08\u7b2c3\u7ae0\uff09\uff0c\u53ef\u4ee5\u4f7f\u6211\u4eec\u5bf9\u540e\u9762\u5404\u79cd\u4e58\u6cd5\u5668\u8bbe\u8ba1\u548c\u5b9e\u65f6\u7b97\u672f\u5f97\u5230\u66f4\u597d\u7684\u7406\u89e3\u3002\u53e6\u4e00\u4e2a\u4f8b\u5b50\u89c1\u4e8e\u7b2c22\u7ae0\uff0c\u5176\u4ece\u66f4\u76f4\u89c2\u7684\u51e0\u4f55\u5b66\u89d2\u5ea6\u4ecb\u7ecd\u4e86\u5750\u6807\u65cb\u8f6c\u6570\u5b57\u8ba1\u7b97\u673a\uff0c\u6216\u8005CORDIC\u7b97\u6cd5\u3002</li> <li>**\u5c06\u8ba1\u7b97\u673a\u7b97\u672f\u4e0e\u8ba1\u7b97\u673a\u5176\u5b83\u5b50\u9886\u57df\u8054\u7cfb\uff1a**\u8ba1\u7b97\u673a\u7b97\u672f\u5e38\u53d7\u8ba1\u7b97\u673a\u4f53\u7cfb\u7ed3\u6784\u548c\u5176\u5b83\u5b50\u9886\u57df\u7684\u5b57\u6837\uff0c\u540c\u65f6\u4e5f\u80fd\u53cd\u8fc7\u6765\u6ecb\u517b\u8fd9\u4e9b\u9886\u57df\u3002\u8fd9\u79cd\u8054\u7cfb\u7684\u4f8b\u5b50\u6bd4\u6bd4\u7686\u662f\u3002\u4f8b\u5982\u5bf9\u4e8e\u8d85\u524d\u8fdb\u4f4d\u52a0\u6cd5\u5668\uff0c\u6211\u4eec\u53ef\u4ee5\u610f\u8bc6\u5230\u5176\u8fdb\u4f4d\u8ba1\u7b97\u5b9e\u9645\u4e0a\u5c31\u662f\u5e76\u884c\u524d\u7f00\u8ba1\u7b97\u7684\u4e00\u4e2a\u7279\u4f8b\uff0c\u800c\u5e76\u884c\u524d\u7f00\u8ba1\u7b97\u5df2\u7ecf\u88ab\u5e76\u884c\u8ba1\u7b97\u7684\u7814\u7a76\u8005\u505a\u51fa\u4e86\u5e7f\u6cdb\u5730\u7814\u7a76\u3002\u795e\u7ecf\u7f51\u7edc\u7684\u7b97\u672f\u5219\u662f\u4e00\u4e2a\u4ecd\u5728\u63a2\u7d22\u7684\u9886\u57df\u3002\u5269\u4f59\u6570\u7cfb\u7edf\uff08residue number system\uff09\u4e3a\u590d\u6742\u6027\u7406\u8bba\u548c\u9ad8\u901f\u7b97\u672f\u7684\u6781\u9650\u611f\u5174\u8da3\u7684\u7814\u7a76\u5458\uff0c\u4ee5\u53ca\u5bb9\u9519\u6570\u5b57\u7cfb\u7edf\u7684\u8bbe\u8ba1\u8005\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9d\u8d35\u7684\u5de5\u5177\u3002</li> <li>**\u5e7f\u6cdb\u6db5\u76d6\u4e86\u91cd\u8981\u4e3b\u9898\uff1a**\u672c\u4e66\u51e0\u4e4e\u6db5\u76d6\u4e86\u8ba1\u7b97\u673a\u7b97\u672f\u7684\u6240\u6709\u91cd\u8981\u7b97\u6cd5\u548c\u786c\u4ef6\u8bbe\u8ba1\u4e3b\u9898\uff0c\u4ece\u800c\u4e3a\u8be5\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5e73\u8861\u4e14\u5b8c\u6574\u7684\u89c6\u89d2\u3002\u6db5\u76d6\u5185\u5bb9\u5305\u62ec\u975e\u5e38\u89c4\u6570\u5b57\u8868\u793a\u65b9\u6cd5\uff083,4\u7ae0\uff09\u3001\u8d8a\u6765\u8d8a\u91cd\u8981\u7684\u67e5\u627e\u8868\u7b97\u672f\uff0824\u7ae0\uff09\u3001\u5bb9\u9519\u548c\u53ef\u9a8c\u8bc1\u7b97\u672f\uff0819,20\u7ae0\uff09\u3001\u4ee5\u53ca\u7b2c\u4e03\u90e8\u5206\uff0825\uff5e28\u7ae0\uff09\u7684\u4e3b\u9898\uff0c\u8fd9\u4e9b\u5185\u5bb9\u5728\u5176\u5b83\u6559\u6750\u4e2d\u5e76\u6ca1\u6709\u5168\u90e8\u51fa\u73b0\u3002</li> <li>**\u5168\u4e66\u91c7\u7528\uff0c\u5e76\u5c3d\u53ef\u80fd\u5730\u4f7f\u7528\u7edf\u4e00\u4e14\u4e00\u81f4\u7684\u7b26\u53f7\u4e0e\u672f\u8bed\uff1a**\u4f8b\u5982\uff0c\u672c\u4e66\u4e2d \\(r\\)r \u603b\u662f\u4ee3\u8868\u6570\u5b57\u8868\u793a\u7684\u57fa\u6570\uff08radix\uff09\uff0c\u6216\u8005\u5904\u7f5a\u548c\u5e73\u65b9\u6839\u4e2d\u7684\u4f59\u6570\u3002\u867d\u7136\u5176\u5b83\u4f5c\u8005\u5728\u4ed6\u4eec\u6587\u7ae0\u7684\u57fa\u672c\u90e8\u5206\u4e2d\u4e5f\u90fd\u57fa\u672c\u8fd9\u6837\u505a\u4e86\uff0c\u4f46\u8bb8\u591a\u4eba\u4ecd\u503e\u5411\u4e8e\u5728\u9ad8\u7ea7\u7814\u7a76\u4e3b\u9898\u4e2d\u7b80\u5355\u5730\u501f\u7528\u53c2\u8003\u8d44\u6599\u4e2d\u7684\u7b26\u53f7\u548c\u672f\u8bed\u3002\u8fd9\u79cd\u65b9\u6cd5\u7684\u597d\u5904\u662f\u4f7f\u5f97\u539f\u4e66\u548c\u53c2\u8003\u8d44\u6599\u95f4\u7684\u8fc7\u5ea6\u66f4\u5bb9\u6613\uff0c\u4f46\u5bf9\u5927\u591a\u6570\u5b66\u751f\u6765\u8bf4\uff0c\u8fd9\u5b8c\u5168\u662f\u4e00\u79cd\u8ff7\u60d1\uff0c\u4ed6\u4eec\u4f9d\u8d56\u539f\u4e66\uff0c\u9664\u975e\u5199\u8bba\u6587\uff0c\u5e76\u4e0d\u4f1a\u53bb\u53c2\u8003\u539f\u59cb\u53c2\u8003\u8d44\u6599\u3002</li> </ol>"},{"location":"Preface_1st/#_4","title":"\u4e3b\u9898\u6458\u8981","text":"<p>\u672c\u4e66\u5305\u62ec\u4e03\u4e2a\u90e8\u5206\u6bcf\u90e8\u5206\u7531\u56db\u7ae0\u7ec4\u6210\uff0c\u5b83\u4eec\u7684\u5199\u4f5c\u52a8\u673a\u5206\u522b\u5982\u4e0b\uff1a</p> <ol> <li>\u7b2c\u4e00\u90e8\u5206\uff1a\u63d0\u4f9b\u4e00\u4e2a\u53f0\u9636\uff0c\u4ee5\u8ba9\u6211\u4eec\u9886\u7565\u63a5\u4e0b\u6765\u7684\u5185\u5bb9\uff0c\u5e76\u8be6\u7ec6\u5730\u4ecb\u7ecd\u5b9a\u70b9\u6570\u7684\u5404\u79cd\u8868\u793a\u65b9\u6cd5\u3002\u5305\u62ec\u5bf9\u6709\u7b26\u53f7\u6570\u3001\u5197\u4f59\u6570\u8868\u793a\u3001\u5269\u4f59\u6570\u8868\u793a\u7684\u8be6\u7ec6\u8ba8\u8bba\u3002</li> <li>\u7b2c\u4e8c\u90e8\u5206\uff1a\u5305\u62ec\u52a0\u6cd5\u548c\u51cf\u6cd5\uff0c\u5b83\u4eec\u6784\u6210\u4e86\u6700\u57fa\u672c\u7684\u7b97\u672f\u6784\u5efa\uff0c\u5e38\u7528\u4e8e\u5b9e\u73b0\u5176\u5b83\u7b97\u672f\u8fd0\u7b97\u3002\u8ba8\u8bba\u5185\u5bb9\u5305\u62ec\u5e38\u6570\u7684\u52a0\u6cd5\uff08\u8ba1\u6570\u5668\uff09\uff0c\u9ad8\u901f\u52a0\u6cd5\u5668\u7684\u5404\u79cd\u8bbe\u8ba1\uff0c\u4ee5\u53ca\u591a\u64cd\u4f5c\u6570\u52a0\u6cd5\u5668\u3002</li> <li>\u7b2c\u4e09\u90e8\u5206\uff1a\u8fd9\u90e8\u5206\u4e13\u95e8\u8ba8\u8bba\u4e58\u6cd5\uff0c\u4ece\u57fa\u672c\u7684\u79fb\u4f4d/\u52a0\u6cd5\u7b97\u6cd5\u5f00\u59cb\uff0c\u5230\u9ad8\u57fa\u3001\u6811\u5f62\u3001\u9635\u5217\u3001\u4f4d\u4e32\u884c\u3001\u6a21\u4e58\u6cd5\u548c\u5176\u5b83\u5404\u79cd\u4e58\u6cd5\uff0c\u6b64\u5916\u8fd8\u8ba8\u8bba\u4e86\u5e73\u65b9\u8fd9\u79cd\u7279\u6b8a\u60c5\u51b5\u3002</li> <li>\u7b2c\u56db\u90e8\u5206\uff1a\u5305\u62ec\u9664\u6cd5\u7b97\u6cd5\u53ca\u5176\u786c\u4ef6\u5b9e\u73b0\uff0c\u4ece\u6700\u57fa\u672c\u7684\u79fb\u4f4d/\u51cf\u6cd5\u7b97\u6cd5\u5f00\u59cb\uff0c\u5230\u9ad8\u57fa\u3001\u9884\u7f29\u653e\u3001\u6a21\u9664\u6cd5\u3001\u9635\u5217\u3001\u6536\u655b\u9664\u6cd5\u3002</li> <li>\u7b2c\u4e94\u90e8\u5206\uff1a\u6d89\u53ca\u5b9e\u6570\u7b97\u672f\uff0c\u5305\u62ec\u8868\u793a\u5b9e\u6570\u7684\u5404\u79cd\u65b9\u6cd5\u3001\u6d6e\u70b9\u7b97\u672f\u3001\u8868\u793a\u4e0e\u8ba1\u7b97\u4e2d\u7684\u8bef\u5dee\uff0c\u4ee5\u53ca\u9ad8\u7cbe\u5ea6\u548c\u53ef\u9a8c\u8bc1\u7b97\u672f\u3002</li> <li>\u7b2c\u516d\u90e8\u5206\uff1a\u6d89\u53ca\u51fd\u6570\u6c42\u503c\uff0c\u4ece\u5e73\u65b9\u6839\u6c42\u503c\u5f00\u59cb\uff0c\u7136\u540e\u662fCORDIC\u7b97\u6cd5\uff0c\u63a5\u7740\u662f\u4e00\u822c\u7684\u6536\u655b\u548c\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u5305\u62ec\u57fa\u4e8e\u67e5\u627e\u8868\u7684\u65b9\u6cd5\u3002</li> <li>\u7b2c\u4e03\u90e8\u5206\uff1a\u5e7f\u6cdb\u5730\u8ba8\u8bba\u4e86\u8bbe\u8ba1\u548c\u5b9e\u73b0\u65b9\u9762\u7684\u4e3b\u9898\uff0c\u5305\u62ec\u6d41\u6c34\u7ebf\u3001\u4f4e\u529f\u8017\u548c\u5bb9\u9519\u7b97\u672f\u3002\u8fd9\u90e8\u5206\u7684\u6700\u540e\u4e00\u7ae0\u8fd8\u63d0\u4f9b\u4e86\u5386\u53f2\u89d2\u5ea6\u548c\u5b9e\u9645\u8ba1\u7b97\u673a\u4e2d\u7b97\u672f\u5355\u5143\u7684\u4f8b\u5b50\u3002</li> </ol>"},{"location":"Preface_1st/#_5","title":"\u672c\u4e66\u7684\u9605\u8bfb\u6307\u5357","text":"<p>\u5bf9\u4e8e\u6559\u5b66\u4f7f\u7528\uff0c\u672c\u4e66\u7684\u6bcf\u7ae0\u4e3b\u9898\u90fd\u53ef\u57281\uff5e2\u5c0f\u65f6\u7684\u8bb2\u5ea7\u4e2d\u6db5\u76d6\u3002\u5728\u4f5c\u8005\u81ea\u5df1\u7684\u6559\u5b66\u4e2d\uff0c\u6bcf\u7ae0\u5206\u522b\u88ab\u7528\u4e8e1.5\u5c0f\u65f6\u7684\u8bb2\u5ea7\uff0c\u6bcf\u54682\u6b21\uff0c\u4e3a\u671f10\u8f74\uff0c\u4e14\u7701\u7565\u6216\u5408\u5e76\u4e86\u90e8\u5206\u7ae0\u8282\uff0c\u4ee5\u4fbf\u5c06\u6750\u6599\u7eb3\u516518\uff5e20\u6b21\u8bb2\u5ea7\u3002\u4f46\u672c\u6587\u7684\u6a21\u5757\u5316\u7ed3\u6784\u4e5f\u9002\u7528\u4e8e\u5176\u5b83\u8bb2\u5ea7\u5f62\u5f0f\u3001\u81ea\u5b66\u6216\u4ece\u4e1a\u4eba\u5458\u5bf9\u8be5\u9886\u57df\u7684\u56de\u987e\u3002\u5728\u540e\u4e24\u79cd\u60c5\u51b5\uff0c\u8bfb\u8005\u53ef\u628a\u6bcf\u7ae0\u770b\u4f5c\u662f\u4e00\u4e2a\u5b66\u4e60\u5355\u5143\uff08\u6bd4\u5982\u4e00\u5468\uff09\uff0c\u800c\u4e0d\u662f\u4e00\u4e2a\u8bb2\u5ea7\u3002\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u8bfb\u8005\u8fdb\u5165\u4e0b\u4e00\u7ae0\u524d\uff0c\u6bcf\u7ae0\u7684\u6240\u6709\u4e3b\u9898\u90fd\u5e94\u88ab\u8986\u76d6\u3002\u5728\u6388\u8bfe\u65f6\u95f4\u8f83\u5c11\u7684\u60c5\u51b5\u4e0b\uff0c\u4e00\u4e9b\u4f4d\u4e8e\u7ae0\u8282\u672b\u5c3e\u7684\u5c0f\u8282\u53ef\u4ee5\u88ab\u7701\u7565\uff0c\u6216\u8005\u4ec5\u4ecb\u7ecd\u52a8\u673a\u4e0e\u5173\u952e\u7ed3\u679c\u3002</p> <p>\u6bcf\u7ae0\u90fd\u63d0\u4f9b\u4e86\u4e0d\u540c\u590d\u6742\u7a0b\u5ea6\u7684\u95ee\u9898\uff0c\u4ece\u7b80\u5355\u5730\u6570\u5b57\u4f8b\u5b50\u6216\u8054\u7cfb\u5230\u8981\u6c42\u66f4\u9ad8\u7684\u7814\u7a76\u6216\u5c0f\u578b\u9879\u76ee\u3002\u8fd9\u4e9b\u95ee\u9898\u662f\u672c\u4e66\u4e0d\u53ef\u5206\u5272\u7684\u4e00\u90e8\u5206\uff1a\u5b83\u4eec\u4e0d\u662f\u4e3a\u4e86\u4f7f\u672c\u4e66\u5728\u4f7f\u7528\u65f6\u66f4\u5177\u5438\u5f15\u529b\u800c\u4e8b\u540e\u6dfb\u52a0\u7684\u3002\u5168\u4e66\u5305\u62ec464\u4e2a\u95ee\u9898\uff08\u6bcf\u7ae015\uff5e18\u4e2a\uff09\u3002\u5047\u8bbe\u6bcf\u5468\u6709\u4e24\u6b21\u8bb2\u5ea7\uff0c\u5219\u53ef\u6bcf\u5468\u6216\u6bcf\u4e24\u5468\u5e03\u7f6e\u4e00\u6b21\u4f5c\u4e1a\uff0c\u6bcf\u6b21\u4f5c\u4e1a\u90fd\u4ee5\u76f8\u5e94\u7684\u4e00\u534a\uff082\u7ae0\uff09\u6216\u5168\u90e8\uff084\u7ae0\uff09\u90e8\u5206\u7684\u5177\u4f53\u5185\u5bb9\u4f5c\u4e3a\u6807\u9898\u3002</p> <p>\u8fd9\u91cc\u4e5f\u4e3a\u6559\u5e08\u63d0\u4f9b\u89e3\u7b54\u624b\u518c\u3002\u4f5c\u8005\u5728UCSB\u7684ECE 252B\u8bfe\u7a0b\u7684\u8be6\u7ec6\u6559\u5b66\u5927\u7eb2\u53ef\u5728\u4e0b\u7f51\u5740\u627e\u5230\uff1a</p> <p>http://www.ece.ucsb.edu/~parhami/ece_252b.htm</p> <p>\u4e00\u4e2a\u7528\u4e8e\u5bf9\u5404\u79cd\u7b97\u672f\u7b97\u6cd5\u8fdb\u884c\u6570\u503c\u5b9e\u9a8c\u7684\u6a21\u62df\u5668\u5219\u53ef\u5728\u4e0b\u7f51\u5740\u627e\u5230\uff1a</p> <p>http://www.ecs.umass.edu/ece/koren/arith/simulator/</p> <p>\u7531Israel Koren\u6559\u6388\u63d0\u4f9b\u3002</p> <p>\u6bcf\u7ae0\u672b\u5c3e\u90fd\u5217\u51fa\u4e86\u8ba1\u7b97\u673a\u7b97\u672f\u7684\u7ecf\u5178\u8bba\u6587\u3001\u5173\u952e\u8bbe\u8ba1\u601d\u60f3\u548c\u91cd\u8981\u7684\u6700\u65b0\u7814\u7a76\u8d21\u732e\u7684\u53c2\u8003\u6587\u732e\u3002\u8fd9\u4e9b\u53c2\u8003\u6587\u732e\u4e3a\u6df1\u5165\u7814\u7a76\u6216\u5b66\u671f\u8bba\u6587\u6216\u8005\u9879\u76ee\u63d0\u4f9b\u4e86\u826f\u597d\u7684\u4e03\u70b9\u3002\u5927\u91cf\u7684\u7ecf\u5178\u8bba\u6587\u548c\u8ba1\u7b97\u673a\u7b97\u672f\u4e2d\u7684\u91cd\u8981\u8d21\u732e\u5df2\u5728\u4e24\u5377\u4e2d\u91cd\u5370[Swar90]\u3002</p> <p>\u8ba1\u7b97\u673a\u7b97\u672f\u9886\u57df\u7684\u65b0\u60f3\u6cd5\u4f1a\u51fa\u73b0\u5728\u88ab\u79f0\u4e3a ARITH-n \u7684\u4f1a\u8bae\u4e2d\uff0c\u4e24\u5e74\u4e00\u6b21\uff0c\u5728\u5947\u6570\u5e74\u77e9\u5f62[ARIT]\u3002\u5176\u5b83\u4f1a\u8bae\u5305\u62ec\uff1a</p> <ul> <li>Asilomar Conference on Signals, Systems, and Computers [Asil]</li> <li>International Conference on Circuits and Systems [ICCS]</li> <li>Midwest Symposium on Circuits and Systems [MSCS]</li> <li>International Conference on Computer Design [ICCD]</li> </ul> <p>\u76f8\u5173\u671f\u520a\u5305\u62ecIEEE Transactions on Computers[TrCo]\uff0c\u7279\u522b\u662f\u5176\u4e2d\u6709\u5173\u8ba1\u7b97\u673a\u7b97\u672f\u7684\u671f\u520a\uff1a</p> <ul> <li>IEEE Transactions on Circuits and Systems[TrCS]</li> <li>Computers &amp; Mathematics with Applications[CoMa]</li> <li>IET Circuits, Devices &amp; Systems[CDS], IET Computers &amp; Digital Techniques[CDT]</li> <li>IEEE Transactions on VLSI Systems[TrVL]</li> <li>Journal of VLSI Signal Processing [JVSP]</li> </ul>"},{"location":"Preface_2nd/","title":"\u7b2c\u4e8c\u7248\u5e8f\u8a00","text":"<p>\u81ea\u300aCOMPUTER ARITHMETIC : Algorithms and Hardware Designs\u300b\u7b2c\u4e00\u7248\u51fa\u7248\u4ee5\u6765\uff0c\u5df2\u7ecf\u8fc7\u53bb\u4e86\u5341\u5e74\u3002\u5c3d\u7ba1\u8fc7\u53bb\u5341\u5e74\u7b97\u672f\u7b97\u6cd5\u548c\u5b9e\u73b0\u6280\u672f\u5728\u4e0d\u65ad\u5730\u8fdb\u6b65\uff0c\u4f46\u8be5\u4e66\u7684\u9876\u5c42\u8bbe\u8ba1\u4ecd\u7136\u5f88\u5408\u7406\u3002\u56e0\u6b64\u9664\u4e86\u5305\u62ec\u4e00\u4e2a\u6709\u5173\u53ef\u91cd\u6784\u7b97\u672f\u7684\u65b0\u7ae0\u8282\u5916\uff0c\u56feP.1\u4e2d\u63cf\u8ff0\u7684\u90e8\u5206\uff08Part\uff09\u548c\u7ae0\u8282\u5c06\u5728\u7b2c\u4e8c\u7248\u4fdd\u6301\u4e0d\u53d8\u3002\u65b0\u7684\u4e00\u7ae0\u53d6\u4ee3\u4e86\u539f\u5148\u7684\u7b2c28\u7ae0\uff0c\u5176\u539f\u5148\u5185\u5bb9\u88ab\u5b89\u6392\u5230\u4e86\u9644\u9875\u4e2d\u3002\u4f5c\u8005\u5c42\u8003\u8651\u6dfb\u52a0\u4e00\u4e2a\u9644\u5f55\uff0c\u4ee5\u5217\u51fa\u7f51\u7ad9\u548c\u5176\u5b83\u4e92\u8054\u7f51\u8d44\u6e90\uff0c\u4ee5\u4f9b\u8fdb\u4e00\u6b65\u5b66\u4e60\u3002\u4f46\u4e92\u8054\u7f51\u8d44\u6e90\u7684\u4f4d\u7f6e\u548c\u5185\u5bb9\u662f\u9ad8\u5ea6\u52a8\u6001\u7684\uff0c\u56e0\u6b64\u4f5c\u8005\u51b3\u5b9a\u5c06\u8fd9\u4e9b\u4fe1\u606f\u653e\u5728\u4f5c\u8005\u4e3a\u672c\u4e66\u5efa\u7acb\u7684\u914d\u5957\u7f51\u7ad9\u4e0a\uff0c\u53ef\u901a\u8fc7\u4ed6\u7684\u4e2a\u4eba\u7f51\u7ad9\u8bbf\u95ee\uff1a</p> <p>http://www.ece.ucsb.edu/~parhami/</p> <p>\u4e4b\u6240\u4ee5\u6dfb\u52a0\u6709\u5173\u53ef\u91cd\u6784\u7b97\u672f\u7684\u65b0\u7ae0\u8282\uff0c\u662f\u56e0\u4e3a\u73b0\u5728\u8d8a\u6765\u8d8a\u591a\u7684\u7b97\u672f\u529f\u80fd\u662f\u5728FPGA\u6216\u7c7bFPGA\u7684\u53ef\u914d\u7f6e\u903b\u8f91\u5668\u4ef6\u4e0a\u5b9e\u73b0\u7684\u3002\u8fd9\u7c7b\u65b9\u6cd5\u5bf9\u4e8e\u65b0\u8bbe\u8ba1\u7684\u539f\u578b\u5f00\u53d1\u3001\u5c0f\u6279\u91cf\u6216\u72ec\u4e00\u65e0\u4e8c\u7684\u7cfb\u7edf\uff0c\u6216\u8005\u9700\u8981\u5728\u73b0\u573a\u5347\u7ea7\u66f4\u65b0\uff0c\u5feb\u901f\u53d1\u5c55\u7684\u4ea7\u54c1\uff0c\u90fd\u662f\u975e\u5e38\u5177\u6709\u5438\u5f15\u529b\u7684\u3002\u56e0\u6b64\u63cf\u8ff0\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u88ab\u8ba4\u4e3a\u5408\u7406\u7684\u8bbe\u8ba1\u4ee5\u53ca\u8bbe\u8ba1\u7b56\u7565\u4e5f\u662f\u975e\u5e38\u6709\u7528\u7684\u3002\u65b0\u6750\u6599\u4e0e\u7b2c\u4e03\u90e8\u5206\u7684\u5176\u5b83\u4e09\u7ae0\u80fd\u5f88\u597d\u5730\u878d\u5408\u5728\u4e00\u8d77\uff0c\u6240\u6709\u7684\u8fd9\u4e9b\u90fd\u662f\u6709\u5173\u5b9e\u73b0\uff08implement\uff09\u7684\u4e3b\u9898\u3002\u65b0\u7684\u7b2c28\u7ae0\u6d89\u53ca\u7684\u4f8b\u5b50\u5305\u62ec\u57fa\u4e8e\u67e5\u627e\u8868\u7684\u51fd\u6570\u6c42\u503c\uff0c\u4ee5\u53caFPGA\u4e0a\u7684\u51e0\u4e2a\u52a0\u6cd5\u5668\u548c\u4e58\u6cd5\u5668\u8bbe\u8ba1\u3002</p> <p>\u7b2c\u4e8c\u7248\u4e5f\u8fdb\u884c\u4e86\u4e00\u4e9b\u6269\u5145\u3001\u6539\u8fdb\u3001\u6f84\u6e05\u548c\u66f4\u6b63\u3002\u8bb8\u591a\u8282\u90fd\u65b0\u589e\u4e86\u6750\u6599\uff0c\u4ee5\u53cd\u6620\u65b0\u7684\u60f3\u6cd5\u4e0e\u53d1\u5c55\u3002\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\uff0c\u65e7\u7684\u5c0f\u7ed3\u88ab\u5408\u5e76\uff0c\u5e76\u4e3a\u65b0\u7684\u60f3\u6cd5\u6216\u8bbe\u8ba1\u521b\u5efa\u4e86\u65b0\u7684\u5c0f\u8282\u3002\u5728\u7b2c\u4e8c\u7248\u4e2d\uff0c\u65b0\u7684\u5408\u6269\u5145\u7684\u4e3b\u9898\u4ee5\u7ae0\u8282\u4f4d\u957f\u5ea6\u8fdb\u884c\u4e86\u5904\u7406\uff0c\u5305\u62ec\u4ee5\u4e0b\u5185\u5bb9\uff08\u62ec\u53f7\u5185\u4e3a\u7ae0\u8282\u7f16\u53f7\uff09\uff1a</p> <ul> <li>\u6a21\u4e8c\u64cd\u4f5c\u6570\u548c\u591a\u64cd\u4f5c\u6570\u52a0\u6cd5\u5668\uff087.6, 8.6\uff09</li> <li>\u622a\u65ad\u6811\u548c\u9635\u5217\u4e58\u6cd5\u5668\uff0811.4\uff09</li> <li>\u91cd\u53e0\u5546\u4f4d\u9009\u62e9\uff0815.2\uff09</li> <li>\u8499\u54e5\u9a6c\u5229\u6a21\u4e58\u6cd5/\u7ea6\u5316\uff0815.4\uff09</li> <li>\u4f5c\u4e3a\u9664\u6cd5\u7279\u6b8a\u60c5\u51b5\u7684\u5012\u6570\uff0815.5\uff09</li> <li>\u6d6e\u70b9FMA\u5355\u5143\uff08fused-multiply-add\uff09\uff0818.5\uff09</li> <li>\u533a\u95f4\u7b97\u6570\uff0c\u5305\u62ec\u533a\u95f4\u725b\u987f\u8fed\u4ee3\u6cd5\uff0820.6\uff09</li> <li>bipartite table\u548cmultipartie table\u65b9\u6cd5\uff0824.6\uff09</li> </ul> <p>\u6b64\u5916\u8fd8\u5f15\u5165\u4e86\u65b0\u7684\u7ae0\u672b\u95ee\u9898\uff0c\u4f7f\u5f97\u95ee\u9898\u7684\u603b\u6570\u8fbe\u5230\u4e86718\u4e2a\u3002\u4f5c\u8005\u6ca1\u5728\u8fd9\u7bc7\u5e8f\u8a00\u4e2d\u52a0\u5165\u65b0\u7684\u4e00\u822c\u53c2\u8003\u8d44\u6599\uff0c\u800c\u662f\u8c8c\u7f8e\u5730\u66f4\u65b0\u548c\u62d3\u5c55\u4e86\u7b2c\u4e00\u7248\u5e8f\u8a00\u672b\u5c3e\u7684\u53c2\u8003\u8d44\u6599\u6e05\u5355\uff0c\u4ee5\u4fbf\u63d0\u4f9b\u4e00\u4e2a\u5355\u4e00\u7684\u7efc\u5408\u6e05\u5355\u3002</p> <p>\u4e00\u5982\u65e2\u5f80\uff0c\u4f5c\u8005\u6b22\u8fce\u5927\u5bb6\u5c31\u53d1\u73b0\u7684\u9519\u8bef\u3001\u9700\u8fdb\u4e00\u6b65\u6f84\u6e05\u7684\u4e3b\u9898\u3001\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6848\u4ee5\u53ca\u5173\u4e8e\u65b0\u4e3b\u9898\u6216\u7ec3\u4e60\u7684\u60f3\u6cd5\u8fdb\u884c\u4ea4\u6d41</p> <p>Behrooz Parhami</p> <p>August 2009, Santa Barbara, CA</p>"},{"location":"translation/","title":"\u4f5c\u8005\u7f51\u7ad9","text":"<p>https://web.ece.ucsb.edu/~parhami/text_comp_arit.htm</p> <p>https://web.ece.ucsb.edu/~parhami/ece_252b.htm</p>"},{"location":"Part_01/","title":"\u6570\u5b57\u7684\u8868\u793a\u65b9\u6cd5","text":"<p>NUMBER REPRESENTATION</p> <p>\u201cMathematics, like the Nile, begins in minuteness, but ends in magnificence.\u201d    \u2014 CHARLES CALEB COLTON</p> <p>\u201c\u6570\u5b66\u5c31\u50cf\u5c3c\u7f57\u6cb3\u4e00\u6837\uff0c\u59cb\u4e8e\u5fae\u5c0f\uff0c\u7ec8\u4e8e\u4f1f\u5927\u3002\u201d  \u2014 \u67e5\u5c14\u65af\u00b7\u5361\u83b1\u00b7\u4f2f\u00b7\u79d1\u5c14\u987f</p> <p>\u201cOf all the great things that are found among us the existence of nothing is the greatest.\u201d \u2014 LEONARDO DAVINCI</p> <p>\u201c\u5728\u6211\u4eec\u53d1\u73b0\u7684\u4f1f\u5927\u4e8b\u7269\u4e2d\uff0c\u201c\u65e0\u201d\u7684\u5b58\u5728\u662f\u6700\u4f1f\u5927\u7684\u3002\u201d  \u2014 \u83b1\u6602\u7eb3\u591a\u00b7\u8fbe\u82ac\u5947</p> <p>NUMBER REPRESENTATION IS ARGUABLY THE MOST  IMPORTANT TOPIC IN COMPUTER arithmetic. In justifying this claim, it suffices to note that several important classes of number representations were discovered, or rescued from obscurity, by computer designers in their quest for simpler and faster circuits. Furthermore, the choice of number representation affects the implementation cost and delay of all arithmetic operations. We thus begin our study of computer arithmetic by reviewing conventional and exotic representation methods for integers. Conventional methods are of course used extensively. Some of the unconventional methods have been applied to special-purpose digital systems or in the intermediate steps of arithmetic hardware implementations where they are often invisible to computer users. This part consists of the following four chapters:</p> <p>\u6570\u5b57\u8868\u793a\u53ef\u4ee5\u8bf4\u662f\u8ba1\u7b97\u673a\u7b97\u672f\u4e2d\u6700\u91cd\u8981\u7684\u4e3b\u9898\u3002 \u4e3a\u4e86\u8bc1\u660e\u8fd9\u4e00\u8bf4\u6cd5\u7684\u5408\u7406\u6027\uff0c\u53ea\u9700\u6307\u51fa\u51e0\u7c7b\u91cd\u8981\u7684\u6570\u5b57\u8868\u793a\u5f62\u5f0f\u662f\u7531\u8ba1\u7b97\u673a\u8bbe\u8ba1\u8005\u5728\u5bfb\u6c42\u66f4\u7b80\u5355\u548c\u66f4\u5feb\u7684\u7535\u8def\u65f6\u53d1\u73b0\u7684\u6216\u4ece\u9ed8\u9ed8\u65e0\u95fb\u4e2d\u62ef\u6551\u51fa\u6765\u7684\u3002 \u6b64\u5916\uff0c\u6570\u5b57\u8868\u793a\u7684\u9009\u62e9\u4f1a\u5f71\u54cd\u6240\u6709\u7b97\u672f\u8fd0\u7b97\u7684\u5b9e\u73b0\u6210\u672c\u548c\u5ef6\u8fdf\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u901a\u8fc7\u56de\u987e\u6574\u6570\u7684\u4f20\u7edf\u548c\u5947\u5f02\u8868\u793a\u65b9\u6cd5\u6765\u5f00\u59cb\u8ba1\u7b97\u673a\u7b97\u672f\u7684\u7814\u7a76\u3002 \u4f20\u7edf\u65b9\u6cd5\u5f53\u7136\u88ab\u5e7f\u6cdb\u4f7f\u7528\u3002 \u4e00\u4e9b\u975e\u5e38\u89c4\u65b9\u6cd5\u5df2\u5e94\u7528\u4e8e\u4e13\u7528\u6570\u5b57\u7cfb\u7edf\u6216\u7b97\u672f\u786c\u4ef6\u5b9e\u73b0\u7684\u4e2d\u95f4\u6b65\u9aa4\uff0c\u5176\u4e2d\u5b83\u4eec\u901a\u5e38\u5bf9\u8ba1\u7b97\u673a\u7528\u6237\u6765\u8bf4\u662f\u4e0d\u53ef\u89c1\u7684\u3002 \u672c\u90e8\u5206\u7531\u4ee5\u4e0b\u56db\u7ae0\u7ec4\u6210\uff1a</p> <ul> <li>\u7b2c\u4e00\u7ae0 \u6570\u5b57\u4e0e\u7b97\u672f Numbers and Arithmetic</li> <li>\u7b2c\u4e8c\u7ae0 \u6709\u7b26\u53f7\u6570\u7684\u8868\u793a Representing Signed Numbers</li> <li>\u7b2c\u4e09\u7ae0 \u5197\u4f59\u6570\u7cfb\u7edf Redundant Number Systems</li> <li>\u7b2c\u56db\u7ae0 \u5269\u4f59\u6570\u7cfb\u7edf Residue Number Systems</li> </ul>"},{"location":"Part_01/01/","title":"1. \u6570\u5b57\u4e0e\u7b97\u672f","text":"<p>Numbers and Arithmetic</p> <p>\u201cMathematics is the queen of the sciences and arithmetic is the queen of mathematics.\u201d </p> <p>\u200b                                                                                                       CARL FRIEDRICH GAUSS</p> <p>\u201c\u6570\u5b66\u662f\u79d1\u5b66\u7684\u5973\u738b\uff0c\u7b97\u672f\u662f\u6570\u5b66\u7684\u5973\u738b\u3002\u201d</p> <p>\u200b                                  \u5361\u5c14\u00b7\u5f17\u91cc\u5fb7\u91cc\u5e0c\u00b7\u9ad8\u65af</p> <p>This chapter motivates the reader, sets the context in which the material in the rest of the book is presented, and reviews positional representations of fixed-point numbers. The chapter ends with a review of methods for number radix conversion and a preview of other number representation methods to be covered. </p> <p>\u672c\u7ae0\u65e8\u5728\u6fc0\u53d1\u8bfb\u8005\u7684\u5174\u8da3\uff0c\u8bbe\u7f6e\u672c\u4e66\u5176\u4f59\u90e8\u5206\u7684\u6750\u6599\u5448\u73b0\u7684\u80cc\u666f\uff0c\u5e76\u56de\u987e\u5b9a\u70b9\u6570\u7684\u4f4d\u7f6e\u8868\u793a\u3002\u672c\u7ae0\u6700\u540e\u56de\u987e\u4e86\u4e0d\u540c\u57fa\u6570\u8f6c\u6362\u7684\u65b9\u6cd5\u548c\u5176\u4ed6\u6570\u5b57\u8868\u793a\u65b9\u6cd5\u7684\u9884\u89c8\u3002</p> <p>Chapter topics include: \u7ae0\u8282\u4e3b\u9898\u5305\u62ec\uff1a</p> <p>1.1 \u4ec0\u4e48\u662f\u8ba1\u7b97\u673a\u7b97\u672f WHAT IS COMPUTER ARITHMETIC</p> <p>1.2 \u542f\u53d1\u6027\u793a\u4f8b MOTIVATING EXAMPLES</p> <p>1.3 \u6570\u5b57\u53ca\u5176\u7f16\u7801 NUMBERS AND THEIR ENCODINGS</p> <p>1.4 \u56fa\u5b9a\u57fa\u6570\u7684\u4f4d\u7f6e\u6570\u5b57\u8868\u793a\u7cfb\u7edf FIXED RADIX POSITIONAL NUMBER SYSTEMS</p> <p>1.5 \u6570\u5b57\u57fa\u6570\u8f6c\u6362 NUMBER RADIX CONVERSION</p> <p>1.6 \u6570\u8868\u793a\u7cfb\u7edf\u7684\u5206\u7c7b CLASSES OF NUMBER REPRESENTATIONS</p>"},{"location":"Part_01/01/#11","title":"1.1 \u4ec0\u4e48\u662f\u8ba1\u7b97\u673a\u7b97\u672f\uff1f","text":"<p>A sequence of events, begun in late 1994 and extending into 1995, embarrassed the world\u2019s largest computer chip manufacturer and put the normally dry subject of computer arithmetic on the front pages of major newspapers. The events were rooted in the work of Thomas Nicely, a mathematician at the Lynchburg College in Virginia, who was interested in twin primes (consecutive odd numbers such as 29 and 31 that are both prime). Nicely\u2019s work involved the distribution of twin primes and, particularly, the sum of their reciprocals  S = 1 / 5 + 1 / 7 + 1 / 11 + 1 / 13 + 1 / 17 + 1 / 19 + 1 / 29 + 1 / 31 +  \u00b7 \u00b7 \u00b7 + 1 /p + 1 /(p + 2 ) + \u00b7 \u00b7 \u00b7 .  While it is known that the infinite sum  S  has a finite value, no one knows what the value is. </p> <p>\u4ece 1994 \u5e74\u5e95\u5f00\u59cb\u4e00\u76f4\u6301\u7eed\u5230 1995 \u5e74\u7684\u4e00\u7cfb\u5217\u4e8b\u4ef6\u8ba9\u4e16\u754c\u4e0a\u6700\u5927\u7684\u8ba1\u7b97\u673a\u82af\u7247\u5236\u9020\u5546\u9677\u5165\u5c34\u5c2c\u5883\u5730\uff0c\u5e76\u5c06\u901a\u5e38\u67af\u71e5\u7684\u8ba1\u7b97\u673a\u7b97\u672f\u4e3b\u9898\u767b\u4e0a\u4e86\u5404\u5927\u62a5\u7eb8\u7684\u5934\u7248\u3002\u8fd9\u4e9b\u4e8b\u4ef6\u6e90\u4e8e\u5f17\u5409\u5c3c\u4e9a\u6797\u5947\u5821\u5b66\u9662\u6570\u5b66\u5bb6\u6258\u9a6c\u65af\u00b7\u5c3c\u65af\u5229 (Thomas Nicely) \u7684\u5de5\u4f5c\uff0c\u4ed6\u5bf9\u5b6a\u751f\u7d20\u6570\uff08\u8fde\u7eed\u5947\u6570\uff0c\u4f8b\u5982 29 \u548c 31 \u90fd\u662f\u7d20\u6570\uff09\u5f88\u611f\u5174\u8da3\u3002 Nicely \u7684\u5de5\u4f5c\u6d89\u53ca\u5b6a\u751f\u7d20\u6570\u7684\u5206\u5e03\uff0c\u7279\u522b\u662f\u5b83\u4eec\u7684\u5012\u6570\u4e4b\u548c S = 1 / 5 + 1 / 7 + 1 / 11 + 1 / 13 + 1 / 17 + 1 / 19 + 1 / 29 + 1 / 31 +\u00b7  \u00b7 \u00b7 + 1 /p + 1 /(p + 2 ) + \u00b7 \u00b7 \u00b7 \u3002\u867d\u7136\u5df2\u77e5\u65e0\u9650\u548c S \u662f\u4e00\u4e2a\u6709\u9650\u503c\uff0c\u4f46\u6ca1\u6709\u4eba\u77e5\u9053\u8be5\u503c\u662f\u591a\u5c11\u3002</p> <p>Nicely was using several different computers for his work and in March 1994 added a machine based on the Intel Pentium processor to his collection. Soon he began noticing inconsistencies in his calculations and was able to trace them back to the values computed for \\(1/p\\) and \\(1/(p + 2 )\\) on the Pentium processor. At first, he suspected his own programs, the compiler, and the operating system, but by October, he became convinced that the Intel Pentium chip was at fault. This suspicion was confirmed by several other researchers following a barrage of e-mail exchanges and postings on the Internet.</p> <p>Nicely \u5728\u5de5\u4f5c\u4e2d\u4f7f\u7528\u4e86\u51e0\u53f0\u4e0d\u540c\u7684\u8ba1\u7b97\u673a\uff0c\u5e76\u4e8e 1994 \u5e74 3 \u6708\u5728\u4ed6\u7684\u6536\u85cf\u4e2d\u6dfb\u52a0\u4e86\u4e00\u53f0\u57fa\u4e8e Intel Pentium \u5904\u7406\u5668\u7684\u8ba1\u7b97\u673a\u3002\u5f88\u5feb\u4ed6\u5f00\u59cb\u6ce8\u610f\u5230 \u8ba1\u7b97\u4e2d\u7684\u4e0d\u4e00\u81f4\u4e4b\u5904\uff0c\u5e76\u80fd\u591f\u5c06\u5176\u8ffd\u6eaf\u5230\u5954\u817e\u5904\u7406\u5668\u4e0a\u4e3a \\(1/p\\) \u548c \\(1/(p + 2 )\\) \u8ba1\u7b97\u7684\u503c\u3002\u8d77\u521d\uff0c\u4ed6\u6000\u7591\u81ea\u5df1\u7684\u7a0b\u5e8f\u3001\u7f16\u8bd1\u5668\u548c\u64cd\u4f5c\u7cfb\u7edf\uff0c\u4f46\u5230\u4e86\u5341\u6708\u4efd\uff0c\u4ed6\u786e\u4fe1\u82f1\u7279\u5c14\u5954\u817e\u82af\u7247\u51fa\u4e86\u95ee\u9898\u3002\u7ecf\u8fc7\u4e00\u7cfb\u5217\u7535\u5b50\u90ae\u4ef6\u4ea4\u6d41\u548c\u4e92\u8054\u7f51\u4e0a\u7684\u53d1\u5e16\u540e\uff0c\u5176\u4ed6\u51e0\u4f4d\u7814\u7a76\u4eba\u5458\u8bc1\u5b9e\u4e86\u8fd9\u4e00\u6000\u7591\u3002</p> <p>The diagnosis finally came from Tim Coe, an engineer at Vitesse Semiconductor. Coe built a model of Pentium\u2019s floating-point division hardware based on the radix-4 SRT (named for Sweeny, Robertson, and Tocher) algorithm and came up with an example that produces the worst-case error. Using double-precision floating-point computation, the ratio  c = 4 195 835 / 3 145 727 = 1.333 820 44 \u00b7 \u00b7 \u00b7 was computed as 1.333 739 06 on the Pentium. This latter result is accurate to only 14 bits; the error is even larger than that of single-precision floating-point and more than 10 orders of magnitude worse than what is expected of double-precision computation [Mole95]. </p> <p>\u6700\u7ec8\u8bca\u65ad\u6765\u81eaVitesse Semiconductor \u7684\u5de5\u7a0b\u5e08Tim Coe\u3002 Coe \u57fa\u4e8e radix-4 SRT\uff08\u4ee5 Sweeny\u3001Robertson \u548c Tocher \u547d\u540d\uff09\u7b97\u6cd5\u6784\u5efa\u4e86 Pentium \u6d6e\u70b9\u9664\u6cd5\u786c\u4ef6\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ea7\u751f\u6700\u574f\u60c5\u51b5\u9519\u8bef\u7684\u793a\u4f8b\u3002\u4f7f\u7528\u53cc\u7cbe\u5ea6\u6d6e\u70b9\u8ba1\u7b97\uff0c\u6bd4\u7387 c = 4 195 835 / 3 145 727 = 1.333 820 44 \u00b7 \u00b7 \u00b7 \u5728\u5954\u817eCPU\u4e0a\u8ba1\u7b97\u4e3a 1.333 739 06\u3002\u540e\u4e00\u4e2a\u7ed3\u679c\u4ec5\u7cbe\u786e\u5230 14 \u6bd4\u7279\uff1b\u8be5\u8bef\u5dee\u751a\u81f3\u6bd4\u5355\u7cbe\u5ea6\u6d6e\u70b9\u7684\u8bef\u5dee\u8fd8\u8981\u5927\uff0c\u5e76\u4e14\u6bd4\u53cc\u7cbe\u5ea6\u8ba1\u7b97\u7684\u9884\u671f\u8bef\u5dee\u8fd8\u8981\u5dee 10 \u4e2a\u6570\u91cf\u7ea7\u4ee5\u4e0a [Mole95]\u3002</p> <p>The rest, as they say, is history. Intel at first dismissed the severity of the problem and admitted only a \u201csubtle flaw,\u201d with a probability of 1 in 9 billion, or once in 27,000 years for the average spreadsheet user, of leading to computational errors. It nevertheless published a \u201cwhite paper\u201d that described the bug and its potential consequences and announced a replacement policy for the defective chips based on \u201ccustomer need\u201d; that is, customers had to show that they were doing a lot of mathematical calculations to get a free replacement. Under heavy criticism from customers, manufacturers using the Pentium chip in their products, and the on-line community, Intel later revised its policy to no-questions-asked replacement. </p> <p>\u5176\u4f59\u7684\uff0c\u6b63\u5982\u4ed6\u4eec\u6240\u8bf4\uff0c\u662f\u5386\u53f2\u3002\u82f1\u7279\u5c14\u8d77\u521d\u5426\u8ba4\u4e86\u95ee\u9898\u7684\u4e25\u91cd\u6027\uff0c\u53ea\u627f\u8ba4\u5b58\u5728\u4e00\u4e2a\u201c\u5fae\u5999\u7684\u7f3a\u9677\u201d\uff0c\u5bfc\u81f4\u8ba1\u7b97\u9519\u8bef\u7684\u6982\u7387\u4e3a 90 \u4ebf\u5206\u4e4b\u4e00\uff0c\u6216\u8005\u5bf9\u4e8e\u666e\u901a\u7535\u5b50\u8868\u683c\u7528\u6237\u6765\u8bf4\u6bcf 27,000 \u5e74\u4e00\u6b21\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u5b83\u8fd8\u662f\u53d1\u5e03\u4e86\u4e00\u4efd\u201c\u767d\u76ae\u4e66\u201d\uff0c\u63cf\u8ff0\u4e86\u8be5\u6f0f\u6d1e\u53ca\u5176\u6f5c\u5728\u540e\u679c\uff0c\u5e76\u5ba3\u5e03\u4e86\u57fa\u4e8e\u201c\u5ba2\u6237\u9700\u6c42\u201d\u7684\u7f3a\u9677\u82af\u7247\u7684\u66f4\u6362\u653f\u7b56\uff1b\u4e5f\u5c31\u662f\u8bf4\uff0c\u5ba2\u6237\u5fc5\u987b\u8bc1\u660e\u4ed6\u4eec\u8fdb\u884c\u4e86\u5927\u91cf\u7684\u6570\u5b66\u8ba1\u7b97\u624d\u80fd\u83b7\u5f97\u514d\u8d39\u66f4\u6362\u3002\u5728\u5ba2\u6237\u3001\u4ea7\u54c1\u4e2d\u4f7f\u7528\u5954\u817e\u82af\u7247\u7684\u5236\u9020\u5546\u4ee5\u53ca\u5728\u7ebf\u793e\u533a\u7684\u4e25\u5389\u6279\u8bc4\u4e0b\uff0c\u82f1\u7279\u5c14\u540e\u6765\u5c06\u5176\u653f\u7b56\u4fee\u6539\u4e3a\u65e0\u6761\u4ef6\u66f4\u6362\u3002</p> <p>Whereas supercomputing, microchips, computer networks, advanced applications (particularly game-playing programs), and many other aspects of computer technology have made the news regularly, the Intel Pentium bug was the first instance of arithmetic (or anything inside the CPU for that matter) becoming front-page news. While this can be interpreted as a sign of pedantic dryness, it is more likely an indicator of stunning technological success. Glaring software failures have come to be routine events in our information-based society, but hardware bugs are rare and newsworthy. </p> <p>\u800c\u8d85\u7ea7\u8ba1\u7b97\u3001\u5fae\u82af\u7247\u3001\u8ba1\u7b97\u673a\u7f51\u7edc\u3001\u9ad8\u7ea7\u5e94\u7528\uff08\u7279\u522b\u662f\u6e38\u620f\u7a0b\u5e8f\uff09\u4ee5\u53ca\u8ba1\u7b97\u673a\u6280\u672f\u7684\u8bb8\u591a\u5176\u4ed6\u65b9\u9762\u90fd\u7ecf\u5e38\u6210\u4e3a\u65b0\u95fb\uff0c\u82f1\u7279\u5c14\u5954\u817e bug \u662f\u7b97\u672f\uff08\u6216 CPU \u5185\u90e8\u7684\u4efb\u4f55\u76f8\u5173\u4e8b\u7269\uff09\u6210\u4e3a\u5934\u7248\u65b0\u95fb\u7684\u7b2c\u4e00\u4e2a\u5b9e\u4f8b\u3002\u867d\u7136\u8fd9\u53ef\u4ee5\u88ab\u89e3\u91ca\u4e3a\u8fc2\u8150\u67af\u71e5\u7684\u8868\u73b0\uff0c\u4f46\u5b83\u66f4\u53ef\u80fd\u662f\u4ee4\u4eba\u60ca\u53f9\u7684\u6280\u672f\u6210\u529f\u7684\u6307\u6807\u3002\u5728\u6211\u4eec\u7684\u4fe1\u606f\u793e\u4f1a\u4e2d\uff0c\u660e\u663e\u7684\u8f6f\u4ef6\u6545\u969c\u5df2\u6210\u4e3a\u5bb6\u5e38\u4fbf\u996d\uff0c\u4f46\u786c\u4ef6\u9519\u8bef\u5374\u5f88\u5c11\u89c1\u4e14\u5177\u6709\u65b0\u95fb\u4ef7\u503c\u3002</p> <p>Having read the foregoing account, you may wonder what the radix-4 SRT division algorithm is and how it can lead to such problems. Well, that\u2019s the whole point of this introduction! You need computer arithmetic to understand the rest of the story. Computer arithmetic is a subfield of digital computer organization. It deals with the hardware realization of arithmetic functions to support various computer architectures as well as with arithmetic algorithms for firmware or software implementation. A major thrust of digital computer arithmetic is the design of hardware algorithms and circuits to enhance the speed of numeric operations. Thus much of what is presented here complements the  architectural  and  algorithmic  speedup techniques studied in the context of high-performance computer architecture and parallel processing. </p> <p>\u8bfb\u5b8c\u4e0a\u9762\u7684\u5185\u5bb9\uff0c\u4f60\u53ef\u80fd\u60f3\u77e5\u9053radix-4 SRT\u9664\u6cd5\u7b97\u6cd5\u662f\u4ec0\u4e48\u4ee5\u53ca\u5b83\u662f\u5982\u4f55\u5bfc\u81f4\u6b64\u7c7b\u95ee\u9898\u7684\u3002\u597d\u4e86\uff0c\u8fd9\u5c31\u662f\u672c\u6b21\u4ecb\u7ecd\u7684\u91cd\u70b9\uff01\u4f60\u9700\u8981\u8ba1\u7b97\u673a\u7b97\u672f\u6765\u7406\u89e3\u6545\u4e8b\u7684\u5176\u4f59\u90e8\u5206\u3002\u8ba1\u7b97\u673a\u7b97\u672f\u662f\u6570\u5b57\u8ba1\u7b97\u673a\u7ec4\u7ec7\u7684\u4e00\u4e2a\u5b50\u9886\u57df\u3002\u5b83\u6d89\u53ca\u7b97\u672f\u51fd\u6570\u7684\u786c\u4ef6\u5b9e\u73b0\u4ee5\u652f\u6301\u5404\u79cd\u8ba1\u7b97\u673a\u4f53\u7cfb\u7ed3\u6784\u4ee5\u53ca\u7528\u4e8e\u56fa\u4ef6\u6216\u8f6f\u4ef6\u5b9e\u73b0\u7684\u7b97\u672f\u7b97\u6cd5\u3002\u6570\u5b57\u8ba1\u7b97\u673a\u7b97\u672f\u7684\u4e00\u4e2a\u4e3b\u8981\u63a8\u52a8\u529b\u662f\u786c\u4ef6\u7b97\u6cd5\u548c\u7535\u8def\u7684\u8bbe\u8ba1\uff0c\u4ee5\u63d0\u9ad8\u6570\u5b57\u8fd0\u7b97\u7684\u901f\u5ea6\u3002\u56e0\u6b64\uff0c\u8fd9\u91cc\u4ecb\u7ecd\u7684\u5927\u90e8\u5206\u5185\u5bb9\u8865\u5145\u4e86\u5728\u9ad8\u6027\u80fd\u8ba1\u7b97\u673a\u4f53\u7cfb\u7ed3\u6784\u548c\u5e76\u884c\u5904\u7406\u7684\u80cc\u666f\u4e0b\u7814\u7a76\u7684\u4f53\u7cfb\u7ed3\u6784\u548c\u7b97\u6cd5\u52a0\u901f\u6280\u672f\u3002</p> <p>Much of our discussion relates to the design of top-of-the-line CPUs with high-performance parallel arithmetic circuits. However, we will at times also deal with slow bit-serial designs for embedded applications, where implementation cost and input/output pin limitations are of prime concern. It would be a mistake, though, to conclude that computer arithmetic is useful only to computer designers. We will see shortly that you can use scientific calculators more effectively and write programs that are more accurate and/or more efficient after a study of computer arithmetic. You will be able to render informed judgment when faced with the problem of choosing a digital signal processor chip for your project. And, of course, you will know what exactly went wrong in the Pentium. </p> <p>\u6211\u4eec\u7684\u5927\u90e8\u5206\u8ba8\u8bba\u90fd\u4e0e\u5177\u6709\u9ad8\u6027\u80fd\u5e76\u884c\u8fd0\u7b97\u7535\u8def\u7684\u9876\u7ea7 CPU \u7684\u8bbe\u8ba1\u6709\u5173\u3002\u7136\u800c\uff0c\u6211\u4eec\u6709\u65f6\u4e5f\u4f1a\u5904\u7406\u5d4c\u5165\u5f0f\u5e94\u7528\u7684\u6162\u901f\u4f4d\u4e32\u884c\u8bbe\u8ba1\uff0c\u5176\u4e2d\u5b9e\u73b0\u6210\u672c\u548c\u8f93\u5165/\u8f93\u51fa\u5f15\u811a\u9650\u5236\u662f\u9996\u8981\u8003\u8651\u7684\u95ee\u9898\u3002\u7136\u800c\uff0c\u5982\u679c\u8ba4\u4e3a\u8ba1\u7b97\u673a\u7b97\u672f\u53ea\u5bf9\u8ba1\u7b97\u673a\u8bbe\u8ba1\u8005\u6709\u7528\uff0c\u90a3\u5c31\u9519\u4e86\u3002\u6211\u4eec\u5f88\u5feb\u5c31\u4f1a\u770b\u5230\uff0c\u5728\u5b66\u4e60\u8ba1\u7b97\u673a\u7b97\u672f\u4e4b\u540e\uff0c\u60a8\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u4f7f\u7528\u79d1\u5b66\u8ba1\u7b97\u5668\u5e76\u7f16\u5199\u66f4\u51c6\u786e\u548c/\u6216\u66f4\u9ad8\u6548\u7684\u7a0b\u5e8f\u3002\u4f60\u4f1a\u5f53\u9762\u4e34\u4e3a\u60a8\u7684\u9879\u76ee\u9009\u62e9\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u5668\u82af\u7247\u7684\u95ee\u9898\u65f6\uff0c\u80fd\u591f\u505a\u51fa\u660e\u667a\u7684\u5224\u65ad\u3002\u5f53\u7136\uff0c\u60a8\u4e5f\u4f1a\u77e5\u9053\u5954\u817e\u5230\u5e95\u51fa\u4e86\u4ec0\u4e48\u95ee\u9898\u3002</p> <p></p> \u786c\u4ef6\uff08\u672c\u4e66\u7684\u91cd\u70b9\uff09 \u8f6f\u4ef6 \u4e3a\u57fa\u7840\u7b97\u672f\u548c\u5176\u4ed6\u8fd0\u7b97\u8bbe\u8ba1\u9ad8\u6548\u7684\u6570\u5b57\u7535\u8def \u5982 + \u3001 \u2212 \u3001 \u00d7 \u3001 \u00f7 \u3001\u5bf9\u6570\u3001\u6b63\u5f26\u548c\u4f59\u5f26\u3002 \u6570\u503c\u65b9\u6cd5\u6c42\u89e3\u7ebf\u6027\u65b9\u7a0b\u7ec4\uff0c\u504f\u5fae\u5206\u65b9\u7a0b\u7b49 \u95ee\u9898\uff1a \u7b97\u6cd5 \u9519\u8bef\u5206\u6790 \u901f\u5ea6/\u6210\u672c\u6743\u8861 \u786c\u4ef6\u5b9e\u73b0 \u6d4b\u8bd5\u3001\u9a8c\u8bc1 \u95ee\u9898\uff1a\u7b97\u6cd5  \u9519\u8bef\u5206\u6790 \u8ba1\u7b97\u590d\u6742\u5ea6 \u7f16\u7a0b \u6d4b\u8bd5\u3001\u9a8c\u8bc1 \u4e00\u822c\u7528\u9014 \u7279\u6b8a\u76ee\u7684\u7528\u9014 \u7075\u6d3b\u7684\u6570\u636e\u8def\u5f84 \u9002\u5408\u5e94\u7528\u9886\u57df\uff0c\u4f8b\u5982\u6570\u5b57\u6ee4\u6ce2 \u5feb\u901f\u539f\u59cb\u64cd\u4f5c\uff0c\u4f8b\u5982 + , \u2212 , \u00d7 , \u00f7 \u56fe\u50cf\u5904\u7406 \u57fa\u51c6\u6d4b\u8bd5 \u96f7\u8fbe\u8ffd\u8e2a <p>\u56fe1.1 \u8ba1\u7b97\u673a\u7b97\u672f\u7684\u8303\u56f4\u3002</p> <p>Figure 1.1 depicts the scope of computer arithmetic. On the hardware side, the focus is on implementing the four basic arithmetic operations (five, if you count square-rooting), as well as commonly used computations such as exponentials, logarithms, and trigonometric functions. For this, we need to develop algorithms, translate them to hardware structures, and choose from among multiple implementations based on cost\u2013performance criteria. Since the exact computations to be carried out by the general-purpose hardware are not known a priori, benchmarking is used to predict the overall system performance for typical operation mixes and to make various design decisions. </p> <p>\u56fe 1.1 \u63cf\u8ff0\u4e86\u8ba1\u7b97\u673a\u7b97\u672f\u7684\u8303\u56f4\u3002\u5728\u786c\u4ef6\u65b9\u9762\uff0c\u91cd\u70b9\u662f\u5b9e\u73b0\u56db\u79cd\u57fa\u672c\u7b97\u672f\u8fd0\u7b97\uff08\u5982\u679c\u7b97\u5e73\u65b9\u6839\u5219\u4e3a\u4e94\u79cd\uff09\uff0c\u4ee5\u53ca\u5e38\u7528\u7684\u8ba1\u7b97\uff0c\u4f8b\u5982\u6307\u6570\u3001\u5bf9\u6570\u548c\u4e09\u89d2\u51fd\u6570\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u9700\u8981\u5f00\u53d1\u7b97\u6cd5\uff0c\u5c06\u5176\u8f6c\u5316\u4e3a\u786c\u4ef6\u7ed3\u6784\uff0c\u5e76\u6839\u636e\u6027\u4ef7\u6bd4\u6807\u51c6\u4ece\u591a\u79cd\u5b9e\u73b0\u4e2d\u8fdb\u884c\u9009\u62e9\u3002\u7531\u4e8e\u5148\u9a8c\u672a\u77e5\u901a\u7528\u786c\u4ef6\u8981\u6267\u884c\u7684\u7cbe\u786e\u8ba1\u7b97\uff0c\u56e0\u6b64\u4f7f\u7528\u57fa\u51c6\u6d4b\u8bd5\u6765\u9884\u6d4b\u5178\u578b\u64cd\u4f5c\u7ec4\u5408\u7684\u6574\u4f53\u7cfb\u7edf\u6027\u80fd\u5e76\u505a\u51fa\u5404\u79cd\u8bbe\u8ba1\u51b3\u7b56\u3002</p> <p>On the software side, the primitive functions are given (e.g., in the form of a hardware chip such as a Pentium processor or a software tool such as Mathematica), and the task is to synthesize cost-effective algorithms, with desirable error characteristics, to solve various problems of interest. These topics are covered in numerical analysis and computational science courses and textbooks and are thus mostly outside the scope of this book. </p> <p>\u5728\u8f6f\u4ef6\u65b9\u9762\uff0c\u7ed9\u51fa\u4e86\u539f\u59cb\u529f\u80fd\uff08\u4f8b\u5982\uff0c\u4ee5\u5954\u817e\u5904\u7406\u5668\u7b49\u786c\u4ef6\u82af\u7247\u6216Mathematica\u7b49\u8f6f\u4ef6\u5de5\u5177\u7684\u5f62\u5f0f\uff09\uff0c\u4efb\u52a1\u662f\u7efc\u5408\u5177\u6709\u6210\u672c\u6548\u76ca\u7684\u7b97\u6cd5\uff0c\u5177\u6709\u7406\u60f3\u7684\u8bef\u5dee\u7279\u6027\uff0c\u4ee5\u89e3\u51b3\u5404\u79cd\u611f\u5174\u8da3\u7684\u95ee\u9898\u3002\u8fd9\u4e9b\u4e3b\u9898\u5305\u542b\u5728\u6570\u503c\u5206\u6790\u548c\u8ba1\u7b97\u79d1\u5b66\u8bfe\u7a0b\u548c\u6559\u79d1\u4e66\u4e2d\uff0c\u56e0\u6b64\u5927\u591a\u4e0d\u5c5e\u4e8e\u672c\u4e66\u7684\u8303\u56f4\u3002</p> <p>Within the hardware realm, we will be dealing with both general-purpose arithmetic/logic units, of the type found in many commercially available processors, and special-purpose structures for solving specific application problems. The differences in the two areas are minor as far as the arithmetic algorithms are concerned. However, in view of the specific technological constraints, production volumes, and performance criteria, hardware implementations tend to be quite different. General-purpose processor chips that are mass-produced have highly optimized custom designs. Implementations of low-volume, special-purpose systems, on the other hand, typically rely on semicustom and off-the-shelf components. However, when critical and strict requirements, such as extreme speed, very low power consumption, and miniature size, preclude the use of semicustom or off-the-shelf components, the much higher cost of a custom design may be justified even for a special-purpose system. </p> <p>\u5728\u786c\u4ef6\u9886\u57df\uff0c\u6211\u4eec\u5c06\u5904\u7406\u5728\u8bb8\u591a\u5546\u7528\u5904\u7406\u5668\u4e2d\u90fd\u5b58\u7684\u901a\u7528\u7684\u7b97\u672f/\u903b\u8f91\u5355\u5143\uff0c\u4ee5\u53ca\u7528\u4e8e\u89e3\u51b3\u7279\u5b9a\u5e94\u7528\u95ee\u9898\u7684\u4e13\u7528\u7ed3\u6784\u3002\u5c31\u7b97\u672f\u7b97\u6cd5\u800c\u8a00\uff0c\u8fd9\u4e24\u4e2a\u9886\u57df\u7684\u5dee\u5f02\u5f88\u5c0f\u3002\u7136\u800c\uff0c\u9274\u4e8e\u5177\u4f53\u7684\u6280\u672f\u9650\u5236\u3001\u4ea7\u91cf\u548c\u6027\u80fd\u6807\u51c6\uff0c\u786c\u4ef6\u5b9e\u73b0\u5f80\u5f80\u6709\u5f88\u5927\u4e0d\u540c\u3002\u6279\u91cf\u751f\u4ea7\u7684\u901a\u7528\u5904\u7406\u5668\u82af\u7247\u5177\u6709\u9ad8\u5ea6\u4f18\u5316\u7684\u5b9a\u5236\u8bbe\u8ba1\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u5c0f\u6279\u91cf\u3001\u7279\u6b8a\u7528\u9014\u7cfb\u7edf\u7684\u5b9e\u73b0\u901a\u5e38\u4f9d\u8d56\u4e8e\u534a\u5b9a\u5236\u548c\u73b0\u6210\u7684\u7ec4\u4ef6\u3002\u7136\u800c\uff0c\u5f53\u5173\u952e\u548c\u4e25\u683c\u7684\u8981\u6c42\uff08\u4f8b\u5982\u6781\u901f\u3001\u6781\u4f4e\u529f\u8017\u548c\u5fae\u578b\u5c3a\u5bf8\uff09\u59a8\u788d\u4f7f\u7528\u534a\u5b9a\u5236\u6216\u73b0\u6210\u7ec4\u4ef6\u65f6\uff0c\u5373\u4f7f\u5bf9\u4e8e\u7279\u6b8a\u7528\u9014\u7684\u7cfb\u7edf\uff0c\u5b9a\u5236\u8bbe\u8ba1\u7684\u9ad8\u5f97\u591a\u7684\u6210\u672c\u4e5f\u53ef\u80fd\u662f\u5408\u7406\u7684\u3002</p>"},{"location":"Part_01/01/#12","title":"1.2 \u542f\u53d1\u6027\u793a\u4f8b","text":"<p>Use a calculator that has the square-root, square, and exponentiation (xy) functions to perform the following computations. Numerical results, obtained with a (10 + 2)-digit scientific calculator, are provided. You may obtain slightly different values.</p> <p>\u4f7f\u7528\u5177\u6709\u5e73\u65b9\u6839\u3001\u5e73\u65b9\u548c\u6307\u6570 (xy) \u51fd\u6570\u7684\u8ba1\u7b97\u5668\u6765\u6267\u884c\u4ee5\u4e0b\u8ba1\u7b97\u3002\u63d0\u4f9b\u4e86\u4f7f\u7528 (10 + 2) \u4f4d\u79d1\u5b66\u8ba1\u7b97\u5668\u83b7\u5f97\u7684\u6570\u503c\u7ed3\u679c\u3002\u60a8\u53ef\u80fd\u4f1a\u83b7\u5f97\u7565\u6709\u4e0d\u540c\u7684\u503c\u3002</p> <p>First, compute \u201cthe 1024th root of 2\u201d in the following two ways:</p> <p>\u9996\u5148\uff0c\u901a\u8fc7\u4ee5\u4e0b\u4e24\u79cd\u65b9\u5f0f\u8ba1\u7b97\u201c2\u76841024\u6b21\u65b9\u6839\u201d\uff1a</p> \\[ \\begin{align} u &amp;= \\underbrace{\\sqrt{\\sqrt{\\dots\\sqrt{2}}}}_{10 \\text{ times}} &amp;= \\text{1.000 677 131}  \\\\ v &amp;= 2^{1/1024} &amp;= \\text{1.000 677 131} \\end{align} \\] <p>Save both  u  and  v  in memory, if possible. If you can\u2019t store  u  and  v, simply recompute them when needed. Now, perform the following two equivalent computations based on  u: 10 times</p> <p>\u5982\u679c\u53ef\u80fd\u7684\u8bdd\uff0c\u5c06 u \u548c v \u4fdd\u5b58\u5728\u5185\u5b58\u4e2d\u3002\u5982\u679c\u60a8\u65e0\u6cd5\u5b58\u50a8 u \u548c v\uff0c\u53ea\u9700\u5728\u9700\u8981\u65f6\u91cd\u65b0\u8ba1\u7b97\u5b83\u4eec\u5373\u53ef\u3002\u73b0\u5728\uff0c\u57fa\u4e8eu\u6267\u884c\u4ee5\u4e0b\u4e24\u4e2a\u7b49\u6548\u8ba1\u7b9710\u6b21</p> \\[ \\begin{align} x &amp;= \\overbrace{(((u^2)^2)...)^2}^{10 \\text{ times}} &amp;= \\text{1.999 999 963} \\\\ {x}' &amp;=  u^{1024} &amp;= \\text{1.999 999 973} \\end{align} \\] <p>Similarly, perform the following two equivalent computations based on v: 10 times \u540c\u6837\u6839\u636ev\u8fdb\u884c\u4ee5\u4e0b\u4e24\u6b21\u7b49\u4ef7\u8ba1\u7b9710\u6b21</p> \\[ \\begin{array}{l} y &amp;= \\overbrace{(((v^2)^2)...)^2}^ {10 \\text{ times}} &amp;= \\text{1.999 999 983} \\\\ {y}' &amp;=  v^{1024} &amp;= \\text{1.999 999 994} \\end{array} \\] <p>The four different values obtained for \\(x, {x}', y, {y}'\\), in lieu of 2, hint that perhaps v and u are not really the same value. Let\u2019s compute their difference:</p> <p>\u4e3a \\(x, {x}', y, {y}'\\)\u83b7\u5f97\u7684\u56db\u4e2a\u4e0d\u540c\u503c\uff08\u4ee3\u66ff 2\uff09\u6697\u793a v \u548c u \u53ef\u80fd\u5e76\u4e0d\u662f\u771f\u6b63\u76f8\u540c\u7684\u503c\u3002\u8ba9\u6211\u4eec\u8ba1\u7b97\u4e00\u4e0b\u5b83\u4eec\u7684\u5dee\u5f02\uff1a $$ w = v \u2212 u = 1 \\times 10^{\u221211} $$ Why isn\u2019t  w  equal to zero? The reason is that even though  u  and  v  are displayed identically, they in fact have different internal representations. Most calculators have hidden or guard digits (the author\u2019s has two) to provide a higher degree of accuracy and to reduce the effect of accumulated errors when long computation sequences are performed. </p> <p>\u4e3a\u4ec0\u4e48 w \u4e0d\u7b49\u4e8e 0\uff1f\u539f\u56e0\u662f\uff0c\u5c3d\u7ba1 u \u548c v \u663e\u793a\u76f8\u540c\uff0c\u4f46\u5b83\u4eec\u5b9e\u9645\u4e0a\u5177\u6709\u4e0d\u540c\u7684\u5185\u90e8\u8868\u793a\u3002\u5927\u591a\u6570\u8ba1\u7b97\u5668\u90fd\u6709\u9690\u85cf\u6216\u4fdd\u62a4\u6570\u5b57\uff08\u4f5c\u8005\u6709\u4e24\u4e2a\uff09\uff0c\u4ee5\u63d0\u4f9b\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u5e76\u51cf\u5c11\u6267\u884c\u957f\u8ba1\u7b97\u5e8f\u5217\u65f6\u7d2f\u79ef\u9519\u8bef\u7684\u5f71\u54cd\u3002</p> <p>Let\u2019s see if we can determine the hidden digits for the  u  and  v  values above. Here is one way:</p> <p>\u8ba9\u6211\u4eec\u770b\u770b\u662f\u5426\u53ef\u4ee5\u786e\u5b9a\u4e0a\u9762 u \u548c v \u503c\u7684\u9690\u85cf\u6570\u5b57\u3002\u8fd9\u662f\u4e00\u79cd\u65b9\u6cd5\uff1a</p> \\[ \\begin{array}{l} (u \u2212 1 ) \u00d7 1000 = \\text{0.677 130 680 [\u9690\u85cf\u00b7\u00b7\u00b7(0)68]} \\\\ (v \u2212 1 ) \u00d7 1000 = \\text{0.677 130 690 [\u9690\u85cf\u00b7\u00b7\u00b7(0)69]} \\end{array} \\] <p>This explains why  w  is not zero, which in turn tells us why  u 1024 =  v 1024. The following simple analysis might be helpful in this regard. </p> <p>\u8fd9\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48 w \u4e0d\u4e3a\u96f6\uff0c\u8fdb\u800c\u544a\u8bc9\u6211\u4eec\u4e3a\u4ec0\u4e48 \\(u^{1024} \\ne v^{1024}\\)\u3002\u4ee5\u4e0b\u7b80\u5355\u5206\u6790\u5728\u8fd9\u65b9\u9762\u53ef\u80fd\u4f1a\u6709\u6240\u5e2e\u52a9\u3002</p> \\[ \\begin{align}{} v^{1024} &amp;=  (u + 10^{\u221211})^{1024} \\\\ &amp;\\approx u^{1024} + 1024 \\times 10^{\u221211} u^{1023} \\approx u^{1024} + 2 \\times 10^{\u22128} \\end{align} \\] <p>The difference between  \\(v^{1024}\\) and  \\(u^{1024}\\) is in good agreement with the result of the preceding analysis. The difference between  \\((((u^2) ^2 ) \u00b7 \u00b7 \u00b7  )^2\\) and \\(u^{1024}\\)  exists because the former is computed through repeated multiplications while the latter uses the built-in exponentiation routine of the calculator, which is likely to be less precise. </p> <p>\\(v^{1024}\\) \u548c \\(u^{1024}\\) \u4e4b\u95f4\u7684\u5dee\u5f02\u4e0e\u524d\u9762\u7684\u5206\u6790\u7ed3\u679c\u975e\u5e38\u543b\u5408\u3002\\((((u^2) ^2 ) \u00b7 \u00b7 \u00b7  )^2\\) \u548c \\(u^{1024}\\) \u4e4b\u95f4\u5b58\u5728\u5dee\u5f02\uff0c\u56e0\u4e3a\u524d\u8005\u662f\u901a\u8fc7\u91cd\u590d\u4e58\u6cd5\u8ba1\u7b97\u7684\uff0c\u800c\u540e\u8005\u4f7f\u7528\u8ba1\u7b97\u5668\u7684\u5185\u7f6e\u6c42\u5e42\u4f8b\u7a0b\uff0c\u53ef\u80fd\u4e0d\u592a\u7cbe\u786e\u3002</p> <p>Despite the discrepancies, the results of the foregoing computations are remarkably precise. The values of  u  and  v  agree to 11 decimal digits, while those of  \\(x, {x}', y, {y}'\\)are identical to 8 digits. This is better than single-precision, floating-point arithmetic on the most elaborate and expensive computers. Do we have a right to expect more from a calculator that costs $20 or less? Ease of use is, of course, a different matter from speed or precision. For a detailed exposition of some deficiencies in current calculators, and a refreshingly new design approach, see [Thim95]. </p> <p>\u5c3d\u7ba1\u5b58\u5728\u5dee\u5f02\uff0c\u4e0a\u8ff0\u8ba1\u7b97\u7684\u7ed3\u679c\u4ecd\u7136\u975e\u5e38\u7cbe\u786e\u3002 u\u548cv\u7684\u503c\u4e00\u81f4\u4e3a11\u4f4d\u5341\u8fdb\u5236\u6570\u5b57\uff0c\u800c\\(x, {x}', y, {y}'\\)\u7684\u503c\u4e00\u81f4\u4e3a8\u4f4d\u6570\u5b57\u3002\u8fd9\u6bd4\u6700\u590d\u6742\u3001\u6700\u6602\u8d35\u7684\u8ba1\u7b97\u673a\u4e0a\u7684\u5355\u7cbe\u5ea6\u6d6e\u70b9\u8fd0\u7b97\u8981\u597d\u3002\u6211\u4eec\u662f\u5426\u6709\u6743\u5bf9\u552e\u4ef7 20 \u7f8e\u5143\u6216\u66f4\u5c11\u7684\u8ba1\u7b97\u5668\u62b1\u6709\u66f4\u9ad8\u7684\u671f\u671b\uff1f\u5f53\u7136\uff0c\u6613\u7528\u6027\u4e0e\u901f\u5ea6\u6216\u7cbe\u5ea6\u662f\u4e0d\u540c\u7684\u95ee\u9898\u3002\u6709\u5173\u5f53\u524d\u8ba1\u7b97\u5668\u7684\u4e00\u4e9b\u7f3a\u9677\u7684\u8be6\u7ec6\u8bf4\u660e\u4ee5\u53ca\u4ee4\u4eba\u8033\u76ee\u4e00\u65b0\u7684\u65b0\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u8bf7\u53c2\u9605 [Thim95]\u3002</p> <p>The example calculations demonstrate that familiarity with computer arithmetic is helpful for appreciating and correctly interpreting our everyday dealings with numbers. There is much more to computer arithmetic, however. Inattention to fundamentals of this field has led to several documented, and no doubt many more unreported, disasters. In the rest of this section, we describe two such events that were caused by inadequate precision and unduly limited range of numerical results. </p> <p>\u793a\u4f8b\u8ba1\u7b97\u8868\u660e\uff0c\u719f\u6089\u8ba1\u7b97\u673a\u7b97\u672f\u6709\u52a9\u4e8e\u7406\u89e3\u548c\u6b63\u786e\u89e3\u91ca\u6211\u4eec\u65e5\u5e38\u5904\u7406\u7684\u6570\u5b57\u3002\u7136\u800c\uff0c\u8ba1\u7b97\u673a\u7b97\u672f\u8fd8\u6709\u66f4\u591a\u5185\u5bb9\u3002\u5bf9\u8fd9\u4e00\u9886\u57df\u57fa\u672c\u539f\u7406\u7684\u5ffd\u89c6\u5bfc\u81f4\u4e86\u51e0\u8d77\u6709\u8bb0\u5f55\u7684\u707e\u96be\uff0c\u6beb\u65e0\u7591\u95ee\u8fd8\u6709\u66f4\u591a\u672a\u62a5\u9053\u7684\u707e\u96be\u3002\u5728\u672c\u8282\u7684\u5176\u4f59\u90e8\u5206\u4e2d\uff0c\u6211\u4eec\u5c06\u63cf\u8ff0\u7531\u7cbe\u5ea6\u4e0d\u8db3\u548c\u6570\u503c\u7ed3\u679c\u8303\u56f4\u8fc7\u5ea6\u6709\u9650\u5f15\u8d77\u7684\u4e24\u4e2a\u6b64\u7c7b\u4e8b\u4ef6\u3002</p> <p>The first such event, which may have led to the loss of 28 human lives in February 1991, is the failure of the American Patriot missile battery in Dhahran, Saudi Arabia, to intercept a number of Iraqi Scud missiles. An investigation by the US General Accounting Office [GAO92] blamed the incident on a \u201csoftware problem\u201d that led to inaccurate calculation of the elapsed time since the last system boot. It was explained that the system\u2019s internal clock measured time in tenths of a second. The measured time was then multiplied by a 24-bit truncated fractional representation of 1/10, with an error of about \\(( 3 / 4 ) \u00d7 10^{\u221223} \u2248 10^{\u22127}\\) . Some error was unavoidable, because 1/10 does not have an exact binary representation. Though rather small, when accumulated over a 10-hour operation period, this error caused the calculated time to be off by roughly \u2153 of a second. Because the Scud missile flew at a speed of about 1700 m/s, its calculated position might have differed from its actual position by more than \u00bd km; an error that is large enough to cause a missed interception. </p> <p>1991 \u5e74 2 \u6708\u53d1\u751f\u7684\u7b2c\u4e00\u8d77\u6b64\u7c7b\u4e8b\u4ef6\u53ef\u80fd\u5bfc\u81f4 28 \u4eba\u4e27\u751f\uff0c\u5f53\u65f6\u4f4d\u4e8e\u6c99\u7279\u963f\u62c9\u4f2f\u8fbe\u5170\u7684\u7f8e\u56fd\u7231\u56fd\u8005\u5bfc\u5f39\u8fde\u672a\u80fd\u62e6\u622a\u591a\u679a\u4f0a\u62c9\u514b\u98de\u6bdb\u817f\u5bfc\u5f39\u3002\u7f8e\u56fd\u5ba1\u8ba1\u603b\u7f72 [GAO92] \u7684\u4e00\u9879\u8c03\u67e5\u5c06\u8be5\u4e8b\u4ef6\u5f52\u548e\u4e8e\u201c\u8f6f\u4ef6\u95ee\u9898\u201d\uff0c\u8be5\u95ee\u9898\u5bfc\u81f4\u81ea\u4e0a\u6b21\u7cfb\u7edf\u542f\u52a8\u4ee5\u6765\u7ecf\u8fc7\u7684\u65f6\u95f4\u8ba1\u7b97\u4e0d\u51c6\u786e\u3002\u636e\u89e3\u91ca\uff0c\u7cfb\u7edf\u7684\u5185\u90e8\u65f6\u949f\u4ee5\u5341\u5206\u4e4b\u4e00\u79d2\u4e3a\u5355\u4f4d\u6d4b\u91cf\u65f6\u95f4\u3002\u7136\u540e\u5c06\u6d4b\u91cf\u7684\u65f6\u95f4\u4e58\u4ee5 1/10 \u7684 24 \u4f4d\u622a\u65ad\u5c0f\u6570\u8868\u793a\uff0c\u8bef\u5dee\u7ea6\u4e3a \\(( 3 / 4 ) \u00d7 10^{\u221223} \u2248 10^{\u22127}\\) \u3002\u4e00\u4e9b\u9519\u8bef\u662f\u4e0d\u53ef\u907f\u514d\u7684\uff0c\u56e0\u4e3a 1/10 \u6ca1\u6709\u7cbe\u786e\u7684\u4e8c\u8fdb\u5236\u8868\u793a\u3002\u867d\u7136\u8fd9\u4e2a\u8bef\u5dee\u5f88\u5c0f\uff0c\u4f46\u5728 10 \u5c0f\u65f6\u7684\u8fd0\u884c\u671f\u95f4\u7d2f\u79ef\u65f6\uff0c\u8be5\u8bef\u5dee\u5bfc\u81f4\u8ba1\u7b97\u65f6\u95f4\u504f\u5dee\u5927\u7ea6 \u2153 \u79d2\u949f\u7684\u65f6\u95f4\u3002\u7531\u4e8e\u98de\u6bdb\u817f\u5bfc\u5f39\u7684\u98de\u884c\u901f\u5ea6\u7ea6\u4e3a1700m/s\uff0c\u5176\u8ba1\u7b97\u4f4d\u7f6e\u53ef\u80fd\u4e0e\u5b9e\u9645\u4f4d\u7f6e\u76f8\u5dee\u00bd\u516c\u91cc\u4ee5\u4e0a\uff1b\u9519\u8bef\u5927\u5230\u8db3\u4ee5\u5bfc\u81f4\u9519\u8fc7\u62e6\u622a\u3002</p> <p>The second such event is the explosion of an Ariane 5 rocket 30 seconds after liftoff in June 1996. Fortunately, this incident, also attributed to a \u201csoftware error\u201d [Lion96], did not lead to any loss of life, but its price tag was the embarrassing collapse of an ambitious development project costing US $7 billion. According to the explanations offered, at some point in the control program, a 64-bit floating-point number pertaining to the horizontal velocity of the rocket was to be converted to a 16-bit signed integer. Because the floating-point number had a value greater than what could fit in a 16-bit signed integer, an overflow exception arose that did not have adequate handling provisions by the software. This caused a processor shutdown, which triggered a cascade of events leading to improper attempts at course correction and the eventual disintegration that spread debris over several square kilometers. The doomed conversion routine was a leftover from the software used for the Ariane 4 rocket, carried over intact according to the maxim \u201cif it ain\u2019t broke, don\u2019t fix it.\u201d However, the designers failed to take into account that within the initial 40 seconds of flight when the system in question was active, the Ariane 5 rocket could reach a horizontal velocity that was about five times that of the Ariane 4. </p> <p>\u7b2c\u4e8c\u8d77\u6b64\u7c7b\u4e8b\u4ef6\u662f 1996 \u5e74 6 \u6708\u963f\u4e3d\u4e9a\u5a1c 5 \u53f7\u706b\u7bad\u5347\u7a7a 30 \u79d2\u540e\u7206\u70b8\u3002\u5e78\u8fd0\u7684\u662f\uff0c\u8fd9\u8d77\u540c\u6837\u5f52\u56e0\u4e8e\u201c\u8f6f\u4ef6\u9519\u8bef\u201d[Lion96]\u7684\u4e8b\u4ef6\u6ca1\u6709\u9020\u6210\u4efb\u4f55\u4eba\u5458\u4f24\u4ea1\uff0c\u4f46\u5176\u4ee3\u4ef7\u662f\u8017\u8d44 70 \u4ebf\u7f8e\u5143\u7684\u96c4\u5fc3\u52c3\u52c3\u7684\u5f00\u53d1\u9879\u76ee\u7684\u5c34\u5c2c\u5d29\u6e83\u3002\u6839\u636e\u63d0\u4f9b\u7684\u89e3\u91ca\uff0c\u5728\u63a7\u5236\u7a0b\u5e8f\u7684\u67d0\u4e2a\u65f6\u523b\uff0c\u4e0e\u706b\u7bad\u6c34\u5e73\u901f\u5ea6\u76f8\u5173\u7684 64 \u4f4d\u6d6e\u70b9\u6570\u5c06\u88ab\u8f6c\u6362\u4e3a 16 \u4f4d\u6709\u7b26\u53f7\u6574\u6570\u3002\u7531\u4e8e\u6d6e\u70b9\u6570\u7684\u503c\u5927\u4e8e 16 \u4f4d\u6709\u7b26\u53f7\u6574\u6570\u6240\u80fd\u5bb9\u7eb3\u7684\u503c\uff0c\u56e0\u6b64\u51fa\u73b0\u4e86\u6ea2\u51fa\u5f02\u5e38\uff0c\u800c\u8f6f\u4ef6\u6ca1\u6709\u63d0\u4f9b\u8db3\u591f\u7684\u5904\u7406\u89c4\u5b9a\u3002\u8fd9\u5bfc\u81f4\u4e86\u5904\u7406\u5668\u5173\u95ed\uff0c\u5f15\u53d1\u4e86\u4e00\u7cfb\u5217\u4e8b\u4ef6\uff0c\u5bfc\u81f4\u822a\u5411\u4fee\u6b63\u7684\u4e0d\u5f53\u5c1d\u8bd5\u4ee5\u53ca\u6700\u7ec8\u7684\u89e3\u4f53\uff0c\u788e\u7247\u6563\u5e03\u5728\u51e0\u5e73\u65b9\u516c\u91cc\u7684\u8303\u56f4\u5185\u3002\u8fd9\u4e2a\u6ce8\u5b9a\u5931\u8d25\u7684\u8f6c\u6362\u7a0b\u5e8f\u662f\u963f\u4e3d\u4e9a\u5a1c 4 \u53f7\u706b\u7bad\u6240\u7528\u8f6f\u4ef6\u7684\u9057\u7559\u90e8\u5206\uff0c\u6309\u7167\u201c\u5982\u679c\u5b83\u6ca1\u6709\u51fa\u4e8b\uff0c\u5c31\u4e0d\u8981\u4fee\u7406\u5b83\u201d\u7684\u683c\u8a00\uff0c\u539f\u5c01\u4e0d\u52a8\u5730\u4fdd\u7559\u4e86\u4e0b\u6765\u3002\u7136\u800c\uff0c\u8bbe\u8ba1\u8005\u6ca1\u6709\u8003\u8651\u5230\uff0c\u5728\u76f8\u5173\u7cfb\u7edf\u6fc0\u6d3b\u7684\u6700\u521d 40 \u79d2\u98de\u884c\u5185\uff0c\u963f\u4e3d\u4e9a\u5a1c 5 \u53f7\u706b\u7bad\u7684\u6c34\u5e73\u901f\u5ea6\u53ef\u80fd\u8fbe\u5230\u963f\u4e3d\u4e9a\u5a1c 4 \u53f7\u706b\u7bad\u7684\u4e94\u500d\u5de6\u53f3\u3002</p>"},{"location":"Part_01/01/#13","title":"1.3 \u6570\u5b57\u53ca\u5176\u7f16\u7801","text":"<p>Number representation methods have advanced in parallel with the evolution of language. The oldest method for representing numbers consisted of the use of stones or sticks. Gradually, as larger numbers were needed, it became difficult to represent them or develop a feeling for their magnitudes. More importantly, comparing large numbers was quite cumbersome. Grouping the stones or sticks (e.g., representing the number 27 by 5 groups of 5 sticks plus 2 single sticks) was only a temporary cure. It was the use of different stones or sticks for representing groups of 5, 10, etc. that produced the first major breakthrough. </p> <p>\u6570\u5b57\u8868\u793a\u65b9\u6cd5\u4e0e\u8bed\u8a00\u7684\u53d1\u5c55\u540c\u6b65\u53d1\u5c55\u3002\u6700\u53e4\u8001\u7684\u8868\u793a\u6570\u5b57\u7684\u65b9\u6cd5\u662f\u4f7f\u7528\u77f3\u5934\u6216\u68cd\u5b50\u3002\u6e10\u6e10\u5730\uff0c\u968f\u7740\u9700\u8981\u66f4\u5927\u7684\u6570\u5b57\uff0c\u4ee3\u8868\u5b83\u4eec\u6216\u5bf9\u5b83\u4eec\u7684\u5927\u5c0f\u4ea7\u751f\u611f\u89c9\u53d8\u5f97\u56f0\u96be\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u6bd4\u8f83\u5927\u91cf\u7684\u6570\u636e\u662f\u76f8\u5f53\u9ebb\u70e6\u7684\u3002\u5c06\u77f3\u5934\u6216\u68cd\u5b50\u5206\u7ec4\uff08\u4f8b\u5982\uff0c\u7528 5 \u7ec4 5 \u6839\u68cd\u5b50\u52a0 2 \u4e2a\u5355\u68cd\u5b50\u4ee3\u8868\u6570\u5b57 27\uff09\u53ea\u662f\u6682\u65f6\u7684\u89e3\u51b3\u529e\u6cd5\u3002\u6b63\u662f\u4f7f\u7528\u4e0d\u540c\u7684\u77f3\u5934\u6216\u68cd\u68d2\u6765\u4ee3\u8868 5 \u4eba\u300110 \u4eba\u7b49\u4e00\u7ec4\uff0c\u624d\u4ea7\u751f\u4e86\u7b2c\u4e00\u4e2a\u91cd\u5927\u7a81\u7834\u3002</p> <p>The latter method gradually evolved into a symbolic form whereby special symbols were used to denote larger units. A familiar example is the Roman numeral system. The units of this system are 1, 5, 10, 50, 100, 500, 1000, 10 000, and 100 000, denoted by the symbols I, V, X, L, C, D, M, ((I)), and (((I))), respectively. A number is represented by a string of these symbols, arranged in descending order of values from left to right. To shorten some of the cumbersome representations, allowance is made to count a symbol as representing a negative value if it is to the left of a larger symbol. For example, IX is used instead of VIIII to denote the number 9 and LD is used for CCCCL to represent the number 450. </p> <p>\u540e\u4e00\u79cd\u65b9\u6cd5\u9010\u6e10\u6f14\u53d8\u6210\u4e00\u79cd\u7b26\u53f7\u5f62\u5f0f\uff0c\u7528\u7279\u6b8a\u7b26\u53f7\u6765\u8868\u793a\u66f4\u5927\u7684\u5355\u4f4d\u3002\u4e00\u4e2a\u719f\u6089\u7684\u4f8b\u5b50\u662f\u7f57\u9a6c\u6570\u5b57\u7cfb\u7edf\u3002\u8be5\u7cfb\u7edf\u7684\u5355\u4f4d\u4e3a 1\u30015\u300110\u300150\u3001100\u3001500\u30011000\u300110 000 \u548c 100 000\uff0c\u5206\u522b\u7528\u7b26\u53f7 I\u3001V\u3001X\u3001L\u3001C\u3001D\u3001M\u3001((I)) \u548c (((I))) \u8868\u793a\u3002\u6570\u5b57\u7531\u8fd9\u4e9b\u7b26\u53f7\u7ec4\u6210\u7684\u5b57\u7b26\u4e32\u8868\u793a\uff0c\u4ece\u5de6\u5230\u53f3\u6309\u503c\u7684\u964d\u5e8f\u6392\u5217\u3002\u4e3a\u4e86\u7f29\u77ed\u4e00\u4e9b\u7e41\u7410\u7684\u8868\u793a\uff0c\u5982\u679c\u7b26\u53f7\u4f4d\u4e8e\u8f83\u5927\u7b26\u53f7\u7684\u5de6\u4fa7\uff0c\u5219\u5141\u8bb8\u5c06\u5176\u8ba1\u4e3a\u8868\u793a\u8d1f\u503c\u3002\u4f8b\u5982\uff0cIX \u4ee3\u66ff VIII \u6765\u8868\u793a\u6570\u5b57 9\uff0c LD \u4ee3\u66ff CCCCL \u4f7f\u7528\u6765\u8868\u793a\u6570\u5b57 450\u3002</p> <p>Clearly, the Roman numeral system is not suitable for representing very large numbers. Furthermore, it is difficult to do arithmetic on numbers represented with this notation. The  positional  system of number representation was first used by the Chinese. In this method, the value represented by each symbol depends not only on its shape but also on its position relative to other symbols. Our conventional method of representing numbers is based on a positional system. </p> <p>\u663e\u7136\uff0c\u7f57\u9a6c\u6570\u5b57\u7cfb\u7edf\u4e0d\u9002\u5408\u8868\u793a\u975e\u5e38\u5927\u7684\u6570\u5b57\u3002\u6b64\u5916\uff0c\u5f88\u96be\u5bf9\u7528\u8fd9\u79cd\u8868\u793a\u6cd5\u8868\u793a\u7684\u6570\u5b57\u8fdb\u884c\u7b97\u672f\u8fd0\u7b97\u3002\u6570\u5b57\u8868\u793a\u7684\u4f4d\u7f6e\u7cfb\u7edf\u9996\u5148\u7531\u4e2d\u56fd\u4eba\u4f7f\u7528\u3002\u5728\u8fd9\u79cd\u65b9\u6cd5\u4e2d\uff0c\u6bcf\u4e2a\u7b26\u53f7\u6240\u4ee3\u8868\u7684\u503c\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u5176\u5f62\u72b6\uff0c\u8fd8\u53d6\u51b3\u4e8e\u5176\u76f8\u5bf9\u4e8e\u5176\u4ed6\u7b26\u53f7\u7684\u4f4d\u7f6e\u3002\u6211\u4eec\u8868\u793a\u6570\u5b57\u7684\u4f20\u7edf\u65b9\u6cd5\u57fa\u4e8e\u4f4d\u7f6e\u7cfb\u7edf\u3002</p> <p>For example in the number 222, each of the \u201c2\u201d digits represents a different value.  The leftmost 2 represents 200. The middle 2 represents 20. Finally, the rightmost 2 is worth 2 units. The representation of time intervals in terms of days, hours, minutes, and seconds (i.e., as four-element vectors) is another example of the positional system. For instance, in the vector  T = 5 5 5 5, the leftmost element denotes 5 days, the second from the left represents 5 hours, the third element stands for 5 minutes, and the rightmost element denotes 5 seconds. </p> <p>\u4f8b\u5982\uff0c\u5728\u6570\u5b57 222 \u4e2d\uff0c\u6bcf\u4e2a\u201c2\u201d\u6570\u5b57\u4ee3\u8868\u4e0d\u540c\u7684\u503c\u3002\u6700\u5de6\u8fb9\u76842\u4ee3\u8868200\u3002\u4e2d\u95f4\u76842\u4ee3\u886820\u3002\u6700\u540e\uff0c\u6700\u53f3\u8fb9\u76842\u503c2\u4e2a\u5355\u4f4d\u3002\u4ee5\u5929\u3001\u5c0f\u65f6\u3001\u5206\u949f\u548c\u79d2\uff08\u5373\u56db\u5143\u7d20\u5411\u91cf\uff09\u8868\u793a\u65f6\u95f4\u95f4\u9694\u662f\u4f4d\u7f6e\u7cfb\u7edf\u7684\u53e6\u4e00\u4e2a\u793a\u4f8b\u3002\u4f8b\u5982\uff0c\u5728\u5411\u91cf T = 5 5 5 5 \u4e2d\uff0c\u6700\u5de6\u8fb9\u7684\u5143\u7d20\u8868\u793a 5 \u5929\uff0c\u5de6\u8fb9\u7b2c\u4e8c\u4e2a\u5143\u7d20\u8868\u793a 5 \u5c0f\u65f6\uff0c\u7b2c\u4e09\u4e2a\u5143\u7d20\u8868\u793a 5 \u5206\u949f\uff0c\u6700\u53f3\u8fb9\u7684\u5143\u7d20\u8868\u793a 5 \u79d2\u3002</p> <p>If in a positional number system, the unit corresponding to each position is a constant multiple of the unit for its right neighboring position, the conventional  fixed-radix positional system is obtained. The decimal number system we use daily is a positional number system with 10 as its constant radix. The representation of time intervals, as just discussed, provides an example of a  mixed-radix  positional system for which the radix is the vector  R = 0 24 60 60. </p> <p>\u5982\u679c\u5728\u4f4d\u7f6e\u6570\u5236\u4e2d\uff0c\u6bcf\u4e2a\u4f4d\u7f6e\u5bf9\u5e94\u7684\u5355\u4f4d\u662f\u5176\u53f3\u76f8\u90bb\u4f4d\u7f6e\u7684\u5355\u4f4d\u7684\u5e38\u6570\u500d\uff0c\u5219\u5f97\u5230\u4f20\u7edf\u7684*\u56fa\u5b9a\u57fa\u6570*\u4f4d\u7f6e\u5236\u3002\u6211\u4eec\u65e5\u5e38\u4f7f\u7528\u7684\u5341\u8fdb\u5236\u6570\u5236\u662f\u4ee510\u4e3a\u5e38\u6570\u57fa\u6570\u7684\u4f4d\u7f6e\u6570\u5236\u3002\u6b63\u5982\u521a\u521a\u8ba8\u8bba\u7684\uff0c\u65f6\u95f4\u95f4\u9694\u7684\u8868\u793a\u63d0\u4f9b\u4e86\u6df7\u5408\u57fa\u6570\u4f4d\u7f6e\u7cfb\u7edf\u7684\u793a\u4f8b\uff0c\u5176\u57fa\u6570\u662f\u5411\u91cf R = 0 24 60 60\u3002</p> <p>The method used to represent numbers affects not just the ease of reading and understanding the notation but also the complexity of arithmetic algorithms used for computing with numbers. The popularity of positional number systems is in part due to the availability of simple and elegant algorithms for performing arithmetic on such numbers. We will see in subsequent chapters that other representations provide advantages over the positional representation in terms of certain arithmetic operations or the needs of particular application areas. However, these systems are of limited use precisely because they do not support universally simple arithmetic. </p> <p>\u7528\u4e8e\u8868\u793a\u6570\u5b57\u7684\u65b9\u6cd5\u4e0d\u4ec5\u5f71\u54cd\u9605\u8bfb\u548c\u7406\u89e3\u7b26\u53f7\u7684\u5bb9\u6613\u7a0b\u5ea6\uff0c\u800c\u4e14\u5f71\u54cd\u7528\u4e8e\u6570\u5b57\u8ba1\u7b97\u7684\u7b97\u672f\u7b97\u6cd5\u7684\u590d\u6742\u6027\u3002\u4f4d\u7f6e\u6570\u5b57\u7cfb\u7edf\u7684\u6d41\u884c\u90e8\u5206\u5f52\u56e0\u4e8e\u5bf9\u8fd9\u4e9b\u6570\u5b57\u6267\u884c\u7b97\u672f\u7684\u7b80\u5355\u800c\u4f18\u96c5\u7684\u7b97\u6cd5\u7684\u53ef\u7528\u6027\u3002\u6211\u4eec\u5c06\u5728\u540e\u7eed\u7ae0\u8282\u4e2d\u770b\u5230\uff0c\u5728\u67d0\u4e9b\u7b97\u672f\u8fd0\u7b97\u6216\u7279\u5b9a\u5e94\u7528\u9886\u57df\u7684\u9700\u6c42\u65b9\u9762\uff0c\u5176\u4ed6\u8868\u793a\u6cd5\u6bd4\u4f4d\u7f6e\u8868\u793a\u6cd5\u5177\u6709\u4f18\u52bf\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u7684\u7528\u9014\u662f\u6709\u9650\u7684\uff0c\u56e0\u4e3a\u5b83\u4eec\u4e0d\u652f\u6301\u666e\u904d\u7b80\u5355\u7684\u7b97\u672f\u3002</p> <p>In digital systems, numbers are encoded by means of binary digits or bits. Suppose you have 4 bits to represent numbers. There are 16 possible codes. You are free to assign the 16 codes to numbers as you please. However, since number representation has significant effects on algorithm and circuit complexity, only some of the wide range of possibilities have found applications. </p> <p>\u5728\u6570\u5b57\u7cfb\u7edf\u4e2d\uff0c\u6570\u5b57\u901a\u8fc7\u4e8c\u8fdb\u5236\u6570\u5b57\u6216\u4f4d\u8fdb\u884c\u7f16\u7801\u3002\u5047\u8bbe\u60a8\u6709 4 \u4f4d\u6765\u8868\u793a\u6570\u5b57\u3002\u6709 16 \u79cd\u53ef\u80fd\u7684\u4ee3\u7801\u3002\u60a8\u53ef\u4ee5\u968f\u610f\u5c06 16 \u4e2a\u4ee3\u7801\u5206\u914d\u7ed9\u53f7\u7801\u3002\u7136\u800c\uff0c\u7531\u4e8e\u6570\u5b57\u8868\u793a\u5bf9\u7b97\u6cd5\u548c\u7535\u8def\u590d\u6742\u6027\u6709\u663e\u7740\u5f71\u54cd\uff0c\u56e0\u6b64\u53ea\u6709\u4e00\u4e9b\u5e7f\u6cdb\u7684\u53ef\u80fd\u6027\u5f97\u5230\u4e86\u5e94\u7528\u3002</p> <p>To simplify arithmetic operations, including the required checking for singularities or special cases, the assignment of codes to numbers must be done in a logical and systematic manner. For example, if you assign codes to 2 and 3 but not to 5, then adding 2 and 3 will cause an \u201coverflow\u201d (yields an unrepresentable value) in your number system. </p> <p>\u4e3a\u4e86\u7b80\u5316\u7b97\u672f\u8fd0\u7b97\uff0c\u5305\u62ec\u6240\u9700\u7684\u5947\u70b9\u6216\u7279\u6b8a\u60c5\u51b5\u68c0\u67e5\uff0c\u5fc5\u987b\u4ee5\u903b\u8f91\u548c\u7cfb\u7edf\u7684\u65b9\u5f0f\u5c06\u4ee3\u7801\u5206\u914d\u7ed9\u6570\u5b57\u3002\u4f8b\u5982\uff0c\u5982\u679c\u60a8\u5c06\u4ee3\u7801\u5206\u914d\u7ed9 2 \u548c 3 \u800c\u4e0d\u662f 5\uff0c\u5219\u6dfb\u52a0 2 \u548c 3 \u5c06\u5bfc\u81f4\u6570\u5b57\u7cfb\u7edf\u4e2d\u7684\u201c\u6ea2\u51fa\u201d\uff08\u4ea7\u751f\u65e0\u6cd5\u8868\u793a\u7684\u503c\uff09\u3002</p> <p>Figure 1.2 shows some examples of assignments of 4-bit codes to numbers. The first choice is to interpret the 4-bit patterns as 4-bit binary numbers, leading to the representation of natural numbers in the range [0, 15]. The signed-magnitude scheme results in integers in the range [\u22127, 7] being represented, with 0 having two representations, (viz., \u00b10). The 3-plus-1 fixed-point number system (3 whole bits, 1 fractional bit) gives us numbers from 0 to 7.5 in increments of 0.5. Viewing the 4-bit codes as signed fractions gives us a range of [\u22120.875, +0.875] or [\u22121, +0.875], depending on whether we use signed-magnitude or 2\u2019s-complement representation. </p> <p>\u56fe 1.2 \u663e\u793a\u4e86\u5c06 4 \u4f4d\u4ee3\u7801\u5206\u914d\u7ed9\u6570\u5b57\u7684\u4e00\u4e9b\u793a\u4f8b\u3002\u7b2c\u4e00\u4e2a\u9009\u62e9\u662f\u5c06 4 \u4f4d\u6a21\u5f0f\u89e3\u91ca\u4e3a 4 \u4f4d\u4e8c\u8fdb\u5236\u6570\uff0c\u4ece\u800c\u5f97\u5230 [0, 15] \u8303\u56f4\u5185\u7684\u81ea\u7136\u6570\u8868\u793a\u3002\u5e26\u7b26\u53f7\u6570\u503c\u65b9\u6848\u5bfc\u81f4\u8868\u793a [\u22127, 7] \u8303\u56f4\u5185\u7684\u6574\u6570\uff0c\u5176\u4e2d 0 \u6709\u4e24\u79cd\u8868\u793a\u5f62\u5f0f\uff08\u5373\u00b10\uff09\u3002 3+1 \u5b9a\u70b9\u6570\u7cfb\u7edf\uff083 \u4e2a\u6574\u6570\u4f4d\uff0c1 \u4e2a\u5c0f\u6570\u4f4d\uff09\u4e3a\u6211\u4eec\u63d0\u4f9b\u4ece 0 \u5230 7.5 \u7684\u6570\u5b57\uff0c\u589e\u91cf\u4e3a 0.5\u3002\u5c06 4 \u4f4d\u4ee3\u7801\u89c6\u4e3a\u6709\u7b26\u53f7\u5206\u6570\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230 [\u22120.875, +0.875] \u6216 [\u22121, +0.875] \u7684\u8303\u56f4\uff0c\u5177\u4f53\u53d6\u51b3\u4e8e\u6211\u4eec\u662f\u4f7f\u7528\u7b26\u53f7\u5e45\u5ea6\u8868\u793a\u8fd8\u662f 2 \u7684\u8865\u7801\u8868\u793a\u3002</p> <p>The 2-plus-2 unsigned floating-point number system in Fig. 1.2, with its 2-bit exponent  e  in {\u22122, \u22121, 0, 1} and 2-bit integer significand  s  in {0, 1, 2, 3}, can represent certain values  s \u00d7 2 e  in [0, 6]. In this system, 0.00 has four representations, 0.50, 1.00, and 2.00 have two representations each, and 0.25, 0.75, 1.50, 3.00, 4.00, and 6.00 are uniquely represented. The 2-plus-2 logarithmic number system, which represents a number by approximating its 2-plus-2, fixed-point, base-2 logarithm, completes the choices shown in Fig. 1.2. </p> <p>\u56fe 1.2 \u4e2d\u7684 2+2 \u65e0\u7b26\u53f7\u6d6e\u70b9\u6570\u7cfb\u7edf\uff0c\u5176 2 \u4f4d\u6307\u6570 e \u5728 {\u22122, \u22121, 0, 1} \u4e2d\uff0c2 \u4f4d\u6574\u6570\u6709\u6548\u6570 s \u5728 {0, 1, 2, 3} \u4e2d\uff0c\u53ef\u4ee5\u8868\u793a [0, 6] \u4e2d\u7684\u67d0\u4e9b\u503c \\(s \\times 2^e\\)\u3002\u5728\u6b64\u7cfb\u7edf\u4e2d\uff0c0.00 \u6709\u56db\u79cd\u8868\u793a\u5f62\u5f0f\uff1a0.50\u30011.00 \u548c 2.00\u6bcf\u4e2a\u90fd\u6709\u4e24\u79cd\u8868\u793a\u5f62\u5f0f\uff0c0.25\u30010.75\u30011.50\u30013.00\u30014.00 \u548c 6.00 \u662f\u552f\u4e00\u8868\u793a\u7684\u3002 2+2 \u5bf9\u6570\u7cfb\u7edf\u901a\u8fc7\u8fd1\u4f3c 2+2\u3001\u5b9a\u70b9\u3001\u4ee5 2 \u4e3a\u5e95\u7684\u5bf9\u6570\u6765\u8868\u793a\u4e00\u4e2a\u6570\uff0c\u5b8c\u6210\u4e86\u56fe 1.2 \u4e2d\u6240\u793a\u7684\u9009\u62e9\u3002</p> <p></p>"},{"location":"Part_01/01/#14","title":"1.4 \u56fa\u5b9a\u57fa\u6570\u4f4d\u7f6e\u6570\u5b57\u7cfb\u7edf","text":"<p>A conventional fixed-radix, fixed-point positional number system is usually based on a positive integer  radix (base)  r  and an implicit digit set {\\(0, 1, \u00b7 \u00b7 \u00b7 ,  r \u2212 1\\)}. Each unsigned integer is represented by a digit vector of length  k +  l, with  k  digits for the whole part and  l  digits for the fractional part. By convention, the digit vector \\(x_{k\u22121} x_{k\u22122} \u00b7 \u00b7 \u00b7 x_1 x_0. x_{\u22121} x_{\u22122} \u00b7 \u00b7 \u00b7 x_{\u2212l}\\) represents the value</p> <p>\u4f20\u7edf\u7684\u5b9a\u57fa\u3001\u5b9a\u70b9\u4f4d\u7f6e\u6570\u7cfb\u7edf\u901a\u5e38\u57fa\u4e8e\u6b63\u6574\u6570\u57fa\u6570\uff08\u5e95\u6570base\uff09\\(r\\) \u548c\u9690\u5f0f\u6570\u5b57\u96c6{\\(0, 1, \u00b7\u00b7\u00b7, r \u2212 1\\)}\u3002\u6bcf\u4e2a\u65e0\u7b26\u53f7\u6574\u6570\u90fd\u7531\u957f\u5ea6\u4e3a \\(k + l\\) \u7684\u6570\u5b57\u5411\u91cf\u8868\u793a\uff0c\u5176\u4e2d \\(k\\) \u8868\u793a\u6574\u6570\u957f\u5ea6\uff0c\\(l\\) \u4f4d\u8868\u793a\u5c0f\u6570\u90e8\u5206\u957f\u5ea6\u3002\u6309\u7167\u60ef\u4f8b\uff0c\u6570\u5b57\u5411\u91cf \\(x_{k\u22121} x_{k\u22122} \u00b7 \u00b7 \u00b7 x_1 x_0. x_{\u22121} x_{\u22122} \u00b7 \u00b7 \u00b7 x_{\u2212l}\\) \u8868\u793a\u503c</p> \\[ (x_{k-1}x_{k-2}\\cdots x_1x_0 . x_{-1}x_{-2}\\cdots x_{-l})_r = \\sum_{i=-l}^{k-1}x_ir^i \\] <p>One can easily generalize to arbitrary radices (not necessarily integer or positive or constant) and digit sets of arbitrary size or composition. In what follows, we restrict our attention to digit sets composed of consecutive integers, since digit sets of other types complicate arithmetic and have no redeeming property. Thus, we denote our digit set by {\u2212 \u03b1, \u2212 \u03b1 + 1, \u00b7 \u00b7 \u00b7 ,  \u03b2 \u2212 1,  \u03b2} = [\u2212 \u03b1,  \u03b2]. </p> <p>\u4eba\u4eec\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u63a8\u5e7f\u5230\u4efb\u610f\u57fa\u6570\uff08\u4e0d\u4e00\u5b9a\u662f\u6574\u6570\u3001\u6b63\u6570\u6216\u5e38\u6570\uff09\u548c\u4efb\u610f\u5927\u5c0f\u6216\u7ec4\u6210\u7684\u6570\u5b57\u96c6\u3002\u5728\u4e0b\u6587\u4e2d\uff0c\u6211\u4eec\u5c06\u6ce8\u610f\u529b\u9650\u5236\u5728\u7531\u8fde\u7eed\u6574\u6570\u7ec4\u6210\u7684\u6570\u5b57\u96c6\u4e0a\uff0c\u56e0\u4e3a\u5176\u4ed6\u7c7b\u578b\u7684\u6570\u5b57\u96c6\u4f7f\u7b97\u672f\u590d\u6742\u5316\u5e76\u4e14\u6ca1\u6709\u53ef\u8d4e\u56de\u7684\u5c5e\u6027\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u5c06\u6570\u5b57\u96c6\u8868\u793a\u4e3a {\u2212\u03b1,\u2212\u03b1+1,\u00b7\u00b7\u00b7,\u03b2\u22121,\u03b2}=[\u2212\u03b1,\u03b2]\u3002</p> <p>The following examples demonstrate the wide range of possibilities in selecting the radix and digit set. </p> <p>\u4ee5\u4e0b\u793a\u4f8b\u6f14\u793a\u4e86\u9009\u62e9\u57fa\u6570\u548c\u6570\u5b57\u96c6\u7684\u5e7f\u6cdb\u53ef\u80fd\u6027\u3002</p> <p>EXAMPLE 1.1 Balanced ternary number system: r = 3, digit set = [\u22121, 1].</p> <p>\u793a\u4f8b1.1 \u5e73\u8861\u4e09\u8fdb\u5236\u6570\u7cfb\u7edf\uff1ar = 3\uff0c\u6570\u5b57\u96c6= [\u22121, 1]\u3002</p> <p>EXAMPLE 1.2 Negative-radix number systems: radix \\(\u2212r\\), digit set = [0, r \u2212 1].</p> <p>\u793a\u4f8b1.2 \u8d1f\u57fa\u6570\u7cfb\u7edf\uff1a\u57fa\u6570 \\(-r\\)\uff0c\u6570\u5b57\u96c6= [\\(0, r \u2212 1\\)]\u3002</p> \\[ \\begin{array}{l} (\\cdots x_5x_4x_3x_2x_1x_0 . x_{-1}x_{-2}x_{-3}x_{-4}x_{-5}x_{-6} \\cdots) = \\sum_{i}x_i(-r)^i \\\\ =\\sum_{\\text{even }i}x_ir^i - \\sum_{\\text{odd }i}x_ir^i \\\\ =(\\cdots x_4x_2x_0 . x_{-2}x_{-4}x_{-6} \\cdots)_r - (\\cdots x_5x_3x_1 . x_{-1}x_{-3}x_{-5} \\cdots)_r \\end{array} \\] <p>r = \u22122 \u4e14\u6570\u5b57\u96c6\u4e3a [0, 1] \u7684\u7279\u6b8a\u60c5\u51b5\u79f0\u4e3a\u8d1f\u4e8c\u8fdb\u5236\u6570\u7cfb</p> <p>EXAMPLE 1.3 Nonredundant signed-digit number systems: digit set [\u2212 \u03b1,  r \u2212 1 \u2212  \u03b1] for radix  r. As an example, one can use the digit set [\u22124, 5] for  r = 10. We denote a negative digit by preceding it with a minus sign, as usual, or by using a hyphen as a left superscript when the minus sign could be mistaken for subtraction. For example, </p> <p>\\((3\\ ^-1\\ 5 )_{ten}\\)  represents the decimal number  295 =   300 \u2212 10 + 5</p> <p>\\((^-3\\ 1\\ 5)_{ten}\\) represents the decimal number \u2212285 = \u2212300 + 10 + 5</p> <p>\u793a\u4f8b1.3 \u975e\u5197\u4f59\u5e26\u7b26\u53f7\u6570\u5b57\u7cfb\u7edf\uff1a\u57fa\u6570\\(r\\)\u7684\u6570\u5b57\u96c6[\u2212 \u03b1, r\u22121\u2212 \u03b1]\u3002\u4e3e\u4e2a\u4f8b\u5b50\uff0cr = 10 \u65f6\u53ef\u4ee5\u4f7f\u7528\u6570\u5b57\u96c6 [\u22124, 5]\u3002\u50cf\u5f80\u5e38\u4e00\u6837\uff0c\u6211\u4eec\u901a\u8fc7\u5728\u8d1f\u6570\u524d\u9762\u52a0\u4e0a\u51cf\u53f7\u6765\u8868\u793a\u8d1f\u6570\uff0c\u6216\u8005\u5f53\u51cf\u53f7\u53ef\u80fd\u88ab\u8bef\u8ba4\u4e3a\u662f\u51cf\u6cd5\u65f6\uff0c\u4f7f\u7528\u8fde\u5b57\u7b26\u4f5c\u4e3a\u5de6\u4e0a\u6807\u3002\u4f8b\u5982\uff0c</p> <p>\\((3\\ ^-1\\ 5 )_{ten}\\)\u200b \u8868\u793a\u5341\u8fdb\u5236\u6570   295 =   300 \u2212 10 + 5</p> <p>\\((^-3\\ 1\\ 5)_{ten}\\) \u8868\u793a\u5341\u8fdb\u5236\u6570 \u2212285 = \u2212300 + 10 + 5</p> <p>EXAMPLE 1.4 Redundant signed-digit number systems: digit set [\u2212 \u03b1,  \u03b2], with  \u03b1+ \u03b2 \u2265  r for radix  r. One can use the digit set [\u22127, 7], say, for  r = 10. In such redundant number systems, certain values may have multiple representations. For example, here are some representations for the decimal number 295:</p> <p>\u793a\u4f8b1.4 \u5197\u4f59\u6709\u7b26\u53f7\u6570\u5b57\u7cfb\u7edf\uff1a\u6570\u5b57\u96c6[\u2212 \u03b1, \u03b2]\uff0c\u5176\u4e2d\u03b1+ \u03b2 \u2265 r \u4e3a\u57fa\u6570r\u3002\u4f8b\u5982\uff0c\u5bf9\u4e8e r = 10\uff0c\u53ef\u4ee5\u4f7f\u7528\u6570\u5b57\u96c6 [\u22127, 7]\u3002\u5728\u8fd9\u79cd\u5197\u4f59\u6570\u5b57\u7cfb\u7edf\u4e2d\uff0c\u67d0\u4e9b\u503c\u53ef\u80fd\u6709\u591a\u79cd\u8868\u793a\u5f62\u5f0f\u3002\u4f8b\u5982\uff0c\u4ee5\u4e0b\u662f\u5341\u8fdb\u5236\u6570 295 \u7684\u4e00\u4e9b\u8868\u793a\u5f62\u5f0f\uff1a</p> \\[ (3\\ ^-1\\ 5)_{ten} =  (3\\ 0\\ ^-5)_{ten} =  (1\\ ^-7\\ 0\\ ^-5 )_{ten} \\] <p>\u6211\u4eec\u5c06\u5728\u7b2c 3 \u7ae0\u8be6\u7ec6\u7814\u7a76\u5197\u4f59\u8868\u793a\u3002</p> <p>EXAMPLE 1.5 Fractional radix number systems:  r = 0.1 with digit set [0, 9]. </p> <p>\u793a\u4f8b1.5 \u5c0f\u6570\u57fa\u6570\u7cfb\u7edf\uff1ar = 0.1\uff0c\u6570\u5b57\u96c6\u4e3a[0, 9]\u3002</p> \\[ \\begin{array}{l} (x_{k\u22121} x_{k\u22122} \\cdots  x_1 x_0 .  x_{\u22121}x_{\u22122} \\cdots  x_{\u2212l})_{one-tenth} = \\sum_{i}10^{-i} \\\\ =(x_{\u2212l}\\cdots x_{\u22122}x_{\u22121}x_0 . x_1 \\cdots x_{k\u22122} x_{k\u22121})_{ten} \\end{array} \\] <p>EXAMPLE 1.6 Irrational radix number systems:  r = \\(\\sqrt{2}\\) with digit set [0, 1]. </p> <p>\u793a\u4f8b1.6 \u65e0\u7406\u57fa\u6570\u7cfb\u7edf\uff1ar = \\(\\sqrt{2}\\)\uff0c\u6570\u5b57\u96c6\u4e3a[0, 1]\u3002</p> \\[ \\begin{array}{l} (\\cdots x_5x_4x_3x_2x_1x_0 . x_{-1}x_{-2}x_{-3}x_{-4}x_{-5}x_{-6} \\cdots)_{\\sqrt2} = \\sum_{i}x_i(\\sqrt{2})^i \\\\ =(\\cdots x_4x_2x_0 . x_{-2}x_{-4}x_{-6} \\cdots)_2 + \\sqrt2(\\cdots x_5x_3x_1 . x_{-1}x_{-3}x_{-5} \\cdots)_2 \\end{array} \\] <p>These examples illustrate the generality of our definition by introducing negative, fractional, and irrational radices and by using both nonredundant or minimal ( r  different digit values) and redundant ( &gt; r  digit values) digit sets in the common case of positive integer radices. We can go even further and make the radix an imaginary or complex number. </p> <p>\u8fd9\u4e9b\u793a\u4f8b\u901a\u8fc7\u5f15\u5165\u8d1f\u6570\u3001\u5c0f\u6570\u548c\u65e0\u7406\u6570\u57fa\u6570\uff0c\u5e76\u5728\u6b63\u6574\u6570\u7684\u5e38\u89c1\u60c5\u51b5\u4e0b\u4f7f\u7528\u975e\u5197\u4f59\u6216\u6700\u5c0f\uff08r \u4e2a\u4e0d\u540c\u7684\u6570\u5b57\u503c\uff09\u548c\u5197\u4f59\uff08&gt; r \u4e2a\u6570\u5b57\u503c\uff09\u6570\u5b57\u96c6\u6765\u8bf4\u660e\u6211\u4eec\u5b9a\u4e49\u7684\u4e00\u822c\u6027\u3002\u6211\u4eec\u53ef\u4ee5\u66f4\u8fdb\u4e00\u6b65\uff0c\u5c06\u57fa\u6570\u8bbe\u4e3a\u865a\u6570\u6216\u590d\u6570\u3002</p> <p>EXAMPLE 1.7 Complex-radix number systems: the quater-imaginary number system uses  \\(r = 2 j\\), where  \\(j = \\sqrt{-1}\\) and the digit set [0, 3]. </p> <p>\u793a\u4f8b 1.7 \u590d\u6570\u57fa\u6570\u7cfb\u7edf\uff1a\u56db\u865a\u6570\u7cfb\u7edf\u4f7f\u7528\\(r = 2 j\\)\uff0c\u5176\u4e2d\\(j = \\sqrt{-1}\\)  \u4ee5\u53ca\u6570\u5b57\u96c6 [0, 3]\u3002</p> \\[ \\begin{array}{l} (\\cdots x_5x_4x_3x_2x_1x_0 . x_{-1}x_{-2}x_{-3}x_{-4}x_{-5}x_{-6} \\cdots)_{2j} = \\sum_{i}x_i(2j)^i \\\\ =(\\cdots x_4x_2x_0 . x_{-2}x_{-4}x_{-6} \\cdots)_{-four} + 2j(\\cdots x_5x_3x_1 . x_{-1}x_{-3}x_{-5} \\cdots)_{four} \\end{array} \\] <p>It is easy to see that any complex number can be represented in the quater-imaginary number system of Example 1.7, with the advantage that ordinary addition (with a slightly modified carry rule) and multiplication can be used for complex-number computations. The modified carry rule is that a carry of \u22121 (a borrow actually) goes two positions to the left when the position sum, or digit total in a given position, exceeds 3. </p> <p>\u5f88\u5bb9\u6613\u770b\u51fa\uff0c\u4efb\u4f55\u590d\u6570\u90fd\u53ef\u4ee5\u7528\u4f8b 1.7 \u7684\u56db\u865a\u6570\u7cfb\u7edf\u8868\u793a\uff0c\u5176\u4f18\u70b9\u662f\u666e\u901a\u52a0\u6cd5\uff08\u7a0d\u5fae\u4fee\u6539\u8fdb\u4f4d\u89c4\u5219\uff09\u548c\u4e58\u6cd5\u53ef\u7528\u4e8e\u590d\u6570\u8ba1\u7b97s\u3002\u4fee\u6539\u540e\u7684\u8fdb\u4f4d\u89c4\u5219\u662f\uff0c\u5f53\u4f4d\u7f6e\u603b\u548c\u6216\u7ed9\u5b9a\u4f4d\u7f6e\u7684\u6570\u5b57\u603b\u6570\u8d85\u8fc7 3 \u65f6\uff0c\u8fdb\u4f4d -1\uff08\u5b9e\u9645\u4e0a\u662f\u501f\u4f4d\uff09\u4f1a\u5411\u5de6\u79fb\u52a8\u4e24\u4e2a\u4f4d\u7f6e\u3002</p> <p>In radix  r, with the standard digit set [0,  r \u2212 1], the number of digits needed to represent the natural numbers in [0,  max] is</p> <p>\u5728\u57fa\u6570 r \u4e2d\uff0c\u4f7f\u7528\u6807\u51c6\u6570\u5b57\u96c6 [0, r \u2212 1]\uff0c\u8868\u793a [0, max] \u4e2d\u7684\u81ea\u7136\u6570\u6240\u9700\u7684\u4f4d\u6570\u4e3a</p> \\[ k=\\left \\lfloor \\log_rmax \\right \\rfloor + 1  = \\left \\lceil \\log_r(max+1) \\right \\rceil \\] <p>Note that the number of different values represented is  max + 1. </p> <p>\u8bf7\u6ce8\u610f\uff0c\u8868\u793a\u7684\u4e0d\u540c\u503c\u7684\u6570\u91cf\u4e3a max + 1\u3002</p> <p>With fixed-point representation using  k  whole and  l  fractional digits, we have </p> <p>\u5bf9\u4e8e\u4f7f\u7528 k \u4e2a\u6574\u6570\u548c l \u4e2a\u5c0f\u6570\u4f4d\u7684\u5b9a\u70b9\u8868\u793a\uff0c\u6211\u4eec\u6709</p> \\[ max = r^k \u2212 r^{\u2212l} = r^k \u2212 ulp \\] <p>We will find the term  ulp, for the unit in least (significant) position, quite useful in describing certain arithmetic concepts without distinguishing between integers and fixed-point representations that include fractional parts. For integers,  ulp = 1. </p> <p>\u6211\u4eec\u4f1a\u53d1\u73b0\u672f\u8bed ulp\u8868\u793a\u7684\u662f\u6700\u5c0f\uff08\u6709\u6548\uff09\u4f4d\u7f6e\u7684\u5355\u4f4d\uff0c\u5728\u63cf\u8ff0\u67d0\u4e9b\u7b97\u672f\u6982\u5ff5\u65f6\u975e\u5e38\u6709\u7528\uff0c\u800c\u65e0\u9700\u533a\u5206\u6574\u6570\u548c\u5305\u542b\u5c0f\u6570\u90e8\u5206\u7684\u5b9a\u70b9\u8868\u793a\u3002\u5bf9\u4e8e\u6574\u6570\uff0culp = 1\u3002</p> <p>Specification of time intervals in terms of weeks, days, hours, minutes, seconds, and milliseconds is an example of mixed-radix representation. Given the two-part radix vector \u00b7 \u00b7 \u00b7  \\(r_3 r_2 r_1 r_0;  r_{\u22121} r_{\u22122}\\)\u00b7 \u00b7 \u00b7 defining the mixed radix, the two-part digit vector \\(\\cdots x_3 x_2 x_1 x_0;  x_{\u22121} x_{\u22122} \\cdots\\) represents the value.</p> <p>\u4ee5\u5468\u3001\u5929\u3001\u5c0f\u65f6\u3001\u5206\u949f\u3001\u79d2\u548c\u6beb\u79d2\u6765\u6307\u5b9a\u65f6\u95f4\u95f4\u9694\u662f\u6df7\u5408\u57fa\u6570\u8868\u793a\u7684\u4e00\u4e2a\u793a\u4f8b\u3002\u7ed9\u5b9a\u4e24\u90e8\u5206\u57fa\u5411\u91cf\\(\\cdots r_3 r_2 r_1 r_0;  r_{\u22121} r_{\u22122} \\cdots\\)\u5b9a\u4e49\u6df7\u5408\u57fa\u6570\uff0c\u548c\u4e24\u90e8\u5206\u6570\u5b57\u5411\u91cf\\(\\cdots x_3 x_2 x_1 x_0;  x_{\u22121} x_{\u22122} \\cdots\\) \u8868\u793a\u503c\u662f</p> <p>$$ \\cdots x_3r_2r_1r_0+x_2r_1r_0+x_1r_0+x0+\\frac{x_{-1}}{r_{-1}}+\\frac{x_{-2}}{r_{-1}r_{-2}}+ \\cdots $$ In the time interval example, the mixed radix is \u00b7 \u00b7 \u00b7 7, 24, 60, 60; 1000 \u00b7 \u00b7 \u00b7 and the digit vector 3, 2, 9, 22, 57; 492 (3 weeks, 2 days, 9 hours, 22 minutes, 57 seconds, and 492 milliseconds) represents</p> <p>\u65f6\u95f4\u95f4\u9694\u793a\u4f8b\u4e2d\uff0c\u6df7\u5408\u57fa\u6570\u4e3a\u2026\u20267\u300124\u300160\u300160\uff1b 1000\u00b7\u00b7\u00b7\u4ee5\u53ca\u6570\u5b57\u5411\u91cf3\u30012\u30019\u300122\u300157\uff1b 492\uff083\u54682\u59299\u5c0f\u65f622\u520657\u79d2\uff0c492\u6beb\u79d2\uff09\u4ee3\u8868\u7684\u662f</p> \\[ \\begin{array}{l} (3\u00d77\u00d724\u00d760\u00d760)+(2\u00d724\u00d760\u00d760)+(9\u00d760\u00d760)+(22\u00d760) \\\\ + 57 + 492 / 1000 = 2 020 977.492 \\text{ \u79d2} \\end{array} \\] <p>In Chapter 4, we will see that mixed-radix representation plays an important role in dealing with values represented in residue number systems. </p> <p>\u5728\u7b2c 4 \u7ae0\u4e2d\uff0c\u6211\u4eec\u5c06\u770b\u5230\u6df7\u5408\u57fa\u6570\u8868\u793a\u5728\u5904\u7406\u4f59\u6570\u7cfb\u7edf\u4e2d\u8868\u793a\u7684\u503c\u65f6\u53d1\u6325\u7740\u91cd\u8981\u4f5c\u7528\u3002</p>"},{"location":"Part_01/01/#15","title":"1.5 \u6570\u5b57\u57fa\u6570\u8f6c\u6362","text":"<p>Assuming that the unsigned value  u  has exact representations in radices  r  and  R, we can write:</p> <p>\u5047\u8bbe\u65e0\u7b26\u53f7\u503c u \u5728\u57fa\u6570 r \u548c R \u4e2d\u5177\u6709\u7cbe\u786e\u8868\u793a\uff0c\u6211\u4eec\u53ef\u4ee5\u5199\uff1a</p> \\[ \\begin{array}{l} u &amp;= w \\cdot v \\\\   &amp;= (x_{k\u22121}x_{k\u22122} \\cdots x_1x_0 . x_{\u22121}x_{\u22122} \\cdots x_{\u2212l})_r \\\\   &amp;= (X_{K\u22121}X_{K\u22122} \\cdots X_1X_0 . X_{\u22121}X_{\u22122} \\cdots X_{\u2212L})R \\end{array} \\] <p>If an exact representation does not exist in one or both of the radices, the foregoing equalities will be approximate. </p> <p>\u5982\u679c\u5728\u4e00\u4e2a\u6216\u4e24\u4e2a\u57fa\u4e2d\u4e0d\u5b58\u5728\u7cbe\u786e\u8868\u793a\uff0c\u5219\u524d\u8ff0\u7b49\u5f0f\u5c06\u662f\u8fd1\u4f3c\u7684\u3002</p> <p>\u57fa\u6570\u8f6c\u6362\u95ee\u9898\u5b9a\u4e49\u5982\u4e0b\uff1a</p> \\[ \\begin{array}{l} \\text{\u7ed9\u5b9a }  &amp; r &amp;\\text{\u65e7\u7684\u57fa\u6570} \\\\              &amp; R &amp;\\text{\u65b0\u7684\u57fa\u6570\uff0c\u4ee5\u53ca} \\\\              &amp; x_is &amp;\\text{\u57fa\u6570r\u8868\u793au\u7684\u7684\u6570\u5b57} \\\\ \\text{\u627e\u51fa } &amp; X_is &amp;\\text{\u57fa\u6570R\u8868\u793au\u7684\u7684\u6570\u5b57} \\end{array} \\] <p>In the rest of this section, we will describe two methods for radix conversion based on doing the arithmetic in the old radix r or in the new radix R. We will also present a shortcut method, involving very little computation, that is applicable when the old and new radices are powers of the same number (e.g., 8 and 16, which are both powers of 2).</p> <p>Note that in converting u from radix r to radix R, where r and R are positive integers, we can convert the whole and fractional parts separately. This is because an integer (fraction) is an integer (fraction), independent of the number representation radix.</p> <p>\u5728\u672c\u8282\u7684\u5176\u4f59\u90e8\u5206\u4e2d\uff0c\u6211\u4eec\u5c06\u63cf\u8ff0\u4e24\u79cd\u57fa\u4e8e\u65e7\u57fa\u6570 r \u6216\u65b0\u57fa\u6570 R \u8fdb\u884c\u7b97\u672f\u7684\u57fa\u6570\u8f6c\u6362\u65b9\u6cd5\u3002\u6211\u4eec\u8fd8\u5c06\u4ecb\u7ecd\u4e00\u79cd\u6377\u5f84\u65b9\u6cd5\uff0c\u6d89\u53ca\u5f88\u5c11\u7684\u8ba1\u7b97\uff0c\u9002\u7528\u4e8e\u65e7\u57fa\u6570\u548c\u65b0\u57fa\u6570\u662f\u76f8\u540c\u6570\u5b57\u7684\u5e42\uff08\u4f8b\u5982 8 \u548c 16\uff0c\u5b83\u4eec\u90fd\u662f 2 \u7684\u5e42\uff09\u7684\u60c5\u51b5\u3002</p> <p>\u8bf7\u6ce8\u610f\uff0c\u5728\u5c06 u \u4ece\u57fa\u6570 r \u8f6c\u6362\u4e3a\u57fa\u6570 R \u65f6\uff0c\u5176\u4e2d r \u548c R \u662f\u6b63\u6574\u6570\uff0c\u6211\u4eec\u53ef\u4ee5\u5206\u522b\u8f6c\u6362\u6574\u6570\u90e8\u5206\u548c\u5c0f\u6570\u90e8\u5206\u3002\u8fd9\u662f\u56e0\u4e3a\u6574\u6570\uff08\u5c0f\u6570\uff09\u5c31\u662f\u6574\u6570\uff08\u5c0f\u6570\uff09\uff0c\u4e0e\u6570\u5b57\u8868\u793a\u57fa\u6570\u65e0\u5173\u3002</p> <p>Doing the arithmetic in the old radix r</p> <p>We use this method when radix- r  arithmetic is more familiar or efficient. The method is useful, for example, when we do manual computations and the old radix is  r = 10. The procedures for converting the whole and fractional parts, along with their justifications or proofs, are given below. </p>"},{"location":"Part_01/01/#r","title":"\u7528\u65e7\u57fa\u6570 r \u8fdb\u884c\u7b97\u672f\u8fd0\u7b97","text":"<p>\u5f53 radix-r \u7b97\u672f\u66f4\u719f\u6089\u6216\u66f4\u6709\u6548\u65f6\uff0c\u6211\u4eec\u4f7f\u7528\u6b64\u65b9\u6cd5\u3002\u4f8b\u5982\uff0c\u5f53\u6211\u4eec\u8fdb\u884c\u624b\u52a8\u8ba1\u7b97\u5e76\u4e14\u65e7\u57fa\u6570\u4e3a r = 10 \u65f6\uff0c\u8be5\u65b9\u6cd5\u5f88\u6709\u7528\u3002\u4e0b\u9762\u7ed9\u51fa\u8f6c\u6362\u6574\u6570\u90e8\u5206\u548c\u5c0f\u6570\u90e8\u5206\u7684\u8fc7\u7a0b\u53ca\u5176\u7406\u7531\u6216\u8bc1\u660e\u3002</p> <p>Converting the whole part w</p> <p>Procedure: Repeatedly divide the integer  \\(w = (x_{k\u22121} x_{k\u22122} \u00b7 \u00b7 \u00b7 x_1 x_0 )_r\\)   by the radix- r representation of  R. The remainders are the  Xi s, with  X 0 generated first. </p> <p>Justification: \\((X_{K\u22121} X_{K\u22122} \u00b7 \u00b7 \u00b7 X_1 X_0)_R \u2212 (X_0)_R\\)  is divisible by  R. Therefore,  X 0 is the remainder of dividing the integer  \\(w = (x_{k\u22121} x_{k\u22122} \u00b7 \u00b7 \u00b7 x_1 x_0 )_r\\)  by the radix- r representation of  R. </p> <p>Example: \\(( 105 )_{ten} = (?)_{five}\\)</p> <p>\u8f6c\u6362\u6574\u6570\u90e8\u5206w</p> <p>\u8fc7\u7a0b\uff1a \u91cd\u590d\u5c06\u6574\u6570 \\(w = (x_{k\u22121} x_{k\u22122} \u00b7 \u00b7 \u00b7 x_1 x_0 )_r\\) \u9664\u4ee5 R \u7684\u57fa\u6570 r \u8868\u793a\u3002\u4f59\u6570\u662f \\(X_i\\)\uff0c\u9996\u5148\u751f\u6210 \\(X_0\\)\u3002</p> <p>\u7406\u7531\uff1a \\((X_{K\u22121} X_{K\u22122} \u00b7 \u00b7 \u00b7 X_1 X_0)_R \u2212 (X_0)_R\\) \u53ef\u88ab R \u6574\u9664\u3002\u56e0\u6b64\uff0c\\(X_0\\) \u662f\u57fa\u6570 r \u8868\u793a\u7684\u6574\u6570 \\(w = (x_{k\u22121} x_{k\u22122} \u00b7 \u00b7 \u00b7 x_1 x_0 )_r\\)  \u9664\u4ee5 R \u7684\u4f59\u6570\u3002</p> <p>\u793a\u4f8b\uff1a\\(( 105 )_{10} = (?)_{5}\\)</p> <p>\u91cd\u590d\u9664\u4ee5 5\uff1a</p> \u5546 \u4f59 105 0 21 1 4 4 0 <p>\u7efc\u4e0a\u6240\u8ff0\uff0c\u6211\u4eec\u5f97\u51fa\u7ed3\u8bba\uff1a\\((105)_{10}\uff1d(410)_5\\)\u3002</p> <p>Converting the fractional part v</p> <p>Procedure: Repeatedly multiply the fraction  \\(v = (. x_{\u22121} x_{\u22122} \\cdots x_{\u2212l})_r\\) by the radix- r representation of  R. In each step, remove the whole part before multiplying again. The whole parts obtained are the  Xi s, with  X\u22121 generated first. </p> <p>Justification: \\(R \u00d7 ( 0. X_{\u22121} X_{\u22122} \\cdots X_{\u2212L})_R = (X_{\u22121}. X_{\u22122} \\cdots X_{\u2212L})_R\\) </p> <p>Example: ( 105.486 ) ten =  ( 410.?  ) five Repeatedly multiply by 5:</p> <p>\u8f6c\u6362\u5c0f\u6570\u90e8\u5206 v</p> <p>\u8fc7\u7a0b\uff1a\u5c06\u5206\u6570 \\(v = (. x_{\u22121} x_{\u22122} \\cdots x_{\u2212l})_r\\) \u4e0e R \u7684\u57fa\u6570 r \u8868\u793a\u91cd\u590d\u76f8\u4e58\u3002\u5728\u6bcf\u4e00\u6b65\u4e2d\uff0c\u5728\u518d\u6b21\u76f8\u4e58\u4e4b\u524d\u5220\u9664\u6574\u6570\u90e8\u5206\u3002\u83b7\u5f97\u7684\u6574\u6570\u90e8\u5206\u662f \\(X_i\\) \uff0c\u9996\u5148\u751f\u6210 \\(X_{\u22121}\\) \u3002</p> <p>\u7406\u7531\uff1a\\(R \u00d7 ( 0. X_{\u22121} X_{\u22122} \\cdots X_{\u2212L})_R = (X_{\u22121}. X_{\u22122} \\cdots X_{\u2212L})_R\\)\u3002</p> <p>\u793a\u4f8b\uff1a\\((105.486)_{10} = (410.?)_{5}\\) </p> <p>\u91cd\u590d\u4e58\u4ee5 5\uff1a</p> \u6574\u4f53\u90e8\u5206 \u5c0f\u6570 .486 2 .430 2 .150 0 .750 3 .750 3 .750 <p>\u7531\u4e0a\u53ef\u77e5\uff0c\\(( 105.486 )_{10} \\approx ( 410.220 33 )_{5}\\)\u3002</p> <p>Doing the arithmetic in the new radix  *R*</p> <p>We use this method when radix- R  arithmetic is more familiar or efficient. The method is useful, for example, when we manually convert numbers to radix 10. Again, the whole and fractional parts are converted separately. </p>"},{"location":"Part_01/01/#r_1","title":"\u7528\u65b0\u57fa\u6570 R \u8fdb\u884c\u7b97\u672f\u8fd0\u7b97","text":"<p>\u5f53\u57fa R \u7b97\u672f\u66f4\u719f\u6089\u6216\u66f4\u9ad8\u6548\u65f6\uff0c\u6211\u4eec\u4f7f\u7528\u6b64\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5f88\u6709\u7528\uff0c\u4f8b\u5982\uff0c\u5f53\u6211\u4eec\u624b\u52a8\u5c06\u6570\u5b57\u8f6c\u6362\u4e3a\u57fa\u6570 10 \u65f6\u3002\u540c\u6837\uff0c\u6574\u6570\u90e8\u5206\u548c\u5c0f\u6570\u90e8\u5206\u662f\u5206\u5f00\u8f6c\u6362\u7684\u3002</p> <p>Converting the whole part w</p> <p>Procedure: Use repeated multiplications by  r  followed by additions according to the formula  ((\u00b7 \u00b7 \u00b7  ((xk\u22121 r +  xk\u22122 )r +  xk\u22123 )r + \u00b7 \u00b7 \u00b7  )r +  x 1 )r +  x 0. </p> <p>Justification: The given formula is the well-known Horner\u2019s method (or rule), first presented in the early nineteenth century, for the evaluation of the  (k \u2212 1 ) th-degree polynomial  xk\u22121 rk\u22121 +  xk\u22122 rk\u22122 + \u00b7 \u00b7 \u00b7 +  x 1 r +  x 0 [Knut97]. </p> <p>Example: ( 410 ) five =  (?  ) ten</p> <p>\u8f6c\u6362\u6574\u6570\u90e8\u5206w</p> <p>\u6b65\u9aa4\uff1a\u6839\u636e\u516c\u5f0f \\(((\u00b7\u00b7\u00b7((x_{k\u22121} r + x_{k\u22122} )r + x_{k\u22123} )r +\u00b7\u00b7\u00b7)r + x_1 )r + x_0\\) \u91cd\u590d\u4e58\u4ee5 r\uff0c\u7136\u540e\u8fdb\u884c\u52a0\u6cd5\u3002</p> <p>\u7406\u7531\uff1a\u7ed9\u5b9a\u7684\u516c\u5f0f\u662f\u8457\u540d\u7684\u970d\u7eb3\u65b9\u6cd5\uff08\u6216\u89c4\u5219\uff09\uff0c\u9996\u6b21\u63d0\u51fa\u4e8e\u5341\u4e5d\u4e16\u7eaa\u521d\uff0c\u7528\u4e8e\u5bf9\\((k \u2212 1 )\\)\u6b21\u591a\u9879\u5f0f \\(x_{k\u22121} r^{k\u22121} + x_{k\u22122} r^{k\u22122} + \u00b7 \u00b7 \u00b7 + x_1 r + x_0\\) \u6c42\u503c [Knut97] \u3002</p> <p>\u793a\u4f8b\uff1a\\(( 410 )_{5} = (?)_{10}\\)</p> \\[ (( 4 \u00d7 5 ) + 1 ) \u00d7 5 + 0 = 105 \u21d2 ( 410 )_5 = ( 105 )_{10} \\] <p>Converting the fractional part v</p> <p>Procedure: Convert the integer  rl \u00d7  ( 0.  v)  and then divide by  rl  in the new radix. </p> <p>Justification: rl \u00d7  ( 0.  v)/rl = 0.  v</p> <p>Example: ( 410.220 33 ) five =  ( 105.?  ) ten ( 0.220 33 ) five \u00d7 55 =  ( 22 033 ) five =  ( 1518 ) ten 1518 / 55 = 1518 / 3125 = 0.485 76</p> <p>\u8f6c\u6362\u5c0f\u6570\u90e8\u5206 v</p> <p>\u8fc7\u7a0b\uff1a\u5c06\u6574\u6570 \\(r^l \u00d7 ( 0. v)\\) \u8f6c\u6362\uff0c\u7136\u540e\u9664\u4ee5\u65b0\u57fa\u6570\u4e2d\u7684 \\(r^l\\)\u3002</p> <p>\u7406\u7531\uff1a\\(r^l\u00d7(0.v)/r^l=0.v\\)</p> <p>\u793a\u4f8b\uff1a$ ( 410.220 33 )_ = ( 105.? )_{10} $</p> \\[ \\begin{array}{l} ( 0.220 33 )_5 \u00d7 5^5 = ( 22 033 )_5 = ( 1518 )_{10} \\\\  1518 / 5^5 = 1518 / 3125 = 0.485 76 \\end{array} \\] <p>From the above, we conclude that  ( 410.220 33 ) five =  ( 105.485 76 ) ten. </p> <p>\u7efc\u4e0a\u6240\u8ff0\uff0c\u6211\u4eec\u5f97\u51fa\u7ed3\u8bba\uff1a( 410.220 33 )\\(_5\\) = ( 105.485 76 ) \\(_{10}\\)\u3002</p> <p>Note: Horner\u2019s method works here as well but is generally less practical. The digits of the fractional part are processed from right to left and the multiplication operation is replaced with division. Figure 1.3 shows how Horner\u2019s method can be applied to the preceding example. </p> <p>\u6ce8\u610f\uff1a\u970d\u7eb3\u7684\u65b9\u6cd5\u5728\u8fd9\u91cc\u4e5f\u9002\u7528\uff0c\u4f46\u901a\u5e38\u4e0d\u592a\u5b9e\u7528\u3002\u5c0f\u6570\u90e8\u5206\u7684\u6570\u5b57\u4ece\u53f3\u5411\u5de6\u5904\u7406\uff0c\u4e58\u6cd5\u8fd0\u7b97\u6539\u4e3a\u9664\u6cd5\u8fd0\u7b97\u3002\u56fe 1.3 \u663e\u793a\u4e86\u970d\u7eb3\u65b9\u6cd5\u5982\u4f55\u5e94\u7528\u4e8e\u524d\u9762\u7684\u793a\u4f8b\u3002</p> <p></p> <p>\u56fe 1.3 \u7528\u4e8e\u5c06 \\((.220 33 )_5\\) \u8f6c\u6362\u4e3a\u5341\u8fdb\u5236\u7684\u970d\u7eb3\u89c4\u5219\u3002</p> <p>Shortcut method for  *r* =  *bg* and  *R* =  *bG*</p>"},{"location":"Part_01/01/#r-bg-r-bg","title":"\\(r = b^g\\) \u548c \\(R = b^G\\) \u7684\u5feb\u6377\u65b9\u6cd5","text":"<p>In the special case when the old and new radices are integral powers of a common base  b, that is,  r =  bg  and  R =  bG, one can convert from radix  r  to radix  b  and then from radix  b to radix  R. Both these conversions are quite simple and require virtually no computation. </p> <p>\u5728\u7279\u6b8a\u60c5\u51b5\u4e0b\uff0c\u5f53\u65b0\u65e7\u57fa\u6570\u662f\u5171\u540c\u57fa\u6570 b \u7684\u6574\u6570\u5e42\u65f6\uff0c\u5373 \\(r = b^g\\) \u548c \\(R = b^G\\)\uff0c\u53ef\u4ee5\u4ece\u57fa\u6570 r \u8f6c\u6362\u4e3a\u57fa\u6570 b\uff0c\u7136\u540e\u4ece\u57fa\u6570 b \u8f6c\u6362\u4e3a\u57fa\u6570 R\u3002\u8fd9\u4e24\u79cd\u8f6c\u6362\u90fd\u975e\u5e38\u7b80\u5355\uff0c\u51e0\u4e4e\u4e0d\u9700\u8981\u8ba1\u7b97\u3002</p> <p>To convert from the old radix  r =  bg  to radix  b, simply convert each radix- r digit individually into a  g-digit radix- b  number and then juxtapose the resulting  g-digit numbers. </p> <p>\u8981\u4ece\u65e7\u7684\u57fa\u6570 \\(r = b^g\\) \u8f6c\u6362\u4e3a\u57fa\u6570 b\uff0c\u53ea\u9700\u5c06\u6bcf\u4e2a\u57fa\u6570 r \u6570\u5b57\u5355\u72ec\u8f6c\u6362\u4e3a g \u4f4d\u57fa\u6570 b \u6570\u5b57\uff0c\u7136\u540e\u5c06\u6240\u5f97\u7684 g \u4f4d\u6570\u5b57\u5e76\u7f6e\u5373\u53ef\u3002</p> <p>To convert from radix  b  to the new radix  R =  bG, form  G-digit groups of the radix- b digits starting from the radix point (to the left and to the right). Then convert the  G-digit radix- b  number of each group into a single radix- R  digit and juxtapose the resulting digits. </p> <p>\u8981\u5c06\u57fa\u6570 b \u8f6c\u6362\u4e3a\u65b0\u7684\u57fa\u6570 \\(R = b^G\\)\uff0c\u8bf7\u4ece\u57fa\u6570\u70b9\u5f00\u59cb\uff08\u5411\u5de6\u548c\u5411\u53f3\uff09\u5f62\u6210\u57fa\u6570 b \u6570\u5b57\u7684 G \u4f4d\u6570\u5b57\u7ec4\u3002\u7136\u540e\u5c06\u6bcf\u7ec4\u7684 G \u4f4d\u57fa\u6570 b \u6570\u8f6c\u6362\u4e3a\u5355\u4e2a\u57fa\u6570 R \u6570\uff0c\u5e76\u5c06\u6240\u5f97\u6570\u5b57\u5e76\u7f6e\u3002</p> <p>EXAMPLE 1.8 ( 2 301.302 ) four =  (?  ) eight We have 4 = 22 and 8 = 23. Thus, conversion through the intermediate radix 2 is used. </p> <p>Each radix-4 digit is independently replaced by a 2-bit radix-2 number. This is followed by 3-bit groupings of the resulting binary digits to find the radix-8 digits. </p> <p>**\u793a\u4f8b**1.8 ( 2 301.302 ) 4 = (?) 8 \u6211\u4eec\u67094 = 22 \u548c8 = 23\u3002\u56e0\u6b64\uff0c\u4f7f\u7528\u901a\u8fc7\u4e2d\u95f4\u57fa\u65702 \u8fdb\u884c\u7684\u8f6c\u6362\u3002</p> <p>\u6bcf\u4e2a radix-4 \u6570\u5b57\u72ec\u7acb\u5730\u66ff\u6362\u4e3a 2 \u4f4d radix-2 \u6570\u5b57\u3002\u63a5\u4e0b\u6765\u662f\u5bf9\u6240\u5f97\u4e8c\u8fdb\u5236\u6570\u5b57\u8fdb\u884c 3 \u4f4d\u5206\u7ec4\u4ee5\u67e5\u627e\u57fa\u6570 8 \u6570\u5b57\u3002</p> \\[ \\begin{array}{l} (2 301.302)_4 &amp;= \\frac{(10}{2}\\frac{11}{3}\\frac{00}{0}\\frac{01}{1}\\frac{.11}{3}\\frac{00}{0}\\frac{10)}{2}\\text{two} \\\\ &amp;=\\frac{(10}{2}\\frac{110}{6}\\frac{001}{1}\\frac{.110}{6}\\frac{010)}{2}\\text{two} = (261.62)_{8} \\end{array} \\] <p>Clearly, when  g = 1 (G = 1 ), the first (second) step of the shortcut conversion procedure is eliminated. This corresponds to the special case of  R =  rG(r =  Rg). For example, conversions between radix 2 and radix 8 or 16 belong to these special cases. </p> <p>\u663e\u7136\uff0c\u5f53g=1\uff08G=1\uff09\u65f6\uff0c\u5feb\u6377\u8f6c\u6362\u8fc7\u7a0b\u7684\u7b2c\u4e00\uff08\u6216\u7b2c\u4e8c\uff09\u6b65\u9aa4\u88ab\u6d88\u9664\u3002\u8fd9\u5bf9\u5e94\u4e8e \\(R = r^G\\)(\\(r = R^g\\)) \u7684\u7279\u6b8a\u60c5\u51b5\u3002\u4f8b\u5982\uff0c\u57fa\u6570 2 \u548c\u57fa\u6570 8 \u6216 16 \u4e4b\u95f4\u7684\u8f6c\u6362\u5c31\u5c5e\u4e8e\u8fd9\u4e9b\u7279\u6b8a\u60c5\u51b5\u3002</p> <p>1.6 CLASSES OF NUMBER REPRESENTATIONS</p>"},{"location":"Part_01/01/#16","title":"1.6 \u6570\u5b57\u8868\u793a\u7684\u7c7b\u522b","text":"<p>In Sections 1.4 and 1.5, we considered the representation of unsigned fixed-point numbers using fixed-radix number systems, with standard and nonstandard digit sets, as well as methods for converting between such representations with standard digit sets. In digital computations, we also deal with signed fixed-point numbers as well as signed and unsigned real values. Additionally, we may use unconventional representations for the purpose of speeding up arithmetic operations or increasing their accuracy. Understanding different ways of representing numbers, including their relative cost-performance benefits and conversions between various representations, is an important prerequisite for designing efficient arithmetic algorithms or circuits. </p> <p>\u5728\u7b2c 1.4 \u8282\u548c\u7b2c 1.5 \u8282\u4e2d\uff0c\u6211\u4eec\u8003\u8651\u4e86\u4f7f\u7528\u56fa\u5b9a\u57fa\u6570\u7cfb\u7edf\u3001\u6807\u51c6\u548c\u975e\u6807\u51c6\u6570\u5b57\u96c6\u6765\u8868\u793a\u65e0\u7b26\u53f7\u5b9a\u70b9\u6570\uff0c\u4ee5\u53ca\u5728\u8fd9\u79cd\u8868\u793a\u4e0e\u6807\u51c6\u6570\u5b57\u96c6\u4e4b\u95f4\u8fdb\u884c\u8f6c\u6362\u7684\u65b9\u6cd5\u3002\u5728\u6570\u5b57\u8ba1\u7b97\u4e2d\uff0c\u6211\u4eec\u8fd8\u5904\u7406\u5e26\u7b26\u53f7\u7684\u5b9a\u70b9\u6570\u4ee5\u53ca\u5e26\u7b26\u53f7\u548c\u65e0\u7b26\u53f7\u7684\u5b9e\u6570\u503c\u3002\u6b64\u5916\uff0c\u6211\u4eec\u53ef\u80fd\u4f1a\u4f7f\u7528\u975e\u5e38\u89c4\u8868\u793a\u6765\u52a0\u901f\u7b97\u672f\u8fd0\u7b97\u6216\u63d0\u9ad8\u5176\u51c6\u786e\u6027\u3002\u4e86\u89e3\u8868\u793a\u6570\u5b57\u7684\u4e0d\u540c\u65b9\u5f0f\uff0c\u5305\u62ec\u5b83\u4eec\u7684\u76f8\u5bf9\u6027\u4ef7\u6bd4\u4f18\u52bf\u4ee5\u53ca\u5404\u79cd\u8868\u793a\u4e4b\u95f4\u7684\u8f6c\u6362\uff0c\u662f\u8bbe\u8ba1\u9ad8\u6548\u7b97\u672f\u7b97\u6cd5\u6216\u7535\u8def\u7684\u91cd\u8981\u5148\u51b3\u6761\u4ef6\u3002</p> <p>In the next three chapters, we will review techniques for representing fixed-point numbers, beginning with conventional methods and then moving on to some unconventional representations. </p> <p>\u5728\u63a5\u4e0b\u6765\u7684\u4e09\u7ae0\u4e2d\uff0c\u6211\u4eec\u5c06\u56de\u987e\u8868\u793a\u5b9a\u70b9\u6570\u7684\u6280\u672f\uff0c\u4ece\u4f20\u7edf\u65b9\u6cd5\u5f00\u59cb\uff0c\u7136\u540e\u8f6c\u5411\u4e00\u4e9b\u975e\u5e38\u89c4\u7684\u8868\u793a\u3002</p> <p>Signed fixed-point numbers, including various ways of representing and handling the sign information, are covered in Chapter 2. Signed-magnitude, biased, and complement representations (including both 1\u2019s and 2\u2019s complement) are covered in some detail. </p> <p>\u7b2c 2 \u7ae0\u4ecb\u7ecd\u4e86\u6709\u7b26\u53f7\u5b9a\u70b9\u6570\uff0c\u5305\u62ec\u8868\u793a\u548c\u5904\u7406\u7b26\u53f7\u4fe1\u606f\u7684\u5404\u79cd\u65b9\u5f0f\u3002\u8fd8\u8be6\u7ec6\u4ecb\u7ecd\u4e86\u6709\u7b26\u53f7\u6570\u503c\u3001\u504f\u7f6e\u548c\u8865\u7801\u8868\u793a\uff08\u5305\u62ec 1 \u548c 2 \u7684\u8865\u7801\uff09\u3002</p> <p>The signed-digit number systems of Chapter 3 can also be viewed as methods for representing signed numbers, although their primary significance lies in the redundancy that allows addition without carry propagation. The material in Chapter 3 is essential for understanding several speedup methods in multiplication, division, and function evaluation. </p> <p>\u7b2c 3 \u7ae0\u7684\u6709\u7b26\u53f7\u6570\u5b57\u7cfb\u7edf\u4e5f\u53ef\u4ee5\u88ab\u89c6\u4e3a\u8868\u793a\u6709\u7b26\u53f7\u6570\u65b9\u6cd5\uff0c\u5c3d\u7ba1\u5b83\u4eec\u7684\u4e3b\u8981\u610f\u4e49\u5728\u4e8e\u5141\u8bb8\u52a0\u6cd5\u800c\u65e0\u9700\u8fdb\u4f4d\u4f20\u64ad\u7684\u5197\u4f59\u3002\u7b2c 3 \u7ae0\u4e2d\u7684\u6750\u6599\u5bf9\u4e8e\u7406\u89e3\u4e58\u6cd5\u3001\u9664\u6cd5\u548c\u51fd\u6570\u6c42\u503c\u4e2d\u7684\u51e0\u79cd\u52a0\u901f\u65b9\u6cd5\u81f3\u5173\u91cd\u8981\u3002</p> <p>Chapter 4 introduces residue number systems (for representing unsigned or signed integers) that allow some arithmetic operations to be performed in a truly parallel fashion at very high speed. Unfortunately, the difficulty of division and certain other arithmetic operations renders these number systems unsuitable for general applications. In Chapter 4, we also use residue representations to explore the limits of fast arithmetic. </p> <p>\u7b2c 4 \u7ae0\u4ecb\u7ecd\u4e86**\u5269\u4f59\u6570**\u7cfb\u7edf\uff08\u7528\u4e8e\u8868\u793a\u65e0\u7b26\u53f7\u6216\u6709\u7b26\u53f7\u6574\u6570\uff09\uff0c\u8be5\u7cfb\u7edf\u5141\u8bb8\u4ee5\u771f\u6b63\u5e76\u884c\u7684\u65b9\u5f0f\u4ee5\u975e\u5e38\u9ad8\u7684\u901f\u5ea6\u6267\u884c\u67d0\u4e9b\u7b97\u672f\u8fd0\u7b97\u3002\u4e0d\u5e78\u7684\u662f\uff0c\u9664\u6cd5\u548c\u67d0\u4e9b\u5176\u4ed6\u7b97\u672f\u8fd0\u7b97\u7684\u56f0\u96be\u4f7f\u5f97\u8fd9\u4e9b\u6570\u5b57\u7cfb\u7edf\u4e0d\u9002\u5408\u4e00\u822c\u5e94\u7528\u3002\u5728\u7b2c 4 \u7ae0\u4e2d\uff0c\u6211\u4eec\u8fd8\u4f7f\u7528**\u7559\u6570**\u8868\u793a\u6765\u63a2\u7d22\u5feb\u901f\u7b97\u672f\u7684\u5c40\u9650\u6027\u3002</p> <p>Representation of real numbers can take different forms. Examples include slash number systems (for representing rational numbers), logarithmic number systems (for representing real values), and of course, floating-point numbers that constitute the primary noninteger data format in modern digital systems. These representations are discussed in Chapter 17 (introductory chapter of Part V), immediately before we deal with algorithms, hardware implementations, and error analyses for real-number arithmetic. </p> <p>\u5b9e\u6570\u7684\u8868\u793a\u53ef\u4ee5\u91c7\u7528\u4e0d\u540c\u7684\u5f62\u5f0f\u3002\u793a\u4f8b\u5305\u62ec\u659c\u6760\u6570\u5b57\u7cfb\u7edf\uff08\u7528\u4e8e\u8868\u793a\u6709\u7406\u6570\uff09\u3001\u5bf9\u6570\u6570\u5b57\u7cfb\u7edf\uff08\u7528\u4e8e\u8868\u793a\u5b9e\u6570\u503c\uff09\uff0c\u5f53\u7136\u8fd8\u6709\u6784\u6210\u73b0\u4ee3\u6570\u5b57\u7cfb\u7edf\u4e2d\u4e3b\u8981\u975e\u6574\u6570\u6570\u636e\u683c\u5f0f\u7684\u6d6e\u70b9\u6570\u3002\u5728\u6211\u4eec\u8ba8\u8bba\u5b9e\u6570\u7b97\u672f\u7684\u7b97\u6cd5\u3001\u786c\u4ef6\u5b9e\u73b0\u548c\u8bef\u5dee\u5206\u6790\u4e4b\u524d\uff0c\u6211\u4eec\u5c06\u5728\u7b2c 17 \u7ae0\uff08\u7b2c\u4e94\u90e8\u5206\u7684\u4ecb\u7ecd\u6027\u7ae0\u8282\uff09\u4e2d\u8ba8\u8bba\u8fd9\u4e9b\u8868\u793a\u5f62\u5f0f\u3002</p> <p>By combining features from two or more of the aforementioned \u201cpure\u201d representations, we can obtain many hybrid schemes. Examples include hybrid binary/signed-digit (see Section 3.4), hybrid residue/binary (see Section 4.5), hybrid logarithmic/signed-digit (see Section 17.6), and hybrid floating-point/logarithmic (see Problem 17.16) representations. </p> <p>\u901a\u8fc7\u7ec4\u5408\u6765\u81ea\u4e24\u4e2a\u6216\u591a\u4e2a\u4e0a\u8ff0\u201c\u7eaf\u201d\u4ee3\u8868\u7684\u7279\u5f81, \u6211\u4eec\u53ef\u4ee5\u83b7\u5f97\u8bb8\u591a\u6df7\u5408\u65b9\u6848\u3002\u793a\u4f8b\u5305\u62ec\u6df7\u5408\u4e8c\u8fdb\u5236/\u7b26\u53f7\u6570\u5b57\uff08\u53c2\u89c1\u7b2c 3.4 \u8282\uff09\u3001\u6df7\u5408\u7559\u6570/\u4e8c\u8fdb\u5236\uff08\u53c2\u89c1\u7b2c 4.5 \u8282\uff09\u3001\u6df7\u5408\u5bf9\u6570/\u7b26\u53f7\u6570\u5b57\uff08\u53c2\u89c1\u7b2c 17.6 \u8282\uff09\u548c\u6df7\u5408\u6d6e\u70b9/\u5bf9\u6570\uff08\u53c2\u89c1\u95ee\u9898 17.16\uff09\u8868\u793a\u3002</p> <p>This is a good place to introduce a notational tool, that we will find quite useful throughout the book. The established dot notation uses heavy dots to represent standard or positively-weighted bits, which we may call posibits. For example, Fig. 1.4a represents the addition of two 4-bit unsigned binary numbers whose posibits have weights \\(1\u30012\u30012^2\\) and \\(2^3\\), from right to left, and whose sum is a 5-bit number. Figure 1.4b depicts the pencil-and-paper algorithm for multiplying two 4-bit unsigned binary numbers, producing four partial products and then adding them, with proper alignments, to derive the 8-bit final result. We will see later that negatively weighted bits, or negabits, are also quite useful, prompting us to introduce the extended dot notation (see Section 2.6). </p> <p>\u8fd9\u662f\u4ecb\u7ecd\u7b26\u53f7\u5de5\u5177\u7684\u597d\u5730\u65b9\uff0c\u6211\u4eec\u4f1a\u53d1\u73b0\u5b83\u5728\u6574\u672c\u4e66\u4e2d\u975e\u5e38\u6709\u7528\u3002\u65e2\u5b9a\u7684\u70b9\u8868\u793a\u6cd5\u4f7f\u7528\u7c97\u70b9\u6765\u8868\u793a\u6807\u51c6\u6216\u6b63\u52a0\u6743\u4f4d\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u5176\u79f0\u4e3a posibits\u3002\u4f8b\u5982\uff0c\u56fe1.4a\u8868\u793a\u4e24\u4e2a4\u4f4d\u65e0\u7b26\u53f7\u4e8c\u8fdb\u5236\u6570\u7684\u76f8\u52a0\uff0c\u5176\u4f4d\u7f6e\u4f4d\u7684\u6743\u91cd\u4ece\u53f3\u5230\u5de6\u5206\u522b\u4e3a\\(1\u30012\u30012^2\\)\u548c\\(2^3\\)\uff0c\u5176\u548c\u4e3a5\u4f4d\u6570\u3002\u56fe1.4b \u63cf\u8ff0\u4e86\u7eb8\u7b14\u7b97\u6cd5\uff0c\u7528\u4e8e\u5c06\u4e24\u4e2a 4 \u4f4d\u65e0\u7b26\u53f7\u4e8c\u8fdb\u5236\u6570\u76f8\u4e58\uff0c\u4ea7\u751f\u56db\u4e2a\u90e8\u5206\u79ef\uff0c\u7136\u540e\u5c06\u5b83\u4eec\u76f8\u52a0\uff0c\u5e76\u8fdb\u884c\u9002\u5f53\u7684\u5bf9\u9f50\uff0c\u4ee5\u83b7\u5f97 8 \u4f4d\u6700\u7ec8\u7ed3\u679c\u3002\u7a0d\u540e\u6211\u4eec\u5c06\u770b\u5230\u8d1f\u6743\u91cd\u4f4d\u6216\u8d1f\u4f4d\u4e5f\u975e\u5e38\u6709\u7528\uff0c\u4fc3\u4f7f\u6211\u4eec\u5f15\u5165\u6269\u5c55\u70b9\u8868\u793a\u6cd5\uff08\u53c2\u89c1\u7b2c 2.6 \u8282\uff09\u3002</p> <p></p> <p>A final point before we conclude this chapter: You can be a proficient arithmetic designer knowing only the following three key number representation systems and their properties:</p> <ul> <li> <p>2\u2019s-complement format (Section 2.4)</p> </li> <li> <p>Binary stored-carry or carry-save format (Section 3.2)</p> </li> <li> <p>Binary floating-point format (Chapter 17)</p> </li> </ul> <p>\u5728\u7ed3\u675f\u672c\u7ae0\u4e4b\u524d\uff0c\u6700\u540e\u4e00\u70b9\u662f\uff1a\u60a8\u53ef\u4ee5\u6210\u4e3a\u4e00\u540d\u719f\u7ec3\u7684\u7b97\u672f\u8bbe\u8ba1\u8005\uff0c\u53ea\u9700\u4e86\u89e3\u4ee5\u4e0b\u4e09\u4e2a\u5173\u952e\u6570\u5b57\u8868\u793a\u7cfb\u7edf\u53ca\u5176\u5c5e\u6027\uff1a</p> <ul> <li>2 \u7684\u8865\u7801\u683c\u5f0f\uff08\u7b2c 2.4 \u8282\uff09</li> <li>\u4e8c\u8fdb\u5236\u5b58\u50a8\u8fdb\u4f4d\u6216\u8fdb\u4f4d\u4fdd\u5b58\u683c\u5f0f\uff08\u7b2c 3.2 \u8282\uff09</li> <li>\u4e8c\u8fdb\u5236\u6d6e\u70b9\u683c\u5f0f\uff08\u7b2c 17 \u7ae0\uff09</li> </ul> <p>All the other formats, discussed in Chapters 2-4, are useful for optimizing application-specific designs or to gain a deeper understanding of the issues involved, but you can ignore them with no serious harm. There are indications, however, that decimal arithmetic may regain the importance it once had, because it avoids errors in the conversion between human-readable numbers and their machine representations.</p> <p>\u7b2c 2~4 \u7ae0\u4e2d\u8ba8\u8bba\u7684\u6240\u6709\u5176\u4ed6\u683c\u5f0f\u5bf9\u4e8e\u4f18\u5316\u7279\u5b9a\u4e8e\u5e94\u7528\u7a0b\u5e8f\u7684\u8bbe\u8ba1\u6216\u6df1\u5165\u4e86\u89e3\u6240\u6d89\u53ca\u7684\u95ee\u9898\u5f88\u6709\u7528\uff0c\u4f46\u60a8\u53ef\u4ee5\u5ffd\u7565\u5b83\u4eec\uff0c\u4e0d\u4f1a\u9020\u6210\u4e25\u91cd\u635f\u5bb3\u3002\u7136\u800c\uff0c\u6709\u8ff9\u8c61\u8868\u660e\uff0c\u5341\u8fdb\u5236\u7b97\u672f\u53ef\u80fd\u4f1a\u6062\u590d\u5176\u66fe\u7ecf\u7684\u91cd\u8981\u6027\uff0c\u56e0\u4e3a\u5b83\u907f\u514d\u4e86\u4eba\u7c7b\u53ef\u8bfb\u6570\u5b57\u4e0e\u5176\u673a\u5668\u8868\u793a\u4e4b\u95f4\u7684\u8f6c\u6362\u9519\u8bef\u3002</p>"},{"location":"Part_01/01/#_1","title":"\u95ee\u9898","text":""},{"location":"Part_01/01/#_2","title":"\u53c2\u8003\u6587\u732e\u548c\u8fdb\u4e00\u6b65\u9605\u8bfb","text":"<pre><code>[Dimi03]    Dimitrov, V. S., and G. A. Jullien, \u201cLoading the Bases: A New Number Representation\n            with Applications,\u201d IEEE Circuits and Systems, Vol. 3, No. 2, pp. 6\u201323, 2003.\n[GAO92]     General Accounting Office, \u201cPatriot Missile Defense: Software Problem Led to\n            System Failure at Dhahran, Saudi Arabia,\u201d US Government Report\n            GAO/IMTEC-92-26, 1992.\n[Knut97]    Knuth, D. E., The Art of Computer Programming, 3rd ed., Vol. 2: Seminumerical\n            Algorithms, Addison-Wesley, 1997.\n[Lion96]    Lions, J. L., \u201cAriane 5 Flight 505 Failure,\u201d Report by the Inquiry Board, July 19, 1996.\n[Loh02]     Loh, E., and G. W. Walster, \u201cRump\u2019s Example Revisited,\u201d Reliable Computing, Vol.\n            8, pp. 245\u2013248, 2002.\n[Mole95]    Moler, C., \u201cA Tale of Two Numbers,\u201d SIAM News, Vol. 28, No. 1, pp. 1, 16, 1995.\n[Parh92]    Parhami, B., \u201cSystolic Number Radix Converters,\u201d Computer J., Vol. 35, No. 4, pp.\n            405\u2013409, August 1992.\n[Parh02]    Parhami, B., \u201cNumber Representation and Computer Arithmetic,\u201d Encyclopedia of\n            Information Systems, Academic Press, Vol. 3, pp. 317\u2013333, 2002.\n[Scot85]    Scott, N. R., Computer Number Systems and Arithmetic, Prentice-Hall, 1985.\n[Silv06]    Silverman, J. H., A Friendly Introduction to Number Theory, Pearson, 2006.\n[Stol04]    Stoll, C., \u201cThe Curious History of the First Pocket Calculator,\u201dScientific American,\n            Vol. 290, No. 1, pp. 92\u201399, January 2004.\n[Thim95]    Thimbleby, H., \u201cA New Calculator and Why It Is Necessary,\u201d Computer J., Vol. 38,\n            No. 6, pp. 418\u2013433, 1995.\n</code></pre>"},{"location":"Part_01/02/","title":"2. \u6709\u7b26\u53f7\u6570\u7684\u8868\u793a","text":"<p>\u201cThis can\u2019t be right . . . it goes into the red!\u201d</p> <p>LITTLE BOY, WHEN ASKED TO SUBTRACT 36 FROM 24 ( CAPTION ON A CARTOON BY UNKNOWN ARTIST)</p> <p>\u201c\u8fd9\u4e0d\u5bf9\u554a\u2026 \u2026\u8981\u6807\u7ea2(\u6b20\u94b1)\u4e86\uff01\u201d</p> <p>\u5f53\u5c0f\u7537\u5b69\u88ab\u8981\u6c42\u4ece 24 \u4e2d\u51cf\u53bb36 \u65f6\uff08\u5361\u901a\u4e0a\u7684\u5b57\u5e55\uff0c\u65e0\u540d\u827a\u672f\u5bb6\uff09</p> <p>This chapter deals with the representation of signed fixed-point numbers by providing an attached sign bit, adding a fixed bias to all numbers, complementing negative values, attaching signs to digit positions, or using signed digits. In view of its importance in the design of fast arithmetic algorithms and hardware, representing signed fixed-point numbers by means of signed digits is further explored in Chapter 3. Chapter topics include:</p> <p>\u672c\u7ae0\u8ba8\u8bba\u6709\u7b26\u53f7\u5b9a\u70b9\u6570\u7684\u8868\u793a\uff0c\u901a\u8fc7\u9644\u52a0\u7b26\u53f7\u4f4d\uff0c\u4e3a\u6240\u6709\u6570\u5b57\u6dfb\u52a0\u56fa\u5b9a\u504f\u5dee\uff0c\u5bf9\u8d1f\u503c\u6c42\u8865\u3001\u5728\u6570\u5b57\u4f4d\u4e0a\u9644\u52a0\u7b26\u53f7\u6216\u4f7f\u7528\u5e26\u7b26\u53f7\u7684\u6570\u5b57\u7b49\u65b9\u6cd5\u3002\u9274\u4e8e\u5176\u5728\u5feb\u901f\u7b97\u672f\u7b97\u6cd5\u548c\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u7b2c 3 \u7ae0\u5c06\u8fdb\u4e00\u6b65\u63a2\u8ba8\u7528\u6709\u7b26\u53f7\u6570\u5b57\u8868\u793a\u6709\u7b26\u53f7\u5b9a\u70b9\u6570\u3002\u672c\u7ae0\u4e3b\u9898\u5305\u62ec\uff1a</p> <p>2.1 \u7b26\u53f7\u5e45\u5ea6\u8868\u793a\u6cd5 Signed-Magnitude Representation</p> <p>2.2 \u504f\u7f6e\u8868\u793a\u6cd5 Biased Representations</p> <p>2.3 \u8865\u7801\u8868\u793a Complement Representations</p> <p>2.4 2 \u548c 1 \u7684\u8865\u7801\u6570 2\u2019s- and 1\u2019s-Complement Numbers</p> <p>2.5 \u76f4\u63a5\u548c\u95f4\u63a5\u6709\u7b26\u53f7\u7b97\u672fDirect and Indirect Signed Arithmetic</p> <p>2.6 \u4f7f\u7528\u5e26\u7b26\u53f7\u4f4d\u7f6e\u6216\u5e26\u7b26\u53f7\u6570\u5b57 Using Signed Positions or Signed Digits</p>"},{"location":"Part_01/02/#21","title":"2.1 \u7b26\u53f7\u5e45\u5ea6\u8868\u793a\u6cd5","text":"<p>The natural numbers 0, 1, 2,  . . . ,  max  can be represented as fixed-point numbers without fractional parts (refer to Section 1.4). In radix  r, the number  k  of digits needed for representing the natural numbers up to  max  is</p> <p>\u81ea\u7136\u6570 0, 1, 2, . \u3002 \u3002 , max \u53ef\u4ee5\u8868\u793a\u4e3a\u6ca1\u6709\u5c0f\u6570\u90e8\u5206\u7684\u5b9a\u70b9\u6570\uff08\u8bf7\u53c2\u9605\u7b2c 1.4 \u8282\uff09\u3002\u5728\u57fa\u6570 r \u4e2d\uff0c\u8868\u793a\u6700\u5927\u5230 max \u7684\u81ea\u7136\u6570\u6240\u9700\u7684\u4f4d\u6570 k \u4e3a</p> \\[ k=\\left \\lfloor \\log_r{max}\\right \\rfloor + 1= \\left \\lceil \\log_r(max+1) \\right \\rceil \\] <p></p> <p>Conversely, with  k  digits, one can represent the values 0 through  \\(r^k \u2212 1\\), inclusive; that is, the intervalo \\([0, r^k \u2212 1] = [0, r^k )\\)f natural numbers. </p> <p>\u76f8\u53cd\uff0c\u5bf9\u4e8e \\(k\\) \u4f4d\u6570\u5b57\uff0c\u53ef\u4ee5\u8868\u793a\u503c \\(0\\) \u5230  \\(r^k \u2212 1\\)\uff08\u542b\u7aef\u70b9\uff09\uff1b\u5373\u81ea\u7136\u6570\u7684\u533a\u95f4 \\([0, r^k \u2212 1] = [0, r^k )\\)\u3002</p> <p>Natural numbers are often referred to as \u201cunsigned integers,\u201d which form a special data type in many programming languages and computer instruction sets. The advantage of using this data type as opposed to \u201cintegers\u201d when the quantities of interest are known to be nonnegative is that a larger representation range can be obtained (e.g., maximum value of 255, rather than 127, with 8 bits). </p> <p>\u81ea\u7136\u6570\u901a\u5e38\u88ab\u79f0\u4e3a\u201c\u65e0\u7b26\u53f7\u6574\u6570\u201d\uff0c\u5b83\u5728\u8bb8\u591a\u7f16\u7a0b\u8bed\u8a00\u548c\u8ba1\u7b97\u673a\u6307\u4ee4\u96c6\u4e2d\u5f62\u6210\u4e00\u79cd\u7279\u6b8a\u7684\u6570\u636e\u7c7b\u578b\u3002\u5f53\u5df2\u77e5\u611f\u5174\u8da3\u7684\u91cf\u4e3a\u975e\u8d1f\u65f6\uff0c\u4f7f\u7528\u6b64\u6570\u636e\u7c7b\u578b\u800c\u4e0d\u662f\u201c\u6574\u6570\u201d\u7684\u4f18\u70b9\u662f\u53ef\u4ee5\u83b7\u5f97\u66f4\u5927\u7684\u8868\u793a\u8303\u56f4\uff08\u4f8b\u5982\uff0c\u6700\u5927\u503c\u4e3a 255\uff0c\u800c\u4e0d\u662f 8 \u4f4d\u7684 127\uff09\u3002</p> <p>One way to represent both positive and negative integers is to use \u201csigned magnitudes,\u201d or the sign-and-magnitude format, in which 1 bit is devoted to sign. The common convention is to let 1 denote a negative sign and 0 a positive sign. In the case of radix-2 numbers with a total width of  k  bits,  k \u22121 bits will be available to represent the magnitude or absolute value of the number. The range of  k-bit signed-magnitude binary numbers is thus [\u2212 ( 2 k\u22121 \u2212 1 ), 2 k\u22121 \u2212 1]. Figure 2.1 depicts the assignment of values to bit patterns for a 4-bit signed-magnitude format. </p> <p>\u8868\u793a\u6b63\u6574\u6570\u548c\u8d1f\u6574\u6570\u7684\u4e00\u79cd\u65b9\u6cd5\u662f\u4f7f\u7528\u201c\u6709\u7b26\u53f7\u7684\u5e45\u5ea6\u201d\u6216\u201c\u7b26\u53f7\u52a0\u5e45\u5ea6\u201d\u683c\u5f0f\uff0c\u5176\u4e2d 1 \u4f4d\u4e13\u7528\u4e8e\u7b26\u53f7\u3002\u5e38\u89c1\u7684\u7ea6\u5b9a\u662f\u8ba9 1 \u8868\u793a\u8d1f\u53f7\uff0c0 \u8868\u793a\u6b63\u53f7\u3002\u4ee5 radix-2 \u603b\u5bbd\u5ea6\u4e3a k \u4f4d\u7684\u6570\u5b57\u4e3a\u4f8b\uff0c\u53ef\u4f7f\u7528 k-1 \u4f4d\u6765\u8868\u793a\u6570\u5b57\u7684\u5927\u5c0f\u6216\u7edd\u5bf9\u503c\u3002\u56e0\u6b64\uff0ck \u4f4d\u6709\u7b26\u53f7\u6570\u503c\u4e8c\u8fdb\u5236\u6570\u7684\u8303\u56f4\u4e3a \\([\u2212 ( 2^{k\u22121} \u2212 1 ), 2^{k\u22121} \u2212 1]\\)\u3002\u56fe 2.1 \u63cf\u8ff0\u4e86 4 \u4f4d\u6709\u7b26\u53f7\u6570\u503c\u683c\u5f0f\u7684\u4f4d\u6a21\u5f0f\u7684\u503c\u5206\u914d\u3002</p> <p>Advantages of signed-magnitude representation include its intuitive appeal, conceptual simplicity, symmetric range, and simple negation (sign change) by flipping or inverting the sign bit. The primary disadvantage is that addition of numbers with unlike signs (subtraction) must be handled differently from that of same-sign operands. </p> <p>\u7b26\u53f7\u52a0\u5e45\u5ea6\u8868\u793a\u7684\u4f18\u70b9\u5305\u62ec\u5176\u76f4\u89c2\u5438\u5f15\u529b\u3001\u6982\u5ff5\u7b80\u5355\u3001\u5bf9\u79f0\u8303\u56f4\u4ee5\u53ca\u901a\u8fc7\u7ffb\u8f6c\u6216\u53cd\u8f6c\u7b26\u53f7\u4f4d\u8fdb\u884c\u7b80\u5355\u6c42\u53cd\uff08\u7b26\u53f7\u66f4\u6539\uff09\u3002\u4e3b\u8981\u7f3a\u70b9\u662f\u5177\u6709\u4e0d\u540c\u7b26\u53f7\u7684\u6570\u5b57\u7684\u52a0\u6cd5\uff08\u51cf\u6cd5\uff09\u5fc5\u987b\u4ee5\u4e0e\u76f8\u540c\u7b26\u53f7\u64cd\u4f5c\u6570\u4e0d\u540c\u7684\u65b9\u5f0f\u5904\u7406\u3002</p> <p>The hardware implementation of an adder for signed-magnitude numbers either involves a magnitude comparator and a separate subtractor circuit or else is based on the use of complement representation (see Section 2.3) internally within the arithmetic/logic unit (ALU). In the latter approach, a negative operand is complemented at the ALU\u2019s input, the computation is done by means of complement representation, and the result is complemented, if necessary, to produce the signed-magnitude output. Because the pre- and postcomplementation steps add to the computation delay, it is better to use the complement representation throughout. This is exactly what modern computers do. </p> <p>\u7528\u4e8e\u6709\u7b26\u53f7\u6570\u503c\u7684\u52a0\u6cd5\u5668\u7684\u786c\u4ef6\u5b9e\u73b0\u6d89\u53ca\u5e45\u5ea6\u6bd4\u8f83\u5668\u548c\u5355\u72ec\u7684\u51cf\u6cd5\u5668\u7535\u8def\uff0c\u6216\u8005\u57fa\u4e8e\u7b97\u672f/\u903b\u8f91\u5355\u5143 (ALU) \u5185\u90e8\u8865\u7801\u8868\u793a\u6cd5\u7684\u4f7f\u7528\uff08\u53c2\u89c1\u7b2c 2.3 \u8282\uff09\u3002\u5728\u540e\u4e00\u79cd\u65b9\u6cd5\u4e2d\uff0c\u8d1f\u64cd\u4f5c\u6570\u5728 ALU \u7684\u8f93\u5165\u5904\u6c42\u8865\uff0c\u8ba1\u7b97\u901a\u8fc7\u6c42\u8865\u8868\u793a\u6765\u5b8c\u6210\uff0c\u5e76\u4e14\u5982\u679c\u9700\u8981\u7684\u8bdd\uff0c\u5bf9\u7ed3\u679c\u6c42\u8865\u4ee5\u4ea7\u751f\u5e26\u7b26\u53f7\u7684\u5e45\u5ea6\u8f93\u51fa\u3002\u7531\u4e8e\u8865\u7801\u524d\u548c\u8865\u7801\u540e\u7684\u6b65\u9aa4\u4f1a\u589e\u52a0\u8ba1\u7b97\u5ef6\u8fdf\uff0c\u56e0\u6b64\u6700\u597d\u59cb\u7ec8\u4f7f\u7528\u8865\u7801\u8868\u793a\u3002\u8fd9\u6b63\u662f\u73b0\u4ee3\u8ba1\u7b97\u673a\u6240\u505a\u7684\u3002</p> <p>Besides the aforementioned extra delay in addition and subtraction, signed-magnitude representation allows two representations for 0, leading to the need for special Biased Representations care in number comparisons or added overhead for detecting \u22120 and changing it to +0. This drawback, however, is unavoidable in any radix-2 number representation system with symmetric range. </p> <p>\u9664\u4e86\u524d\u9762\u63d0\u5230\u7684\u52a0\u6cd5\u548c\u51cf\u6cd5\u7684\u989d\u5916\u5ef6\u8fdf\u4e4b\u5916\uff0c\u6709\u7b26\u53f7\u6570\u503c\u8868\u793a\u5141\u8bb8 0 \u7684\u4e24\u79cd\u8868\u793a\uff0c\u5bfc\u81f4\u5728\u6570\u5b57\u6bd4\u8f83\u4e2d\u9700\u8981\u7279\u6b8a\u7684\u504f\u7f6e\u8868\u793a\uff0c\u6216\u8005\u589e\u52a0\u68c0\u6d4b -0 \u5e76\u5c06\u5176\u66f4\u6539\u4e3a +0 \u7684\u5f00\u9500\u3002 \u7136\u800c\uff0c\u8fd9\u4e2a\u7f3a\u70b9\u5728\u4efb\u4f55\u5177\u6709\u5bf9\u79f0\u8303\u56f4\u7684\u57fa 2 \u6570\u5b57\u8868\u793a\u7cfb\u7edf\u4e2d\u90fd\u662f\u4e0d\u53ef\u907f\u514d\u7684\u3002</p> <p>Figure 2.2 shows the hardware implementation of signed-magnitude addition using selective pre- and postcomplementation. The control circuit receives as inputs the operation to be performed (0 = add, 1 = subtract), the signs of the two operands  x  and  y, the carry-out of the adder, and the sign of the addition result. It produces signals for the adder\u2019s carry-in, complementation of  x, complementation of the addition result, and the sign of the result. Note that complementation hardware is provided only for the  x operand. This is because  x \u2212 y  can be obtained by first computing  y \u2212 x  and then changing the sign of the result. You will understand this design much better after we have covered complement representations of negative numbers in Sections 2.3 and 2.4. </p> <p>\u56fe 2.2 \u663e\u793a\u4e86\u4f7f\u7528\u9009\u62e9\u6027\u524d\u8865\u548c\u540e\u8865\u7684\u6709\u7b26\u53f7\u6570\u503c\u52a0\u6cd5\u7684\u786c\u4ef6\u5b9e\u73b0\u3002\u63a7\u5236\u7535\u8def\u63a5\u6536\u8981\u6267\u884c\u7684\u64cd\u4f5c\uff080 = \u52a0\uff0c1 = \u51cf\uff09\u3001\u4e24\u4e2a\u64cd\u4f5c\u6570 x \u548c y \u7684\u7b26\u53f7\u3001\u52a0\u6cd5\u5668\u7684\u8fdb\u4f4d\u4ee5\u53ca\u52a0\u6cd5\u7ed3\u679c\u7684\u7b26\u53f7\u4f5c\u4e3a\u8f93\u5165\u3002\u5b83\u4ea7\u751f\u52a0\u6cd5\u5668\u7684\u8fdb\u4f4d\u4fe1\u53f7\u3001x \u7684\u8865\u7801\u3001\u52a0\u6cd5\u7ed3\u679c\u7684\u8865\u7801\u4ee5\u53ca\u7ed3\u679c\u7684\u7b26\u53f7\u3002\u8bf7\u6ce8\u610f\uff0c\u4ec5\u4e3a x \u64cd\u4f5c\u6570\u63d0\u4f9b\u8865\u7801\u786c\u4ef6\u3002\u8fd9\u662f\u56e0\u4e3a x \u2212 y \u53ef\u4ee5\u901a\u8fc7\u5148\u8ba1\u7b97 y \u2212 x \u7136\u540e\u6539\u53d8\u7ed3\u679c\u7684\u7b26\u53f7\u6765\u83b7\u5f97\u3002\u5728\u6211\u4eec\u5728 2.3 \u548c 2.4 \u8282\u4e2d\u4ecb\u7ecd\u4e86\u8d1f\u6570\u7684\u8865\u7801\u8868\u793a\u4e4b\u540e\uff0c\u60a8\u5c06\u66f4\u597d\u5730\u7406\u89e3\u8fd9\u79cd\u8bbe\u8ba1\u3002</p> <p></p>"},{"location":"Part_01/02/#22","title":"2.2 \u504f\u7f6e\u8868\u793a\u6cd5","text":"<p>One way to deal with signed numbers is to devise a representation or coding scheme that converts signed numbers into unsigned numbers. For example, the biased representation is based on adding a positive value  bias  to all numbers, allowing us to represent the integers from \u2013 bias  to  max \u2013  bias  using unsigned values from 0 to  max. Such a representation is sometimes referred to as \u201cexcess- bias\u201d (e.g., excess-3 or excess-128) coding. </p> <p>\u5904\u7406\u6709\u7b26\u53f7\u6570\u7684\u4e00\u79cd\u65b9\u6cd5\u662f\u8bbe\u8ba1\u4e00\u79cd\u5c06\u6709\u7b26\u53f7\u6570\u8f6c\u6362\u4e3a\u65e0\u7b26\u53f7\u6570\u7684\u8868\u793a\u6216\u7f16\u7801\u65b9\u6848\u3002\u4f8b\u5982\uff0c\u6709\u504f\u5dee\u8868\u793a\u57fa\u4e8e\u5411\u6240\u6709\u6570\u5b57\u6dfb\u52a0\u6b63\u503c\u504f\u5dee\uff0c\u5141\u8bb8\u6211\u4eec\u4f7f\u7528\u4ece 0 \u5230 max \u7684\u65e0\u7b26\u53f7\u503c\u6765\u8868\u793a\u4ece \\(-bias\\)\u5230\\(max-bias\\)\u7684\u6574\u6570\u3002\u8fd9\u79cd\u8868\u793a\u6709\u65f6\u88ab\u79f0\u4e3a\u201cexcess- bias\u201d (\u201c\u8fc7\u91cf\u504f\u5dee\u201d)\uff08\u4f8b\u5982\uff0cexcess-3 \u6216 excess-3\uff09\u7f16\u7801\u3002</p> <p>We will see in Chapter 17 that biased representation is used to encode the exponent part of a floating-point number. </p> <p>\u6211\u4eec\u5c06\u5728\u7b2c 17 \u7ae0\u4e2d\u770b\u5230\uff0c\u504f\u7f6e\u8868\u793a\u6cd5\u7528\u4e8e\u5bf9\u6d6e\u70b9\u6570\u7684\u6307\u6570\u90e8\u5206\u8fdb\u884c\u7f16\u7801\u3002</p> <p>Figure 2.3 shows how signed integers in the range [\u22128, +7] can be encoded as unsigned values 0 through 15 by using a bias of 8. With  k-bit representations and a bias of 2 k\u22121, the leftmost bit indicates the sign of the value represented (0 = negative, 1 = positive). Note that this is the opposite of the commonly used convention for number signs. With a bias of 2 k\u22121 or 2 k\u22121 \u2212 1, the range of represented integers is almost symmetric. </p> <p>\u56fe 2.3 \u663e\u793a\u4e86 [\u22128, +7] \u8303\u56f4\u5185\u7684\u6709\u7b26\u53f7\u6574\u6570\u5982\u4f55\u7f16\u7801\u4e3a\u4f7f\u7528 8 \u7684\u504f\u5dee\u6765\u8868\u793a 0 \u5230 15 \u4e4b\u95f4\u7684\u65e0\u7b26\u53f7\u503c\u3002\u5bf9\u4e8e k \u4f4d\u8868\u793a\u548c \\(2^{k\u22121}\\) \u7684\u504f\u5dee\uff0c\u6700\u5de6\u8fb9\u7684\u4f4d\u8868\u793a\u6240\u8868\u793a\u503c\u7684\u7b26\u53f7\uff080 = \u8d1f\uff0c1 = \u6b63\uff09\u3002\u8bf7\u6ce8\u610f\uff0c\u8fd9\u4e0e\u5e38\u7528\u7684\u6570\u5b57\u7b26\u53f7\u7ea6\u5b9a\u76f8\u53cd\u3002\u5f53\u504f\u5dee\u4e3a \\(2^{k\u22121}\\) \u6216 \\(2^{k\u22121} \u2212 1\\) \u65f6\uff0c\u8868\u793a\u7684\u6574\u6570\u8303\u56f4\u51e0\u4e4e\u662f\u5bf9\u79f0\u7684\u3002</p> <p></p> <p>\u56fe 2.3 \u504f\u7f6e\u4e3a 8 \u7684 4 \u4f4d\u504f\u7f6e\u6574\u6570\u8868\u793a\u7cfb\u7edf\u3002</p> <p>Biased representation does not lend itself to simple arithmetic algorithms. Addition and subtraction become somewhat more complicated because one must subtract or add the bias from/to the result of a normal add/subtract operation, since</p> <p>\u504f\u7f6e\u8868\u793a\u4e0d\u9002\u5408\u7b80\u5355\u7684\u7b97\u672f\u7b97\u6cd5\u3002\u52a0\u6cd5\u548c\u51cf\u6cd5\u53d8\u5f97\u66f4\u52a0\u590d\u6742\uff0c\u56e0\u4e3a\u5fc5\u987b\u4ece\u6b63\u5e38\u52a0/\u51cf\u8fd0\u7b97\u7684\u7ed3\u679c\u4e2d\u51cf\u53bb\u6216\u6dfb\u52a0\u504f\u5dee\uff0c\u56e0\u4e3a</p> \\[ \\begin{array}{l} x + y + bias = (x + bias) + (y + bias) \u2212 bias \\\\ x \u2212 y + bias = (x + bias) \u2212 (y + bias) + bias \\end{array} \\] <p>With  k-bit numbers and a bias of 2 k\u22121, adding or subtracting the bias amounts to complementing the leftmost bit. Thus, the extra complexity in addition or subtraction is negligible. </p> <p>\u4f46\u5982\u679c\u5bf9\u4e8e k \u4f4d\u6570\u5b57\u662f\\(2^{k\u22121}\\) \u7684\u504f\u5dee\uff0c\u6dfb\u52a0\u6216\u51cf\u53bb\u504f\u5dee\u76f8\u5f53\u4e8e\u5bf9\u6700\u5de6\u8fb9\u7684\u4f4d\u6c42\u8865\u3002\u56e0\u6b64\uff0c\u52a0\u6cd5\u6216\u51cf\u6cd5\u7684\u989d\u5916\u590d\u6742\u6027\u53ef\u4ee5\u5ffd\u7565\u4e0d\u8ba1\u3002</p> <p>Multiplication and division become significantly more difficult if these operations are to be performed directly on biased numbers. For this reason, the practical use of biased representation is limited to the exponent parts of floating-point numbers, which are never multiplied or divided. </p> <p>\u5982\u679c\u76f4\u63a5\u5bf9\u6709\u504f\u5dee\u7684\u6570\u6267\u884c\u4e58\u6cd5\u548c\u9664\u6cd5\uff0c\u8fd9\u4e9b\u8fd0\u7b97\u5c31\u4f1a\u53d8\u5f97\u66f4\u52a0\u56f0\u96be\u3002\u56e0\u6b64\uff0c\u504f\u7f6e\u8868\u793a\u7684\u5b9e\u9645\u4f7f\u7528\u4ec5\u9650\u4e8e\u6d6e\u70b9\u6570\u7684\u6307\u6570\u90e8\u5206\uff0c\u8fd9\u4e9b\u90e8\u5206\u6c38\u8fdc\u4e0d\u4f1a\u88ab\u4e58\u6cd5\u6216\u9664\u6cd5\u3002</p>"},{"location":"Part_01/02/#23","title":"2.3 \u8865\u7801\u8868\u793a","text":"<p>In a complement number representation system, a suitably large complementation constant  M  is selected and the negative value \u2212 x  is represented as the unsigned value  M \u2212  x.  Figure 2.4 depicts the encodings used for positive and negative values and the arbitrary boundary between the two regions. </p> <p>\u5728\u8865\u6570\u8868\u793a\u7cfb\u7edf\u4e2d\uff0c\u9009\u62e9\u9002\u5f53\u5927\u7684\u8865\u5e38\u6570M\uff0c\u5e76\u5c06\u8d1f\u503c-x\u8868\u793a\u4e3a\u65e0\u7b26\u53f7\u503c\\(M-x\\)\u3002</p> <p>\u56fe 2.4 \u63cf\u8ff0\u4e86\u7528\u4e8e\u6b63\u503c\u548c\u8d1f\u503c\u7684\u7f16\u7801\u4ee5\u53ca\u4e24\u4e2a\u533a\u57df\u4e4b\u95f4\u7684\u4efb\u610f\u8fb9\u754c\u3002</p> <p></p> <p>To represent integers in the range [\u2212 N , + P] unambiguously, the complementation constant  M  must satisfy  M \u2265  N + P +1. This is justified by noting that to prevent overlap between the representations of positive and negative values in Figure 2.4, we must have M \u2212  N &gt; P. The choice of  M =  N +  P + 1 yields maximum coding efficiency, since no code will go to waste. </p> <p>\u4e3a\u4e86\u660e\u786e\u5730\u8868\u793a \\([\u2212N , +P]\\) \u8303\u56f4\u5185\u7684\u6574\u6570\uff0c\u8865\u7801\u5e38\u6570 M \u5fc5\u987b\u6ee1\u8db3 \\(M \\ge N + P +1\\)\u3002\u8fd9\u662f\u5408\u7406\u7684\uff0c\u6ce8\u610f\u5230\u4e3a\u4e86\u9632\u6b62\u56fe 2.4 \u4e2d\u6b63\u503c\u548c\u8d1f\u503c\u7684\u8868\u793a\u4e4b\u95f4\u7684\u91cd\u53e0\uff0c\u6211\u4eec\u5fc5\u987b\u6709 \\(M \u2212 N \\gt P\\)\u3002\u9009\u62e9 \\(M = N + P + 1\\) \u53ef\u4ee5\u4ea7\u751f\u6700\u5927\u7684\u7f16\u7801\u6548\u7387\uff0c\u56e0\u4e3a\u4e0d\u4f1a\u6d6a\u8d39\u4efb\u4f55\u4ee3\u7801\u3002</p> <p></p> <p>\u8868 2.1 \u8865\u7801\u7cfb\u7edf\u4e2d\u7684\u52a0\u6cd5\uff0c\u4f7f\u7528\u4e92\u8865\u5e38\u6570M \u548c\u8303\u56f4 \\([\u2212N, +P]\\)</p> \u671f\u671b\u7684\u64cd\u4f5c \u6a21M\u524d\u8ba1\u7b97 \u6ca1\u6709\u4e0a\u6ea2\u7684\u6b63\u786e\u7ed3\u679c \u4e0a\u6ea2\u51fa\u6761\u4ef6 \\((+x)+(+y)\\) \\(x+y\\) \\(x+y\\) \\(x+y \\gt P\\) \\((+x)+(-y)\\) \\(x+(M-y)\\) \u5982\u679c\\(y\\le x\\), \u5f97\u5230\\(x-y\\) \u4e0d\u4f1a \u5982\u679c\\(y\\gt x\\), \u5f97\u5230\\(M-(y-x)\\) \\((-x)+(+y)\\) \\((M-x)+y\\) \u5982\u679c\\(x\\le y\\), \u5f97\u5230\\(y-x\\) \u4e0d\u4f1a \u5982\u679c\\(x\\gt y\\), \u5f97\u5230\\(M-(x-y)\\) \\((-x)+(-y)\\) \\((M-x)+(M-y)\\) \\(M-(x+y)\\) \\(x+y \\gt N\\) <p>In a complement system with the complementation constant  M  and the number representation range [\u2212 N , + P], addition is done by adding the respective unsigned representations (modulo  M). The addition process is thus always the same, independent of the number signs. This is easily understood if we note that in modulo- M  arithmetic adding  M \u2212 1 is the same as subtracting 1. Table 2.1 shows the addition rules for complement representations, along with conditions that lead to overflow. </p> <p>\u5728\u5177\u6709\u8865\u7801\u5e38\u6570 M \u548c\u6570\u5b57\u8868\u793a\u8303\u56f4 [\u2212 N , + P] \u7684\u8865\u7801\u7cfb\u7edf\u4e2d\uff0c\u52a0\u6cd5\u662f\u901a\u8fc7\u5c06\u5404\u4e2a\u65e0\u7b26\u53f7\u8868\u793a\u76f8\u52a0\uff08\u6a21 M\uff09\u6765\u5b8c\u6210\u7684\u3002\u56e0\u6b64\uff0c\u52a0\u6cd5\u8fc7\u7a0b\u603b\u662f\u76f8\u540c\u7684\uff0c\u4e0e\u6570\u5b57\u7b26\u53f7\u65e0\u5173\u3002\u5982\u679c\u6211\u4eec\u6ce8\u610f\u5230\u5728\u6a21 M \u7b97\u672f\u4e2d\u52a0 M \u2212 1 \u4e0e\u51cf 1 \u76f8\u540c\uff0c\u90a3\u4e48\u8fd9\u5f88\u5bb9\u6613\u7406\u89e3\u3002\u8868 2.1 \u663e\u793a\u4e86\u8865\u7801\u8868\u793a\u7684\u52a0\u6cd5\u89c4\u5219\uff0c\u4ee5\u53ca\u5bfc\u81f4\u6ea2\u51fa\u7684\u6761\u4ef6\u3002</p> <p>Subtraction can be performed by complementing the subtrahend and then performing addition. Thus, assuming that a selective complementer is available, addition and subtraction become essentially the same operation, and this is the primary advantage of complement representations. </p> <p>\u51cf\u6cd5\u53ef\u4ee5\u901a\u8fc7\u5bf9\u51cf\u6570\u6c42\u8865\u6765\u8fdb\u884c\uff0c\u7136\u540e\u6267\u884c\u52a0\u6cd5\u3002\u56e0\u6b64\uff0c\u5047\u8bbe\u6709\u9009\u62e9\u6027\u8865\u7801\u5668\u53ef\u7528\uff0c\u52a0\u6cd5\u548c\u51cf\u6cd5\u672c\u8d28\u4e0a\u53d8\u6210\u76f8\u540c\u7684\u8fd0\u7b97\uff0c\u8fd9\u662f\u8865\u7801\u8868\u793a\u7684\u4e3b\u8981\u4f18\u70b9\u3002</p> <p>Complement representation can be used for fixed-point numbers that have a fractional part. The only difference is that consecutive values in the circular representation of Fig. 2.4 will be separated by  ulp  instead of by 1. As a decimal example, given the complementation constant  M = 12.000 and a fixed-point number range of [\u22126.000, +5.999], the fixed-point number \u22123.258 has the complement representation 12.000 \u22123.258 = 8.742. </p> <p>\u8865\u7801\u8868\u793a\u53ef\u7528\u4e8e\u5177\u6709\u5c0f\u6570\u90e8\u5206\u7684\u5b9a\u70b9\u6570\u3002\u552f\u4e00\u7684\u533a\u522b\u662f\u56fe 1 \u7684\u5706\u5f62\u8868\u793a\u4e2d\u7684\u8fde\u7eed\u503c\u3002\u56fe2.4 \u5c06\u7528 ulp \u800c\u4e0d\u662f\u7528 1 \u5206\u9694\u3002\u4f5c\u4e3a\u5341\u8fdb\u5236\u793a\u4f8b\uff0c\u7ed9\u5b9a\u8865\u7801\u5e38\u6570 M = 12.000 \u548c\u5b9a\u70b9\u6570\u8303\u56f4 [\u22126.000, +5.999]\uff0c\u5b9a\u70b9\u6570 \u22123.258 \u7684\u8865\u7801\u8868\u793a\u5f62\u5f0f\u4e3a 12.000 \u22123.258 = 8.742\u3002</p> <p>We note that two auxiliary operations are required for complement representations to be effective: complementation or change of sign (computing  M \u2212  x) and computations of residues mod  M. If finding  M \u2212  x  requires subtraction and finding residues mod  M implies division, then complement representation becomes quite inefficient. Thus M must be selected such that these two operations are simplified. Two choices allow just this for fixed-point radix- r arithmetic with k whole digits and l fractional digits: Radix complement</p> <p>\u6211\u4eec\u6ce8\u610f\u5230\uff0c\u8981\u4f7f\u8865\u7801\u8868\u793a\u6709\u6548\uff0c\u9700\u8981\u4e24\u4e2a\u8f85\u52a9\u64cd\u4f5c\uff1a\u8865\u7801\u6216\u7b26\u53f7\u66f4\u6539\uff08\u8ba1\u7b97 M \u2212 x\uff09\u4ee5\u53ca\u6b8b\u6570 mod M \u7684\u8ba1\u7b97\u3002 \u5982\u679c\u627e\u5230 M \u2212 x \u9700\u8981\u51cf\u6cd5\uff0c\u800c\u627e\u5230 mod M \u4f59\u6570\u610f\u5473\u7740\u9664\u6cd5\uff0c\u90a3\u4e48\u8865\u7801\u8868\u793a\u53d8\u5f97\u975e\u5e38\u4f4e\u6548\u3002 \u56e0\u6b64\uff0c\u5fc5\u987b\u9009\u62e9*M*\u4ee5\u7b80\u5316\u8fd9\u4e24\u4e2a\u64cd\u4f5c\u3002 \u5bf9\u4e8e\u5e26\u6709 k \u6574\u6570\u4f4d\u548c l \u5c0f\u6570\u4f4d\u7684\u5b9a\u70b9\u57fa\u6570 r \u7b97\u672f\uff0c\u6709\u4e24\u79cd\u9009\u62e9\uff1a </p> <ul> <li>\u57fa\u6570\u8865\u7801Radix complement \\(M=r^k\\)</li> <li>\u6570\u5b57\u6216\u51cf\u57fa\u6570\u8865\u7801 Digit or diminished-radix complement \\(M=r^k-ulp\\)</li> </ul> <p>For radix-complement representations, modulo- M reduction is done by ignoring the carry-out from digit position k \u22121 in a (k+ l)-digit radix- r addition. For digit-complement representations, computing the complement of x (i.e., M \u2212 x), is done by simply replacing each nonzero digit xi by r \u2212 1 \u2212 xi. This is particularly easy if r is a power of 2.</p> <p>\u5bf9\u4e8e\u57fa\u6570\u8865\u7801\u8868\u793a\uff0c\u6a21 M \u5f52\u7ea6\u662f\u901a\u8fc7\u5ffd\u7565 (k+l) \u4f4d\u57fa\u6570 r \u52a0\u6cd5\u4e2d\u7684\u6570\u5b57\u4f4d\u7f6e k -1 \u7684\u8fdb\u4f4d\u6765\u5b8c\u6210\u7684\u3002\u5bf9\u4e8e\u6570\u5b57\u8865\u7801\u8868\u793a\uff0c\u8ba1\u7b97 x \u7684\u8865\u7801\uff08\u5373 M \u2212 x\uff09\u662f\u901a\u8fc7\u7b80\u5355\u5730\u5c06\u6bcf\u4e2a\u975e\u96f6\u6570\u5b57 xi \u66ff\u6362\u4e3a r \u2212 1 \u2212 xi \u6765\u5b8c\u6210\u7684\u3002\u5982\u679c r \u662f 2 \u7684\u5e42\uff0c\u8fd9\u5c24\u5176\u5bb9\u6613\u3002</p> <p>Complementation with M = rk and mod- M reduction with M = rk \u2212 ulp are similarly simple. You should be able to supply the details for radix r after reading Section 2.4, which deals with the important special case of r = 2.</p> <p>M = rk \u7684\u4e92\u8865\u548c M = rk \u2212 ulp \u7684 mod-M \u7ea6\u7b80\u4e5f\u540c\u6837\u7b80\u5355\u3002\u9605\u8bfb\u7b2c 2.4 \u8282\u540e\uff0c\u60a8\u5e94\u8be5\u80fd\u591f\u63d0\u4f9b\u57fa\u6570 r \u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u8be5\u8282\u6d89\u53ca r = 2 \u7684\u91cd\u8981\u7279\u6b8a\u60c5\u51b5\u3002</p>"},{"location":"Part_01/02/#24-2s-1s","title":"2.4 2\u2019S \u548c1\u2019S \u8865\u7801\u6570","text":"<p>2\u2019S- AND 1\u2019S-COMPLEMENT NUMBERS</p> <p>In the special case of r = 2, the radix complement representation that corresponds to M = 2 k is known as 2\u2019s complement. Figure 2.5 shows the 4-bit, 2\u2019s-complement integer system (k = 4, l = 0, M = 2^4 = 16 ) and the meanings of the 16 representations allowed with 4 bits. The boundary between positive and negative values is drawn approximately in the middle to make the range roughly symmetric and to allow simple sign detection (the leftmost bit is the sign).</p> <p>\u5728 r = 2 \u7684\u7279\u6b8a\u60c5\u51b5\u4e0b\uff0c\u5bf9\u5e94\u4e8e \\(M = 2^k\\) \u7684\u57fa\u6570\u8865\u7801\u8868\u793a\u5f62\u5f0f\u79f0\u4e3a**\u4e8c\u8fdb\u5236\u8865\u7801**\u3002\u56fe 2.5 \u663e\u793a\u4e86 4 \u4f4d 2 \u8865\u7801\u6574\u6570\u7cfb\u7edf\uff08\\(k = 4\uff0cl = 0\uff0cM = 2^4 = 16\\)\uff09\u4ee5\u53ca 4 \u4f4d\u5141\u8bb8\u7684 16 \u79cd\u8868\u793a\u7684\u542b\u4e49\u3002\u6b63\u503c\u548c\u8d1f\u503c\u4e4b\u95f4\u7684\u8fb9\u754c\u5927\u7ea6\u7ed8\u5236\u5728\u4e2d\u95f4\uff0c\u4ee5\u4f7f\u8303\u56f4\u5927\u81f4\u5bf9\u79f0\u5e76\u5141\u8bb8\u7b80\u5355\u7684\u7b26\u53f7\u68c0\u6d4b\uff08\u6700\u5de6\u8fb9\u7684\u4f4d\u662f\u7b26\u53f7\uff09\u3002</p> <p></p> <p>The 2\u2019s complement of a number  x  can be found via bitwise complementation of  x and the addition of  ulp:</p> <p>\u6570\u5b57 x \u7684 2 \u8865\u7801\u53ef\u4ee5\u901a\u8fc7 x \u7684\u6309\u4f4d\u6c42\u8865\u548c ulp \u7684\u52a0\u6cd5\u6c42\u51fa\uff1a</p> \\[ 2^k \u2212 x = [ ( 2^k \u2212 ulp) \u2212 x] + ulp = x^{compl} + ulp \\] <p>Note that the binary representation of 2 k \u2212  ulp  consists of all 1s, making  ( 2 k \u2212  ulp) \u2212  x equivalent to the bitwise complement of  x, denoted as  x compl. Whereas finding the bitwise complement of  x  is easy, adding  ulp  to the result is a slow process, since in the worst case it involves full carry propagation. We will see later how this addition of  ulp  can usually be avoided. </p> <p>\u6ce8\u610f\\(2^k \u2212 ulp\\) \u7684\u4e8c\u8fdb\u5236\u8868\u793a\u5f62\u5f0f\u5168\u4e3a 1\uff0c\u4f7f\u5f97 \\((2^k \u2212 ulp) \u2212 x\\) \u7b49\u4ef7\u4e8e x \u7684\u6309\u4f4d\u8865\u7801\uff0c\u8868\u793a\u4e3a \\(x^{compl}\\)\u3002\u867d\u7136\u627e\u5230 x \u7684\u6309\u4f4d\u8865\u7801\u5f88\u5bb9\u6613\uff0c\u4f46\u5c06 ulp \u6dfb\u52a0\u5230\u7ed3\u679c\u4e2d\u662f\u4e00\u4e2a\u7f13\u6162\u7684\u8fc7\u7a0b\uff0c\u56e0\u4e3a\u5728\u6700\u574f\u7684\u60c5\u51b5\u4e0b\u5b83\u6d89\u53ca\u5b8c\u5168\u8fdb\u4f4d\u4f20\u64ad\u3002\u7a0d\u540e\u6211\u4eec\u5c06\u770b\u5230\u901a\u5e38\u5982\u4f55\u907f\u514d\u505a\u52a0 ulp\u3002</p> <p>To add numbers modulo 2 k , we simply drop a carry-out of 1 produced by position k \u2212 1. Since this carry is worth 2 k  units, dropping it is equivalent to reducing the magnitude of the result by 2 k . </p> <p>\u4e3a\u4e86\u5bf9\u6a21 \\(2^k\\) \u8fdb\u884c\u52a0\u6cd5\uff0c\u6211\u4eec\u53ea\u9700\u5220\u9664\u4f4d\u7f6e \\(k \u2212 1\\) \u751f\u6210\u7684 \\(1\\) \u8fdb\u4f4d\u5373\u53ef\u3002\u7531\u4e8e\u8be5\u8fdb\u4f4d\u503c\u662f \\(2^k\\) \u5355\u4f4d\uff0c\u56e0\u6b64\u5220\u9664\u5b83\u76f8\u5f53\u4e8e\u5c06\u7ed3\u679c\u7684\u5927\u5c0f\u51cf\u5c11 \\(2^k\\) \u3002</p> <p>The range of representable numbers in a 2\u2019s-complement number system with  k whole bits is from \u2212 2 k\u22121 to 2 k\u22121 \u2212  ulp</p> <p>k \u4e2a\u6574\u6570\u4f4d\u7684 2 \u8865\u6570\u7cfb\u7edf\u4e2d\u53ef\u8868\u793a\u7684\u6570\u5b57\u8303\u56f4\u4e3a\uff1a\u4ece\\(\u2212 2^{k\u22121}\\) \u81f3 \\(2^{k\u22121} \u2212 ulp\\)</p> <p>Because of this slightly asymmetric range, complementation can lead to overflow! Thus, if complementation is done as a separate sign change operation, it must include overflow detection. However, we will see later that complementation needed to convert subtraction into addition requires no special provision. </p> <p>\u7531\u4e8e\u8fd9\u4e2a\u8303\u56f4\u7a0d\u5fae\u4e0d\u5bf9\u79f0\uff0c\u6c42\u8865\u53ef\u80fd\u4f1a\u5bfc\u81f4\u6ea2\u51fa\uff01\u56e0\u6b64\uff0c\u5982\u679c\u8865\u7801\u4f5c\u4e3a\u5355\u72ec\u7684\u7b26\u53f7\u66f4\u6539\u64cd\u4f5c\u5b8c\u6210\uff0c\u5219\u5b83\u5fc5\u987b\u5305\u62ec\u6ea2\u51fa\u68c0\u6d4b\u3002\u7136\u800c\uff0c\u6211\u4eec\u7a0d\u540e\u4f1a\u770b\u5230\uff0c\u5c06\u51cf\u6cd5\u8f6c\u6362\u4e3a\u52a0\u6cd5\u6240\u9700\u7684\u8865\u6570\u4e0d\u9700\u8981\u7279\u6b8a\u89c4\u5b9a\u3002</p> <p>The name \u201c2\u2019s complement\u201d actually comes from the special case of  k = 1 that leads to the complementation constant  M = 2. In this case, represented numbers have 1 whole bit, which acts as the sign, and  l  fractional bits. Thus, fractional values in the range [\u22121, 1 \u2212  ulp] are represented in such a fractional 2\u2019s-complement number system. Figure 2.5 can be readily modified to represent this number system by simply inserting a radix point after the leading digit for numbers outside the circle (turning them into 0.000, 0.001, and so on) and replacing each value  x  inside the circle with  x/ 8 (0, 0.125, 0.25, and so on). </p> <p>\u201c2 \u7684\u8865\u7801\u201d\u8fd9\u4e2a\u540d\u79f0\u5b9e\u9645\u4e0a\u6765\u81ea k = 1 \u7684\u7279\u6b8a\u60c5\u51b5\uff0c\u5b83\u5bfc\u81f4\u8865\u7801\u5e38\u6570 \\(M = 2\\)\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u8868\u793a\u7684\u6570\u5b57\u6709 1 \u4e2a\u6574\u6570\u4f4d\uff08\u5145\u5f53\u7b26\u53f7\uff09\u548c \\(l\\) \u4e2a\u5c0f\u6570\u4f4d\u3002\u56e0\u6b64\uff0c\\([\u22121, 1\u2212ulp]\\) \u8303\u56f4\u5185\u7684\u5c0f\u6570\u503c\u4ee5\u8fd9\u6837\u7684\u5c0f\u6570 2 \u8865\u7801\u6570\u5b57\u7cfb\u7edf\u8868\u793a\u3002\u56fe 2.5 \u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u4fee\u6539\u6765\u8868\u793a\u8fd9\u4e2a\u6570\u5b57\u7cfb\u7edf\uff0c\u53ea\u9700\u5728\u5706\u5916\u6570\u5b57\u7684\u524d\u5bfc\u6570\u5b57\u540e\u9762\u63d2\u5165\u4e00\u4e2a\u5c0f\u6570\u70b9\uff08\u5c06\u5b83\u4eec\u53d8\u6210 0.000\u30010.001 \u7b49\uff09\uff0c\u5e76\u5c06\u5706\u5185\u7684\u6bcf\u4e2a\u503c x \u66ff\u6362\u4e3a x/ 8\uff080\u30010.125\u30010.25 \u7b49\uff09\u3002</p> <p>The digit or diminished-radix complement representation is known as  1\u2019s complement in the special case of  r = 2. The complementation constant in this case is  M = 2 k \u2212  ulp. For example, Fig. 2.6 shows the 4-bit, 1\u2019s-complement integer system ( k = 4,  l = 0,  M = 24 \u2212 1 = 15) and the meanings of the 16 representations allowed with 4 bits. The boundary between positive and negative values is again drawn approximately in the middle to make the range symmetric and to allow simple sign detection (the leftmost bit is the sign). </p> <p>\u5728 r = 2 \u7684\u7279\u6b8a\u60c5\u51b5\u4e0b\uff0c\u6570\u5b57\u6216\u51cf\u57fa\u8865\u7801\u8868\u793a\u5f62\u5f0f\u79f0\u4e3a 1 \u7684\u8865\u7801\u3002\u8fd9\u79cd\u60c5\u51b5\u4e0b\u7684\u8865\u7801\u5e38\u6570\u4e3a \\(M = 2^k \u2212 ulp\\)\u3002\u4f8b\u5982\uff0c\u56fe 2.6 \u663e\u793a\u4e86 4 \u4f4d\u30011 \u7684\u8865\u7801\u6574\u6570\u7cfb\u7edf \\(( k = 4, l = 0, M = 2^4 \u2212 1 = 15)\\) \u4ee5\u53ca 4 \u4f4d\u5141\u8bb8\u7684 16 \u79cd\u8868\u793a\u7684\u542b\u4e49\u3002\u6b63\u503c\u548c\u8d1f\u503c\u4e4b\u95f4\u7684\u8fb9\u754c\u518d\u6b21\u5927\u7ea6\u5728\u4e2d\u95f4\u7ed8\u5236\uff0c\u4ee5\u4f7f\u8303\u56f4\u5bf9\u79f0\u5e76\u5141\u8bb8\u7b80\u5355\u7684\u7b26\u53f7\u68c0\u6d4b\uff08\u6700\u5de6\u8fb9\u7684\u4f4d\u662f\u7b26\u53f7\uff09\u3002</p> <p></p> <p>Note that compared with the 2\u2019s-complement representation of Fig. 2.5, the representation for \u22128 has been eliminated and instead an alternate code has been assigned to 0 (technically, \u22120). This may somewhat complicate 0 detection in that both the all-0s and the all-1s patterns represent 0. The arithmetic circuits can be designed such that the all-1s pattern is detected and automatically converted to the all-0s pattern. Keeping \u22120 intact does not cause problems in computations, however, since all computations are modulo 15. For example, adding +1 (0001) to \u22120 (1111) will yield the correct result of +1 (0001) when the addition is done modulo 15. </p> <p>\u8bf7\u6ce8\u610f\uff0c\u4e0e\u56fe 2.5 \u7684 2 \u8865\u7801\u8868\u793a\u76f8\u6bd4\uff0c-8 \u7684\u8868\u793a\u5df2\u88ab\u6d88\u9664\uff0c\u800c\u662f\u5c06\u66ff\u4ee3\u4ee3\u7801\u5206\u914d\u7ed9 0\uff08\u6280\u672f\u4e0a\u4e3a -0\uff09\u3002\u8fd9\u53ef\u80fd\u4f1a\u4f7f 0 \u68c0\u6d4b\u53d8\u5f97\u6709\u4e9b\u590d\u6742\uff0c\u56e0\u4e3a\u5168 0 \u548c\u5168 1 \u6a21\u5f0f\u90fd\u8868\u793a 0\u3002\u7b97\u672f\u7535\u8def\u53ef\u4ee5\u8bbe\u8ba1\u4e3a\u68c0\u6d4b\u5168 1 \u6a21\u5f0f\u5e76\u81ea\u52a8\u8f6c\u6362\u4e3a\u5168 0 \u6a21\u5f0f\u3002\u4fdd\u6301-0\u4e0d\u53d8\u4e0d\u4f1a\u5bfc\u81f4\u8ba1\u7b97\u51fa\u73b0\u95ee\u9898\uff0c\u56e0\u4e3a\u6240\u6709\u8ba1\u7b97\u90fd\u662f\u6a21 15\u3002\u4f8b\u5982\uff0c\u5c06 +1 (0001) \u6dfb\u52a0\u5230 -0 (1111) \u5c06\u4ea7\u751f\u6b63\u786e\u7684\u7ed3\u679c+1 (0001)\uff0c \u56e0\u4e3a\u52a0\u6cd5\u6700\u540e\u4ee5 15 \u53d6\u6a21\u3002</p> <p>The 1\u2019s complement of a number  x  can be found by bitwise complementation: ( 2^k \u2212  ulp) \u2212  x =  x compl</p> <p>\u6570\u5b57 x \u7684 1 \u8865\u7801\u53ef\u4ee5\u901a\u8fc7\u6309\u4f4d\u8865\u6c42\u51fa\uff1a$ (2^k \u2212 ulp) \u2212 x = x^{compl}$</p> <p>To add numbers modulo \\(2^k \u2212 ulp\\), we simply drop a carry-out of 1 produced by position k \u2212 1 and simultaneously insert a carry-in of 1 into position \\(\u2212 l\\). Since the dropped carry is worth 2 k  units and the inserted carry is worth  ulp, the combined effect is to reduce the magnitude of the result by \\(2^k \u2212 ulp\\). In terms of hardware, the carry-out of our ( k +  l)-bit adder should be directly connected to its carry-in; this is known as  end-around carry. </p> <p>\u4e3a\u4e86\u5bf9\u6a21 \\(2^k \u2212 ulp\\) \u8fdb\u884c\u52a0\u6cd5\uff0c\u6211\u4eec\u53ea\u9700\u5220\u9664\u4f4d\u7f6e \\(k \u2212 1\\) \u4ea7\u751f\u7684 1 \u7684\u8fdb\u4f4d\u8f93\u51fa\uff0c\u540c\u65f6\u5c06 1 \u7684\u8fdb\u4f4d\u63d2\u5165\u5230\u4f4d\u7f6e \\(\u2212l\\)\u4e2d\u3002\u7531\u4e8e\u4e22\u5f03\u7684\u8fdb\u4f4d\u503c\u4e3a \\(2^k\\)\u4e2a\u5355\u4f4d\uff0c\u800c\u63d2\u5165\u7684\u8fdb\u4f4d\u4ef7\u503c\u4e3a \\(ulp\\)\uff0c\u56e0\u6b64\u7efc\u5408\u6548\u679c\u662f\u5c06\u7ed3\u679c\u7684\u5927\u5c0f\u51cf\u5c11 \\(2^k \u2212 ulp\\)\u3002\u5728\u786c\u4ef6\u65b9\u9762\uff0c\u6211\u4eec\u7684\uff08\\(k+l\\)\uff09\u4f4d\u52a0\u6cd5\u5668\u7684\u8fdb\u4f4d\u8f93\u51fa\u5e94\u8be5\u76f4\u63a5\u8fde\u63a5\u5230\u5b83\u7684\u8fdb\u4f4d\u8f93\u5165\uff1b\u8fd9\u5c31\u662f\u6240\u8c13\u7684*\u672b\u7aef\u5faa\u73af\u8fdb\u4f4d*\u3002</p> <p>The foregoing scheme properly handles any sum that equals or exceeds 2 k . When the sum is 2 k \u2212  ulp, however, the carry-out will be zero and modular reduction is not accomplished. As suggested earlier, such an all-1s result can be interpreted as an alternate representation of 0 that is either kept intact (making 0 detection more difficult) or is automatically converted by hardware to +0. </p> <p>\u4e0a\u8ff0\u65b9\u6848\u6b63\u786e\u5730\u5904\u7406\u7b49\u4e8e\u6216\u8d85\u8fc72 k \u7684\u4efb\u4f55\u603b\u548c\u3002\u7136\u800c\uff0c\u5f53\u603b\u548c\u4e3a \\(2^k \u2212 ulp\\) \u65f6\uff0c\u8fdb\u4f4d\u5c06\u4e3a\u96f6\uff0c\u5e76\u4e14\u672a\u5b8c\u6210\u6a21\u7ea6\u7b80\u3002\u5982\u524d\u6240\u8ff0\uff0c\u8fd9\u6837\u7684\u5168 1 \u7ed3\u679c\u53ef\u4ee5\u89e3\u91ca\u4e3a 0 \u7684\u66ff\u4ee3\u8868\u793a\uff0c\u5b83\u8981\u4e48\u4fdd\u6301\u4e0d\u53d8\uff08\u4f7f 0 \u68c0\u6d4b\u66f4\u52a0\u56f0\u96be\uff09\uff0c\u8981\u4e48\u7531\u786c\u4ef6\u81ea\u52a8\u8f6c\u6362\u4e3a +0\u3002</p> <p>The range of representable numbers in a 1\u2019s-complement number system with  k whole bits is from \\(\u2212(2^{k\u22121} \u2212 ulp)\\) to \\(2^{k\u22121} \u2212 ulp\\) . This symmetric range is one of the advantages of 1\u2019s-complement number representation. </p> <p>k \u4e2a\u6574\u6570\u4f4d\u7684 1 \u8865\u6570\u7cfb\u7edf\u4e2d\u53ef\u8868\u793a\u7684\u6570\u5b57\u8303\u56f4\u4e3a\u4ece\\(\u2212(2^{k\u22121} \u2212 ulp)\\)\u5230\\(2^{k\u22121} \u2212 ulp\\)\u3002\u8fd9\u79cd\u5bf9\u79f0\u8303\u56f4\u662f 1 \u8865\u7801\u6570\u5b57\u8868\u793a\u7684\u4f18\u70b9\u4e4b\u4e00\u3002</p> <p>Table 2.2 presents a brief comparison of radix- and digit-complement number representation systems for radix  r. We might conclude from Table 2.2 that each of the two complement representation schemes has some advantages and disadvantages with respect to the other, making them equally desirable. However, since complementation is often performed for converting subtraction to addition, the addition of  ulp  required in the case of 2\u2019s-complement numbers can be accomplished by providing a carry-in of 1 into the least significant, or (\u2212 l)th, position of the adder. Figure 2.7 shows the required elements for a 2\u2019s-complement adder/subtractor. With the complementation disadvantage mitigated in this way, 2\u2019s-complement representation has become the favored choice in virtually all modern digital systems.</p> <p>\u8868 2.2 \u7b80\u8981\u6bd4\u8f83\u4e86\u57fa\u6570 r \u7684\u57fa\u6570\u548c\u6570\u5b57\u8865\u6570\u8868\u793a\u7cfb\u7edf\u3002\u6211\u4eec\u53ef\u4ee5\u4ece\u8868 2.2 \u4e2d\u5f97\u51fa\u7ed3\u8bba\uff0c\u4e24\u79cd\u8865\u7801\u8868\u793a\u65b9\u6848\u76f8\u5bf9\u4e8e\u53e6\u4e00\u79cd\u65b9\u6848\u90fd\u6709\u4e00\u4e9b\u4f18\u70b9\u548c\u7f3a\u70b9\uff0c\u56e0\u6b64\u5b83\u4eec\u540c\u6837\u503c\u5f97\u671f\u5f85\u3002\u7136\u800c\uff0c\u7531\u4e8e\u901a\u5e38\u6267\u884c\u8865\u7801\u6765\u5c06\u51cf\u6cd5\u8f6c\u6362\u4e3a\u52a0\u6cd5\uff0c\u56e0\u6b64\u5728 2 \u8865\u7801\u6570\u7684\u60c5\u51b5\u4e0b\u6240\u9700\u7684 ulp \u52a0\u6cd5\u53ef\u4ee5\u901a\u8fc7\u5411\u52a0\u6cd5\u5668\u7684\u6700\u4f4e\u6709\u6548\u4f4d\u7f6e\u6216\u7b2c \\((\u2212l)\\) \u4e2a\u4f4d\u7f6e\u63d0\u4f9b\u8fdb\u4f4d 1 \u6765\u5b8c\u6210\u3002\u56fe 2.7 \u663e\u793a\u4e86 2 \u8865\u7801\u52a0\u6cd5\u5668/\u51cf\u6cd5\u5668\u6240\u9700\u7684\u5143\u7d20\u3002\u52a3\u52bf\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\u7f13\u89e3\uff0c2 \u7684\u8865\u7801\u8868\u793a\u5df2\u6210\u4e3a\u51e0\u4e4e\u6240\u6709\u73b0\u4ee3\u6570\u5b57\u7cfb\u7edf\u4e2d\u7684\u9996\u9009\u3002</p> \u7279\u5f81/\u7279\u6027 \u57fa\u6570\u8865\u7801 \u6570\u5b57\u8865\u7801 \u5bf9\u79f0\u6027\uff08P=N\uff1f\uff09 \u5bf9\u4e8e\u5947\u6570 r \u53ef\u80fd\uff08\u5b9e\u9645\u7528\u7684\u90fd\u662f\u5076\u6570\uff09 \u5bf9\u4e8e\u5947\u5076\u6570 r \u90fd\u662f \u72ec\u7279\u7684\u96f6\uff1f Yes No \u6c42\u8865 \u5bf9\u6240\u6709\u6570\u5b57\u6c42\u53cd\u5e76\u6dfb\u52a0 ulp \u5bf9\u6240\u6709\u6570\u5b57\u6c42\u8865 Mod-M \u52a0\u6cd5 \u4e22\u5f03\u8fdb\u4f4d\u8f93\u51fa \u672b\u7aef\u5faa\u73af\u8fdb\u4f4d <p></p> <p>Interestingly, the arrangement shown in Fig. 2.7 also removes the disadvantage of asymmetric range. If the operand  y  is \u22122 k\u22121, represented in 2\u2019s complement as 1 followed by all 0s, its complementation does not lead to overflow. This is because the 2\u2019s complement of  y  is essentially represented in two parts:  y compl, which represents 2 k\u22121 \u2212 1, and  cin  which represents 1. </p> <p>\u6709\u8da3\u7684\u662f\uff0c\u56fe2.7\u6240\u793a\u7684\u5b89\u6392\u4e5f\u6d88\u9664\u4e86\u4e0d\u5bf9\u79f0\u8303\u56f4\u8fd9\u4e2a\u7f3a\u70b9\u3002\u5982\u679c\u64cd\u4f5c\u6570 y \u4e3a \\(\u22122^{k\u22121}\\)\uff0c\u5219\u7528 2 \u7684\u8865\u7801\u8868\u793a\u4e3a 1\u540e\u9762\u51680\uff0c\u5176\u8865\u7801\u4e0d\u4f1a\u5bfc\u81f4\u6ea2\u51fa\u3002\u8fd9\u662f\u56e0\u4e3a y \u7684 2 \u8865\u7801\u672c\u8d28\u4e0a\u7531\u4e24\u90e8\u5206\u8868\u793a\uff1a\\(y^{compl}\\)\uff0c\u8868\u793a \\(2^{k\u22121} \u2212 1\\)\uff0c\\(c_{in}\\) \u8868\u793a 1\u3002</p> <p>Occasionally we need to extend the number of digits in an operand to make it of the same length as another operand. For example, if a 16-bit number is to be added to a 32-bit number, the former is first converted to 32-bit format, with the two 32-bit numbers then added using a 32-bit adder. Unsigned- or signed-magnitude fixed-point binary numbers can be extended from the left (whole part) or the right (fractional part) by simply padding them with 0s. This type of range or precision extension is only slightly more difficult for 2\u2019s- and 1\u2019s-complement numbers. </p> <p>\u6709\u65f6\u6211\u4eec\u9700\u8981\u6269\u5c55\u4e00\u4e2a\u64cd\u4f5c\u6570\u7684\u4f4d\u6570\uff0c\u4f7f\u5176\u4e0e\u53e6\u4e00\u4e2a\u64cd\u4f5c\u6570\u7684\u957f\u5ea6\u76f8\u540c\u3002\u4f8b\u5982\uff0c\u5982\u679c\u8981\u5c06 16 \u4f4d\u6570\u5b57\u4e0e 32 \u4f4d\u6570\u5b57\u76f8\u52a0\uff0c\u5219\u9996\u5148\u5c06 16 \u4f4d\u6570\u5b57\u8f6c\u6362\u4e3a 32 \u4f4d\u683c\u5f0f\uff0c\u7136\u540e\u4f7f\u7528 32 \u4f4d\u52a0\u6cd5\u5668\u5c06\u4e24\u4e2a 32 \u4f4d\u6570\u5b57\u76f8\u52a0\u3002\u65e0\u7b26\u53f7\u6216\u6709\u7b26\u53f7\u6570\u503c\u5b9a\u70b9\u4e8c\u8fdb\u5236\u6570\u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u5730\u7528 0 \u586b\u5145\u6765\u4ece\u5de6\u4fa7\uff08\u6574\u4e2a\u90e8\u5206\uff09\u6216\u53f3\u4fa7\uff08\u5c0f\u6570\u90e8\u5206\uff09\u8fdb\u884c\u6269\u5c55\u3002\u5bf9\u4e8e 2 \u548c 1 \u8865\u7801\u6570\u5b57\u6765\u8bf4\uff0c\u8fd9\u79cd\u7c7b\u578b\u7684\u8303\u56f4\u6216\u7cbe\u5ea6\u6269\u5c55\u53ea\u662f\u7a0d\u5fae\u56f0\u96be\u4e00\u4e9b\u3002</p> <p>Given a 2\u2019s-complement number\\(x_{k\u22121} x_{k\u22122} \u00b7 \u00b7 \u00b7 x_1 x_0 . x_{\u22121} x_{\u22122} \u00b7 \u00b7 \u00b7 x_{\u2212l}\\), extension can be achieved from the left by replicating the sign bit ( sign extension) and from the right by padding it with 0s. </p> <p>\u7ed9\u5b9a\u4e00\u4e2a 2 \u7684\u8865\u7801 \\(x_{k\u22121} x_{k\u22122} \u00b7 \u00b7 \u00b7 x_1 x_0 . x_{\u22121} x_{\u22122} \u00b7 \u00b7 \u00b7 x_{\u2212l}\\)\uff0c\u53ef\u4ee5\u901a\u8fc7\u590d\u5236\u7b26\u53f7\u4f4d\uff08\u7b26\u53f7\u6269\u5c55\uff09\u4ece\u5de6\u4fa7\u5b9e\u73b0\u6269\u5c55\uff0c\u5e76\u901a\u8fc7\u7528 0 \u586b\u5145\u4ece\u53f3\u4fa7\u5b9e\u73b0\u6269\u5c55\u3002</p> \\[ \\cdots x_{k\u22121} x_{k\u22121} x_{k\u22121} x_{k\u22121} x_{k\u22122} \u00b7 \u00b7 \u00b7 x_1 x_0 . x_{\u22121} x_{\u22122} \u00b7 \u00b7 \u00b7 x_{\u2212l} 000 \\cdots \\] <p>To justify the foregoing rule, note that when the number of whole (fractional) digits is increased from  k ( l) to  k ( l), the complementation constant increases from  M = 2 k  to  M  = 2 k. Hence, the difference of the two complementation constants</p> <p>\u4e3a\u4e86\u8bc1\u660e\u4e0a\u8ff0\u89c4\u5219\u7684\u5408\u7406\u6027\uff0c\u8bf7\u6ce8\u610f\uff0c\u5f53\u6574\u6570\uff08\u5c0f\u6570\uff09\u4f4d\u6570\u4ece \\(k ( l)\\) \u589e\u52a0\u5230 \\({k}' ({l}')\\) \u65f6\uff0c\u8865\u7801\u5e38\u6570\u4ece \\(M = 2^k\\) \u589e\u52a0\u5230\\({M}' = 2^{{k}'}\\)\u3002\u56e0\u6b64\uff0c\u4e24\u4e2a\u8865\u7801\u5e38\u6570\u7684\u5dee</p> \\[ {M}' \u2212 M = 2^{{k}'} \u2212 2^k = 2^k ( 2^{{k}'\u2212 k}  \u2212 1 ) \\] <p>must be added to the representation of any negative number. This difference is a binary integer consisting of  k \u2212  k  1s followed by  k  0s; hence the need for sign extension. </p> <p>\u5fc5\u987b\u6dfb\u52a0\u5230\u4efb\u4f55\u8d1f\u6570\u7684\u8868\u793a\u4e2d\u3002\u8be5\u5dee\u503c\u662f\u4e00\u4e2a\u4e8c\u8fdb\u5236\u6574\u6570\uff0c\u7531 \\({k}' \u2212 k\\) \u4e2a 1 \u548c\u540e\u9762\u7684 k \u4e2a 0 \u7ec4\u6210\uff1b\u56e0\u6b64\u9700\u8981\u7b26\u53f7\u6269\u5c55\u3002</p> <p>A 1\u2019s-complement number must be sign-extended from both ends:</p> <p>1 \u7684\u8865\u7801\u6570\u5fc5\u987b\u4ece\u4e24\u7aef\u8fdb\u884c\u7b26\u53f7\u6269\u5c55\uff1a</p> \\[ \\cdots x_{k\u22121} x_{k\u22121} x_{k\u22121} x_{k\u22121} x_{k\u22122} \u00b7 \u00b7 \u00b7 x_1 x_0 . x_{\u22121} x_{\u22122} \u00b7 \u00b7 \u00b7 x_{\u2212l} x_{k\u22121} x_{k\u22121} x_{k\u22121}  \\cdots \\] <p>Justifying the rule above for 1\u2019s-complement numbers is left as an exercise. </p> <p>\u8bc1\u660e\u4e0a\u8ff0 1 \u8865\u7801\u89c4\u5219\u7684\u7559\u4f5c\u7ec3\u4e60\u3002</p> <p>An unsigned binary number can be multiplied or divided by 2^h  via an  h-bit left or right shift, essentially changing the location of the radix point within the original digit-vector.  To perform similar operations on 2\u2019s- and 1\u2019s-complement numbers, the operand must be first extended, so that the vacated positions on the right or left side of the fixed-width number after shifting receive the correct digit values. Put another way, in performing an h-bit right shift for dividing a number by 2^h, copies of the sign bit must be shifted in from the left. In the case of an  h-bit left shift to multiply an operand by 2^h, we need to shift in the sign bit for 1\u2019s complement and 0s for 2\u2019s complement. </p> <p>\u65e0\u7b26\u53f7\u4e8c\u8fdb\u5236\u6570\u53ef\u4ee5\u901a\u8fc7 h \u4f4d\u5de6\u79fb\u6216\u53f3\u79fb\u4e58\u4ee5\u6216\u9664\u4ee5 \\(2^h\\)\uff0c\u672c\u8d28\u4e0a\u6539\u53d8\u4e86\u539f\u59cb\u6570\u5b57\u5411\u91cf\u4e2d\u5c0f\u6570\u70b9\u7684\u4f4d\u7f6e\u3002\u8981\u5bf9 2 \u548c 1 \u8865\u7801\u8fdb\u884c\u7c7b\u4f3c\u7684\u64cd\u4f5c\uff0c\u5fc5\u987b\u5148\u6269\u5c55\u64cd\u4f5c\u6570\uff0c\u4ee5\u4fbf\u56fa\u5b9a\u5bbd\u5ea6\u6570\u5b57\u5728\u79fb\u4f4d\u540e\u53f3\u4fa7\u6216\u5de6\u4fa7\u7a7a\u51fa\u7684\u4f4d\u7f6e\u63a5\u6536\u5230\u6b63\u786e\u7684\u6570\u5b57\u503c\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u5728\u6267\u884c h \u4f4d\u53f3\u79fb\u4ee5\u5c06\u6570\u5b57\u9664\u4ee5 \\(2^h\\) \u65f6\uff0c\u7b26\u53f7\u4f4d\u7684\u526f\u672c\u5fc5\u987b\u4ece\u5de6\u4fa7\u79fb\u5165\u3002\u5728 h \u4f4d\u5de6\u79fb\u5c06\u64cd\u4f5c\u6570\u4e58\u4ee5 \\(2^h\\) \u7684\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u9700\u8981\u79fb\u5165 1 \u8865\u7801\u7684\u7b26\u53f7\u4f4d\u548c 2 \u8865\u7801\u7684 0\u3002</p>"},{"location":"Part_01/02/#25","title":"2.5 \u76f4\u63a5\u548c\u95f4\u63a5\u6709\u7b26\u53f7\u7b97\u672f","text":"<p>DIRECT AND INDIRECT SIGNED ARITHMETIC</p> <p>In the preceding pages, we dealt with the addition and subtraction of signed numbers for a variety of number representation schemes (signed-magnitude, biased, complement). In all these cases, signed numbers were handled directly by the addition/subtraction hardware ( direct signed arithmetic), consistent with our desire to avoid using separate addition and subtraction units. </p> <p>\u5728\u524d\u9762\u7684\u51e0\u9875\u4e2d\uff0c\u6211\u4eec\u8ba8\u8bba\u4e86\u5404\u79cd\u6570\u5b57\u8868\u793a\u65b9\u6848\uff08\u6709\u7b26\u53f7\u6570\u503c\u3001\u6709\u504f\u5dee\u3001\u8865\u7801\uff09\u7684\u6709\u7b26\u53f7\u6570\u7684\u52a0\u6cd5\u548c\u51cf\u6cd5\u3002\u5728\u6240\u6709\u8fd9\u4e9b\u60c5\u51b5\u4e0b\uff0c\u5e26\u7b26\u53f7\u7684\u6570\u5b57\u90fd\u7531\u52a0\u6cd5/\u51cf\u6cd5\u786c\u4ef6\u76f4\u63a5\u5904\u7406\uff08\u76f4\u63a5\u5e26\u7b26\u53f7\u7b97\u672f\uff09\uff0c\u8fd9\u4e0e\u6211\u4eec\u907f\u514d\u4f7f\u7528\u5206\u5f00\u7684\u52a0\u6cd5\u548c\u51cf\u6cd5\u5355\u5143\u7684\u613f\u671b\u4e00\u81f4\u3002</p> <p>For some arithmetic operations, it may be desirable to restrict the hardware to unsigned operands, thus necessitating  indirect signed arithmetic. Basically, the operands are converted to unsigned values, a tentative result is obtained based on these unsigned values, and finally the necessary adjustments are made to find the result corresponding to the original signed operands. Figure 2.8 depicts the direct and indirect approaches to signed arithmetic. </p> <p>\u5bf9\u4e8e\u67d0\u4e9b\u7b97\u672f\u8fd0\u7b97\uff0c\u53ef\u80fd\u9700\u8981\u5c06\u786c\u4ef6\u9650\u5236\u4e3a\u65e0\u7b26\u53f7\u64cd\u4f5c\u6570\uff0c\u56e0\u6b64\u9700\u8981 \u95f4\u63a5\u6709\u7b26\u53f7\u7b97\u672f\u3002\u57fa\u672c\u4e0a\uff0c\u64cd\u4f5c\u6570\u88ab\u8f6c\u6362\u4e3a\u65e0\u7b26\u53f7\u503c\uff0c\u6839\u636e\u8fd9\u4e9b\u65e0\u7b26\u53f7\u503c\u83b7\u5f97\u6682\u5b9a\u7ed3\u679c\uff0c\u6700\u540e\u8fdb\u884c\u5fc5\u8981\u7684\u8c03\u6574\u4ee5\u627e\u5230\u4e0e\u539f\u59cb\u6709\u7b26\u53f7\u64cd\u4f5c\u6570\u76f8\u5bf9\u5e94\u7684\u7ed3\u679c\u3002\u56fe 2.8 \u63cf\u8ff0\u4e86\u6709\u7b26\u53f7\u7b97\u672f\u7684\u76f4\u63a5\u548c\u95f4\u63a5\u65b9\u6cd5\u3002</p> <p></p> <p>Indirect signed arithmetic can be performed, for example, for multiplication or division of signed numbers, although we will see in Parts III and IV that direct algorithms are also available for this purpose. The process is trivial for signed-magnitude numbers. If  x  and  y  are biased numbers, then both the sign removal and adjustment steps involve addition/subtraction. If  x  and  y  are complement numbers, these steps involve selective complementation. </p> <p>\u95f4\u63a5\u6709\u7b26\u53f7\u7b97\u672f\u53ef\u4ee5\u6267\u884c\uff0c\u4f8b\u5982\u6709\u7b26\u53f7\u6570\u7684\u4e58\u6cd5\u6216\u9664\u6cd5\uff0c\u5c3d\u7ba1\u6211\u4eec\u5c06\u5728\u7b2c\u4e09\u90e8\u5206\u548c\u7b2c\u56db\u90e8\u5206\u4e2d\u770b\u5230\u76f4\u63a5\u7b97\u6cd5\u4e5f\u53ef\u7528\u4e8e\u6b64\u76ee\u7684\u3002\u5bf9\u4e8e\u7b26\u53f7-\u5e45\u5ea6\u8868\u793a\u6765\u8bf4\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u5f88\u7b80\u5355\u3002\u5982\u679cx\u548cy\u662f\u504f\u7f6e\u6570\uff0c\u5219\u53bb\u9664\u7b26\u53f7\u548c\u8c03\u6574\u6b65\u9aa4\u90fd\u6d89\u53ca\u52a0\u6cd5/\u51cf\u6cd5\u3002\u5982\u679c x \u548c y \u662f\u8865\u7801\uff0c\u5219\u8fd9\u4e9b\u6b65\u9aa4\u6d89\u53ca\u9009\u62e9\u6027\u4e92\u8865\u3002</p> <p>This type of preprocessing for operands, and postprocessing for computation results, is useful not only for dealing with signed values but also in the case of unacceptable or inconvenient operand values. For example, in computing sin  x, the operand can be brought to within [0,  \u03c0/ 2] by taking advantage of identities such as sin (\u2212 x) = \u2212 sin  x  and sin ( 2 \u03c0 + x) = sin (\u03c0 \u2212 x) = sin  x. Chapter 22 contains examples of such transformations. </p> <p>\u8fd9\u79cd\u7c7b\u578b\u7684\u64cd\u4f5c\u6570\u9884\u5904\u7406\u548c\u8ba1\u7b97\u7ed3\u679c\u540e\u5904\u7406\u4e0d\u4ec5\u5bf9\u4e8e\u5904\u7406\u6709\u7b26\u53f7\u503c\u5f88\u6709\u7528\uff0c\u800c\u4e14\u5728\u5904\u7406\u4e0d\u53ef\u63a5\u53d7\u6216\u4e0d\u65b9\u4fbf\u7684\u64cd\u4f5c\u6570\u503c\u7684\u60c5\u51b5\u4e0b\u4e5f\u5f88\u6709\u7528\u3002\u4f8b\u5982\uff0c\u5728\u8ba1\u7b97 sin x \u65f6\uff0c\u53ef\u4ee5\u5229\u7528 \\(\\sin(\u2212 x) = \u2212\\sin x\\) \u548c \\(\\sin ( 2 \\pi + x) = \\sin (\\pi \u2212 x) = \\sin x\\) \u7b49\u6052\u7b49\u5f0f\u5c06\u64cd\u4f5c\u6570\u9650\u5236\u5728 [0, \u03c0/ 2] \u8303\u56f4\u5185\u3002\u7b2c 22 \u7ae0\u5305\u542b\u6b64\u7c7b\u8f6c\u6362\u7684\u793a\u4f8b\u3002</p> <p>As a second example, some division algorithms become more efficient when the divisor is in a certain range (e.g., close to 1). In this case, the dividend and divisor can be scaled by the same factor in a preprocessing step to bring the divisor within the desired range (see Section 15.1).</p> <p>\u4f5c\u4e3a\u7b2c\u4e8c\u4e2a\u4f8b\u5b50\uff0c\u5f53\u9664\u6570\u5728\u4e00\u5b9a\u8303\u56f4\u5185\uff08\u4f8b\u5982\uff0c\u63a5\u8fd1 1\uff09\u65f6\uff0c\u67d0\u4e9b\u9664\u6cd5\u7b97\u6cd5\u4f1a\u53d8\u5f97\u66f4\u6709\u6548\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u88ab\u9664\u6570\u548c\u9664\u6570\u53ef\u4ee5\u5728\u9884\u5904\u7406\u6b65\u9aa4\u4e2d\u6309\u76f8\u540c\u7684\u56e0\u5b50\u7f29\u653e\uff0c\u4ee5\u4f7f\u9664\u6570\u5904\u4e8e\u6240\u9700\u7684\u8303\u56f4\u5185\uff08\u53c2\u89c1\u7b2c 15.1 \u8282\uff09\u3002</p>"},{"location":"Part_01/02/#26","title":"2.6 \u4f7f\u7528\u5e26\u7b26\u53f7\u4f4d\u7f6e\u6216\u5e26\u7b26\u53f7\u6570\u5b57","text":"<p>Using Signed Positions or Signed Digits</p> <p>The value of a 2\u2019s-complement number can be found by using the standard binary-to-decimal conversion process, except that the weight of the most significant bit (sign position) is taken to be negative. Figure 2.9 shows an example 8-bit, 2\u2019s-complement number converted to decimal by considering its sign bit to have the negative weight \u22122^7.</p> <p>2 \u7684\u8865\u7801\u6570\u7684\u503c\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528\u6807\u51c6\u4e8c\u8fdb\u5236\u5230\u5341\u8fdb\u5236\u7684\u8f6c\u6362\u8fc7\u7a0b\uff0c\u4e0d\u540c\u4e4b\u5904\u5728\u4e8e\u6700\u9ad8\u6709\u6548\u4f4d\uff08\u7b26\u53f7\u4f4d\u7f6e\uff09\u7684\u6743\u91cd\u88ab\u53d6\u4e3a\u8d1f\u6570\u3002\u56fe 2.9 \u663e\u793a\u4e86\u4e00\u4e2a 8 \u4f4d 2 \u8865\u7801\u6570\u8f6c\u6362\u4e3a\u5341\u8fdb\u5236\u7684\u793a\u4f8b\uff0c\u8003\u8651\u5176\u7b26\u53f7\u4f4d\u5177\u6709\u8d1f\u6743\u91cd \u2212\\(2^7\\)\u3002</p> <p></p> <p>This very important property of 2\u2019s-complement systems is used to advantage in many algorithms that deal directly with signed numbers. The property is formally expressed as follows:</p> <p>2 \u8865\u7801\u7cfb\u7edf\u7684\u8fd9\u4e00\u975e\u5e38\u91cd\u8981\u7684\u5c5e\u6027\u5728\u8bb8\u591a\u76f4\u63a5\u5904\u7406\u6709\u7b26\u53f7\u6570\u7684\u7b97\u6cd5\u4e2d\u5f97\u5230\u4e86\u5229\u7528\u3002\u8be5\u5c5e\u6027\u6b63\u5f0f\u8868\u793a\u5982\u4e0b\uff1a</p> \\[ \\begin{array}{l} x &amp;= (x_{k\u22121} x_{k\u22122} \\cdots x_1 x_0 . x_{\u22121} x_{\u22122} \\cdots x_{\u2212l})_{2's\u2212compl} \\\\   &amp;= \u2212x_{k\u22121}2^{k\u22121} + \\sum_{i=-l}^{k-2}x_i2^i \\end{array} \\] <p>\u8bc1\u660e\u662f\u76f8\u5f53\u7b80\u5355\u7684\uff0c\u5982\u679c\u6211\u4eec\u8003\u8651\u5206\u522b\u4e24\u79cd\u60c5\u51b5\uff1a\\(x_{k-1}=0\\) \u548c \\(x_{k-1}=1\\)</p> <p>\u5bf9\u4e8e\\(x_{k-1}=0\\) \u7684\u60c5\u51b5\u6211\u4eec\u6709</p> \\[ \\begin{array}{l} x &amp;= (0x_{k\u22122} \\cdots x_1 x_0 . x_{\u22121} x_{\u22122} \\cdots x_{\u2212l})_{2's\u2212compl} \\\\   &amp;= (0x_{k\u22122} \\cdots x_1 x_0 . x_{\u22121} x_{\u22122} \\cdots x_{\u2212l})_2 \\\\   &amp;= \\sum_{i=-l}^{k-2}x_i2^i \\end{array} \\] <p>\u5bf9\u4e8e\\(x_{k-1}=1\\) \u7684\u60c5\u51b5\u6211\u4eec\u6709</p> \\[ \\begin{array}{l} x &amp;= (1x_{k\u22122} \\cdots x_1 x_0 . x_{\u22121} x_{\u22122} \\cdots x_{\u2212l})_{2's\u2212compl} \\\\   &amp;= -[2^k-(1x_{k\u22122} \\cdots x_1 x_0 . x_{\u22121} x_{\u22122} \\cdots x_{\u2212l})_2] \\\\   &amp;= -2^{k-1}+\\sum_{i=-l}^{k-2}x_i2^i \\end{array} \\] <p>Developing the corresponding interpretation for 1\u2019s-complement numbers is left as an exercise. </p> <p>\u5f00\u53d1 1 \u8865\u7801\u7684\u76f8\u5e94\u89e3\u91ca\u7559\u4f5c\u7ec3\u4e60\u3002</p> <p>A simple generalization of the notion above immediately suggests itself [Kore81]. Let us assign negative weights to an arbitrary subset of the  k +  l  positions in a radix- r number and positive weights to the rest of the positions. A vector</p> <p>\u4e0a\u8ff0\u6982\u5ff5\u7684\u7b80\u5355\u6982\u62ec\u7acb\u5373\u663e\u73b0\u51fa\u6765[Kore81]\u3002\u8ba9\u6211\u4eec\u5c06\u8d1f\u6743\u91cd\u5206\u914d\u7ed9\u57fa\u6570 r \u6570\u4e2d \\(k + l\\) \u4e2a\u4f4d\u7f6e\u7684\u4efb\u610f\u5b50\u96c6\uff0c\u5e76\u5c06\u6b63\u6743\u91cd\u5206\u914d\u7ed9\u5176\u4f59\u4f4d\u7f6e\u3002\u4e00\u4e2a\u5411\u91cf</p> \\[ \u03bb = (\u03bb_{k\u22121} \u03bb_{k\u22122} \u00b7 \u00b7 \u00b7 \u03bb_1 \u03bb_0 . \u03bb_{\u22121} \u03bb_{\u22122} \u00b7 \u00b7 \u00b7 \u03bb_{\u2212l}) \\] <p>with elements  \u03bbi  in {\u22121, 1}, can be used to specify the signs associated with the various positions. With these conventions, the value represented by the digit vector  x  of length k +  l  is</p> <p>\u5143\u7d20 \\(\u03bb_i\\) \u5c5e\u4e8e {\u22121, 1} \uff0c\u53ef\u7528\u4e8e\u6307\u5b9a\u4e0e\u4efb\u610f\u4f4d\u7f6e\u76f8\u5173\u7684\u7b26\u53f7\u3002\u6839\u636e\u8fd9\u4e9b\u7ea6\u5b9a\uff0c\u957f\u5ea6\u4e3a \\(k + l\\) \u7684\u6570\u5b57\u5411\u91cf x \u8868\u793a\u7684\u503c\u662f</p> \\[ (x_{k\u22121} x_{k\u22122} \\cdots x_1 x_0. x_{\u22121} x_{\u22122} \\cdots x_{\u2212l})_{r, \u03bb} = \\sum_{i=-l}^{k-1}\\lambda_ix_ir^i \\] <p>Note that the scheme above covers unsigned radix- r, 2\u2019s-complement, and negative-radix number systems as special cases:</p> <p>\u8bf7\u6ce8\u610f\uff0c\u4e0a\u9762\u7684\u65b9\u6848\u6db5\u76d6\u4e86\u65e0\u7b26\u53f7\u57fa\u6570 r\u30012 \u7684\u8865\u7801\u548c\u8d1f\u57fa\u6570\u7cfb\u7edf\u4f5c\u4e3a\u7279\u6b8a\u60c5\u51b5\uff1a</p> <pre><code>\u03bb =  1  1  1 \u00b7 \u00b7 \u00b7  1  1  1  1     \u6b63\u57fa\u6570 Positive radix\n\u03bb = \u22121  1  1 \u00b7 \u00b7 \u00b7  1  1  1  1     2\u7684\u8865\u7801 2's complement\n\u03bb =          \u00b7 \u00b7 \u00b7 \u22121  1 \u22121  1     \u8d1f\u57fa\u6570 Negative radix\n</code></pre> <p>We can take one more step in the direction of generality and postulate that instead of a single sign vector \u03bb being associated with the digit positions in the number system (i.e., with all numbers represented), a separate sign vector is defined for each number. Thus, the digits are viewed as having signed values:</p> <p>\u6211\u4eec\u53ef\u4ee5\u5728\u4e00\u822c\u6027\u7684\u65b9\u5411\u4e0a\u518d\u8fc8\u51fa\u4e00\u6b65\uff0c\u5047\u8bbe\u4e0d\u662f\u5355\u4e2a\u7b26\u53f7\u5411\u91cf \u03bb \u4e0e\u6570\u5b57\u7cfb\u7edf\u4e2d\u7684\u6570\u5b57\u4f4d\u7f6e\u76f8\u5173\u8054\uff08\u5373\u8868\u793a\u6240\u6709\u6570\u5b57\uff09\uff0c\u4e3a\u6bcf\u4e2a\u6570\u5b57\u5b9a\u4e49\u4e00\u4e2a\u5355\u72ec\u7684\u7b26\u53f7\u5411\u91cf\u3002\u56e0\u6b64\uff0c\u6570\u5b57\u88ab\u89c6\u4e3a\u5177\u6709\u6709\u7b26\u53f7\u503c\uff1a</p> \\[ x_i = \\lambda_i|x_i| \\text{ \u5176\u4e2d }\\lambda_i \\in \\{ -1, 1\\} \\] <p>Here,  \u03bbi  is the sign and | xi| is the magnitude of the  i th digit. In fact once we begin to view the digits as signed values, there is no reason to limit ourselves to signed-magnitude representation of the digit values. Any type of coding, including biased or complement representation, can be used for the digits. Furthermore, the range of digit values need not be symmetric. We have already covered some examples of such signed-digit number systems in Section 1.4 (see Examples 1.1, 1.3, and 1.4). </p> <p>\u8fd9\u91cc\uff0c \\(\u03bb_i\\) \u662f\u7b26\u53f7\u800c \\(|x_i|\\)\u662f\u7b2c i \u4f4d\u6570\u5b57\u7684\u5927\u5c0f\u3002\u4e8b\u5b9e\u4e0a\uff0c\u4e00\u65e6\u6211\u4eec\u5f00\u59cb\u5c06\u6570\u5b57\u89c6\u4e3a\u6709\u7b26\u53f7\u503c\uff0c\u5c31\u6ca1\u6709\u7406\u7531\u5c06\u81ea\u5df1\u9650\u5236\u4e8e\u503c\u7684\u7b26\u53f7\u5e45\u5ea6\u8868\u793a\u3002\u4efb\u4f55\u7c7b\u578b\u7684\u7f16\u7801\uff0c\u5305\u62ec\u504f\u7f6e\u6216\u8865\u7801\u8868\u793a\uff0c\u90fd\u53ef\u4ee5\u7528\u4e8e\u6570\u5b57\u3002\u6b64\u5916\uff0c\u6570\u5b57\u503c\u7684\u8303\u56f4\u4e0d\u5fc5\u662f\u5bf9\u79f0\u7684\u3002\u6211\u4eec\u5df2\u7ecf\u5728 1.4 \u8282\u4e2d\u4ecb\u7ecd\u4e86\u6b64\u7c7b\u5e26\u7b26\u53f7\u6570\u5b57\u7cfb\u7edf\u7684\u4e00\u4e9b\u793a\u4f8b\uff08\u53c2\u89c1\u793a\u4f8b 1.1\u30011.3 \u548c 1.4\uff09\u3002</p> <p>Basically, any set [\u2212 \u03b1,  \u03b2] of  r  or more consecutive integers that includes 0 can be used as the digit set for radix  r. If exactly  r  digit values are used, then the number system is irredundant and offers a unique representation for each value within its range. On the other hand, if more than  r  digit values are used,  \u03c1 =  \u03b1 +  \u03b2 + 1 \u2212  r  represents the  redundancy index  of the number system and some values will have multiple representations. In Chapter 3, we will see that such redundant representations can eliminate the propagation of carries in addition and thus allow us to implement truly parallel fast adders. </p> <p>\u57fa\u672c\u4e0a\uff0c\u4efb\u4f55\u5305\u542b 0 \u7684 r \u4e2a\u6216\u66f4\u591a\u8fde\u7eed\u6574\u6570\u7684\u96c6\u5408 [\u2212 \u03b1, \u03b2] \u90fd\u53ef\u4ee5\u7528\u4f5c\u57fa\u6570 r \u7684\u6570\u5b57\u96c6\u3002\u5982\u679c\u6070\u597d\u4f7f\u7528 r \u4f4d\u503c\uff0c\u5219\u6570\u5b57\u7cfb\u7edf\u662f\u975e\u5197\u4f59\u7684\uff0c\u5e76\u4e3a\u5176\u8303\u56f4\u5185\u7684\u6bcf\u4e2a\u503c\u63d0\u4f9b\u552f\u4e00\u7684\u8868\u793a\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u5982\u679c\u4f7f\u7528\u591a\u4e8e r \u4e2a\u6570\u5b57\u7684\u503c\uff0c\u5219 \\(\u03c1 = \u03b1 + \u03b2 + 1 \u2212 r\\) \u8868\u793a\u6570\u5b57\u7cfb\u7edf\u7684 \u5197\u4f59\u7d22\u5f15 \uff0c\u5e76\u4e14\u67d0\u4e9b\u503c\u5c06\u5177\u6709\u591a\u79cd\u8868\u793a\u5f62\u5f0f\u3002\u5728\u7b2c3\u7ae0\u4e2d\uff0c\u6211\u4eec\u5c06\u770b\u5230\u8fd9\u79cd\u5197\u4f59\u8868\u793a\u53ef\u4ee5\u989d\u5916\u6d88\u9664\u8fdb\u4f4d\u4f20\u64ad\uff0c\u4ece\u800c\u4f7f\u6211\u4eec\u80fd\u591f\u5b9e\u73b0\u771f\u6b63\u7684\u5e76\u884c\u5feb\u901f\u52a0\u6cd5\u5668\u3002</p> <p>As an example of nonredundant signed-digit representations, consider a radix-4 number system with the digit set [\u22121, 2]. A  k-digit number of this type can represent any integer from \u2212 ( 4 k \u2212 1 )/ 3 to 2 ( 4 k \u2212 1 )/ 3. Given a standard radix-4 integer using the digit set [0, 3], it can be converted to the preceding representation by simply rewriting each digit of 3 as \u22121 + 4, where the second term becomes a carry of 1 that propagates leftward. Figure 2.10 shows a numerical example. Note that the result may require  k + 1 digits. </p> <p>\u4f5c\u4e3a\u975e\u5197\u4f59\u7b26\u53f7\u6570\u5b57\u8868\u793a\u7684\u793a\u4f8b\uff0c\u8bf7\u8003\u8651\u5177\u6709\u6570\u5b57\u96c6 [\u22121, 2] \u7684\u57fa 4 \u6570\u5b57\u7cfb\u7edf\u3002\u8fd9\u79cd\u7c7b\u578b\u7684 k \u4f4d\u6570\u5b57\u53ef\u4ee5\u8868\u793a\u4ece \\(- (4^k - 1 )/3\\) \u5230 \\(2(4^k - 1)/3\\) \u7684\u4efb\u4f55\u6574\u6570\u3002\u7ed9\u5b9a\u4f7f\u7528\u6570\u5b57\u96c6 [0, 3] \u7684\u6807\u51c6\u57fa 4 \u6574\u6570\uff0c\u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u5730\u5c06 3 \u7684\u6bcf\u4e2a\u6570\u5b57\u91cd\u5199\u4e3a \\(-1 + 4\\) \u6765\u8f6c\u6362\u4e3a\u524d\u9762\u7684\u8868\u793a\u5f62\u5f0f\uff0c\u5176\u4e2d\u7b2c\u4e8c\u9879\u6210\u4e3a\u5411\u5de6\u4f20\u64ad\u7684\u8fdb\u4f4d 1\u3002\u56fe 2.10 \u663e\u793a\u4e86\u4e00\u4e2a\u6570\u503c\u793a\u4f8b\u3002\u8bf7\u6ce8\u610f\uff0c\u7ed3\u679c\u53ef\u80fd\u9700\u8981 \\(k + 1\\) \u6570\u5b57\u3002</p> <p></p> <p>The conversion process of Fig. 2.10 stops when there remains no digit with value 3 that needs to be rewritten. The reverse conversion is similarly done by rewriting any digit of \u22121 as 3 with a borrow of 1 (carry of \u22121). </p> <p>\u5f53\u6ca1\u6709\u9700\u8981\u91cd\u5199\u7684\u503c\u4e3a3\u7684\u6570\u5b57\u65f6\uff0c\u56fe2.10\u7684\u8f6c\u6362\u8fc7\u7a0b\u505c\u6b62\u3002\u53cd\u5411\u8f6c\u6362\u7c7b\u4f3c\u5730\u901a\u8fc7\u5c06\u4efb\u4f55 -1 \u6570\u5b57\u91cd\u5199\u4e3a 3 \u5e76\u501f\u4f4d 1\uff08\u8fdb\u4f4d -1\uff09\u6765\u5b8c\u6210\u3002</p> <p>More generally, to convert between digit sets, each old digit value is rewritten as a valid new digit value and an appropriate transfer (carry or borrow) into the next higher digit position. Because these transfers can propagate, the conversion process is essentially a digit-serial one, beginning with the least-significant digit. </p> <p>\u66f4\u4e00\u822c\u5730\u8bf4\uff0c\u4e3a\u4e86\u5728\u6570\u5b57\u96c6\u4e4b\u95f4\u8fdb\u884c\u8f6c\u6362\uff0c\u6bcf\u4e2a\u65e7\u6570\u5b57\u503c\u90fd\u88ab\u91cd\u5199\u4e3a\u6709\u6548\u7684\u65b0\u6570\u5b57\u503c\uff0c\u5e76\u9002\u5f53\u8f6c\u79fb\uff08\u8fdb\u4f4d\u6216\u501f\u4f4d\uff09\u5230\u4e0b\u4e00\u4e2a\u66f4\u9ad8\u7684\u6570\u5b57\u4f4d\u7f6e\u3002\u7531\u4e8e\u8fd9\u4e9b\u4f20\u8f93\u53ef\u4ee5\u4f20\u64ad\uff0c\u56e0\u6b64\u8f6c\u6362\u8fc7\u7a0b\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u6570\u5b57\u4e32\u884c\u8fc7\u7a0b\uff0c\u4ece\u6700\u4f4e\u6709\u6548\u4f4d\u5f00\u59cb\u3002</p> <p>As an example of redundant signed-digit representations, consider a radix-4 number system with the digit set [\u22122, 2]. A  k-digit number of this type can represent any integer from \u22122 ( 4 k \u2212 1 )/ 3 to 2 ( 4 k \u2212 1 )/ 3. Given a standard radix-4 number using the digit set [0, 3], it can be converted to the preceding representation by simply rewriting each digit of 3 as \u22121 + 4 and each digit of 2 as \u22122 + 4, where the second term in each case becomes a carry of 1 that propagates leftward. Figure 2.11 shows a numerical example. </p> <p>\u4f5c\u4e3a\u5197\u4f59\u7b26\u53f7\u6570\u5b57\u8868\u793a\u7684\u793a\u4f8b\uff0c\u8bf7\u8003\u8651\u5177\u6709\u6570\u5b57\u96c6 [\u22122, 2] \u7684\u57fa 4 \u6570\u5b57\u7cfb\u7edf\u3002\u8fd9\u79cd\u7c7b\u578b\u7684 k \u4f4d\u6570\u5b57\u53ef\u4ee5\u8868\u793a\u4ece \\(\u22122 ( 4^k \u2212 1 )/ 3 \u5230 2 ( 4^k \u2212 1 )/ 3\\) \u7684\u4efb\u4f55\u6574\u6570\u3002\u7ed9\u5b9a\u4f7f\u7528\u6570\u5b57\u96c6 [0, 3] \u7684\u6807\u51c6\u57fa 4 \u6570\u5b57\uff0c\u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u5730\u5c06 3 \u7684\u6bcf\u4e2a\u6570\u5b57\u91cd\u5199\u4e3a \\(\u22121 + 4\\) \u5e76\u5c06 2 \u7684\u6bcf\u4e2a\u6570\u5b57\u91cd\u5199\u4e3a \\(\u22122 + 4\\) \u6765\u8f6c\u6362\u4e3a\u524d\u9762\u7684\u8868\u793a\u5f62\u5f0f\uff0c\u5176\u4e2d\u6bcf\u79cd\u60c5\u51b5\u4e0b\u7684\u7b2c\u4e8c\u9879\u90fd\u6210\u4e3a\u5411\u5de6\u4f20\u64ad\u7684\u8fdb\u4f4d 1\u3002\u56fe 2.11 \u663e\u793a\u4e86\u4e00\u4e2a\u6570\u503c\u793a\u4f8b\u3002</p> <p></p> <p>In this case, the transfers do not propagate, since each transfer of 1 can be absorbed by the next higher position that has a digit value in [\u22122, 1], forming a final result digit in [\u22122, 2]. The conversion process from conventional radix-4 to the preceding redundant representation is thus carry-free. The reverse process, however, remains digit-serial. </p> <p>\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u4f20\u8f93\u4e0d\u4f1a\u4f20\u64ad\uff0c\u56e0\u4e3a\u6bcf\u4e2a 1 \u7684\u4f20\u8f93\u90fd\u53ef\u4ee5\u88ab\u5177\u6709 [\u22122, 1] \u4e2d\u6570\u5b57\u503c\u7684\u4e0b\u4e00\u4e2a\u66f4\u9ad8\u4f4d\u7f6e\u5438\u6536\uff0c\u5f62\u6210\u6700\u7ec8\u7ed3\u679c\u6570\u5b57\u8303\u56f4\u5728[\u22122, 2]\u3002\u56e0\u6b64\uff0c\u4ece\u4f20\u7edf\u57fa\u6570 4 \u5230\u524d\u9762\u7684\u5197\u4f59\u8868\u793a\u7684\u8f6c\u6362\u8fc7\u7a0b\u662f\u65e0\u8fdb\u4f4d\u7684\u3002\u7136\u800c\uff0c\u76f8\u53cd\u7684\u8fc7\u7a0b\u4ecd\u7136\u662f\u6570\u5b57\u4e32\u884c\u7684\u3002</p> <p>We end this chapter by extending the dot notation of Section 1.6 to include negatively weighted bits, or negabits, which are represented as small hollow circles. Using this extended dot notation, positive-radix, 2\u2019s-complement, and negative-radix numbers, compared earlier in this section, can be represented graphically as in Fig. 2.12. Also, arithmetic algorithms on such numbers can be visualized for better understanding. For example, Fig. 2.13 depicts the operands, intermediate values, and final results when </p> <p>\u6211\u4eec\u901a\u8fc7\u6269\u5c55\u7b2c 1.6 \u8282\u7684\u70b9\u8868\u793a\u6cd5\u6765\u7ed3\u675f\u672c\u7ae0\uff0c\u4ee5\u5305\u62ec\u8d1f\u6743\u91cd\u4f4d\u6216\u8d1f\u4f4d\uff0c\u5b83\u4eec\u8868\u793a\u4e3a\u5c0f\u7a7a\u5fc3\u5706\u5708\u3002\u4f7f\u7528\u8fd9\u79cd\u6269\u5c55\u7684\u70b9\u8868\u793a\u6cd5\uff0c\u672c\u8282\u524d\u9762\u6bd4\u8f83\u7684\u6b63\u57fa\u6570\u30012 \u7684\u8865\u7801\u548c\u8d1f\u57fa\u6570\u53ef\u4ee5\u7528\u56fe\u5f62\u8868\u793a\uff0c\u5982\u56fe 2.12 \u6240\u793a\u3002\u6b64\u5916\uff0c\u53ef\u4ee5\u5c06\u8fd9\u4e9b\u6570\u5b57\u7684\u7b97\u672f\u7b97\u6cd5\u53ef\u89c6\u5316\uff0c\u4ee5\u4fbf\u66f4\u597d\u5730\u7406\u89e3\u3002\u4f8b\u5982\uff0c\u56fe2.13\u63cf\u8ff0\u4e86\u56fe2.11\u65f6\u7684\u64cd\u4f5c\u6570\u3001\u4e2d\u95f4\u503c\u548c\u6700\u7ec8\u7ed3\u679c</p> <p></p> <p>adding or multiplying 2\u2019s-complement numbers. As a case in point, Fig. 2.13b helps us understand that to multiply 2\u2019s-complement numbers, we need a process that allows us to add partial results containing a mix of posibits and negabits, in a way that yields a final result that includes only 1 negabit.</p> <p>2 \u7684\u8865\u7801\u6570\u76f8\u52a0\u6216\u76f8\u4e58\u3002\u4f5c\u4e3a\u4e00\u4e2a\u4f8b\u5b50\uff0c\u56fe 2.13b \u5e2e\u52a9\u6211\u4eec\u7406\u89e3\uff0c\u8981\u4e58\u4ee5 2 \u7684\u8865\u7801\uff0c\u6211\u4eec\u9700\u8981\u4e00\u4e2a\u8fc7\u7a0b\uff0c\u5141\u8bb8\u6211\u4eec\u5c06\u5305\u542b\u6b63\u4f4d\u548c\u8d1f\u4f4d\u6df7\u5408\u7684\u90e8\u5206\u7ed3\u679c\u76f8\u52a0\uff0c\u4ece\u800c\u4ea7\u751f\u4ec5\u5305\u542b 1 \u4e2a\u8d1f\u4f4d\u7684\u6700\u7ec8\u7ed3\u679c\u3002</p>"},{"location":"Part_01/02/#_1","title":"\u95ee\u9898","text":""},{"location":"Part_01/02/#_2","title":"\u53c2\u8003\u6587\u732e\u548c\u8fdb\u4e00\u6b65\u9605\u8bfb","text":"<pre><code>[Aviz61]    Avizienis, A., \u201cSigned-Digit Number Representation for Fast Parallel Arithmetic,\u201d\n            IRE Trans. Electronic Computers, Vol. 10, pp. 389\u2013400, 1961.\n[Gosl80]    Gosling, J. B., Design of Arithmetic Units for Digital Computers, Macmillan,\n            1980.\n[Knut97]    Knuth, D. E., The Art of Computer Programming, 3rd ed., Vol. 2: Seminumerical\n            Algorithms, Addison-Wesley, 1997.\n[Kore81]    Koren, I., and Y. Maliniak, \u201cOn Classes of Positive, Negative, and Imaginary Radix\n            Number Systems,\u201d IEEE Trans. Computers, Vol. 30, No. 5, pp. 312\u2013317, 1981.\n[Korn94]    Kornerup, P., \u201cDigit-Set Conversions: Generalizations and Applications,\u201d IEEE\n            Trans. Computers, Vol. 43, No. 8, pp. 622\u2013629, 1994.\n[Parh90]    Parhami, B., \u201cGeneralized Signed-Digit Number Systems: A Unifying Framework\n            for Redundant Number Representations,\u201d IEEE Trans. Computers, Vol. 39, No. 1,\n            pp. 89\u201398, 1990.\n</code></pre>"},{"location":"Part_01/03/","title":"3. \u5197\u4f59\u6570\u7cfb\u7edf","text":"<p>Redundant Number Systems</p> <p>\u201cNumbers constitute the only universal language.\u201d </p> <p>\u2014 NATHANAE LWEST</p> <p>\u201c\u6570\u5b57\u6784\u6210\u4e86\u552f\u4e00\u7684\u901a\u7528\u8bed\u8a00\u3002\u201d</p> <p>\u2014 \u7eb3\u6492\u5c3c\u5c14\u00b7\u97e6\u65af\u7279</p> <p>This chapter deals with the representation of signed fixed-point numbers using a positive integer radix  r  and a redundant digit set composed of more than  r  digit values. After showing that such representations eliminate carry propagation, we cover variations in digit sets, addition algorithms, input/output conversions, and arithmetic support functions. Chapter topics include:</p> <p>\u672c\u7ae0\u8ba8\u8bba\u6709\u7b26\u53f7\u5b9a\u70b9\u6570\u4f7f\u7528\u6b63\u6574\u6570\u57fa\u6570r\u548c\u7531\u591a\u4e8er\u4e2a\u6570\u5b57\u503c\u7ec4\u6210\u7684\u5197\u4f59\u6570\u5b57\u96c6\u7684\u8868\u793a\u6cd5\u3002\u5728\u8bc1\u660e\u8fd9\u79cd\u8868\u793a\u6d88\u9664\u4e86\u8fdb\u4f4d\u4f20\u64ad\u4e4b\u540e\uff0c\u6211\u4eec\u4ecb\u7ecd\u4e86\u6570\u5b57\u96c6\u3001\u52a0\u6cd5\u7b97\u6cd5\u3001\u8f93\u5165/\u8f93\u51fa\u8f6c\u6362\u548c\u7b97\u672f\u652f\u6301\u51fd\u6570\u7684\u53d8\u5316\u3002\u7ae0\u8282\u4e3b\u9898\u5305\u62ec\uff1a</p> <p>3.1 \u5904\u7406\u8fdb\u4f4d\u95ee\u9898 Coping with the Carry Problem</p> <p>3.2 \u8ba1\u7b97\u673a\u7b97\u672f\u4e2d\u7684\u5197\u4f59 Redundancy in Computer Arithmetic</p> <p>3.3 \u6570\u5b57\u96c6\u548c\u6570\u5b57\u96c6\u8f6c\u6362Digit Sets and Digit-Set Conversions</p> <p>3.4 \u5e7f\u4e49\u7684\u6709\u7b26\u53f7\u6570\u5b57\u6570 Generalized Signed-Digit Numbers</p> <p>3.5 \u65e0\u8fdb\u4f4d\u52a0\u6cd5\u7b97\u6cd5 Carry-Free Addition Algorithms</p> <p>3.6 \u8f6c\u6362\u548c\u652f\u6301\u529f\u80fd Conversions and Support Functions</p>"},{"location":"Part_01/03/#31","title":"3.1 \u5904\u7406\u8fdb\u4f4d\u95ee\u9898","text":"<p>Addition is a primary building block in implementing arithmetic operations. If addition is slow or expensive, all other operations suffer in speed or cost. Addition can be slow and/or expensive because:</p> <p>a. With  k-digit operands, one has to allow for O( k) worst-case carry-propagation stages in simple ripple-carry adder design. </p> <p>b. The carry computation network is a major source of complexity and cost in the design of carry-lookahead and other fast adders. </p> <p>The carry problem can be dealt with in several ways:</p> <p>1. Limit carry propagation to within a small number of bits. </p> <p>2. Detect the end of propagation rather than wait for worst-case time. </p> <p>3. Speed up propagation via lookahead and other methods. </p> <p>4. Ideal: Eliminate carry propagation altogether! </p> <p>\u52a0\u6cd5\u662f\u5b9e\u73b0\u7b97\u672f\u8fd0\u7b97\u7684\u4e3b\u8981\u6784\u5efa\u5757\u3002\u5982\u679c\u52a0\u6cd5\u901f\u5ea6\u6162\u6216\u6210\u672c\u9ad8\uff0c\u5219\u6240\u6709\u5176\u4ed6\u64cd\u4f5c\u7684\u901f\u5ea6\u6216\u6210\u672c\u90fd\u4f1a\u53d7\u5230\u5f71\u54cd\u3002\u52a0\u6cd5\u53ef\u80fd\u4f1a\u5f88\u6162\u548c/\u6216\u6602\u8d35\u662f\u56e0\u4e3a\uff1a</p> <p>a. \u5bf9\u4e8e k \u4f4d\u64cd\u4f5c\u6570\uff0c\u5728\u7b80\u5355\u7684\u7eb9\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\u8bbe\u8ba1\u4e2d\u5fc5\u987b\u8003\u8651\u5230 O(k) \u4e2a\u6700\u574f\u60c5\u51b5\u7684\u8fdb\u4f4d\u4f20\u64ad\u9636\u6bb5\u3002</p> <p>b. \u8fdb\u4f4d\u8ba1\u7b97\u7f51\u7edc\u662f\u8d85\u524d\u8fdb\u4f4d\u548c\u5176\u4ed6\u5feb\u901f\u52a0\u6cd5\u5668\u8bbe\u8ba1\u4e2d\u590d\u6742\u6027\u548c\u6210\u672c\u7684\u4e3b\u8981\u6765\u6e90\u3002</p> <p>\u8fdb\u4f4d\u95ee\u9898\u53ef\u4ee5\u901a\u8fc7\u591a\u79cd\u65b9\u5f0f\u5904\u7406\uff1a</p> <ol> <li> <p>\u5c06\u8fdb\u4f4d\u4f20\u64ad\u9650\u5236\u5728\u5c11\u91cf\u4f4d\u5185\u3002</p> </li> <li> <p>\u68c0\u6d4b\u4f20\u64ad\u7684\u7ed3\u675f\u800c\u4e0d\u662f\u7b49\u5f85\u6700\u574f\u60c5\u51b5\u7684\u65f6\u95f4\u3002</p> </li> <li> <p>\u901a\u8fc7\u8d85\u524d\u770b\u548c\u5176\u4ed6\u65b9\u6cd5\u52a0\u901f\u4f20\u64ad\u3002</p> </li> <li> <p>\u7406\u60f3\uff1a\u5b8c\u5168\u6d88\u9664\u8fdb\u4f4d\u4f20\u64ad\uff01</p> </li> </ol> <p>As examples of option 1, hybrid-redundant and residue number system representations are covered in Section 3.4 and Chapter 4, respectively. Asynchronous adder design (option 2) is considered in Section 5.4. Speedup methods for carry propagation are covered in Chapters 6 and 7. </p> <p>In the remainder of this chapter, we deal with option 4, focusing first on the question: Can numbers be represented in such a way that addition does not involve carry propagation? We will see shortly that this is indeed possible. The resulting number representations can be used as the primary encoding scheme in the design of high-performance systems and are also useful in representing intermediate results in machines that use conventional number representation. </p> <p>\u4f5c\u4e3a\u9009\u9879 1 \u7684\u793a\u4f8b\uff0c\u7b2c 3.4 \u8282\u548c\u7b2c 4 \u7ae0\u5206\u522b\u4ecb\u7ecd\u4e86\u6df7\u5408\u5197\u4f59\u548c\u6b8b\u6570\u7cfb\u7edf\u8868\u793a\u3002\u7b2c 5.4 \u8282\u8003\u8651\u4e86\u5f02\u6b65\u52a0\u6cd5\u5668\u8bbe\u8ba1\uff08\u9009\u9879 2\uff09\u3002\u7b2c 6 \u7ae0\u548c\u7b2c 7 \u7ae0\u4ecb\u7ecd\u4e86\u8fdb\u4f4d\u4f20\u64ad\u7684\u52a0\u901f\u65b9\u6cd5\u3002</p> <p>\u5728\u672c\u7ae0\u7684\u5176\u4f59\u90e8\u5206\uff0c\u6211\u4eec\u5c06\u8ba8\u8bba\u9009\u9879 4\uff0c\u9996\u5148\u5173\u6ce8\u8fd9\u4e2a\u95ee\u9898\uff1a\u6570\u5b57\u662f\u5426\u53ef\u4ee5\u7528\u52a0\u6cd5\u4e0d\u6d89\u53ca\u8fdb\u4f4d\u4f20\u64ad\u7684\u65b9\u5f0f\u8868\u793a\uff1f\u6211\u4eec\u5f88\u5feb\u5c31\u4f1a\u770b\u5230\u8fd9\u786e\u5b9e\u662f\u53ef\u80fd\u7684\u3002\u7531\u6b64\u4ea7\u751f\u7684\u6570\u5b57\u8868\u793a\u53ef\u4ee5\u7528\u4f5c\u9ad8\u6027\u80fd\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u7684\u4e3b\u8981\u7f16\u7801\u65b9\u6848\uff0c\u5e76\u4e14\u4e5f\u53ef\u7528\u4e8e\u8868\u793a\u4f7f\u7528\u4f20\u7edf\u6570\u5b57\u8868\u793a\u7684\u673a\u5668\u4e2d\u7684\u4e2d\u95f4\u7ed3\u679c\u3002</p> <p>We begin with a decimal example  (r = 10 ), assuming the standard digit set [0, 9].  Consider the addition of the following two decimal numbers without carry propagation.  For this, we simply compute \u201cposition sums\u201d and write them down in the corresponding columns. We can use the symbols  A = 10,  B = 11,  C = 12, etc., for the extended digit values or simply represent them with two standard digits. </p> <p>\u6211\u4eec\u4ece\u4e00\u4e2a\u5341\u8fdb\u5236\u793a\u4f8b (r = 10) \u5f00\u59cb\uff0c\u5047\u8bbe\u6807\u51c6\u6570\u5b57\u96c6 [0, 9]\u3002 \u8003\u8651\u4ee5\u4e0b\u4e24\u4e2a\u5341\u8fdb\u5236\u6570\u76f8\u52a0\u800c\u4e0d\u8fdb\u884c\u8fdb\u4f4d\u4f20\u64ad\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u53ea\u9700\u8ba1\u7b97\u201c\u4f4d\u7f6e\u603b\u548c\u201d\u5e76\u5c06\u5176\u5199\u5728\u76f8\u5e94\u7684\u5217\u4e2d\u3002\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u7b26\u53f7 A = 10\u3001B = 11\u3001C = 12 \u7b49\u6765\u8868\u793a\u6269\u5c55\u6570\u5b57\u503c\uff0c\u6216\u8005\u7b80\u5355\u5730\u7528\u4e24\u4e2a\u6807\u51c6\u6570\u5b57\u6765\u8868\u793a\u5b83\u4eec\u3002</p> <pre><code>   5  7  8  2  4  9\n+  6  2  9  3  8  9     Operand digits in [0, 9]\n----------------------------------------------------\n  11  9 17  5 12 18     Position sums in [0, 18]\n</code></pre> <p>So, if we allow the digit set [0, 18], the scheme works, but only for the first addition! Subsequent additions will cause problems. </p> <p>\u56e0\u6b64\uff0c\u5982\u679c\u6211\u4eec\u5141\u8bb8\u6570\u5b57\u96c6 [0, 18]\uff0c\u5219\u8be5\u65b9\u6848\u6709\u6548\uff0c\u4f46\u4ec5\u9002\u7528\u4e8e\u7b2c\u4e00\u6b21\u52a0\u6cd5\uff01\u540e\u7eed\u6dfb\u52a0\u4f1a\u51fa\u73b0\u95ee\u9898\u3002</p> <p>Consider now adding two numbers in the radix-10 number system using the digit set [0, 18]. The sum of digits for each position is in [0, 36], which can be decomposed into an interim sum in [0, 16] and a transfer digit in [0, 2]. In other words</p> <p>\u73b0\u5728\u8003\u8651\u4f7f\u7528\u6570\u5b57\u96c6[0, 18]\u5c06\u57fa 10 \u6570\u5b57\u7cfb\u7edf\u4e2d\u7684\u4e24\u4e2a\u6570\u5b57\u76f8\u52a0\u3002\u6bcf\u4e2a\u4f4d\u7f6e\u7684\u6570\u5b57\u548c\u5728[0, 36]\u4e2d\uff0c\u53ef\u4ee5\u5206\u89e3\u4e3a[0, 16]\u4e2d\u7684\u4e2d\u95f4\u548c\u548c[0, 2]\u4e2d\u7684\u8f6c\u79fb\u6570\u5b57\u3002\u6362\u53e5\u8bdd\u8bf4</p> <p>\u200b     [0, 36] = 10 \u00d7 [0, 2] + [0, 16]</p> <p>Adding the interim sum and the incoming transfer digit yields a digit in [0, 18] and creates no new transfer. In interval notation, we have</p> <p>\u5c06\u4e34\u65f6\u603b\u548c\u4e0e\u4f20\u5165\u7684\u4f20\u8f93\u6570\u5b57\u76f8\u52a0\u4f1a\u4ea7\u751f [0, 18] \u4e2d\u7684\u6570\u5b57\uff0c\u5e76\u4e14\u4e0d\u4f1a\u521b\u5efa\u65b0\u7684\u4f20\u8f93\u3002\u5728\u533a\u95f4\u8868\u793a\u6cd5\u4e2d\uff0c\u6211\u4eec\u6709</p> <p>\u200b    [0, 16] + [0, 2] = [0, 18]</p> <p>Figure 3.1 shows an example addition. </p> <p>\u56fe 3.1 \u663e\u793a\u4e86\u4e00\u4e2a\u52a0\u6cd5\u793a\u4f8b\u3002</p> <p></p> <p>So, even though we cannot do true carry-free addition (Fig. 3.2a), the next best thing, where carry propagates by only one position (Fig. 3.2b), is possible if we use the digit set [0, 18] in radix 10. We refer to this best possible scheme as \u201ccarry-free\u201d addition. The key to the ability to do carry-free addition is the representational redundancy that provides multiple encodings for some numbers. Figure 3.2c shows that the single-stage propagation of transfers can be eliminated by a simple lookahead scheme; that is, instead of first computing the transfer into position  i  based on the digits  xi\u22121 and  yi\u22121 and then combining it with the interim sum, we can determine  si  directly from  xi,  yi,  xi\u22121, and yi\u22121. This may make the adder logic somewhat more complex, but in general the result is higher speed. </p> <p>\u56e0\u6b64\uff0c\u5373\u4f7f\u6211\u4eec\u4e0d\u80fd\u8fdb\u884c\u771f\u6b63\u7684\u65e0\u8fdb\u4f4d\u52a0\u6cd5\uff08\u56fe 3.2a\uff09\uff0c\u5982\u679c\u6211\u4eec\u5728\u57fa\u6570 10 \u4e2d\u4f7f\u7528\u6570\u5b57\u96c6 [0, 18]\uff0c\u5219\u4e0b\u4e00\u4e2a\u6700\u597d\u7684\u65b9\u6848\u662f\u53ef\u80fd\u7684\uff0c\u5176\u4e2d\u8fdb\u4f4d\u4ec5\u4f20\u64ad\u4e00\u4e2a\u4f4d\u7f6e\uff08\u56fe 3.2b\uff09\u3002\u6211\u4eec\u5c06\u8fd9\u79cd\u6700\u4f73\u53ef\u80fd\u65b9\u6848\u79f0\u4e3a\u201c\u65e0\u8fdb\u4f4d\u201d\u52a0\u6cd5\u3002\u8fdb\u884c\u65e0\u8fdb\u4f4d\u52a0\u6cd5\u7684\u80fd\u529b\u7684\u5173\u952e\u662f\u8868\u793a\u5197\u4f59\uff0c\u5b83\u4e3a\u67d0\u4e9b\u6570\u5b57\u63d0\u4f9b\u4e86\u591a\u79cd\u7f16\u7801\u3002\u56fe3.2c\u663e\u793a\u5355\u7ea7\u4f20\u8f93\u7684\u4f20\u64ad\u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u7684\u524d\u77bb\u65b9\u6848\u6765\u6d88\u9664\uff1b\u4e5f\u5c31\u662f\u8bf4\uff0c\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u6839\u636e \\(x_i\u3001y_i\u3001x_{i\u22121}\\) \u548c \\(y_{i\u22121}\\) \u786e\u5b9a \\(s_i\\)\uff0c\u800c\u4e0d\u662f\u9996\u5148\u6839\u636e\u6570\u5b57 \\(x_{i\u22121}\\) \u548c \\(y_{i\u22121}\\) \u8ba1\u7b97\u5230\u4f4d\u7f6e \\(i\\) \u7684\u8f6c\u79fb\uff0c\u7136\u540e\u5c06\u5176\u4e0e\u4e34\u65f6\u548c\u76f8\u7ed3\u5408\u3002\u8fd9\u53ef\u80fd\u4f1a\u4f7f\u52a0\u6cd5\u5668\u903b\u8f91\u66f4\u52a0\u590d\u6742\uff0c\u4f46\u901a\u5e38\u7ed3\u679c\u662f\u901f\u5ea6\u66f4\u9ad8\u3002</p> <p></p> <p>In the decimal example of Fig. 3.1, the digit set [0, 18] was used to effect carry-free addition. The 9 \u201cdigit\u201d values 10 through 18 are redundant. However, we really do not need this much redundancy in a decimal number system for carry-free addition; the digit set [0, 11] will do. Our example addition (after converting the numbers to the new digit set) is shown in Fig. 3.3. </p> <p>\u5728\u56fe 3.1 \u7684\u5341\u8fdb\u5236\u793a\u4f8b\u4e2d\uff0c\u6570\u5b57\u96c6 [0, 18] \u7528\u4e8e\u5b9e\u73b0\u65e0\u8fdb\u4f4d\u52a0\u6cd5\u3002 10 \u5230 18 \u7684 9 \u4e2a\u201c\u6570\u5b57\u201d\u503c\u662f\u5197\u4f59\u7684\u3002\u5728\u5341\u8fdb\u5236\u6570\u5b57\u7cfb\u7edf\u4e2d\uff0c\u6211\u4eec\u786e\u5b9e\u4e0d\u9700\u8981\u8fd9\u4e48\u591a\u5197\u4f59\u6765\u8fdb\u884c\u65e0\u8fdb\u4f4d\u52a0\u6cd5\uff1b\u6570\u5b57\u96c6 [0, 11] \u5373\u53ef\u3002\u6211\u4eec\u7684\u52a0\u6cd5\u793a\u4f8b\uff08\u5c06\u6570\u5b57\u8f6c\u6362\u4e3a\u65b0\u7684\u6570\u5b57\u96c6\u4e4b\u540e\uff09\u5982\u56fe 3.3 \u6240\u793a\u3002</p> <p></p> <p>A natural question at this point is: How much redundancy in the digit set is needed to enable carry-free addition? For example, will the example addition of Fig. 3.3 work with the digit set [0, 10]? (Try it and see.) We will answer this question in Section 3.5. </p> <p>\u6b64\u65f6\u4e00\u4e2a\u81ea\u7136\u7684\u95ee\u9898\u662f\uff1a\u6570\u5b57\u96c6\u4e2d\u9700\u8981\u591a\u5c11\u5197\u4f59\u624d\u80fd\u5b9e\u73b0\u65e0\u8fdb\u4f4d\u52a0\u6cd5\uff1f\u4f8b\u5982\uff0c\u56fe 3.3 \u4e2d\u7684\u52a0\u6cd5\u793a\u4f8b\u662f\u5426\u9002\u7528\u4e8e\u6570\u5b57\u96c6 [0, 10]\uff1f \uff08\u5c1d\u8bd5\u4e00\u4e0b\u770b\u770b\u3002\uff09\u6211\u4eec\u5c06\u5728 3.5 \u8282\u4e2d\u56de\u7b54\u8fd9\u4e2a\u95ee\u9898\u3002</p>"},{"location":"Part_01/03/#32","title":"3.2 \u8ba1\u7b97\u673a\u7b97\u672f\u4e2d\u7684\u5197\u4f59","text":"<p>Redundancy is used extensively for speeding up arithmetic operations. The oldest example, first suggested in 1959 [Metz59], pertains to carry-save or stored-carry numbers using the radix-2 digit set [0, 2] for fast addition of a sequence of binary operands. Figure 3.4 provides an example, showing how the intermediate sum is kept in stored-carry format, allowing each subsequent addition to be performed in a carry-free manner. </p> <p>\u5197\u4f59\u88ab\u5e7f\u6cdb\u7528\u4e8e\u52a0\u901f\u7b97\u672f\u8fd0\u7b97\u3002\u6700\u53e4\u8001\u7684\u793a\u4f8b\u4e8e 1959 \u5e74\u9996\u6b21\u63d0\u51fa [Metz59]\uff0c\u6d89\u53ca\u4f7f\u7528\u57fa\u6570 2 \u6570\u5b57\u96c6 [0, 2] \u8fdb\u884c\u4e8c\u8fdb\u5236\u64cd\u4f5c\u6570\u5e8f\u5217\u7684\u5feb\u901f\u52a0\u6cd5\u7684\u8fdb\u4f4d\u4fdd\u5b58\u6216\u5b58\u50a8\u8fdb\u4f4d\u6570\u3002\u56fe 3.4 \u63d0\u4f9b\u4e86\u4e00\u4e2a\u793a\u4f8b\uff0c\u663e\u793a\u4e86\u4e2d\u95f4\u548c\u5982\u4f55\u4ee5\u5b58\u50a8\u8fdb\u4f4d\u683c\u5f0f\u4fdd\u5b58\uff0c\u4ece\u800c\u5141\u8bb8\u4ee5\u65e0\u8fdb\u4f4d\u65b9\u5f0f\u6267\u884c\u6bcf\u4e2a\u540e\u7eed\u52a0\u6cd5\u3002</p> <p></p> <p>Why is this scheme called carry-save or stored-carry? Figure 3.5 provides an explanation. Let us use the 2-bit encoding</p> <p>\u4e3a\u4ec0\u4e48\u8fd9\u4e2a\u65b9\u6848\u88ab\u79f0\u4e3a\u8fdb\u4f4d\u4fdd\u5b58\u6216\u5b58\u50a8\u8fdb\u4f4d\uff1f\u56fe 3.5 \u63d0\u4f9b\u4e86\u4e00\u4e2a\u89e3\u91ca\u3002\u8ba9\u6211\u4eec\u4f7f\u75282\u4f4d\u7f16\u7801</p> <p>\u200b      0 :  (0, 0),  1 : (0, 1) \u6216 (1, 0),  2 :  (1, 1)</p> <p>to represent the digit set [0, 2]. With this encoding, each stored-carry number is really composed of two binary numbers, one for each bit of the encoding. These two binary numbers can be added to an incoming binary number, producing two binary numbers composed of the sum bits kept in place and the carry bits shifted one position to the left. </p> <p>\u8868\u793a\u6570\u5b57\u96c6 [0, 2]\u3002\u901a\u8fc7\u8fd9\u79cd\u7f16\u7801\uff0c\u6bcf\u4e2a\u5b58\u50a8\u8fdb\u4f4d\u6570\u5b9e\u9645\u4e0a\u7531\u4e24\u4e2a\u4e8c\u8fdb\u5236\u6570\u7ec4\u6210\uff0c\u6bcf\u4e2a\u4e8c\u8fdb\u5236\u6570\u5bf9\u5e94\u7f16\u7801\u7684\u6bcf\u4e00\u4f4d\u3002\u8fd9\u4e24\u4e2a\u4e8c\u8fdb\u5236\u6570\u53ef\u4ee5\u4e0e\u4f20\u5165\u7684\u4e8c\u8fdb\u5236\u6570\u76f8\u52a0\uff0c\u4ea7\u751f\u4e24\u4e2a\u4e8c\u8fdb\u5236\u6570\uff0c\u5176\u4e2d\u548c\u4f4d\u4fdd\u6301\u5728\u539f\u4f4d\uff0c\u8fdb\u4f4d\u4f4d\u5411\u5de6\u79fb\u52a8\u4e00\u4f4d\u3002</p> <p>These sum and carry bits form the partial sum and can be stored in two registers for the next addition. Thus, the carries are \u201csaved\u201d or \u201cstored\u201d instead of being allowed to propagate. </p> <p>\u8fd9\u4e9b\u548c\u548c\u8fdb\u4f4d\u4f4d\u5f62\u6210\u90e8\u5206\u548c\uff0c\u5e76\u4e14\u53ef\u4ee5\u5b58\u50a8\u5728\u4e24\u4e2a\u5bc4\u5b58\u5668\u4e2d\u4ee5\u4f9b\u4e0b\u4e00\u6b21\u52a0\u6cd5\u4f7f\u7528\u3002\u56e0\u6b64\uff0c\u8fdb\u4f4d\u88ab\u201c\u4fdd\u5b58\u201d\u6216\u201c\u5b58\u50a8\u201d\uff0c\u800c\u4e0d\u662f\u88ab\u5141\u8bb8\u4f20\u64ad\u3002</p> <p></p> <p>Figure 3.5 shows that one stored-carry number and one standard binary number can be added to form a stored-carry sum in a single full-adder delay (2\u20134 gate levels, depending on the full adder\u2019s logic implementation of the outputs  s =  x \u2295  y \u2295  c in and c out =  xy\u2228 xc in \u2228 yc in ). This is significantly faster than standard carry-propagate addition to accumulate the sum of several binary numbers, even if a fast carry-lookahead adder is used for the latter. Of course once the final sum has been obtained in stored-carry form, it may have to be converted to standard binary by using a carry-propagate adder to add the two components of the stored-carry number. The key point is that the carry-propagation delay occurs only once, at the very end, rather than in each addition step. </p> <p>\u56fe3.5\u663e\u793a\u4e861\u4e2a\u5b58\u50a8\u8fdb\u4f4d\u6570\u548c1\u4e2a\u6807\u51c6\u4e8c\u8fdb\u5236\u6570\u53ef\u4ee5\u76f8\u52a0\u5f97\u5230\u5b58\u50a8\u8fdb\u4f4d\u6570\uff0c\u9700\u8981\u5355\u4e2a\u5168\u52a0\u5668\u5ef6\u8fdf\uff082-4 \u4e2a\u95e8\u7ea7\uff0c\u53d6\u51b3\u4e8e\u5168\u52a0\u5668\u7684\u8f93\u51fa\u903b\u8f91\u5b9e\u73b0 s = x \u2295 y \u2295 c in \u548c c out = xy\u2228 xc in \u2228 yc in \uff09\u3002\u8fd9\u6bd4\u7d2f\u52a0\u51e0\u4e2a\u4e8c\u8fdb\u5236\u6570\u4e4b\u548c\u7684\u6807\u51c6\u8fdb\u4f4d\u4f20\u64ad\u52a0\u6cd5\u8981\u5feb\u5f97\u591a\uff0c\u5373\u4f7f\u540e\u8005\u4f7f\u7528\u5feb\u901f\u8fdb\u4f4d\u8d85\u524d\u52a0\u6cd5\u5668\u4e5f\u662f\u5982\u6b64\u3002\u5f53\u7136\uff0c\u4e00\u65e6\u4ee5\u5b58\u50a8\u8fdb\u4f4d\u5f62\u5f0f\u83b7\u5f97\u6700\u7ec8\u603b\u548c\uff0c\u53ef\u80fd\u5fc5\u987b\u4f7f\u7528\u8fdb\u4f4d\u4f20\u64ad\u52a0\u6cd5\u5668\u5c06\u5b58\u50a8\u8fdb\u4f4d\u6570\u7684\u4e24\u4e2a\u5206\u91cf\u76f8\u52a0\uff0c\u5c06\u5176\u8f6c\u6362\u4e3a\u6807\u51c6\u4e8c\u8fdb\u5236\u3002\u5173\u952e\u70b9\u662f\u8fdb\u4f4d\u4f20\u64ad\u5ef6\u8fdf\u4ec5\u5728\u6700\u540e\u53d1\u751f\u4e00\u6b21\uff0c\u800c\u4e0d\u662f\u5728\u6bcf\u4e2a\u52a0\u6cd5\u6b65\u9aa4\u4e2d\u53d1\u751f\u3002</p> <p>Since the carry-save addition scheme of Fig. 3.5 converts three binary numbers to two binary numbers with the same sum, it is sometimes referred to as a 3/2 reduction circuit or (3; 2) counter. The latter name reflects the essential function of a full adder: it counts the number of 1s among its three input bits and outputs the result as a 2-bit binary number. More on this in Chapter 8. </p> <p>\u7531\u4e8e\u56fe 3.5 \u7684\u8fdb\u4f4d\u4fdd\u5b58\u52a0\u6cd5\u65b9\u6848\u5c06\u4e09\u4e2a\u4e8c\u8fdb\u5236\u6570\u8f6c\u6362\u4e3a\u5177\u6709\u76f8\u540c\u548c\u7684\u4e24\u4e2a\u4e8c\u8fdb\u5236\u6570\uff0c\u56e0\u6b64\u6709\u65f6\u5c06\u5176\u79f0\u4e3a 3/2 \u5f52\u7ea6\u7535\u8def\u6216 (3; 2) \u8ba1\u6570\u5668\u3002\u540e\u4e00\u4e2a\u540d\u79f0\u53cd\u6620\u4e86\u5168\u52a0\u5668\u7684\u57fa\u672c\u529f\u80fd\uff1a\u5b83\u8ba1\u7b97\u4e09\u4e2a\u8f93\u5165\u4f4d\u4e2d 1 \u7684\u6570\u91cf\uff0c\u5e76\u5c06\u7ed3\u679c\u4f5c\u4e3a 2 \u4f4d\u4e8c\u8fdb\u5236\u6570\u8f93\u51fa\u3002\u66f4\u591a\u5185\u5bb9\u8bf7\u53c2\u89c1\u7b2c 8 \u7ae0\u3002</p> <p>Other examples of the use of redundant representations in computer arithmetic are found in fast multiplication and division schemes, where the multiplier or quotient is represented or produced in redundant form. More on these in Parts III and IV. </p> <p>\u5728\u8ba1\u7b97\u673a\u7b97\u672f\u4e2d\u4f7f\u7528\u5197\u4f59\u8868\u793a\u7684\u5176\u4ed6\u793a\u4f8b\u53ef\u4ee5\u5728\u5feb\u901f\u4e58\u6cd5\u548c\u9664\u6cd5\u65b9\u6848\u4e2d\u627e\u5230\uff0c\u5176\u4e2d\u4e58\u6570\u6216\u5546\u4ee5\u5197\u4f59\u5f62\u5f0f\u8868\u793a\u6216\u4ea7\u751f\u3002\u6709\u5173\u8fd9\u4e9b\u7684\u66f4\u591a\u4fe1\u606f\uff0c\u8bf7\u53c2\u89c1\u7b2c\u4e09\u90e8\u5206\u548c\u7b2c\u56db\u90e8\u5206\u3002</p>"},{"location":"Part_01/03/#33","title":"3.3 \u6570\u5b57\u96c6\u548c\u6570\u5b57\u96c6\u8f6c\u6362","text":"<p>Conventional radix- r numbers use the standard digit set [0, r \u2212 1]. However, many other redundant and nonredundant digit sets are possible. A necessary condition is that the digit set contain at least r different digit values. If it contains more than r values, the number system is redundant.</p> <p>\u4f20\u7edf\u7684\u57fa\u6570 r \u6570\u5b57\u4f7f\u7528\u6807\u51c6\u6570\u5b57\u96c6 \\([0, r \u2212 1]\\)\u3002\u7136\u800c\uff0c\u8bb8\u591a\u5176\u4ed6\u5197\u4f59\u548c\u975e\u5197\u4f59\u6570\u5b57\u96c6\u4e5f\u662f\u53ef\u80fd\u7684\u3002\u5fc5\u8981\u6761\u4ef6\u662f\u6570\u5b57\u96c6\u5408\u81f3\u5c11\u5305\u542br\u4e2a\u4e0d\u540c\u7684\u6570\u5b57\u503c\u3002\u5982\u679c\u5b83\u5305\u542b\u591a\u4e8e r \u503c\uff0c\u5219\u6570\u5b57\u7cfb\u7edf\u662f\u5197\u4f59\u7684\u3002</p> <p>Conversion of numbers between standard and other digit sets is quite simple and essentially entails a digit-serial process in which, beginning at the right end of the given number, each digit is rewritten as a valid digit in the new digit set and a transfer (carry or borrow) into the next higher digit position. This conversion process is essentially like carry propagation in that it must be done from right to left and, in the worst case, the most significant digit is affected by a \u201ccarry\u201d coming from the least significant position. The following examples illustrate the process (see also the examples at the end of Section 2.6).</p> <p>\u6807\u51c6\u6570\u5b57\u96c6\u548c\u5176\u4ed6\u6570\u5b57\u96c6\u4e4b\u95f4\u7684\u6570\u5b57\u8f6c\u6362\u975e\u5e38\u7b80\u5355\uff0c\u672c\u8d28\u4e0a\u9700\u8981\u4e00\u4e2a\u6570\u5b57\u4e32\u884c\u8fc7\u7a0b\uff0c\u5176\u4e2d\u4ece\u7ed9\u5b9a\u6570\u5b57\u7684\u53f3\u7aef\u5f00\u59cb\uff0c\u6bcf\u4e2a\u6570\u5b57\u90fd\u88ab\u91cd\u5199\u4e3a\u65b0\u6570\u5b57\u96c6\u4e2d\u7684\u6709\u6548\u6570\u5b57\uff0c\u5e76\u8f6c\u79fb\uff08\u8fdb\u4f4d\u6216\u501f\u4f4d\uff09\u5230\u4e0b\u4e00\u4e2a\u66f4\u9ad8\u7684\u6570\u5b57\u4f4d\u7f6e\u3002\u6b64\u8f6c\u6362\u8fc7\u7a0b\u672c\u8d28\u4e0a\u7c7b\u4f3c\u4e8e\u8fdb\u4f4d\u4f20\u64ad\uff0c\u56e0\u4e3a\u5b83\u5fc5\u987b\u4ece\u53f3\u5230\u5de6\u5b8c\u6210\uff0c\u5e76\u4e14\u5728\u6700\u574f\u7684\u60c5\u51b5\u4e0b\uff0c\u6700\u9ad8\u6709\u6548\u6570\u5b57\u4f1a\u53d7\u5230\u6765\u81ea\u6700\u4f4e\u6709\u6548\u4f4d\u7f6e\u7684\u201c\u8fdb\u4f4d\u201d\u7684\u5f71\u54cd\u3002\u4ee5\u4e0b\u793a\u4f8b\u8bf4\u660e\u4e86\u8be5\u8fc7\u7a0b\uff08\u53e6\u8bf7\u53c2\u89c1\u7b2c 2.6 \u8282\u672b\u5c3e\u7684\u793a\u4f8b\uff09\u3002</p> <p>EXAMPLE 3.1 Convert the following radix-10 number with the digit set [0, 18] to one using the conventional digit set [0, 9].</p> <p>\u793a\u4f8b3.1 \u5c06\u4ee5\u4e0b\u6570\u5b57\u96c6[0, 18] \u7684\u57fa10 \u6570\u8f6c\u6362\u4e3a\u4f7f\u7528\u4f20\u7edf\u6570\u5b57\u96c6[0, 9] \u7684\u3002</p> <pre><code>  11  9 17 10 12 18   Rewrite 18 as 10 (carry 1) +8\n  11  9 17 10 13  8   13 = 10 (carry 1) + 3\n  11  9 17 11  3  8   11 = 10 (carry 1) + 1\n  11  9 18  1  3  8   18 = 10 (carry 1) + 8\n  11 10  8  1  3  8   10 = 10 (carry 1) + 0\n  12  0  8  1  3  8   12 = 10 (carry 1) + 2\n1  2  0  8  1  3  8   Answer: all digits in [0, 9]\n</code></pre> <p>EXAMPLE 3.2 Convert the following radix-2 carry-save number to binary; that is, from digit set [0, 2] to digit set [0, 1].</p> <p>\u793a\u4f8b3.2 \u5c06\u4ee5\u4e0b\u57fa2 \u8fdb\u4f4d\u4fdd\u5b58\u6570\u8f6c\u6362\u4e3a\u4e8c\u8fdb\u5236\uff1b\u5373\u4ece\u6570\u5b57\u96c6[0, 2]\u5230\u6570\u5b57\u96c6[0, 1]\u3002</p> <pre><code>  1 1 2 0 2 0   Rewrite 2 as 2 (carry 1) + 0\n  1 1 2 1 0 0   2 = 2 (carry 1) + 0\n  1 2 0 1 0 0   2 = 2 (carry 1) + 0\n  2 0 0 1 0 0   2 = 2 (carry 1) + 0\n1 0 0 0 1 0 0   Answer: all digits in [0, 1]\n</code></pre> <p>Another way to accomplish the preceding conversion is to decompose the carry-save number into two numbers, both of which have 1s where the original number has a digit of 2. The sum of these two numbers is then the desired binary number.</p> <p>\u5b8c\u6210\u4e0a\u8ff0\u8f6c\u6362\u7684\u53e6\u4e00\u79cd\u65b9\u6cd5\u662f\u5c06\u8fdb\u4f4d\u4fdd\u5b58\u6570\u5206\u89e3\u4e3a\u4e24\u4e2a\u6570\uff0c\u8fd9\u4e24\u4e2a\u6570\u90fd\u662f 1\uff0c\u800c\u539f\u59cb\u6570\u7684\u4f4d\u6570\u4e3a 2\u3002\u8fd9\u4e24\u4e2a\u6570\u7684\u548c\u5c31\u662f\u6240\u9700\u7684\u4e8c\u8fdb\u5236\u6570\u3002</p> <pre><code>  1 1 1 0 1 0 First number: \u201csum\u201d bits\n+ 0 0 1 0 1 0 Second number: \u201ccarry\u201d bits\n--------------------------------------------\n1 0 0 0 1 0 0 Sum of the two numbers\n</code></pre> <p>EXAMPLE 3.3 Digit values do not have to be positive. We reconsider Example 3.1 using the asymmetric target digit set [\u22126, 5].</p> <p>\u793a\u4f8b3.3 \u6570\u5b57\u503c\u4e0d\u5fc5\u662f\u6b63\u6570\u3002\u6211\u4eec\u4f7f\u7528\u4e0d\u5bf9\u79f0\u76ee\u6807\u6570\u5b57\u96c6 [\u22126, 5] \u91cd\u65b0\u8003\u8651\u793a\u4f8b 3.1\u3002</p> <pre><code>   11   9  17  10  12  18    Rewrite 18 as 20 (carry 2) \u2212 2\n   11   9  17  10  14  \u22122    14 = 10 (carry 1) + 4\n   11   9  17  11   4  \u22122    11 = 10 (carry 1) + 1\n   11   9  18   1   4  \u22122    18 = 20 (carry 2) \u2212 2\n   11  11  \u22122   1   4  \u22122    11 = 10 (carry 1) + 1\n   12   1  \u22122   1   4  \u22122    12 = 10 (carry 1) + 2\n1   2   1  \u22122   1   4  \u22122    Answer: all digits in [\u22126, 5]\n</code></pre> <p>On line 2 of this conversion, we could have rewritten 14 as 20 (carry 2) \u2212 6, which would have led to a different, but equivalent, representation. In general, several representations may be possible with a redundant digit set.</p> <p>\u5728\u8fd9\u4e2a\u8f6c\u6362\u7684\u7b2c 2 \u884c\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06 14 \u91cd\u5199\u4e3a 20 (carry 2) \u2212 6\uff0c\u8fd9\u5c06\u5bfc\u81f4\u4e0d\u540c\u4f46\u7b49\u6548\u7684\u8868\u793a\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u5197\u4f59\u6570\u5b57\u96c6\u53ef\u80fd\u6709\u591a\u79cd\u8868\u793a\u5f62\u5f0f\u3002</p> <p>EXAMPLE 3.4 If we change the target digit set of Example 3.2 from [0, 1] to [\u22121, 1], we can do the conversion digit-serially as before. However, carry-free conversion is possible for this example if we rewrite each 2 as 2 (carry 1) + 0 and each 1 as 2 (carry 1) \u22121.</p> <p>\u4f8b3.4 \u5982\u679c\u6211\u4eec\u5c06\u4f8b3.2 \u7684\u76ee\u6807\u6570\u5b57\u96c6\u4ece[0, 1] \u66f4\u6539\u4e3a[\u22121, 1]\uff0c\u6211\u4eec\u53ef\u4ee5\u50cf\u4ee5\u524d\u4e00\u6837\u8fdb\u884c\u6570\u5b57\u4e32\u884c\u8f6c\u6362\u3002\u7136\u800c\uff0c\u5982\u679c\u6211\u4eec\u5c06\u6bcf\u4e2a 2 \u91cd\u5199\u4e3a 2 (\u8fdb\u4f4d 1) + 0\uff0c\u5e76\u5c06\u6bcf\u4e2a 1 \u91cd\u5199\u4e3a 2 (\u8fdb\u4f4d 1) -1\uff0c\u5219\u5728\u672c\u793a\u4f8b\u4e2d\uff0c\u65e0\u8fdb\u4f4d\u8f6c\u6362\u662f\u53ef\u80fd\u7684\u3002</p> <p>The resulting interim digits in [\u22121, 0] can absorb an incoming carry of 1 with no further propagation.</p> <p>[\u22121, 0] \u4e2d\u4ea7\u751f\u7684\u4e2d\u95f4\u6570\u5b57\u53ef\u4ee5\u5438\u6536\u4f20\u5165\u7684 1 \u8fdb\u4f4d\uff0c\u800c\u4e0d\u4f1a\u8fdb\u4e00\u6b65\u4f20\u64ad\u3002</p> <pre><code>   1  1  2  0  2  0  Given carry-save number\n  \u22121 \u22121  0  0  0  0  Interim digits in [\u22121, 0]\n   1  1  1  0  1  0  Transfer digits in [0, 1]\n1  0  0  0  1  0  0  Answer: all digits in [\u22121, 1]\n</code></pre>"},{"location":"Part_01/03/#34","title":"3.4 \u5e7f\u4e49\u6709\u7b26\u53f7\u6570\u5b57\u6570","text":"<p>We have seen thus far that the digit set of a radix- r  positional number system need not be the standard set [0,  r\u22121]. Using the digit set [\u22121, 1] for radix-2 numbers was proposed by E. Collignon as early as 1897 [Glas81]. Whether this was just a mathematical curiosity, or motivated by an application or advantage, is not known. In the early 1960s, Avizienis [Aviz61] defined the class of signed-digit number systems with symmetric digit sets [\u2212 \u03b1,  \u03b1] and radix  r &gt;  2, where  \u03b1  is any integer in the range  r/ 2 + 1 \u2264  \u03b1 \u2264  r \u2212 1.  These number systems allow at least 2 r/ 2 + 3 digit values, instead of the minimum required  r  values, and are thus redundant. </p> <p>\u5230\u76ee\u524d\u4e3a\u6b62\u6211\u4eec\u5df2\u7ecf\u770b\u5230\uff0c\u57fa\u6570 r \u4f4d\u7f6e\u6570\u7cfb\u7edf\u7684\u6570\u5b57\u96c6\u4e0d\u4e00\u5b9a\u662f\u6807\u51c6\u96c6 \\([0, r\u22121]\\)\u3002 E. Collignon \u65e9\u5728 1897 \u5e74\u5c31\u63d0\u51fa\u4f7f\u7528\u6570\u5b57\u96c6 \\([\u22121, 1]\\) \u8868\u793a\u57fa 2 \u6570 [Glas81]\u3002\u8fd9\u662f\u5426\u53ea\u662f\u4e00\u79cd\u6570\u5b66\u597d\u5947\u5fc3\uff0c\u8fd8\u662f\u51fa\u4e8e\u5e94\u7528\u6216\u4f18\u52bf\u7684\u52a8\u673a\uff0c\u5c1a\u4e0d\u6e05\u695a\u3002 20 \u4e16\u7eaa 60 \u5e74\u4ee3\u521d\uff0cAvizienis [Aviz61] \u5b9a\u4e49\u4e86\u5177\u6709\u5bf9\u79f0\u6570\u5b57\u96c6\u7684\u6709\u7b26\u53f7\u6570\u7684\u6570\u5b57\u7cfb\u7edf\u7c7b \\([\u2212 \u03b1, \u03b1]\\) \u4e14\u57fa\u6570 \\(r &gt; 2\\)\uff0c\u5176\u4e2d \\(\u03b1\\) \u662f \\(\\left \\lfloor r/2 \\right \\rfloor + 1 \u2264 \u03b1 \u2264 r \u2212 1\\) \u8303\u56f4\u5185\u7684\u4efb\u610f\u6574\u6570\u3002\u8fd9\u4e9b\u6570\u5b57\u7cfb\u7edf\u5141\u8bb8\u81f3\u5c11 \\(2 \\left \\lfloor r/2 \\right \\rfloor + 3\\) \u4f4d\u6570\u5b57\u503c\uff0c\u800c\u4e0d\u662f\u6240\u9700\u7684\u6700\u5c0f r \u503c\uff0c\u56e0\u6b64\u662f\u5197\u4f59\u7684\u3002</p> <p>Subsequently, redundant number systems with general, possibly asymmetric, digit sets of the form [\u2212 \u03b1,  \u03b2] were studied as tools for unifying all redundant number representations used in practice. This class is called \u201cgeneralized signed-digit (GSD) representation\u201d and differs from the ordinary signed-digit (OSD) representation of Avizienis in its more general digit set as well as the possibility of higher or lower redundancy. </p> <p>\u968f\u540e\u53c8\u6709\u7814\u7a76\u5177\u6709\u4e00\u822c\u7684\u3001\u53ef\u80fd\u4e0d\u5bf9\u79f0\u7684\u3001\u5f62\u5f0f\u4e3a \\([\u2212 \u03b1, \u03b2]\\) \u7684\u6570\u5b57\u96c6\u7684\u5197\u4f59\u6570\u7cfb\u7edf\uff0c\u4f5c\u4e3a\u5de5\u5177\u6765\u7edf\u4e00\u5b9e\u8df5\u4e2d\u4f7f\u7528\u7684\u6240\u6709\u5197\u4f59\u6570\u8868\u793a\u3002\u6b64\u7c7b\u79f0\u4e3a\u201c\u5e7f\u4e49\u7b26\u53f7\u6570\u5b57 (GSD) \u8868\u793a\u201d\uff0c\u4e0e Avizienis \u7684\u666e\u901a\u7b26\u53f7\u6570\u5b57 (OSD) \u8868\u793a\u4e0d\u540c\uff0c\u5176\u66f4\u901a\u7528\u7684\u6570\u5b57\u96c6\u4ee5\u53ca\u66f4\u9ad8\u6216\u66f4\u4f4e\u5197\u4f59\u7684\u53ef\u80fd\u6027\u3002</p> <p>Binary stored-carry numbers, with  r = 2 and digit set [0, 2], offer a good example for the usefulness of asymmetric digit sets. Higher redundancy is exemplified by the digit set [\u22127, 7] in radix 4 or [0, 3] in radix 2. An example for lower redundancy is the binary signed-digit (BSD) representation with  r = 2 and digit set [\u22121, 1]. None of these is covered by OSD. </p> <p>\u4e8c\u8fdb\u5236\u5b58\u50a8\u8fdb\u4f4d\u6570\uff0c\u5176\u4e2d r = 2 \u548c\u6570\u5b57\u96c6 [0, 2]\uff0c\u4e3a\u975e\u5bf9\u79f0\u6570\u5b57\u96c6\u7684\u6709\u7528\u6027\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f88\u597d\u7684\u4f8b\u5b50\u3002\u8f83\u9ad8\u5197\u4f59\u7684\u793a\u4f8b\u662f\u57fa\u6570 4 \u4e2d\u7684\u6570\u5b57\u96c6 [\u22127, 7] \u6216\u57fa\u6570 2 \u4e2d\u7684 [0, 3]\u3002\u8f83\u4f4e\u5197\u4f59\u7684\u793a\u4f8b\u662f\u4e8c\u8fdb\u5236\u6709\u7b26\u53f7\u6570\u5b57 (BSD) \u8868\u793a\uff0c\u5176\u4e2d r = 2 \u548c\u6570\u5b57\u96c6 [\u22121, 1]\u3002 OSD \u4e0d\u6db5\u76d6\u8fd9\u4e9b\u5185\u5bb9\u3002</p> <p>An important parameter of a GSD number system is its  redundancy index, defined as \u03c1 =  \u03b1 +  \u03b2 + 1 \u2212  r (i.e., the amount by which the size of its digit set exceeds the size  r  of a nonredundant digit set for radix  r). Figure 3.6 presents a taxonomy of redundant and nonredundant positional number systems showing the names of some useful subclasses and their various relationships. Note that the redundancy index  \u03c1  is quite general and can be applied to any digit set. Another way of quantifying the redundancy of a number system with the symmetric digit set [\u2212 \u03b1,  \u03b1] in radix  r  is to use the ratio  h =  \u03b1/(r \u2212 1 ). This formulation of redundancy, which is inapplicable to the general digit set [\u2212 \u03b1,  \u03b2], has been used in connection with high-radix division algorithms, to be discussed in Chapter 14. Besides its general inapplicability, the index  h  suffers from the problem that it varies from 1 (for no redundancy), through 1 (for  \u03b1 =  r \u2212 1), to values larger than 1 for highly redundant number representation systems. Encountering redundancy indices below 1 is unusual and could be misleading.</p> <p>GSD \u6570\u5b57\u7cfb\u7edf\u7684\u4e00\u4e2a\u91cd\u8981\u53c2\u6570\u662f\u5176**\u5197\u4f59\u6307\u6570**\uff0c\u5b9a\u4e49\u4e3a \\(\u03c1 = \u03b1 + \u03b2 + 1 \u2212 r\\)\uff08\u5373\uff0c\u5176\u6570\u5b57\u96c6\u7684\u5927\u5c0f\u8d85\u8fc7\u57fa\u6570 r \u7684\u975e\u5197\u4f59\u6570\u5b57\u96c6\u7684\u5927\u5c0f r \u7684\u91cf\uff09\u3002\u56fe 3.6 \u5c55\u793a\u4e86\u5197\u4f59\u548c\u975e\u5197\u4f59\u4f4d\u7f6e\u6570\u5b57\u7cfb\u7edf\u7684\u5206\u7c7b\uff0c\u663e\u793a\u4e86\u4e00\u4e9b\u6709\u7528\u5b50\u7c7b\u7684\u540d\u79f0\u53ca\u5176\u5404\u79cd\u5173\u7cfb\u3002\u8bf7\u6ce8\u610f\uff0c\u5197\u4f59\u6307\u6570 \u03c1 \u975e\u5e38\u901a\u7528\uff0c\u53ef\u4ee5\u5e94\u7528\u4e8e\u4efb\u4f55\u6570\u5b57\u96c6\u3002\u5ea6\u91cf\u5177\u6709\u57fa\u6570 r \u4e2d\u7684\u5bf9\u79f0\u6570\u5b57\u96c6 \\([\u2212 \u03b1, \u03b1]\\) \u7684\u6570\u5b57\u7cfb\u7edf\u7684\u5197\u4f59\u5ea6\u7684\u53e6\u4e00\u79cd\u65b9\u6cd5\u662f\u4f7f\u7528\u6bd4\u7387 \\(h = \u03b1/(r \u2212 1 )\\)\u3002\u8fd9\u79cd\u5197\u4f59\u516c\u5f0f\u4e0d\u9002\u7528\u4e8e\u4e00\u822c\u6570\u5b57\u96c6 \\([\u2212 \u03b1, \u03b2]\\)\uff0c\u5df2\u4e0e\u9ad8\u57fa\u6570\u9664\u6cd5\u7b97\u6cd5\u7ed3\u5408\u4f7f\u7528\uff0c\u5c06\u5728\u7b2c 14 \u7ae0\u4e2d\u8ba8\u8bba\u3002\u9664\u4e86\u5176\u4e00\u822c\u4e0d\u9002\u7528\u6027\u4e4b\u5916\uff0c\u7d22\u5f15 h \u8fd8\u5b58\u5728\u4ee5\u4e0b\u95ee\u9898\uff1a\u5b83\u4ece \\(\\frac{1}{2}\\)\uff08\u5bf9\u4e8e\u65e0\u5197\u4f59\uff09\u5230 1\uff08\u5bf9\u4e8e \u03b1 = r \u2212 1\uff09\u5230\u5927\u4e8e 1 \u7684\u503c\u7528\u4e8e\u9ad8\u5ea6\u5197\u4f59\u7684\u6570\u5b57\u8868\u793a\u7cfb\u7edf\u3002\u9047\u5230\u4f4e\u4e8e 1 \u7684\u5197\u4f59\u6307\u6570\u662f\u4e0d\u5bfb\u5e38\u7684\uff0c\u5e76\u4e14\u53ef\u80fd\u4f1a\u4ea7\u751f\u8bef\u5bfc\u3002</p> <p></p> <p>Any hardware implementation of GSD arithmetic requires the choice of a binary encoding scheme for the  \u03b1 +  \u03b2 + 1 digit values in the digit set [\u2212 \u03b1,  \u03b2]. Multivalued logic realizations have been considered, but we limit our discussion here to binary logic and proceed to show the importance and implications of the encoding scheme chosen through some examples. </p> <p>\u4efb\u4f55 GSD \u7b97\u672f\u7684\u786c\u4ef6\u5b9e\u73b0\u90fd\u9700\u8981\u9009\u62e9\u4e8c\u8fdb\u5236\u7684\u7f16\u7801\u65b9\u6848\u5bf9\u6570\u5b57\u96c6 \\([\u2212 \u03b1, \u03b2]\\) \u4e2d \\(\u03b1 + \u03b2 + 1\\) \u4e2a\u6570\u5b57\u503c\u7f16\u7801\u3002\u5df2\u7ecf\u8003\u8651\u4e86\u591a\u503c\u903b\u8f91\u5b9e\u73b0\uff0c\u4f46\u6211\u4eec\u5c06\u8fd9\u91cc\u7684\u8ba8\u8bba\u9650\u5236\u4e3a\u4e8c\u8fdb\u5236\u903b\u8f91\uff0c\u5e76\u7ee7\u7eed\u901a\u8fc7\u4e00\u4e9b\u793a\u4f8b\u6765\u5c55\u793a\u6240\u9009\u62e9\u7684\u7f16\u7801\u65b9\u6848\u7684\u91cd\u8981\u6027\u548c\u542b\u4e49\u3002</p> <p>Consider, for example, the BSD number system with  r = 2 and the digit set [\u22121, 1]. One needs at least 2 bits to encode these three digit values. Figure 3.7 shows four of the many possible encodings that can be used. </p> <p>\u4f8b\u5982\uff0c\u8003\u8651 BSD \u6570\u5b57\u7cfb\u7edf\uff0c\u5176\u4e2d r = 2 \u548c\u6570\u5b57\u96c6 [\u22121, 1]\u3002\u81f3\u5c11\u9700\u8981 2 \u4f4d\u6765\u5bf9\u8fd9\u4e09\u4f4d\u6570\u5b57\u503c\u8fdb\u884c\u7f16\u7801\u3002\u56fe 3.7 \u663e\u793a\u4e86\u53ef\u4ee5\u4f7f\u7528\u7684\u591a\u79cd\u53ef\u80fd\u7f16\u7801\u4e2d\u7684\u56db\u79cd\u3002</p> <p></p> <p>With the ( n,  p) encoding, the code (1, 1) may be considered an alternate representation of 0 or else viewed as an invalid combination. Many implementations have shown that the ( n,  p) encoding tends to simplify the hardware and also increases the speed by reducing the number of gate levels [Parh88]. The 1-out-of-3 encoding requires more bits per number but allows the detection of some storage and processing errors. </p> <p>\u5bf9\u4e8e (n, p) \u7f16\u7801\uff0c\u4ee3\u7801 (1, 1) \u53ef\u4ee5\u88ab\u89c6\u4e3a 0 \u7684\u66ff\u4ee3\u8868\u793a\uff0c\u6216\u8005\u88ab\u89c6\u4e3a\u65e0\u6548\u7ec4\u5408\u3002\u8bb8\u591a\u5b9e\u65bd\u8868\u660e( n, p) \u7f16\u7801\u503e\u5411\u4e8e\u7b80\u5316\u786c\u4ef6\uff0c\u5e76\u901a\u8fc7\u51cf\u5c11\u95e8\u7ea7\u6570\u91cf\u6765\u63d0\u9ad8\u901f\u5ea6 [Parh88]\u3002 3 \u53d6 1 \u7f16\u7801\u6bcf\u4e2a\u6570\u5b57\u9700\u8981\u66f4\u591a\u4f4d\uff0c\u4f46\u5141\u8bb8\u68c0\u6d4b\u4e00\u4e9b\u5b58\u50a8\u548c\u5904\u7406\u9519\u8bef\u3002</p> <p>The  (n,  p)  and 2\u2019s-complement encodings of Fig. 3.7 are examples of encodings in which two-valued signals having various weights collectively represent desired values. Figure 3.8a depicts three new symbols, besides posibits and negabits previously introduced in Figs. 1.4 and 2.13. A  doublebit  represents one of the two values in the set {0, 2}. A  negadoublebit  is a negatively weighted doublebit. Finally, a  unibit  assumes one of the two values in {\u22121, 1}. A posibit and a negabit together represent one of the values in the set {\u22121, 0, 1}, yielding the  (n,  p)  encoding of a BSD. A negadoublebit and a posibit form a 2-bit 2\u2019s-complement number capable of representing a value in [\u22122, 1] and thus a BSD. These two encodings for a 5-digit BSD number are shown in Fig. 3.8b. The third representation in Fig. 3.8b is derived from the second one by shifting the negadoublebits to the left by one position and changing them into negabits. Each BSD digit now spans two digit positions in its encoding. These weighted bit-set encodings have been found quite useful for the efficient representation and processing of redundant numbers [Jabe05]. </p> <p>\u56fe 3.7 \u7684 (n, p) \u548c 2 \u8865\u7801\u7f16\u7801\u662f\u5177\u6709\u5404\u79cd\u6743\u91cd\u7684\u4e8c\u503c\u4fe1\u53f7\u5171\u540c\u8868\u793a\u671f\u671b\u503c\u7684\u7f16\u7801\u793a\u4f8b\u3002\u9664\u4e86\u4e4b\u524d\u5728\u56fe 1.4 \u548c 2.13 \u4e2d\u4ecb\u7ecd\u7684**\u6b63\u4f4d**\u548c**\u8d1f\u4f4d**\u4e4b\u5916\uff0c\u56fe 3.8a \u8fd8\u63cf\u8ff0\u4e86\u4e09\u4e2a\u65b0\u7b26\u53f7\u3002 **\u53cc\u4f4d**\u8868\u793a\u96c6\u5408 {0, 2} \u4e2d\u7684\u4e24\u4e2a\u503c\u4e4b\u4e00\u3002**\u8d1f\u53cc\u4f4d**\u662f\u8d1f\u52a0\u6743\u53cc\u4f4d\u3002\u6700\u540e\uff0c\u4e00\u4e2a\u5355\u6bd4\u7279\u91c7\u7528 {\u22121, 1} \u4e2d\u7684\u4e24\u4e2a\u503c\u4e4b\u4e00\u3002\u6b63\u4f4d\u548c\u8d1f\u4f4d\u4e00\u8d77\u8868\u793a\u96c6\u5408 {\u22121, 0, 1} \u4e2d\u7684\u503c\u4e4b\u4e00\uff0c\u4ea7\u751f BSD \u7684 (n, p) \u7f16\u7801\u3002 negadoublebit \u548c posibit \u5f62\u6210\u4e00\u4e2a 2 \u4f4d 2 \u7684\u8865\u7801\u6570\uff0c\u80fd\u591f\u8868\u793a [\u22122, 1] \u4e2d\u7684\u503c\uff0c\u4ece\u800c\u8868\u793a BSD\u30025 \u4f4d BSD \u53f7\u7801\u7684\u8fd9\u4e24\u79cd\u7f16\u7801\u5982\u56fe 3.8b \u6240\u793a\u3002\u56fe 3.8b \u4e2d\u7684\u7b2c\u4e09\u79cd\u8868\u793a\u6cd5\u662f\u4ece\u7b2c\u4e8c\u79cd\u8868\u793a\u6cd5\u4e2d\u5bfc\u51fa\u7684\uff0c\u65b9\u6cd5\u662f\u5c06\u8d1f\u53cc\u4f4d\u5411\u5de6\u79fb\u52a8\u4e00\u4f4d\u5e76\u5c06\u5176\u66f4\u6539\u4e3a\u8d1f\u4f4d\u3002\u6bcf\u4e2a BSD \u6570\u5b57\u73b0\u5728\u5728\u5176\u7f16\u7801\u4e2d\u8de8\u8d8a\u4e24\u4e2a\u6570\u5b57\u4f4d\u7f6e\u3002\u4eba\u4eec\u53d1\u73b0\u8fd9\u4e9b\u52a0\u6743\u4f4d\u96c6\u7f16\u7801\u5bf9\u4e8e\u5197\u4f59\u6570\u7684\u6709\u6548\u8868\u793a\u548c\u5904\u7406\u975e\u5e38\u6709\u7528[Jabe05]\u3002</p> <p></p> <p>Hybrid signed-digit representations [Phat94] came about from an attempt to strike a balance between algorithmic speed and implementation cost by introducing redundancy in selected positions only. For example, standard binary representation may be used with BSD digits allowed in every third position, as shown in the addition example of Fig. 3.9. </p> <p>\u6df7\u5408\u7b26\u53f7\u6570\u5b57\u8868\u793a\u6cd5 [Phat94] \u7684\u4ea7\u751f\u662f\u4e3a\u4e86\u901a\u8fc7\u4ec5\u5728\u9009\u5b9a\u4f4d\u7f6e\u5f15\u5165\u5197\u4f59\u6765\u5728\u7b97\u6cd5\u901f\u5ea6\u548c\u5b9e\u73b0\u6210\u672c\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002\u4f8b\u5982\uff0c\u6807\u51c6\u4e8c\u8fdb\u5236\u8868\u793a\u53ef\u4ee5\u4e0e\u6bcf\u7b2c\u4e09\u4e2a\u4f4d\u7f6e\u5141\u8bb8\u7684 BSD \u6570\u5b57\u4e00\u8d77\u4f7f\u7528\uff0c\u5982\u56fe 3.9 \u7684\u52a0\u6cd5\u793a\u4f8b\u6240\u793a\u3002</p> <p></p> <p>The addition algorithm depicted in Fig. 3.9 proceeds as follows. First one completes the position sums  pi  that are in [0, 2] for standard binary and [\u22122, 2] in BSD positions. The BSD position sums are then broken into an interim sum  wi  and transfer  ti+1, both in [\u22121, 1]. For the interim sum digit, the value 1 (\u22121) is chosen only if it is certain that the incoming transfer cannot be 1 (\u22121); that is, when the two binary operand digits in position  i \u2212 1 are (not) both 0s. The worst-case carry propagation spans a single group, beginning with a BSD that produces a transfer digit in [\u22121, 1] and ending with the next higher BSD position. </p> <p>\u56fe 3.9 \u4e2d\u63cf\u8ff0\u7684\u52a0\u6cd5\u7b97\u6cd5\u8fdb\u884c\u5982\u4e0b\u3002\u7b2c\u4e00\u4e2a\u5b8c\u6210\u6807\u51c6\u4e8c\u8fdb\u5236\u7684 [0, 2] \u548c BSD \u4f4d\u7f6e\u7684 [\u22122, 2] \u4e2d\u7684\u4f4d\u7f6e\u603b\u548c \\(p_i\\)\u3002\u7136\u540e\uff0cBSD \u4f4d\u7f6e\u548c\u88ab\u5206\u89e3\u4e3a\u4e34\u65f6\u548c \\(w_i\\) \u5e76\u4f20\u8f93 \\(t_{i+1}\\)\uff0c\u4e24\u8005\u90fd\u5728 [\u22121, 1] \u4e2d\u3002\u5bf9\u4e8e\u4e34\u65f6\u548c\u6570\u4f4d\uff0c\u4ec5\u5f53\u786e\u5b9a\u4f20\u5165\u4e0d\u80fd\u4e3a 1 (\u22121) \u65f6\u624d\u9009\u62e9\u503c 1 (\u22121)\uff1b\u4e5f\u5c31\u662f\u8bf4\uff0c\u5f53\u4f4d\u7f6e \\(i \u2212 1\\) \u4e2d\u7684\u4e24\u4e2a\u4e8c\u8fdb\u5236\u64cd\u4f5c\u6570\u6570\u5b57\uff08\u4e0d\u662f\uff09\u90fd\u662f 0 \u65f6\u3002\u6700\u574f\u60c5\u51b5\u7684\u8fdb\u4f4d\u4f20\u64ad\u8de8\u8d8a\u5355\u4e2a\u7ec4\uff0c\u4ece\u5728 [\u22121, 1] \u4e2d\u4ea7\u751f\u4f20\u8f93\u6570\u5b57\u7684 BSD \u5f00\u59cb\uff0c\u5e76\u4ee5\u4e0b\u4e00\u4e2a\u66f4\u9ad8\u7684 BSD \u4f4d\u7f6e\u7ed3\u675f\u3002</p> <p>More generally, the group size can be  g  rather than 3. A larger group size reduces the hardware complexity (since the adder block in a BSD position is more complex than that in other positions) but adds to the carry-propagation delay in the worst case; hence, the hybrid scheme offers a trade-off between speed and cost. </p> <p>\u66f4\u4e00\u822c\u5730\uff0c\u7ec4\u5927\u5c0f\u53ef\u4ee5\u662f g \u800c\u4e0d\u662f 3\u3002\u8f83\u5927\u7684\u7ec4\u5927\u5c0f\u4f1a\u964d\u4f4e\u786c\u4ef6\u590d\u6742\u6027\uff08\u56e0\u4e3a BSD \u4f4d\u7f6e\u7684\u52a0\u6cd5\u5668\u5757\u6bd4\u5176\u4ed6\u4f4d\u7f6e\u7684\u52a0\u6cd5\u5668\u5757\u66f4\u590d\u6742\uff09\uff0c\u4f46\u5728\u6700\u574f\u7684\u60c5\u51b5\u4e0b\u4f1a\u589e\u52a0\u8fdb\u4f4d\u4f20\u64ad\u5ef6\u8fdf\uff1b\u56e0\u6b64\uff0c\u6df7\u5408\u65b9\u6848\u63d0\u4f9b\u4e86\u901f\u5ea6\u548c\u6210\u672c\u4e4b\u95f4\u7684\u6743\u8861\u3002</p> <p>Hybrid signed-digit representation with uniform spacing of BSD positions can be viewed as a special case of GSD systems. For the example of Fig. 3.9, arranging the numbers in 3-digit groups starting from the right end leads to a radix-8 GSD system with digit set [\u22124, 7]: that is, digit values from  (\u22121 0 0 ) two to  ( 1 1 1 ) two. So the hybrid scheme of Fig. 3.9 can be viewed as an implementation of (digit encoding for) this particular radix-8 GSD representation. </p> <p>\u5177\u6709\u5747\u5300 BSD \u4f4d\u7f6e\u95f4\u8ddd\u7684\u6df7\u5408\u7b26\u53f7\u6570\u5b57\u8868\u793a\u53ef\u4ee5\u88ab\u89c6\u4e3a GSD \u7cfb\u7edf\u7684\u7279\u4f8b\u3002\u5bf9\u4e8e\u56fe 3.9 \u7684\u793a\u4f8b\uff0c\u4ece\u53f3\u7aef\u5f00\u59cb\u5c06\u6570\u5b57\u6392\u5217\u4e3a 3 \u4f4d\u7ec4\uff0c\u5f97\u5230\u4e00\u4e2a\u6570\u5b57\u96c6\u4e3a [\u22124, 7] \u7684\u57fa 8 GSD \u7cfb\u7edf\uff1a\u5373\u4ece (\u22121 0 0 ) 2 \u5230 ( 1 1 1 ) 2 \u7684\u6570\u5b57\u503c\u3002\u56e0\u6b64\uff0c\u56fe 3.9 \u7684\u6df7\u5408\u65b9\u6848\u53ef\u4ee5\u88ab\u89c6\u4e3a\u6b64\u7279\u5b9a\u57fa 8 GSD \u8868\u793a\uff08\u7684\u6570\u5b57\u7f16\u7801\uff09\u7684\u5b9e\u73b0\u3002</p> <p>The hybrid-redundant representation of Fig. 3.9, constituting an encoding for the radix-8 digit set [\u22124, 7], is depicted in Fig. 3.10 using extended dot notation. The asymmetry of the digit set, and thus of the number representation range, is an unfortunate feature of such representations that allow only posibits in nonredundant positions. By removing the latter restriction, we can obtain more desirable symmetric hybrid-redundant representations, exemplified by the second encoding of Fig. 3.10, which constitutes an encoding for the radix-8 digit set [\u22124, 4]. Arithmetic on all such extended hybrid-redundant representations can be performed with equal ease [Jabe06]. </p> <p>\u56fe 3.9 \u7684\u6df7\u5408\u5197\u4f59\u8868\u793a\u6784\u6210\u4e86\u57fa\u6570 8 \u6570\u5b57\u96c6 [\u22124, 7] \u7684\u7f16\u7801\uff0c\u5728\u56fe 3.10 \u4e2d\u4f7f\u7528\u6269\u5c55\u70b9\u8868\u793a\u6cd5\u8fdb\u884c\u4e86\u63cf\u8ff0\u3002\u6570\u5b57\u96c6\u7684\u4e0d\u5bf9\u79f0\u6027\u4ee5\u53ca\u6570\u5b57\u8868\u793a\u8303\u56f4\u7684\u4e0d\u5bf9\u79f0\u6027\u662f\u6b64\u7c7b\u4ec5\u5141\u8bb8\u975e\u5197\u4f59\u4f4d\u7f6e\u4e2d\u7684 pos \u4f4d\u7684\u8868\u793a\u6cd5\u7684\u4e00\u4e2a\u4e0d\u5e78\u7279\u5f81\u3002\u901a\u8fc7\u6d88\u9664\u540e\u4e00\u4e2a\u9650\u5236\uff0c\u6211\u4eec\u53ef\u4ee5\u83b7\u5f97\u66f4\u7406\u60f3\u7684\u5bf9\u79f0\u6df7\u5408\u5197\u4f59\u8868\u793a\uff0c\u5982\u56fe3.10\u7684\u7b2c\u4e8c\u4e2a\u7f16\u7801\u6240\u793a\uff0c\u5b83\u6784\u6210\u4e86\u57fa8\u6570\u5b57\u96c6[\u22124, 4]\u7684\u7f16\u7801\u3002\u6240\u6709\u6b64\u7c7b\u6269\u5c55\u6df7\u5408\u5197\u4f59\u8868\u793a\u7684\u7b97\u672f\u90fd\u53ef\u4ee5\u540c\u6837\u8f7b\u677e\u5730\u6267\u884c[Jabe06]\u3002</p> <p></p>"},{"location":"Part_01/03/#35","title":"3.5 \u65e0\u8fdb\u4f4d\u52a0\u6cd5\u7b97\u6cd5","text":"<p>The GSD carry-free addition algorithm, corresponding to the scheme of Fig. 3.2b, is as follows:</p> <p>GSD\u65e0\u8fdb\u4f4d\u52a0\u6cd5\u7b97\u6cd5\uff0c\u5bf9\u5e94\u56fe3.2b\u7684\u65b9\u6848\u5982\u4e0b\uff1a</p> <p>Carry-free addition algorithm for GSD numbers</p> <ul> <li> <p>Compute the position sums pi = xi + yi.</p> </li> <li> <p>Divide each pi into a transfer ti+1 and an interim sum wi = pi \u2212 rti+1.</p> </li> <li> <p>Add the incoming transfers to obtain the sum digits si = wi + ti.</p> </li> </ul> <p>GSD \u6570\u5b57\u7684\u65e0\u8fdb\u4f4d\u52a0\u6cd5\u7b97\u6cd5</p> <ul> <li> <p>\u8ba1\u7b97\u4f4d\u7f6e\u603b\u548c \\(p_i = x_i + y_i\\)\u3002</p> </li> <li> <p>\u5c06\u6bcf\u4e2a \\(p_i\\) \u5206\u4e3a\u8fdb\u4f4d \\(t_{i+1}\\) \u4e0e\u4e2d\u95f4\u603b\u548c \\(w_i = p_i \u2212 rt_{i+1}\\)\u3002</p> </li> <li> <p>\u5c06\u4f20\u5165\u4f20\u8f93\u76f8\u52a0\u4ee5\u83b7\u5f97\u6570\u5b57\u603b\u548c \\(s_i = w_i + t_i\\)\u3002</p> </li> </ul> <p>Let us assume that the transfer digits ti are from the digit set [\u2212 \u03bb, \u00b5]. To ensure that the last step leads to no new transfer, the following condition must be satisfied:</p> <p>\u8ba9\u6211\u4eec\u5047\u8bbe\u4f20\u8f93\u6570\u5b57 \\(t_i\\) \u6765\u81ea\u6570\u5b57\u96c6 \\([\u2212 \u03bb, \u00b5]\\)\u3002\u4e3a\u4e86\u786e\u4fdd\u6700\u540e\u4e00\u6b65\u4e0d\u4f1a\u5bfc\u81f4\u65b0\u7684\u8f6c\u79fb\uff0c\u5fc5\u987b\u6ee1\u8db3\u4ee5\u4e0b\u6761\u4ef6\uff1a $$ \\begin{array}{c} -\\alpha+\\lambda &amp; \\le p_i-rt_{i+1} \\le &amp; \\beta-\\mu \\ | &amp; \\text{ \u4e2d\u95f4\u548c } &amp; | \\ \\text{\u5982\u679c\u4f20\u5165\u7684\u2212\u03bb\u662f\u53ef\u5438\u6536\u7684\uff0c\u6700\u5c0f\u7684\u4e2d\u95f4\u548c} &amp; \\text{} &amp; \\text{\u5982\u679c\u4f20\u5165\u7684\u00b5\u662f\u53ef\u5438\u6536\u7684\uff0c\u6700\u5927\u7684\u4e2d\u95f4\u548c} \\end{array} $$ From the preceding inequalities, we can easily derive the conditions  \u03bb \u2265  \u03b1/(r \u2212 1 ) and  \u00b5 \u2265  \u03b2/(r \u2212 1 ). Once  \u03bb  and  \u00b5  are known, we choose the transfer digit value by comparing the position sum  pi  against  \u03bb +  \u00b5 + 2 constants  Cj, \u2212 \u03bb \u2264  j \u2264  \u00b5 + 1, with the transfer digit taken to be  j  if and only if  Cj \u2264  pi &lt; Cj+1. Formulas giving possible values for these constants can be found in [Parh90]. Here, we describe a simple intuitive method for deriving these constants. </p> <p>\u4ece\u524d\u9762\u7684\u4e0d\u7b49\u5f0f\uff0c\u6211\u4eec\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u63a8\u5bfc\u51fa\u6761\u4ef6 \\(\u03bb \u2265 \u03b1/(r \u2212 1 )\\) \u548c \\(\u00b5 \u2265 \u03b2/(r \u2212 1 )\\)\u3002\u4e00\u65e6\u5df2\u77e5 \u03bb \u548c \u00b5\uff0c\u6211\u4eec\u901a\u8fc7\u5c06\u4f4d\u7f6e\u603b\u548c \\(p_i\\) \u4e0e \\(\u03bb + \u00b5 + 2\\) \u5e38\u6570 \\(C_j\\) \u8fdb\u884c\u6bd4\u8f83\u6765\u9009\u62e9\u4f20\u8f93\u6570\u5b57\u503c\uff0c\\(\u2212 \u03bb \u2264 j \u2264 \u00b5 + 1\\)\uff0c\u5f53\u4e14\u4ec5\u5f53 \\(C_j \u2264 p_i &lt; C_{j+1}\\) \u65f6\uff0c\u4f20\u8f93\u6570\u5b57\u53d6\u4e3a j\u3002\u7ed9\u51fa\u8fd9\u4e9b\u5e38\u91cf\u53ef\u80fd\u503c\u7684\u516c\u5f0f\u53ef\u4ee5\u5728 [Parh90] \u4e2d\u627e\u5230\u3002\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u63cf\u8ff0\u4e86\u4e00\u79cd\u7b80\u5355\u76f4\u89c2\u7684\u65b9\u6cd5\u6765\u5bfc\u51fa\u8fd9\u4e9b\u5e38\u6570\u3002</p> <p>EXAMPLE 3.5 For  r = 10 and digit set [\u22125, 9], we need  \u03bb \u2265 5 / 9 and  \u00b5 \u2265 1. Given minimal values for  \u03bb  and  \u00b5  that minimize the hardware complexity, we find by choosing the minimal values for  \u03bb  and  \u00b5</p> <p>\u4f8b 3.5 \u5bf9\u4e8e r = 10 \u548c\u6570\u5b57\u96c6 [\u22125, 9]\uff0c\u6211\u4eec\u9700\u8981 \\(\u03bb \u2265 5 / 9\\) \u4e14 \\(\u00b5 \u2265 1\\)\u3002\u7ed9\u5b9a \u03bb \u548c \u00b5 \u7684\u6700\u5c0f\u503c\u4ee5\u6700\u5c0f\u5316\u786c\u4ef6\u590d\u6742\u6027\uff0c\u6211\u4eec\u901a\u8fc7\u9009\u62e9 \u03bb \u548c \u00b5 \u7684\u6700\u5c0f\u503c\u6765\u627e\u5230</p> \\[ \\begin{array}{c} \\lambda_{min}=\\mu_{min}=1 \\text{ \u5c31\u662f\u8bf4\u4f20\u8f93\u7684\u6570\u5b57\u662f\u5728[-1, 1]\u4e2d} \\\\ -\\infty=C_{-1} \\text{, } -4\\le C_0 \\le -1\\text{, }  6 \\le C_1 \\le 9\\text{, }  C_2=+\\infty \\end{array} \\] <p>We next show how the allowable values for the comparison constant C 1, shown above, are derived. The position sum pi is in [\u221210, 18]. We can set ti+1 to 1 for pi values as low as 6; for pi = 6, the resulting interim sum of \u22124 can absorb any incoming transfer in [\u22121, 1] without falling outside [\u22125, 9]. On the other hand, we must transfer 1 for pi values of 9 or more. Thus, for pi \u2265 C 1, where 6 \u2264 C 1 \u2264 9, we choose an outgoing transfer of 1. Similarly, for pi &lt; C 0, we choose an outgoing transfer of \u22121, where \u22124 \u2264 C 0 \u2264 \u22121. In all other cases, the outgoing transfer is 0.</p> <p>\u63a5\u4e0b\u6765\u6211\u4eec\u5c06\u5c55\u793a\u5982\u4f55\u5bfc\u51fa\u4e0a\u9762\u6240\u793a\u7684\u6bd4\u8f83\u5e38\u6570 \\(C_1\\) \u7684\u5141\u8bb8\u503c\u3002\u4f4d\u7f6e\u548c \\(p_i\\) \u5728 [\u221210, 18] \u4e2d\u3002\u5bf9\u4e8e\u4f4e\u81f3 6 \u7684 \\(p_i\\) \u503c\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06 \\(t_{i+1}\\) \u8bbe\u7f6e\u4e3a 1\uff1b\u5bf9\u4e8e \\(p_i = 6\\)\uff0c\u6240\u5f97\u7684\u4e34\u65f6\u548c \\(-4\\) \u53ef\u4ee5\u5438\u6536 [\u22121, 1] \u4e2d\u7684\u4efb\u4f55\u4f20\u5165\u4f20\u8f93\uff0c\u800c\u4e0d\u4f1a\u843d\u5728 [\u22125, 9] \u4e4b\u5916\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u5f53 \\(p_i\\) \u503c\u4e3a 9 \u6216\u66f4\u5927\u65f6\uff0c\u6211\u4eec\u5fc5\u987b\u4f20\u8f93 1\u3002\u56e0\u6b64\uff0c\u5bf9\u4e8e \\(p_i \u2265 C_1\\)\uff0c\u5176\u4e2d \\(6 \u2264 C_1 \u2264 9\\)\uff0c\u6211\u4eec\u9009\u62e9\u4f20\u51fa\u4f20\u8f93\u4e3a 1\u3002\u7c7b\u4f3c\u5730\uff0c\u5bf9\u4e8e \\(p_i &lt; C_0\\)\uff0c\u6211\u4eec\u9009\u62e9 \\(-1\\) \u7684\u4f20\u51fa\u4f20\u8f93\uff0c\u5176\u4e2d \\(-4 \u2264 C_0 \u2264 -1\\)\u3002\u5728\u6240\u6709\u5176\u4ed6\u60c5\u51b5\u4e0b\uff0c\u4f20\u51fa\u4f20\u8f93\u5747\u4e3a 0\u3002</p> <p>Assuming that the position sum pi is represented as a 6-bit, 2\u2019s-complement number abcdef , good choices for the comparison constants in the above ranges are C 0 = \u22124 and C 1 = 8. The logic expressions for the signals g 1 and g\u22121 then become g\u22121 = a(\u00af c \u2228 \u00af d)</p> <p>\u5047\u8bbe\u4f4d\u7f6e\u548c \\(p_i\\) \u8868\u793a\u4e3a 6 \u4f4d\u30012 \u7684\u8865\u6570 \\(abcdef\\) \uff0c\u5219\u4e0a\u8ff0\u8303\u56f4\u5185\u7684\u6bd4\u8f83\u5e38\u6570\u7684\u8f83\u597d\u9009\u62e9\u662f \\(C_0 = \u22124\\) \u548c \\(C_1 = 8\\)\u3002\u4fe1\u53f7 \\(g_1\\) \u548c \\(g_{\u22121}\\) \u7684\u903b\u8f91\u8868\u8fbe\u5f0f\u53d8\u4e3a </p> <p>\\(g_{\u22121} = a(\\overline c \\vee \\overline d)\\)   \u751f\u6210\u22121 \u7684\u4f20\u8f93</p> <p>\\(g_1 = \\overline a (b \\vee c)\\)  \u751f\u62101\u7684\u8f6c\u8d26</p> <p>An example addition is shown in Fig. 3.11.</p> <p>\u56fe 3.11 \u663e\u793a\u4e86\u53e6\u5916\u4e00\u4e2a\u793a\u4f8b\u3002</p> <p></p> <p>It is proven in [Parh90] that the preceding carry-free addition algorithm is applicable to a redundant representation if and only if one of the following sets of conditions is satisfied:</p> <p>[Parh90]\u4e2d\u8bc1\u660e\uff0c\u5f53\u4e14\u4ec5\u5f53\u6ee1\u8db3\u4ee5\u4e0b\u4e00\u7ec4\u6761\u4ef6\u4e4b\u4e00\u65f6\uff0c\u524d\u8ff0\u65e0\u8fdb\u4f4d\u52a0\u6cd5\u7b97\u6cd5\u624d\u9002\u7528\u4e8e\u5197\u4f59\u8868\u793a\uff1a</p> <p>a. \\(r \\gt 2\uff0c\u03c1 \\ge 3\\)</p> <p>b. \\(r \\gt 2\uff0c\u03c1 = 2\uff0c\u03b1 \\ne 1\uff0c\u03b2 \\ne 1\\)</p> <p>In other words, the carry-free algorithm is not applicable for  r = 2,  \u03c1 = 1, or  \u03c1 = 2 with  \u03b1 = 1 or  \u03b2 = 1. In such cases, a limited-carry addition algorithm is available: </p> <p>\u6362\u53e5\u8bdd\u8bf4\uff0c\u65e0\u8fdb\u4f4d\u7b97\u6cd5\u4e0d\u9002\u7528\u4e8e \\(r = 2\u3001\u03c1 = 1\\) \u6216 \\(\u03c1 = 2\\)\u5176\u4e2d \u03b1 = 1 \u6216 \u03b2 = 1\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u53ef\u4ee5\u4f7f\u7528\u6709\u9650\u8fdb\u4f4d\u52a0\u6cd5\u7b97\u6cd5\uff1a</p> <p>Limited-carry addition algorithm for GSD numbers </p> <p>Compute the position sums  pi =  xi +  yi. </p> <p>Compare each  pi  to a constant to determine whether  ei+1 = \u201clow\u201d or \u201chigh\u201d ( ei+1 is a binary range estimate for  ti+1). </p> <p>Given  ei, divide each  pi  into a transfer  ti+1 and an interim sum  wi =  pi \u2212  rti+1. </p> <p>Add the incoming transfers to obtain the sum digits  si =  wi +  ti. </p> <p>GSD \u6570\u5b57\u7684\u6709\u9650\u8fdb\u4f4d\u52a0\u6cd5\u7b97\u6cd5</p> <ul> <li> <p>\u8ba1\u7b97\u4f4d\u7f6e\u603b\u548c \\(p_i = x_i + y_i\\)\u3002</p> </li> <li> <p>\u5c06\u6bcf\u4e2a \\(p_i\\) \u4e0e\u5e38\u6570\u8fdb\u884c\u6bd4\u8f83\uff0c\u4ee5\u786e\u5b9a \\(e_{i+1}\\) =\u201c\u4f4e\u201d\u8fd8\u662f\u201c\u9ad8\u201d\uff08\\(e_{i+1}\\) \u662f \\(t_{i+1}\\) \u7684\u4e8c\u8fdb\u5236\u8303\u56f4\u4f30\u8ba1\u503c\uff09\u3002</p> </li> <li> <p>\u7ed9\u5b9a \\(e_i\\)\uff0c\u5c06\u6bcf\u4e2a \\(p_i\\) \u5206\u4e3a\u4f20\u8f93 \\(t_{i+1}\\) \u548c\u4e34\u65f6\u548c \\(w_i = p_i \u2212 rt_{i+1}\\)\u3002</p> </li> <li> <p>\u5c06\u4f20\u5165\u4f20\u8f93\u76f8\u52a0\u4ee5\u83b7\u5f97\u6570\u5b57\u603b\u548c \\(s_i = w_i + t_i\\)\u3002</p> </li> </ul> <p>This \u201climited-carry\u201d GSD addition algorithm is depicted in Fig. 3.12a; in an alternative implementation (Fig. 3.12b), the \u201ctransfer estimate\u201d stage is replaced by another transfer generation/addition phase. </p> <p>\u8fd9\u79cd\u201c\u6709\u9650\u8fdb\u4f4d\u201dGSD \u6dfb\u52a0\u7b97\u6cd5\u5982\u56fe 3.12a \u6240\u793a\uff1b\u5728\u66ff\u4ee3\u5b9e\u73b0\u4e2d\uff08\u56fe3.12b\uff09\uff0c\u201c\u4f20\u8f93\u4f30\u8ba1\u201d\u9636\u6bb5\u88ab\u53e6\u4e00\u4e2a\u4f20\u8f93\u751f\u6210/\u6dfb\u52a0\u9636\u6bb5\u53d6\u4ee3\u3002</p> <p></p> <p>Even though Figs. 3.12a and 3.12b appear similar, they are quite different in terms of the internal designs of the square boxes in the top and middle rows. In both cases, however, the sum digit  si  depends on  xi,  yi,  xi\u22121,  yi\u22121,  xi\u22122, and  yi\u22122. Rather than wait for the limited transfer propagation from stage  i \u2212 2 to  i, one can try to provide the necessary information directly from stage i \u2212 2 to stage i. This leads to an implementation with parallel carries\\(t_{i+1}^{(1)}\\) and \\(t_{i+1}^{(2)}\\) from stage i, which is sometimes applicable (Fig. 3.12c).</p> <p>\u5c3d\u7ba1 3.12a\u548c3.12b\u770b\u8d77\u6765\u5f88\u76f8\u4f3c\uff0c\u4f46\u5728\u9876\u6392\u548c\u4e2d\u95f4\u6392\u7684\u65b9\u6846\u7684\u5185\u90e8\u8bbe\u8ba1\u65b9\u9762\u5b83\u4eec\u6709\u5f88\u5927\u4e0d\u540c\u3002\u7136\u800c\uff0c\u5728\u8fd9\u4e24\u79cd\u60c5\u51b5\u4e0b\uff0c\u603b\u548c\u6570\u5b57 \\(s_i\\) \u53d6\u51b3\u4e8e \\(x_i\u3001y_i\u3001x_{i\u22121}\u3001y_{i\u22121}\u3001x_{i\u22122}\\) \u548c \\(y_{i\u22122}\\)\u3002\u4e0e\u5176\u7b49\u5f85\u4ece\u7b2c i \u2212 2 \u9636\u6bb5\u5230\u7b2c i \u9636\u6bb5\u7684\u6709\u9650\u4f20\u8f93\u4f20\u64ad\uff0c\u4e0d\u5982\u5c1d\u8bd5\u63d0\u4f9b\u5fc5\u8981\u7684\u4fe1\u606f\u76f4\u63a5\u4ece\u9636\u6bb5 \\(i \u2212 2\\) \u4f20\u9012\u5230\u9636\u6bb5 \\(i\\)\u3002\u8fd9\u5bfc\u51fa\u4e00\u4e2a\u5b9e\u73b0\u662f\u5e76\u884c\u627f\u8f7d\u6765\u81ea\u9636\u6bb5 \\(i\\) \u7684\u4e24\u4e2a\u8fdb\u4f4d\\(t_{i+1}^{(1)}\\)\u548c \\(t_{i+2}^{(2)}\\)\uff0c\u8fd9\u6709\u65f6\u662f\u9002\u7528\u7684\uff08\u56fe 3.12c\uff09\u3002</p> <p>EXAMPLE 3.6 Figure 3.13 depicts the use of carry estimates in limited-carry addition of radix-2 numbers with the digit set [\u22121, 1]. Here we have  \u03c1 = 1,  \u03bb min = 1, and  \u00b5 min = 1. The \u201clow\u201d and \u201chigh\u201d subranges for transfer digits are [\u22121, 0] and [0, 1], respectively, with a transfer  ti+1 in \u201chigh\u201d indicated if  pi \u2265 0. </p> <p>\u793a\u4f8b3.6 \u56fe3.13 \u63cf\u8ff0\u4e86\u6570\u5b57\u96c6[\u22121, 1] \u7684\u57fa2 \u6570\u7684\u6709\u9650\u8fdb\u4f4d\u52a0\u6cd5\u4e2d\u8fdb\u4f4d\u4f30\u8ba1\u7684\u4f7f\u7528\u3002\u8fd9\u91cc\u6211\u4eec\u6709 \\(\u03c1 = 1\uff0c\u03bb_{min} = 1\uff0c\u03bc_{min} = 1\\)\u3002\u4f20\u8f93\u6570\u5b57\u7684\u201c\u4f4e\u201d\u548c\u201c\u9ad8\u201d\u5b50\u8303\u56f4\u5206\u522b\u4e3a [\u22121, 0] \u548c [0, 1]\uff0c\u5982\u679c \\(p_i \u2265 0\\)\uff0c\u5219\u8868\u793a\u201c\u9ad8\u201d\u4e2d\u7684\u4f20\u8f93 \\(t_{i+1}\\)\u3002</p> <p></p> <p>\u56fe 3.13 \u901a\u8fc7\u8fdb\u4f4d\u4f30\u8ba1\u5bf9\u6570\u5b57\u96c6 [\u22121, 1] \u7684\u57fa 2 \u6570\u8fdb\u884c\u6709\u9650\u8fdb\u4f4d\u52a0\u6cd5\u3002\u5f53\u4f20\u5165\u4f20\u8f93\u4f4d\u4e8e [0, 1] \u65f6\uff0c\u4f4d\u7f6e\u548c -1 \u4fdd\u6301\u4e0d\u53d8\uff0c\u800c\u5982\u679c\u4f20\u5165\u4f20\u8f93\u4f4d\u4e8e [\u22121, 0]\uff0c\u5219\u5c06\u5176\u91cd\u5199\u4e3a 1\uff0c\u8fdb\u4f4d\u4e3a -1\u3002\u8be5\u65b9\u6848\u4fdd\u8bc1 \\(t_i = w_i\\)\uff0c\u56e0\u6b64 \\(-1 \u2264 s_i \u2264 1\\)\u3002</p> <p>EXAMPLE 3.7 Figure 3.14 shows another example of limited-carry addition with  r = 2, digit set [0, 3],  \u03c1 = 2,  \u03bb min = 0, and  \u00b5 min = 3, using carry estimates. The \u201clow\u201d and \u201chigh\u201d subranges for transfer digits are [0, 2] and [1, 3], respectively, with a transfer  ti+1 in \u201chigh\u201d indicated if  pi \u2265 4. </p> <p>\u793a\u4f8b3.7 \u56fe3.14 \u663e\u793a\u4e86\u4f7f\u7528\u8fdb\u4f4d\u4f30\u8ba1\u7684\u9650\u5236\u8fdb\u4f4d\u52a0\u6cd5\u7684\u53e6\u4e00\u4e2a\u793a\u4f8b\uff0c\u5176\u4e2d\\(r = 2\\)\u3001\u6570\u5b57\u96c6[0, 3]\u3001\\(\u03c1 = 2\u3001\u03bb_{min} = 0 \u548c\u03bc_{min} = 3\\)\u3002 \u4f20\u8f93\u6570\u5b57\u7684\u201c\u9ad8\u201d\u548c\u201c\u4f4e\u201d\u5b50\u8303\u56f4\u5206\u522b\u4e3a [0, 2] \u548c [1, 3]\uff0c\u5176\u4e2d\u4f20\u8f93 \\(t_{i+1}\\) \u5982\u679c \\(p_i \u2265 4\\)\uff0c\u5219\u8868\u793a\u201c\u9ad8\u201d\u3002</p> <p></p> <p>\u56fe 3.14 \u901a\u8fc7\u8fdb\u4f4d\u4f30\u8ba1\u5bf9\u6570\u5b57\u96c6 [0, 3] \u7684\u57fa 2 \u6570\u8fdb\u884c\u6709\u9650\u8fdb\u4f4d\u52a0\u6cd5\u3002\u5f53\u4f20\u5165\u4f20\u8f93\u4f4d\u4e8e [0, 2] \u65f6\uff0c\u4f4d\u7f6e\u548c 1 \u4fdd\u6301\u4e0d\u53d8\uff0c\u800c\u5982\u679c\u4f20\u5165\u4f20\u8f93\u4f4d\u4e8e [1, 3]\uff0c\u5219\u5c06\u5176\u91cd\u5199\u4e3a -1\uff0c\u8fdb\u4f4d\u4e3a 1\u3002</p> <p>EXAMPLE 3.8 Figure 3.15 shows the same addition as in Example 3.7 ( r = 2, digit set [0, 3],  \u03c1 = 2,  \u03bb min = 0,  \u00b5 min = 3) using the repeated-carry scheme of Fig. 3.12b. </p> <p>\u4f8b 3.8 \u56fe 3.15 \u663e\u793a\u4e86\u4e0e\u4f8b 3.7 \u76f8\u540c\u7684\u52a0\u6cd5\uff08 \\(r = 2\\)\uff0c\u6570\u5b57\u96c6 [0, 3], \\(\u03c1 = 2, \u03bb_{min} = 0, \u00b5_{min} = 3\\)) \u4f7f\u7528\u56fe 3.12b \u7684\u91cd\u590d\u8fdb\u4f4d\u65b9\u6848\u3002</p> <p></p> <p>EXAMPLE 3.9 Figure 3.16 shows the same addition as in Example 3.7 ( r = 2, digit set [0, 3],  \u03c1 = 2,  \u03bb min = 0,  \u00b5 min = 3) using the parallel-carries scheme of Fig. 3.12c. </p> <p>\u4f8b 3.9 \u56fe 3.16 \u663e\u793a\u4e86\u4e0e\u4f8b 3.7 \u76f8\u540c\u7684\u52a0\u6cd5\uff08 \\(r = 2\\)\uff0c\u6570\u5b57\u96c6 [0, 3], \\(\u03c1 = 2, \u03bb_{min} = 0, \u00b5_{min} = 3\\)) \u4f7f\u7528\u56fe 3.12c \u7684\u5e76\u884c\u8fdb\u4f4d\u65b9\u6848\u3002</p> <p></p> <p>Subtraction of GSD numbers is very similar to addition. With a symmetric digit set, one can simply invert the signs of all digits in the subtractor  y  to obtain a representation of \u2212 y and then perform the addition x+ (\u2212 y) using a carry-free or limited-carry algorithm as already discussed. Negation of a GSD number with an asymmetric digit set is somewhat more complicated, but can still be performed by means of a carry-free algorithm [Parh93].</p> <p>GSD \u6570\u5b57\u7684\u51cf\u6cd5\u4e0e\u52a0\u6cd5\u975e\u5e38\u76f8\u4f3c\u3002\u5bf9\u4e8e\u5bf9\u79f0\u6570\u5b57\u96c6\uff0c\u53ef\u4ee5\u7b80\u5355\u5730\u53cd\u8f6c\u51cf\u6cd5\u5668 \\(y\\) \u4e2d\u6240\u6709\u6570\u5b57\u7684\u7b26\u53f7\u4ee5\u83b7\u5f97\\(\u2212y\\)\u7684\u8868\u793a\uff0c\u7136\u540e\u4f7f\u7528\u5df2\u7ecf\u8ba8\u8bba\u8fc7\u7684\u65e0\u8fdb\u4f4d\u6216\u6709\u9650\u8fdb\u4f4d\u7b97\u6cd5\u6267\u884c\u52a0\u6cd5 \\(x+ (\u2212 y)\\)\u3002\u5177\u6709\u975e\u5bf9\u79f0\u6570\u5b57\u96c6\u7684 GSD \u6570\u7684\u6c42\u53cd\u7a0d\u5fae\u590d\u6742\u4e00\u4e9b\uff0c\u4f46\u4ecd\u7136\u53ef\u4ee5\u901a\u8fc7\u65e0\u8fdb\u4f4d\u7b97\u6cd5 [Parh93] \u6765\u6267\u884c\u3002</p> <p>This algorithm basically converts a radix- r number from the digit set [\u2212 \u03b2, \u03b1], which results from changing the signs of the individual digits of y, to the original digit set [\u2212 \u03b1, \u03b2]. Alternatively, a direct subtraction algorithm can be applied by first computing position differences in [\u2212 \u03b1 \u2212 \u03b2, \u03b1 + \u03b2], then forming interim differences and transfer digits. Details are omitted here.</p> <p>\u57fa\u672c\u4e0a\u8be5\u7b97\u6cd5\u662f\u5c06\u57fa\u6570 r \u7684\u6570\u4ece\u6570\u5b57\u96c6 \\([\u2212 \u03b2, \u03b1]\\) \u8f6c\u6362\u4e3a\u539f\u59cb\u6570\u5b57\u96c6\\([\u2212 \u03b1, \u03b2]\\)\uff0c\u8be5\u6570\u5b57\u96c6\u662f\u901a\u8fc7\u66f4\u6539 y \u7684\u5404\u4e2a\u6570\u5b57\u7684\u7b26\u53f7\u800c\u4ea7\u751f\u7684\u3002\u6216\u8005\u4e5f\u53ef\u4ee5\u901a\u8fc7\u9996\u5148\u8ba1\u7b97 [\u2212 \u03b1 \u2212 \u03b2, \u03b1 + \u03b2] \u4e2d\u7684\u4f4d\u7f6e\u5dee\uff0c\u7136\u540e\u5f62\u6210\u4e34\u65f6\u5dee\u5e76\u4f20\u8f93\u6570\u5b57\u6765\u5e94\u7528\u76f4\u63a5\u51cf\u6cd5\u7b97\u6cd5\u3002\u6b64\u5904\u7701\u7565\u8be6\u7ec6\u5185\u5bb9\u3002</p>"},{"location":"Part_01/03/#36","title":"3.6 \u8f6c\u6362\u548c\u652f\u6301\u529f\u80fd","text":"<p>Since input numbers provided from the outside (machine or human interface) are in standard binary or decimal and outputs must be presented in the same way, conversions between binary or decimal and GSD representations are required.</p> <p>\u7531\u4e8e\u4ece\u5916\u90e8\uff08\u673a\u5668\u6216\u4eba\u673a\u754c\u9762\uff09\u63d0\u4f9b\u7684\u8f93\u5165\u6570\u5b57\u662f\u6807\u51c6\u4e8c\u8fdb\u5236\u6216\u5341\u8fdb\u5236\uff0c\u5e76\u4e14\u8f93\u51fa\u5fc5\u987b\u4ee5\u76f8\u540c\u7684\u65b9\u5f0f\u5448\u73b0\uff0c\u56e0\u6b64\u9700\u8981\u4e8c\u8fdb\u5236\u6216\u5341\u8fdb\u5236\u4e0e GSD \u8868\u793a\u4e4b\u95f4\u7684\u8f6c\u6362\u3002</p> <p>EXAMPLE 3.10 Consider number conversions from or to standard binary to or from BSD representation. To convert from signed binary to BSD, we simply attach the common number sign to each digit, if the ( s, v) code of Fig. 3.7 is to be used for the BSD digits. Otherwise, we need a simple digitwise converter from the ( s, v) code to the desired code. To convert from BSD to signed binary, we separate the positive and negative digits into a positive and a negative binary number, respectively. A subtraction then yields the desired result. Here is an example:</p> <p>\u793a\u4f8b3.10 \u8003\u8651\u6807\u51c6\u4e8c\u8fdb\u5236\u4e0eBSD\u8868\u793a\u4e4b\u95f4\u7684\u6570\u5b57\u8f6c\u6362\u3002</p> <p>\u4e3a\u4e86\u4ece\u6709\u7b26\u53f7\u4e8c\u8fdb\u5236\u8f6c\u6362\u4e3a BSD\uff0c\u5982\u679c\u56fe 3.7 \u7684 (s, v) \u4ee3\u7801\u7528\u4e8e BSD \u6570\u5b57\uff0c\u6211\u4eec\u53ea\u9700\u5c06\u516c\u5171\u6570\u5b57\u7b26\u53f7\u9644\u52a0\u5230\u6bcf\u4e2a\u6570\u5b57\u4e0a\u3002\u5426\u5219\uff0c\u6211\u4eec\u9700\u8981\u4e00\u4e2a\u7b80\u5355\u7684\u6570\u5b57\u8f6c\u6362\u5668\uff0c\u5c06 ( s, v) \u4ee3\u7801\u8f6c\u6362\u4e3a\u6240\u9700\u7684\u7f16\u7801\u3002</p> <p>\u4e3a\u4e86\u4ece BSD \u8f6c\u6362\u4e3a\u6709\u7b26\u53f7\u4e8c\u8fdb\u5236\uff0c\u6211\u4eec\u5c06\u6b63\u6570\u548c\u8d1f\u6570\u5206\u522b\u5206\u6210\u6b63\u4e8c\u8fdb\u5236\u6570\u548c\u8d1f\u4e8c\u8fdb\u5236\u6570\u3002\u7136\u540e\u8fdb\u884c\u51cf\u6cd5\u5373\u53ef\u5f97\u5230\u6240\u9700\u7684\u7ed3\u679c\u3002\u8fd9\u662f\u4e00\u4e2a\u4f8b\u5b50\uff1a</p> <pre><code>1 \u22121  0 \u22121  0  +6 \u7684 BSD \u8868\u793a BSD representation of +6 \n1  0  0  0  0  \u6b63\u6570\u90e8\u5206\uff08+1\u5904\u7684\u4f4d\uff09Positive part (1 digits)\n0  1  0  1  0  \u8d1f\u6570\u90e8\u5206\uff08\u22121\u5904\u7684\u4f4d\uff09Negative part (\u22121 digits)\n0  0  1  1  0  \u5dee\u503c=\u8f6c\u6362\u7ed3\u679c Difference = conversion result\n</code></pre> <p>The positive and negative parts required above are particularly easy to obtain if the BSD number is represented using the ( n, p) code of Fig. 3.7. The reader should be able to modify the process above for dealing with numbers, or deriving results, in 2\u2019s-complement format.</p> <p>\u5982\u679c BSD \u6570\u5b57\u4f7f\u7528\u56fe 3.7 \u7684 (n, p) \u4ee3\u7801\u8868\u793a\u7684\u8bdd\uff0c\u4e0a\u8ff0\u6240\u9700\u7684\u6b63\u8d1f\u90e8\u5206\u7279\u522b\u5bb9\u6613\u83b7\u5f97\u3002\u8bfb\u8005\u5e94\u8be5\u80fd\u591f\u4fee\u6539\u4e0a\u8ff0\u8fc7\u7a0b\uff0c\u4ee5 2 \u7684\u8865\u7801\u683c\u5f0f\u5904\u7406\u6570\u5b57\u6216\u5bfc\u51fa\u7ed3\u679c\u3002</p> <p>The conversion from redundant to nonredundant representation essentially involves carry propagation and is thus rather slow. It is expected, however, that we will not need conversions very often. Conversion is done at the input and output. Thus, if long sequences of computation are performed between input and output, the conversion overhead can become negligible. </p> <p>\u4ece\u5197\u4f59\u8868\u793a\u5230\u975e\u5197\u4f59\u8868\u793a\u7684\u8f6c\u6362\u672c\u8d28\u4e0a\u6d89\u53ca\u8fdb\u4f4d\u4f20\u64ad\uff0c\u56e0\u6b64\u76f8\u5f53\u6162\u3002\u7136\u800c\uff0c\u9884\u8ba1\u6211\u4eec\u4e0d\u4f1a\u7ecf\u5e38\u9700\u8981\u8f6c\u6362\u3002\u8f6c\u6362\u5728\u8f93\u5165\u548c\u8f93\u51fa\u5904\u5b8c\u6210\u3002\u56e0\u6b64\uff0c\u5982\u679c\u5728\u8f93\u5165\u548c\u8f93\u51fa\u4e4b\u95f4\u6267\u884c\u957f\u5e8f\u5217\u7684\u8ba1\u7b97\uff0c\u5219\u8f6c\u6362\u5f00\u9500\u53ef\u4ee5\u5ffd\u7565\u4e0d\u8ba1\u3002</p> <p>Storage overhead (the larger number of bits that may be needed to represent a GSD digit compared to a standard digit in the same radix) used to be a major disadvantage of redundant representations. However, with advances in VLSI (very large-scale integration) technology, this is no longer a major drawback; though the increase in the number of pins for input and output may still be a factor.</p> <p>\u5b58\u50a8\u5f00\u9500\uff08GSD\u8868\u793a\u4e0e\u76f8\u540c\u57fa\u6570\u4e2d\u7684\u6807\u51c6\u6570\u5b57\u8868\u793a\u76f8\u6bd4\uff0c\u53ef\u80fd\u9700\u8981\u7684\u8f83\u5927\u4f4d\u6570\u7684\u6570\u5b57\uff09\u66fe\u7ecf\u662f\u5197\u4f59\u8868\u793a\u7684\u4e3b\u8981\u7f3a\u70b9\u3002\u7136\u800c\uff0c\u968f\u7740VLSI\uff08\u8d85\u5927\u89c4\u6a21\u96c6\u6210\uff09\u6280\u672f\u7684\u8fdb\u6b65\uff0c\u8fd9\u4e0d\u518d\u662f\u4e00\u4e2a\u4e3b\u8981\u7f3a\u70b9\uff1b\u5c3d\u7ba1\u8f93\u5165\u548c\u8f93\u51fa\u5f15\u811a\u6570\u91cf\u7684\u589e\u52a0\u53ef\u80fd\u4ecd\u7136\u662f\u4e00\u4e2a\u56e0\u7d20\u3002</p> <p>In the rest of this section, we review some properties of GSD representations that are important for the implementation of arithmetic support functions: zero detection, sign test, and overflow handling [Parh93]. </p> <p>\u5728\u672c\u8282\u7684\u5176\u4f59\u90e8\u5206\u4e2d\uff0c\u6211\u4eec\u5c06\u56de\u987e GSD \u8868\u793a\u7684\u4e00\u4e9b\u5bf9\u4e8e\u7b97\u672f\u652f\u6301\u51fd\u6570\u7684\u5b9e\u73b0\u5f88\u91cd\u8981\u7684\u5c5e\u6027\uff1a\u96f6\u68c0\u6d4b\u3001\u7b26\u53f7\u6d4b\u8bd5\u548c\u6ea2\u51fa\u5904\u7406 [Parh93]\u3002</p> <p>In a GSD number system, the integer 0 may have multiple representations. For example, the three-digit numbers 0 0 0 and \u22121 4 0 both represent 0 in radix 4. However, in the special case of  \u03b1 &lt; r  and  \u03b2 &lt; r, zero is uniquely represented by the all-0s vector. So despite redundancy and multiple representations, comparison of numbers for equality can be simple in this common special case, since it involves subtraction and detecting the all-0s pattern. </p> <p>\u5728GSD\u6570\u5b57\u7cfb\u7edf\u4e2d\uff0c\u6574\u65700\u53ef\u4ee5\u6709\u591a\u79cd\u8868\u793a\u5f62\u5f0f\u3002\u4f8b\u5982\uff0c\u4e09\u4f4d\u6570 0 0 0 \u548c \u22121 4 0 \u90fd\u8868\u793a\u57fa\u6570 4 \u4e2d\u7684 0\u3002\u4f46\u662f\uff0c\u5728 \u03b1 &lt; r \u548c \u03b2 &lt; r \u7684\u7279\u6b8a\u60c5\u51b5\u4e0b\uff0c\u96f6\u7531\u5168 0 \u5411\u91cf\u552f\u4e00\u8868\u793a\u3002\u56e0\u6b64\uff0c\u5c3d\u7ba1\u5b58\u5728\u5197\u4f59\u548c\u591a\u91cd\u8868\u793a\uff0c\u4f46\u5728\u8fd9\u79cd\u5e38\u89c1\u7684\u7279\u6b8a\u60c5\u51b5\u4e0b\uff0c\u6570\u5b57\u6bd4\u8f83\u662f\u5426\u76f8\u7b49\u53ef\u4ee5\u5f88\u7b80\u5355\uff0c\u56e0\u4e3a\u5b83\u6d89\u53ca\u51cf\u6cd5\u548c\u68c0\u6d4b\u5168 0 \u6a21\u5f0f\u3002</p> <p>Sign test, and thus any relational comparison ( &lt; , \u2264, etc.), is more difficult. The sign of a GSD number in general depends on all its digits. Thus sign test is slow if done through signal propagation (ripple design) or expensive if done by a fast lookahead circuit (contrast this with the trivial sign test for signed-magnitude and 2\u2019s-complement representations). In the special case of  \u03b1 &lt; r  and  \u03b2 &lt; r, the sign of a number is identical to the sign of its most significant nonzero digit. Even in this special case, determination of sign requires scanning of all digits, a process that can be as slow as worst-case carry propagation. </p> <p>\u7b26\u53f7\u6d4b\u8bd5\u4ee5\u53ca\u4efb\u4f55\u5173\u7cfb\u6bd4\u8f83\uff08&lt;\u3001\u2264\u7b49\uff09\u90fd\u66f4\u52a0\u56f0\u96be\u3002 GSD \u7f16\u53f7\u7684\u7b26\u53f7\u901a\u5e38\u53d6\u51b3\u4e8e\u5176\u6240\u6709\u6570\u5b57\u3002\u56e0\u6b64\uff0c\u5982\u679c\u901a\u8fc7\u4fe1\u53f7\u4f20\u64ad\uff08ripple\u7eb9\u6ce2\u8bbe\u8ba1\uff09\u8fdb\u884c\u7b26\u53f7\u6d4b\u8bd5\uff0c\u5219\u901f\u5ea6\u5f88\u6162\uff1b\u5982\u679c\u901a\u8fc7\u5feb\u901f\u5148\u884c\u7535\u8def\u8fdb\u884c\uff0c\u5219\u7b26\u53f7\u6d4b\u8bd5\u6210\u672c\u8f83\u9ad8\uff08\u4e0e\u7b26\u53f7\u5e45\u5ea6\u548c 2 \u8865\u7801\u8868\u793a\u7684\u7b80\u5355\u7b26\u53f7\u6d4b\u8bd5\u76f8\u6bd4\uff09\u3002\u5728 \u03b1 &lt; r \u548c \u03b2 &lt; r \u7684\u7279\u6b8a\u60c5\u51b5\u4e0b\uff0c\u6570\u5b57\u7684\u7b26\u53f7\u4e0e\u5176\u6700\u9ad8\u6709\u6548\u975e\u96f6\u6570\u5b57\u7684\u7b26\u53f7\u76f8\u540c\u3002\u5373\u4f7f\u5728\u8fd9\u79cd\u7279\u6b8a\u60c5\u51b5\u4e0b\uff0c\u786e\u5b9a\u7b26\u53f7\u4e5f\u9700\u8981\u626b\u63cf\u6240\u6709\u6570\u5b57\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u53ef\u80fd\u4e0e\u6700\u574f\u60c5\u51b5\u7684\u8fdb\u4f4d\u4f20\u64ad\u4e00\u6837\u6162\u3002</p> <p>Overflow handling is also more difficult in GSD arithmetic. Consider the addition of two  k-digit numbers. Such an addition produces a transfer-out digit  tk . Since  tk  is produced using the worst-case assumption about the as yet unknown  tk\u22121, we can get an overflow indication ( tk = 0) even when the result can be represented with  k  digits.  It is possible to perform a test to see whether the overflow is real and, if it is not, to obtain a  k-digit representation for the true result. However, this test and conversion are fairly slow. </p> <p>GSD \u7b97\u6cd5\u4e2d\u7684\u6ea2\u51fa\u5904\u7406\u4e5f\u66f4\u52a0\u56f0\u96be\u3002\u8003\u8651\u4e24\u4e2a k \u4f4d\u6570\u5b57\u7684\u52a0\u6cd5\u3002\u8fd9\u6837\u7684\u52a0\u6cd5\u4ea7\u751f\u8f6c\u51fa\u6570\u5b57tk \u3002\u7531\u4e8e tk \u662f\u4f7f\u7528\u5173\u4e8e\u672a\u77e5 tk\u22121 \u7684\u6700\u574f\u60c5\u51b5\u5047\u8bbe\u751f\u6210\u7684\uff0c\u56e0\u6b64\u5373\u4f7f\u7ed3\u679c\u53ef\u4ee5\u7528 k \u4f4d\u6570\u5b57\u8868\u793a\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u83b7\u5f97\u6ea2\u51fa\u6307\u793a\uff08 tk = 0\uff09\u3002\u53ef\u4ee5\u6267\u884c\u6d4b\u8bd5\u6765\u67e5\u770b\u6ea2\u51fa\u662f\u5426\u771f\u5b9e\uff0c\u5982\u679c\u4e0d\u662f\uff0c\u5219\u83b7\u5f97\u771f\u5b9e\u7ed3\u679c\u7684 k \u4f4d\u8868\u793a\u3002\u7136\u800c\uff0c\u8fd9\u4e2a\u6d4b\u8bd5\u548c\u8f6c\u6362\u76f8\u5f53\u7f13\u6162\u3002</p> <p>The difficulties with sign test and overflow detection can nullify some or all of the speed advantages of GSD number representations. This is why applications of GSD are presently limited to special-purpose systems or to internal number representations, which are subsequently converted to standard representation. </p> <p>\u7b26\u53f7\u6d4b\u8bd5\u548c\u6ea2\u51fa\u68c0\u6d4b\u7684\u56f0\u96be\u53ef\u80fd\u4f1a\u62b5\u6d88 GSD \u6570\u5b57\u8868\u793a\u7684\u90e8\u5206\u6216\u5168\u90e8\u901f\u5ea6\u4f18\u52bf\u3002\u8fd9\u5c31\u662f\u4e3a\u4ec0\u4e48GSD\u76ee\u524d\u4ec5\u9650\u4e8e\u5e94\u7528\u5728\u4e13\u7528\u7cfb\u7edf\u6216\u5185\u90e8\u6570\u5b57\u8868\u793a\uff0c\u968f\u540e\u5c31\u4f1a\u8f6c\u6362\u4e3a\u6807\u51c6\u8868\u793a\u3002</p>"},{"location":"Part_01/03/#_1","title":"\u95ee\u9898\uff08\u7565\uff09","text":""},{"location":"Part_01/03/#_2","title":"\u53c2\u8003\u6587\u732e\u548c\u8fdb\u4e00\u6b65\u9605\u8bfb","text":"<pre><code>[Aviz61] Avizienis, A., \u201cSigned-Digit Number Representation for Fast Parallel Arithmetic,\u201d\n         IRE Trans. Electronic Computers, Vol. 10, pp. 389\u2013400, 1961.\n[Glas81] Glaser, A., History of Binary and Other Nondecimal Numeration, rev. ed., Tomash\n         Publishers, 1981.\n[Jabe05] Jaberipur, G., B. Parhami, and M. Ghodsi, \u201cWeighted Two-Valued Digit-Set\n         Encodings: Unifying Efficient Hardware Representation Schemes for Redundant\n         Number Systems,\u201d IEEE Trans. Circuits and Systems I, Vol. 52, No. 7,\n         pp. 1348\u20131357, 2005.\n[Jabe06] Jaberipur, G., B. Parhami, and M. Ghodsi, \u201cAn Efficient Universal Addition Scheme\n         for All Hybrid-Redundant Representations with Weighted Bit-Set Encoding,\u201d J. VLSI\n         Signal Processing, Vol. 42, pp. 149\u2013158, 2006.\n[Korn94] Kornerup, P., \u201cDigit-Set Conversions: Generalizations and Applications,\u201d IEEE\n         Trans. Computers, Vol. 43, No. 8, pp. 622\u2013629, 1994.\n[Metz59] Metze, G., and J. E. Robertson, \u201cElimination of Carry Propagation in Digital\n         Computers,\u201d Information Processing \u201959 (Proceedings of a UNESCO Conference),\n         1960, pp. 389\u2013396.\n[Parh88] Parhami, B., \u201cCarry-Free Addition of Recoded Binary Signed-Digit Numbers,\u201d IEEE\n         Trans. Computers, Vol. 37, No. 11, pp. 1470\u20131476, 1988.\n[Parh90] Parhami, B., \u201cGeneralized Signed-Digit Number Systems: A Unifying Framework for\n         Redundant Number Representations,\u201d IEEE Trans. Computers, Vol. 39, No. 1, pp.\n         89\u201398, 1990.\n[Parh93] Parhami, B., \u201cOn the Implementation of Arithmetic Support Functions for\n         Generalized Signed-Digit Number Systems,\u201d IEEE Trans. Computers, Vol. 42, No. 3,\n         pp. 379\u2013384, 1993.\n[Parh96] Parhami, B., \u201cComments on \u2018High-Speed Area-Efficient Multiplier Design Using\n         Multiple-Valued Current Mode Circuits,\u2019\u201d IEEE Trans. Computers, Vol. 45, No. 5,\n         pp. 637\u2013638, 1996.\n[Parh08] Parhami, B., \u201cDouble-Least-Significant-Bits 2\u2019s-Complement Number\n         Representation Scheme with Bitwise Complementation and Symmetric Range,\u201d IET\n         Circuits, Devices &amp; Systems, Vol. 2, No. 2, pp. 179\u2013186, 2008.\n[Phat94] Phatak, D. S., and I. Koren, \u201cHybrid Signed-Digit Number Systems: A Unified\n         Framework for Redundant Number Representations with Bounded Carry Propagation\n         Chains,\u201d IEEE Trans. Computers, Vol. 43, No. 8, pp. 880\u2013891, 1994.\n[Phat01] Phatak, D. S., T. Goff, and I. Koren, \u201cConstant-Time Addition and Simultaneous\n         Format Conversion Based on Redundant Binary Representations,\u201d IEEE Trans.\n         Computers, Vol. 50, No. 11, pp. 1267\u20131278, 2001.\n[Tenc06] Tenca, A. F., S. Park, and L. A. Tawalbeh, \u201cCarry-Save Representation Is\n         Shift-Unsafe: The Problem and Its Solution,\u201d IEEE Trans. Computers, Vol. 55, No. 5,\n         pp. 630\u2013635, 2006\n</code></pre>"},{"location":"Part_01/04/","title":"4 \u5269\u4f59\u6570\u7cfb\u7edf","text":"<p>Residue Number Systems</p> <p>\u201cGod created the integers, all else is the work of man\u201d </p> <p>\u200b                           \u2014\u2014 LEOPOLD KRONECKER , 1886</p> <p>\u201c\u4e0a\u5e1d\u521b\u9020\u4e86\u6574\u6570\uff0c\u5176\u4ed6\u4e00\u5207\u90fd\u662f\u4eba\u7c7b\u7684\u5de5\u4f5c\u201d</p> <p>\u200b                           \u2014\u2014 \u5229\u5965\u6ce2\u5fb7\u00b7\u514b\u7f57\u5185\u514b , 1886</p> <p>By converting arithmetic on large numbers to arithmetic on a collection of smaller numbers, residue number system (RNS) representations produce significant speedup for some classes of arithmetic-intensive algorithms in signal processing applications. Additionally, RNS arithmetic is a valuable tool for theoretical studies of the limits of fast arithmetic. In this chapter, we study RNS representations and arithmetic, along with their advantages and drawbacks. Chapter topics include:</p> <p>\u901a\u8fc7\u5c06\u5bf9\u4e8e\u5927\u6570\u7684\u7b97\u672f\u8f6c\u6362\u4e3a\u5bf9\u4e8e\u8f83\u5c0f\u6570\u96c6\u5408\u7684\u7b97\u672f\uff0c\u5269\u4f59\u6570\u6570\u7cfb\u7edf\uff08RNS\uff09\u8868\u793a\u5bf9\u4e8e\u4fe1\u53f7\u5904\u7406\u5e94\u7528\u4e2d\u67d0\u4e9b\u7c7b\u578b\u7684\u7b97\u672f\u5bc6\u96c6\u578b\u7b97\u6cd5\u4ea7\u751f\u663e\u8457\u7684\u52a0\u901f\u3002\u6b64\u5916\uff0cRNS \u7b97\u672f\u5bf9\u4e8e\u5feb\u901f\u7b97\u672f\u6781\u9650\u7684\u7406\u8bba\u7814\u7a76\u6765\u8bf4\u662f\u4e00\u4e2a\u5f88\u6709\u4ef7\u503c\u7684\u5de5\u5177\u3002\u5728\u672c\u7ae0\u4e2d\uff0c\u6211\u4eec\u7814\u7a76 RNS \u8868\u793a\u548c\u7b97\u6cd5\uff0c\u4ee5\u53ca\u5b83\u4eec\u7684\u4f18\u70b9\u548c\u7f3a\u70b9\u3002\u7ae0\u8282\u4e3b\u9898\u5305\u62ec\uff1a</p> <p>4.1 RNS\u8868\u793a\u548c\u7b97\u672f RNS Representation and Arithmetic</p> <p>4.2 \u9009\u62e9 RNS \u6a21\u6570 Choosing the RNS Moduli</p> <p>4.3 \u6570\u5b57\u7684\u7f16\u7801\u548c\u89e3\u7801 Encoding and Decoding of Numbers</p> <p>4.4 \u56f0\u96be\u7684RNS\u7b97\u672f\u8fd0\u7b97 Difficult RNS Arithmetic Operations</p> <p>4.5 \u5197\u4f59RNS\u8868\u793a Redundant RNS Representations</p> <p>4.6 RNS \u4e2d\u5feb\u901f\u7b97\u672f\u7684\u5c40\u9650\u6027 Limits of Fast Arithmetic in RNS</p>"},{"location":"Part_01/04/#41-rns","title":"4.1 RNS \u8868\u793a\u548c\u7b97\u6cd5","text":"<p>What number has the remainders of 2, 3, and 2 when divided by the numbers 7, 5, and 3, respectively? This puzzle, written in the form of a verse by the Chinese scholar Sun Tsu more than 1500 years ago [Jenk93], is perhaps the first documented use of number representation using multiple residues. The puzzle essentially asks us to convert the coded representation  ( 2|3|2 )  of a residue number system, based on the moduli  ( 7|5|3 ), into standard decimal format. </p> <p>\u54ea\u4e2a\u6570\u5b57\u5206\u522b\u9664\u4ee5\u6570\u5b57 7\u30015 \u548c 3 \u65f6\uff0c\u4f59\u6570\u4e3a 2\u30013 \u548c 2\uff1f\u8fd9\u4e2a\u8c1c\u9898\u7531\u4e2d\u56fd\u5b66\u8005\u5b59\u5b50\u5728 1500 \u591a\u5e74\u524d\u4ee5\u8bd7\u53e5\u7684\u5f62\u5f0f\u5199\u6210 [Jenk93]\uff0c\u53ef\u80fd\u662f\u7b2c\u4e00\u4e2a\u6709\u8bb0\u5f55\u7684\u4f7f\u7528\u591a\u4e2a\u4f59\u6570\u7684\u6570\u5b57\u8868\u793a\u5f62\u5f0f\u3002\u8be5\u96be\u9898\u672c\u8d28\u4e0a\u8981\u6c42\u6211\u4eec\u5c06\u57fa\u4e8e\u6a21\uff087|5|3 \uff09\u7684\u4f59\u6570\u7cfb\u7edf\u7684\u7f16\u7801\u8868\u793a\uff08 2|3|2 \uff09\u8f6c\u6362\u4e3a\u6807\u51c6\u5341\u8fdb\u5236\u683c\u5f0f\u3002</p> <p>In a residue number system (RNS), a number  x  is represented by the list of its residues with respect to  k  pairwise relatively prime moduli  mk\u22121  &gt; \u00b7 \u00b7 \u00b7  &gt; m 1  &gt; m 0. The residue xi  of  x  with respect to the  i th modulus  mi  is akin to a digit and the entire  k-residue representation of  x  can be viewed as a  k-digit number, where the digit set for the  i th position is [0,  mi \u2212 1]. Notationally, we write</p> <p>\u5728\u4f59\u6570\u7cfb\u7edf (RNS) \u4e2d\uff0c\u6570\u5b57 x \u7531\u5176\u76f8\u5bf9\u4e8e k \u4e2a\u6210\u5bf9\u4e92\u7d20\u6a21 \\(m_{k\u22121} &gt; \u00b7 \u00b7 \u00b7 &gt; m_1 &gt; m_0\\) \u7684\u4f59\u6570\u5217\u8868\u8868\u793a\u3002x \u76f8\u5bf9\u4e8e\u7b2c i \u4e2a\u6a21\u6570 \\(m_i\\) \u7684\u4f59\u6570 \\(x_i\\) \u7c7b\u4f3c\u4e8e\u4e00\u4e2a\u6570\u5b57\uff0c\u5e76\u4e14 x \u7684\u6574\u4e2a k \u4f59\u6570\u8868\u793a\u53ef\u4ee5\u89c6\u4e3a\u4e00\u4e2a k \u4f4d\u6570\u5b57\uff0c\u5176\u4e2d\u7b2c i \u4e2a\u4f4d\u7f6e\u7684\u6570\u5b57\u96c6\u662f [\\(0, m_{i \u2212 1}\\)]\u3002\u6211\u4eec\u8bb0\u4e3a</p> \\[ x_i = x \\mod m_i = \\left \\langle x  \\right \\rangle _{mi} \\] <p>and specify the RNS representation of  x  by enclosing the list of residues, or digits, in parentheses. For example, </p> <p>\u5e76\u901a\u8fc7\u5c06\u4f59\u6570\u6216\u6570\u5b57\u5217\u8868\u62ec\u5728\u62ec\u53f7\u4e2d\u6765\u6307\u5b9a x \u7684 RNS \u8868\u793a\u5f62\u5f0f\u3002\u4f8b\u5982\uff0c</p> \\[ x = ( 2|3|2 )_{RNS ( 7|5|3 )} \\] <p>represents the puzzle given at the beginning of this section. The list of moduli can be deleted from the subscript when we have agreed on a default set. In many of the examples of this chapter, the following RNS is assumed:</p> <p>\u4ee3\u8868\u672c\u8282\u5f00\u5934\u7ed9\u51fa\u7684\u96be\u9898\u3002\u5f53\u6211\u4eec\u5c31\u9ed8\u8ba4\u96c6\u8fbe\u6210\u4e00\u81f4\u65f6\uff0c\u53ef\u4ee5\u4ece\u4e0b\u6807\u4e2d\u5220\u9664\u6a21\u6570\u5217\u8868\u3002\u5728\u672c\u7ae0\u7684\u8bb8\u591a\u793a\u4f8b\u4e2d\uff0c\u5047\u8bbe\u4e86\u4ee5\u4e0b RNS\uff1a</p> <p>RNS ( 8|7|5|3 )      \u7b2c 4 \u7ae0\u7684\u9ed8\u8ba4 RNS</p> <p>The product  M  of the  k  pairwise relatively prime moduli is the number of different representable values in the RNS and is known as its  dynamic range. </p> <p>k \u4e2a\u6210\u5bf9\u4e92\u8d28\u6a21\u7684\u4e58\u79ef M \u662f RNS \u4e2d\u4e0d\u540c\u53ef\u8868\u793a\u503c\u7684\u6570\u91cf\uff0c\u79f0\u4e3a\u5176\u52a8\u6001\u8303\u56f4\u3002</p> \\[ M = m_{k\u22121} \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 m_1 \u00d7 m_0 \\] <p>For example,  M = 8 \u00d7 7 \u00d7 5 \u00d7 3 = 840 is the total number of distinct values that are representable in our chosen 4-modulus RNS. Because of the equality</p> <p>\u4f8b\u5982\uff0c\\(M = 8 \u00d7 7 \u00d7 5 \u00d7 3 = 840\\) \u662f\u6211\u4eec\u9009\u62e9\u7684 4 \u6a21 RNS \u4e2d\u53ef\u8868\u793a\u7684\u4e0d\u540c\u503c\u7684\u603b\u6570\u3002\u56e0\u4e3a\u7b49\u5f0f</p> \\[ \\left \\langle -x \\right \\rangle _{m_i} = \\left \\langle M-x \\right \\rangle _{m_i} \\] <p>the 840 available values can be used to represent numbers 0 through 839, \u2212420 through +419, or any other interval of 840 consecutive integers. In effect, negative numbers are represented using a complement system with the complementation constant  M . </p> <p>840 \u4e2a\u53ef\u7528\u503c\u53ef\u7528\u4e8e\u8868\u793a\u6570\u5b57 0 \u5230 839\u3001-420 \u5230 +419\uff0c\u6216 840 \u4e2a\u8fde\u7eed\u6574\u6570\u7684\u4efb\u4f55\u5176\u4ed6\u533a\u95f4\u3002\u5b9e\u9645\u4e0a\uff0c\u8d1f\u6570\u662f\u4f7f\u7528\u5177\u6709\u8865\u7801\u5e38\u6570 M \u7684\u8865\u7801\u7cfb\u7edf\u6765\u8868\u793a\u7684\u3002</p> <p>Here are some example numbers in RNS ( 8|7|5|3 ):</p> <p>\u4ee5\u4e0b\u662f RNS \u4e2d\u7684\u4e00\u4e9b\u793a\u4f8b\u6570\u5b57 ( 8|7|5|3 )\uff1a</p> <pre><code>( 0 | 0 | 0 | 0 ) RNS \u4ee3\u88680\u6216840\u6216\u00b7\u00b7\u00b7\u00b7\n( 1 | 1 | 1 | 1 ) RNS \u4ee3\u88681\u6216841\u6216\u00b7\u00b7\u00b7\u00b7\n( 2 | 2 | 2 | 2 ) RNS \u4ee3\u88682\u6216842\u6216\u00b7\u00b7\u00b7\u00b7\n( 0 | 1 | 3 | 2 ) RNS \u4ee3\u88688\u6216848\u6216\u00b7\u00b7\u00b7\u00b7\n( 5 | 0 | 1 | 0 ) RNS \u4ee3\u886821\u6216861\u6216\u00b7\u00b7\u00b7\u00b7\n( 0 | 1 | 4 | 1 ) RNS \u4ee3\u886864\u6216904\u6216\u00b7\u00b7\u00b7\u00b7\n( 2 | 0 | 0 | 2 ) RNS \u4ee3\u8868\u221270\u6216770\u6216\u00b7\u00b7\u00b7\u00b7\n( 7 | 6 | 4 | 2 ) RNS \u4ee3\u8868\u22121\u6216839\u6216\u00b7\u00b7\u00b7\u00b7\n</code></pre> <p>Given the RNS representation of  x, the representation of \u2212 x  can be found by complementing each of the digits  xi  with respect to its modules  mi (0 digits are left unchanged). </p> <p>\u7ed9\u5b9a x \u7684 RNS \u8868\u793a\uff0c\u2212 x \u7684\u8868\u793a\u53ef\u4ee5\u901a\u8fc7\u5bf9\u6bcf\u4e2a\u6570\u5b57 xi \u76f8\u5bf9\u4e8e\u5176\u6a21\u5757 mi \u6c42\u8865\u6765\u627e\u5230\uff080 \u4f4d\u4fdd\u6301\u4e0d\u53d8\uff09\u3002</p> <p>Thus, given that 21 =  ( 5 | 0 | 1 | 0 ) RNS, we find</p> <p>\u56e0\u6b64\uff0c\u5047\u8bbe 21 = ( 5 | 0 | 1 | 0 ) RNS\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230</p> \\[ \u221221 = ( 8 \u2212 5 | 0 | 5 \u2212 1 | 0 )_{RNS} = ( 3 | 0 | 4 | 0 )_{RNS} \\] <p>Any RNS can be viewed as a weighted representation. We will present a general method for determining the position weights (the Chinese remainder theorem) in Section 4.3. For RNS ( 8|7|5|3 ), the weights associated with the four positions are</p> <p>\u4efb\u4f55 RNS \u90fd\u53ef\u4ee5\u88ab\u89c6\u4e3a\u52a0\u6743\u8868\u793a\u3002\u6211\u4eec\u5c06\u5728 4.3 \u8282\u4e2d\u63d0\u51fa\u786e\u5b9a\u4f4d\u7f6e\u6743\u91cd\u7684\u901a\u7528\u65b9\u6cd5\uff08\u4e2d\u56fd\u5269\u4f59\u5b9a\u7406\uff09\u3002\u5bf9\u4e8e RNS ( 8|7|5|3 )\uff0c\u4e0e\u56db\u4e2a\u4f4d\u7f6e\u76f8\u5173\u7684\u6743\u91cd\u4e3a </p> <p>\u200b          105     120    336    280</p> <p>As an example,  ( 1 | 2 | 4 | 0 ) RNS represents the number</p> <p>\u4f8b\u5982\uff0c( 1 | 2 | 4 | 0 ) RNS \u4ee3\u8868\u6570\u5b57</p> \\[ \\left \\langle (105\u00d71)+(120\u00d72)+(336\u00d74)+(280\u00d70) \\right \\rangle _{840}=\\left \\langle 1689 \\right \\rangle _{840}=9 \\] <p>In practice, each residue must be represented or encoded in binary. For our example RNS, such a representation would require 11 bits (Fig. 4.1). To determine the number representation efficiency of our 4-modulus RNS, we note that 840 different values are being represented using 11 bits, compared with 2048 values possible with binary representation. Thus, the representational efficiency is</p> <p>\u5b9e\u9645\u4e0a\uff0c\u6bcf\u4e2a\u4f59\u6570\u5fc5\u987b\u4ee5\u4e8c\u8fdb\u5236\u8868\u793a\u6216\u7f16\u7801\u3002\u5bf9\u4e8e\u6211\u4eec\u7684\u793a\u4f8b RNS\uff0c\u8fd9\u6837\u7684\u8868\u793a\u9700\u8981 11 \u4f4d\uff08\u56fe 4.1\uff09\u3002\u4e3a\u4e86\u786e\u5b9a 4 \u6a21 RNS \u7684\u6570\u5b57\u8868\u793a\u6548\u7387\uff0c\u6211\u4eec\u6ce8\u610f\u5230\u4f7f\u7528 11 \u4f4d\u8868\u793a\u4e86 840 \u4e2a\u4e0d\u540c\u7684\u503c\uff0c\u800c\u4e8c\u8fdb\u5236\u8868\u793a\u53ef\u80fd\u8868\u793a 2048 \u4e2a\u503c\u3002\u56e0\u6b64\uff0c\u8868\u5f81\u6548\u7387\u4e3a \\(840 / 2048 = 41\\%\\)</p> <p>Since log2 840 = 9.714, another way to quantify the representational efficiency is to note that in our example RNS, about 1.3 bits of the 11 bits go to waste. </p> <p>\u7531\u4e8e \\(\\log_2 840 = 9.714\\)\uff0c\u91cf\u5316\u8868\u793a\u6548\u7387\u7684\u53e6\u4e00\u79cd\u65b9\u6cd5\u662f, \u672c\u4f8b\u4e2d\uff0c11 \u4f4d\u4e2d\u5927\u7ea6\u6709 1.3 \u4f4d\u88ab\u6d6a\u8d39\u4e86\u3002</p> <p></p> <p>\u56fe 4.1 RNS ( 8 | 7 | 5 | 3 ) \u7684\u4e8c\u8fdb\u5236\u7f16\u7801\u6570\u5b57\u683c\u5f0f </p> <p>As noted earlier, the sign of an RNS number can be changed by independently complementing each of its digits with respect to its modulus. Similarly, addition, subtraction, and multiplication can be performed by independently operating on each digit. The following examples for RNS ( 8 | 7 | 5 | 3 )  illustrate the process:</p> <p>\u5982\u524d\u6240\u8ff0\uff0cRNS \u7f16\u53f7\u7684\u7b26\u53f7\u53ef\u4ee5\u901a\u8fc7\u72ec\u7acb\u66f4\u6539\u5bf9\u6bcf\u4e2a\u6570\u5b57\u7684\u6a21\u6570\u6c42\u8865\u3002\u7c7b\u4f3c\u5730\uff0c\u52a0\u6cd5\u3001\u51cf\u6cd5\u548c\u4e58\u6cd5\u53ef\u4ee5\u901a\u8fc7\u5bf9\u6bcf\u4e2a\u6570\u5b57\u8fdb\u884c\u72ec\u7acb\u8fd0\u7b97\u6765\u8fdb\u884c\u3002\u4ee5\u4e0b RNS ( 8 | 7 | 5 | 3 ) \u793a\u4f8b\u8bf4\u660e\u4e86\u8be5\u8fc7\u7a0b\uff1a </p> <pre><code>( 5 | 5 | 0 | 2 ) RNS    \u4ee3\u8868x=+5\n( 7 | 6 | 4 | 2 ) RNS    \u8868\u793a y = \u22121\n( 4 | 4 | 4 | 1 ) RNS    x + y\uff1a(5 + 7) mod 8 = 4\u3001(5 + 6) mod 7 = 4 \u7b49\u3002\n( 6 | 6 | 1 | 0 ) RNS    x \u2212 y\uff1a(5 \u2212 7) mod 8 = 6\u3001(5 \u2212 6) mod 7 = 6 \u7b49\u3002\n                        \uff08\u6216\u8005\uff0c\u627e\u5230 -y \u5e76\u52a0\u4e0a x\uff09\n( 3 | 2 | 0 | 1 ) RNS    x \u00d7 y\uff1a5 \u00d7 78 = 3\u30015 \u00d7 67 = 2 \u7b49\u3002\n</code></pre> <p>Figure 4.2 depicts the structure of an adder, subtractor, or multiplier for RNS arithmetic. Since each digit is a relatively small number, these operations can be quite fast and simple in RNS. This speed and simplicity are the primary advantages of RNS arithmetic. In the case of addition, for example, carry propagation is limited to within a single residue (a few bits). Thus, RNS representation pretty much solves the carry-propagation problem. As for multiplication, a 4 \u00d7 4 multiplier for example is considerably more than four times simpler than a 16 \u00d7 16 multiplier, besides being much faster. In fact, since the residues are small (say, 6 bits wide), it is quite feasible to implement addition, subtraction, and multiplication by direct table lookup. With 6-bit residues, say, each operation requires a 4K \u00d7 6 table. Thus, excluding division, a complete arithmetic unit module for one 6-bit residue can be implemented with 9 KB of memory. </p> <p>\u56fe 4.2 \u63cf\u8ff0\u4e86 RNS \u7b97\u672f\u7684\u52a0\u6cd5\u5668\u3001\u51cf\u6cd5\u5668\u6216\u4e58\u6cd5\u5668\u7684\u7ed3\u6784\u3002\u7531\u4e8e\u6bcf\u4e2a\u6570\u5b57\u90fd\u662f\u4e00\u4e2a\u76f8\u5bf9\u8f83\u5c0f\u7684\u6570\u5b57\uff0c\u56e0\u6b64\u8fd9\u4e9b\u64cd\u4f5c\u5728 RNS \u4e2d\u53ef\u4ee5\u975e\u5e38\u5feb\u901f\u4e14\u7b80\u5355\u3002\u8fd9\u79cd\u901f\u5ea6\u548c\u7b80\u5355\u6027\u662f RNS \u7b97\u6cd5\u7684\u4e3b\u8981\u4f18\u70b9\u3002\u4f8b\u5982\uff0c\u5728\u52a0\u6cd5\u7684\u60c5\u51b5\u4e0b\uff0c\u8fdb\u4f4d\u4f20\u64ad\u4ec5\u9650\u4e8e\u5355\u4e2a\u4f59\u6570\uff08\u4e00\u4e9b\u6bd4\u7279\u4f4d\uff09\u3002\u56e0\u6b64\uff0cRNS \u8868\u793a\u51e0\u4e4e\u89e3\u51b3\u4e86\u8fdb\u4f4d\u4f20\u64ad\u95ee\u9898\u3002\u81f3\u4e8e\u4e58\u6cd5\uff0c\u4f8b\u5982 4 \u00d7 4 \u4e58\u6cd5\u5668\u6bd4 16 \u00d7 16 \u4e58\u6cd5\u5668\u7b80\u5355\u56db\u500d\u591a\uff0c\u800c\u4e14\u901f\u5ea6\u66f4\u5feb\u3002\u4e8b\u5b9e\u4e0a\uff0c\u7531\u4e8e\u4f59\u6570\u5f88\u5c0f\uff08\u6bd4\u59826\u4f4d\u5bbd\uff09\uff0c\u901a\u8fc7\u76f4\u63a5\u67e5\u8868\u6765\u5b9e\u73b0\u52a0\u6cd5\u3001\u51cf\u6cd5\u548c\u4e58\u6cd5\u662f\u76f8\u5f53\u53ef\u884c\u7684\u3002\u4f8b\u5982\uff0c\u5bf9\u4e8e 6 \u4f4d\u4f59\u6570\uff0c\u6bcf\u4e2a\u64cd\u4f5c\u90fd\u9700\u8981\u4e00\u4e2a 4K \u00d7 6 \u8868\u3002\u56e0\u6b64\uff0c\u9664\u4e86\u9664\u6cd5\u4e4b\u5916\uff0c\u4e00\u4e2a 6 \u4f4d\u4f59\u6570\u7684\u5b8c\u6574\u7b97\u672f\u5355\u5143\u6a21\u5757\u53ef\u4ee5\u7528 9 KB \u7684\u5185\u5b58\u6765\u5b9e\u73b0\u3002</p> <p></p> <p>Unfortunately, however, what we gain in terms of the speed and simplicity of addition, subtraction, and multiplication can be more than nullified by the complexity of division and the difficulty of certain auxiliary operations such as sign test, magnitude comparison, and overflow detection. Given the numbers</p> <p>\u7136\u800c\u4e0d\u5e78\u7684\u662f\uff0c\u6211\u4eec\u5728\u52a0\u6cd5\u3001\u51cf\u6cd5\u548c\u4e58\u6cd5\u7684\u901f\u5ea6\u548c\u7b80\u5355\u6027\u65b9\u9762\u6240\u83b7\u5f97\u7684\u6210\u679c\u53ef\u80fd\u4f1a\u88ab\u9664\u6cd5\u7684\u590d\u6742\u6027\u548c\u67d0\u4e9b\u8f85\u52a9\u64cd\u4f5c\uff08\u4f8b\u5982\u7b26\u53f7\u6d4b\u8bd5\u3001\u5e45\u5ea6\u6bd4\u8f83\u548c\u6ea2\u51fa\u68c0\u6d4b\uff09\u7684\u96be\u5ea6\u6240\u62b5\u6d88\u3002\u5bf9\u4e8e\u4e0b\u9762\u4e24\u4e2a\u6570\u5b57</p> <p>\u200b      ( 7 | 2 | 2 | 1 ) RNS   \u548c   ( 2 | 5 | 0 | 1 ) RNS</p> <p>we cannot easily tell their signs, determine which of the two is larger, or find out whether ( 1 | 0 | 2 | 2 ) RNS represents their true sum as opposed to the residue of their sum modulo 840. </p> <p>\u6211\u4eec\u65e0\u6cd5\u8f7b\u6613\u8fa8\u522b\u5b83\u4eec\u7684\u7b26\u53f7\uff0c\u786e\u5b9a\u4e24\u8005\u4e2d\u54ea\u4e00\u4e2a\u66f4\u5927\uff0c\u6216\u8005\u627e\u51fa ( 1 | 0 | 2 | 2 ) RNS \u662f\u5426\u4ee3\u8868\u5b83\u4eec\u7684\u771f\u5b9e\u548c\uff0c\u800c\u4e0d\u662f\u5b83\u4eec\u6a21 840 \u7684\u548c\u7684\u4f59\u6570\u3002</p> <p>These difficulties have thus far limited the application of RNS representations to certain signal processing problems in which additions and multiplications are used either exclusively or predominantly and the results are within known ranges (e.g., digital filters, Fourier transforms). We discuss division and other \u201cdifficult\u201d RNS operations in Section 4.4. </p> <p>\u8fc4\u4eca\u4e3a\u6b62\uff0c\u8fd9\u4e9b\u56f0\u96be\u9650\u5236\u4e86 RNS \u8868\u793a\u5728\u67d0\u4e9b\u4fe1\u53f7\u5904\u7406\u95ee\u9898\u4e2d\u7684\u5e94\u7528\uff0c\u5728\u8fd9\u4e9b\u95ee\u9898\u4e2d\uff0c\u4ec5\u4f7f\u7528\u52a0\u6cd5\u548c\u4e58\u6cd5\uff0c\u6216\u8005\u4e3b\u8981\u4f7f\u7528\u52a0\u6cd5\u548c\u4e58\u6cd5\uff0c\u5e76\u4e14\u7ed3\u679c\u5728\u5df2\u77e5\u8303\u56f4\u5185\uff08\u4f8b\u5982\uff0c\u6570\u5b57\u6ee4\u6ce2\u5668\u3001\u5085\u7acb\u53f6\u53d8\u6362\uff09\u3002\u6211\u4eec\u5728 4.4 \u8282\u4e2d\u8ba8\u8bba\u9664\u6cd5\u548c\u5176\u4ed6\u201c\u56f0\u96be\u201d\u7684 RNS \u64cd\u4f5c\u3002</p>"},{"location":"Part_01/04/#42-rns","title":"4.2 \u9009\u62e9 RNS \u6a21\u6570","text":"<p>The set of the moduli chosen for RNS affects both the representational efficiency and the complexity of arithmetic algorithms. In general, we try to make the moduli as small as possible, since it is the magnitude of the largest modulus  mk\u22121 that dictates the speed of arithmetic operations. We also often try to make all the moduli comparable in magnitude to the largest one, since with the computation speed already dictated by  mk\u22121, there is usually no advantage in fragmenting the design of Fig. 4.2 through the use of very small moduli at the right end. </p> <p>\u4e3a RNS \u9009\u62e9\u7684\u6a21\u96c6\u4f1a\u5f71\u54cd\u7b97\u672f\u7b97\u6cd5\u7684\u8868\u793a\u6548\u7387\u548c\u590d\u6742\u6027\u3002\u4e00\u822c\u6765\u8bf4\u6211\u4eec\u5c1d\u8bd5\u4f7f\u6a21\u91cf\u5c3d\u53ef\u80fd\u5c0f\uff0c\u8fd9\u662f\u53ef\u80fd\u7684\uff0c\u56e0\u4e3a\u6700\u5927\u6a21 \\(m_{k\u22121}\\) \u7684\u5927\u5c0f\u51b3\u5b9a\u4e86\u7b97\u672f\u8fd0\u7b97\u7684\u901f\u5ea6\u3002\u6211\u4eec\u8fd8\u7ecf\u5e38\u5c1d\u8bd5\u4f7f\u6240\u6709\u6a21\u6570\u5728\u5927\u5c0f\u4e0a\u4e0e\u6700\u5927\u6a21\u6570\u76f8\u5f53\uff0c\u56e0\u4e3a\u8ba1\u7b97\u901f\u5ea6\u5df2\u7ecf\u7531 \\(m_{k\u22121}\\)\u51b3\u5b9a\uff0c\u901a\u8fc7\u5728\u53f3\u7aef\u4f7f\u7528\u975e\u5e38\u5c0f\u7684\u6a21\u6570\u6765\u5206\u5272\u56fe 4.2 \u7684\u8bbe\u8ba1\u901a\u5e38\u6ca1\u6709\u4f18\u52bf\u3002</p> <p>We illustrate the process of selecting the RNS moduli through an example. Let us assume that we want to represent unsigned integers in the range 0 to (100 000)ten, requiring 17 bits with unsigned binary representation. </p> <p>\u6211\u4eec\u901a\u8fc7\u4e00\u4e2a\u4f8b\u5b50\u6765\u8bf4\u660e\u9009\u62e9 RNS \u6a21\u6570\u7684\u8fc7\u7a0b\u3002\u8ba9\u6211\u4eec\u5047\u8bbe\u6211\u4eec\u60f3\u8981\u8868\u793a 0 \u5230 \\((100 000)_{10}\\) \u8303\u56f4\u5185\u7684\u65e0\u7b26\u53f7\u6574\u6570\uff0c\u9700\u8981 17 \u4f4d\u65e0\u7b26\u53f7\u4e8c\u8fdb\u5236\u8868\u793a\u3002</p> <p>A simple strategy is to pick prime numbers in sequence until the dynamic range  M becomes adequate. Thus, we pick  m 0 = 2,  m 1 = 3,  m 2 = 5, etc. After we add  m 5 = 13 to our list, the dynamic range becomes</p> <p>\u4e00\u4e2a\u7b80\u5355\u7684\u7b56\u7565\u662f\u4f9d\u6b21\u9009\u62e9\u7d20\u6570\uff0c\u76f4\u5230\u52a8\u6001\u8303\u56f4M\u53d8\u5f97\u8db3\u591f\u4e86\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u9009\u62e9 \\(m_0 = 2\\)\u3001\\(m_1 = 3\\)\u3001\\(m_2 = 5\\) \u7b49\u7b49\u3002\u5f53\u6dfb\u52a0\u5230 \\(m_5 = 13\\) \u540e\u5bf9\u4e8e\u6211\u4eec\u7684\u5217\u8868\uff0c\u52a8\u6001\u8303\u56f4\u53d8\u4e3a</p> <p>\u200b        RNS ( 13 | 11 | 7 | 5 | 3 | 2 )           M  = 30 030</p> <p>This range is not yet adequate, so we add  m 6 = 17 to the list:</p> <p>\u8fd9\u4e2a\u8303\u56f4\u8fd8\u4e0d\u591f\uff0c\u6240\u4ee5\u6211\u4eec\u5c06 m 6 = 17 \u6dfb\u52a0\u5230\u5217\u8868\u4e2d\uff1a</p> <p>\u200b        RNS ( 17 | 13 | 11 | 7 | 5 | 3 | 2 )    M = 510 510</p> <p>The dynamic range is now 5.1 times as large as needed, so we can remove the modulus 5 and still have adequate range:</p> <p>\u52a8\u6001\u8303\u56f4\u73b0\u5728\u662f\u6240\u9700\u7684 5.1 \u500d\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u5220\u9664\u6a21\u6570 5 \u5e76\u4e14\u4ecd\u7136\u6709\u8db3\u591f\u7684\u8303\u56f4\uff1a</p> <p>\u200b        RNS(17 | 13 | 11 | 7 | 3 | 2)             M = 102 102</p> <p>With binary encoding of the six residues, the number of bits needed for encoding each number is</p> <p>\u901a\u8fc7\u5bf9\u516d\u4e2a\u4f59\u6570\u8fdb\u884c\u4e8c\u8fdb\u5236\u7f16\u7801\uff0c\u5bf9\u6bcf\u4e2a\u6570\u5b57\u8fdb\u884c\u7f16\u7801\u6240\u9700\u7684\u4f4d\u6570\u4e3a</p> <p>\u200b        5 + 4 + 4 + 3 + 2 + 1 = 19 \u4f4d</p> <p>Now, since the speed of arithmetic operations is dictated by the 5-bit residues modulo m 5, we can combine the pairs of moduli 2 and 13, and 3 and 7, with no speed penalty. This leads to:</p> <p>\u73b0\u5728\uff0c\u7531\u4e8e\u7b97\u672f\u8fd0\u7b97\u7684\u901f\u5ea6\u7531\u6a21 \\(m_5\\) \u7684 5 \u4f4d\u4f59\u6570\u51b3\u5b9a\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u7ec4\u5408\u6a21 2 \u548c 13\u3001\u6a21 3 \u548c 7 \u7684\u5bf9\uff0c\u800c\u4e0d\u4f1a\u5f71\u54cd\u901f\u5ea6\u3002\u8fd9\u5bfc\u81f4\uff1a</p> <p>\u200b         RNS ( 26 | 21 | 17 | 11 )                 M = 102 102</p> <p>This alternative RNS still needs 5 + 5 + 5 + 4 = 19 bits per operand, but has two fewer modules in the arithmetic unit. </p> <p>\u6b64\u66ff\u4ee3 RNS \u6bcf\u4e2a\u64cd\u4f5c\u6570\u4ecd\u9700\u8981 5 + 5 + 5 + 4 = 19 \u4f4d\uff0c\u4f46\u7b97\u672f\u5355\u5143\u4e2d\u7684\u6a21\u5757\u5c11\u4e86\u4e24\u4e2a\u3002</p> <p>Better results can be obtained if we proceed as above, but include powers of smaller primes before moving to larger primes. The chosen moduli will still be pairwise relatively prime, since powers of any two prime numbers are relatively prime. For example, after including  m 0 = 2 and  m 1 = 3 in our list of moduli, we note that 22 is smaller than the next prime 5. So we modify  m 0 and  m 1 to get</p> <p>\u5982\u679c\u6211\u4eec\u6309\u7167\u4e0a\u8ff0\u6b65\u9aa4\u8fdb\u884c\uff0c\u4f46\u5728\u8f6c\u5411\u8f83\u5927\u7d20\u6570\u4e4b\u524d\u5148\u5305\u62ec\u8f83\u5c0f\u7d20\u6570\u7684\u5e42\uff0c\u53ef\u4ee5\u83b7\u5f97\u66f4\u597d\u7684\u7ed3\u679c\u3002\u6240\u9009\u62e9\u7684\u6a21\u6570\u4ecd\u5c06\u662f\u6210\u5bf9\u4e92\u8d28\u7684\uff0c\u56e0\u4e3a\u4efb\u4f55\u4e24\u4e2a\u7d20\u6570\u7684\u5e42\u90fd\u662f\u4e92\u8d28\u7684\u3002\u4f8b\u5982\uff0c\u5728\u6a21\u6570\u5217\u8868\u4e2d\u5305\u542b \\(m_0 = 2\\) \u548c \\(m_1 = 3\\) \u540e\uff0c\u6211\u4eec\u6ce8\u610f\u5230 \\(2^2\\) \u5c0f\u4e8e\u4e0b\u4e00\u4e2a\u7d20\u6570 5\u3002\u56e0\u6b64\u6211\u4eec\u4fee\u6539 \\(m_0\\) \u548c \\(m_1\\) \u4ee5\u83b7\u5f97</p> <p>\u200b         RNS ( 22 | 3 )                                   M = 12</p> <p>This strategy is consistent with our desire to minimize the magnitude of the largest modulus. Similarly, after we have included  m 2 = 5 and  m 3 = 7, we note that both 23 and 32 are smaller than the next prime 11. So the next three steps lead to</p> <p>\u8be5\u7b56\u7565\u4e0e\u6211\u4eec\u6700\u5c0f\u5316\u6700\u5927\u6a21\u91cf\u7684\u613f\u671b\u662f\u4e00\u81f4\u7684\u3002\u7c7b\u4f3c\u5730\uff0c\u5728\u6211\u4eec\u5305\u542b \\(m_2 = 5\\) \u548c \\(m_3 = 7\\) \u540e\uff0c\u6211\u4eec\u6ce8\u610f\u5230 \\(2^3\\)</p> <p>\u548c \\(3^2\\) \u6bd4\u4e0b\u4e00\u4e2a\u7d20\u6570 11 \u5c0f\u3002\u6240\u4ee5\u63a5\u4e0b\u6765\u7684\u4e09\u4e2a\u6b65\u9aa4\u5bfc\u81f4</p> <p>\u200b       RNS ( 32 | 23 | 7 | 5 )                      M = 2520</p> <p>\u200b       RNS ( 11 | 32 | 23 | 7 | 5 )             M = 27 720</p> <p>\u200b       RNS ( 13 | 11 | 32 | 23 | 7 | 5 )    M = 360 360</p> <p>The dynamic range is now 3.6 times as large as needed, so we can replace the modulus 9 with 3 and then combine the pair 5 and 3 to obtain</p> <p>\u73b0\u5728\u52a8\u6001\u8303\u56f4\u662f\u6240\u9700\u7684 3.6 \u500d\uff0c\u56e0\u6b64\u6211\u4eec\u53ef\u4ee5\u5c06\u6a21\u6570 9 \u66ff\u6362\u4e3a 3\uff0c\u7136\u540e\u5c06 5 \u548c 3 \u7ec4\u5408\u8d77\u6765\u5f97\u5230</p> <p>\u200b       RNS ( 15 | 13 | 11 | 23 | 7 )          M = 120 120</p> <p>The number of bits needed by this last RNS is</p> <p>\u6700\u540e\u4e00\u4e2a RNS \u6240\u9700\u7684\u4f4d\u6570\u4e3a</p> <p>\u200b       4 + 4 + 4 + 3 + 3 = 18 \u4f4d</p> <p>which is better than our earlier result of 19 bits. The speed has also improved because the largest residue is now 4 bits wide instead of 5. Other variations are possible. For example, given the simplicity of operations with power-of-2 moduli, we might want to backtrack and maximize the size of our even modulus within the 4-bit residue limit</p> <p>\u8fd9\u6bd4\u6211\u4eec\u4e4b\u524d\u7684 19 \u4f4d\u7ed3\u679c\u8981\u597d\u3002\u901f\u5ea6\u4e5f\u5f97\u5230\u4e86\u63d0\u9ad8\uff0c\u56e0\u4e3a\u6700\u5927\u4f59\u6570\u73b0\u5728\u662f 4 \u4f4d\u5bbd\uff0c\u800c\u4e0d\u662f 5 \u4f4d\u3002\u5176\u4ed6\u53d8\u5316\u4e5f\u662f\u53ef\u80fd\u7684\u3002\u4f8b\u5982\uff0c\u8003\u8651\u5230 2 \u6b21\u5e42\u6a21\u8fd0\u7b97\u7684\u7b80\u5355\u6027\uff0c\u6211\u4eec\u53ef\u80fd\u5e0c\u671b\u5728 4 \u4f4d\u4f59\u6570\u9650\u5236\u5185\u56de\u6eaf\u5e76\u6700\u5927\u5316\u5076\u6570\u6a21\u7684\u5927\u5c0f</p> <p>\u200b        RNS ( 24 | 13 | 11 | 32 | 7 | 5 )    M = 720 720</p> <p>We can now remove 5 or 7 from the list of moduli, but the resulting RNS is in fact inferior to RNS(15|13|11|23|7). This might not be the case with other examples; thus, once we have converged on a feasible set of moduli, we should experiment with other sets that can be derived from it by increasing the power of the even modulus at hand. </p> <p>\u6211\u4eec\u73b0\u5728\u53ef\u4ee5\u4ece\u6a21\u6570\u5217\u8868\u4e2d\u5220\u9664 5 \u6216 7\uff0c\u4f46\u751f\u6210\u7684 RNS \u5b9e\u9645\u4e0a\u4e0d\u5982 RNS(15|13|11|23|7)\u3002\u5176\u4ed6\u793a\u4f8b\u53ef\u80fd\u5e76\u975e\u5982\u6b64\uff1b\u56e0\u6b64\uff0c\u4e00\u65e6\u6211\u4eec\u6536\u655b\u5230\u4e00\u7ec4\u53ef\u884c\u7684\u6a21\u6570\uff0c\u6211\u4eec\u5e94\u8be5\u5c1d\u8bd5 \u901a\u8fc7\u589e\u52a0\u73b0\u6709\u5076\u6a21\u6570\u7684\u5e42\uff0c\u5e76\u4f7f\u7528\u53ef\u4ee5\u4ece\u4e2d\u5bfc\u51fa\u7684\u5176\u4ed6\u96c6\u5408\u3002</p> <p>The preceding strategy for selecting the RNS moduli is guaranteed to lead to the smallest possible number of bits for the largest modulus, thus maximizing the speed of RNS arithmetic. However, speed and cost do not just depend on the widths of the residues but also on the moduli chosen. For example, we have already noted that power-of-2 moduli simplify the required arithmetic operations, so that the modulus 16 might be better than the smaller modulus 13 (except, perhaps, with table-lookup implementation). Moduli of the form 2 a \u2212 1 are also desirable and are referred to as low-cost moduli [Merr64], [Parh76]. From our discussion of addition of 1\u2019s-complement numbers in Section 2.4, we know that addition modulo 2 a \u2212 1 can be performed using a standard a-bit binary adder with end-around carry. </p> <p>\u4e0a\u8ff0\u9009\u62e9RNS\u6a21\u6570\u7684\u7b56\u7565\u4fdd\u8bc1\u4e86\u6700\u5927\u6a21\u6570\u7684\u5c3d\u53ef\u80fd\u5c11\u7684\u4f4d\u6570\uff0c\u4ece\u800c\u6700\u5927\u5316RNS\u7b97\u6cd5\u7684\u901f\u5ea6\u3002\u7136\u800c\uff0c\u901f\u5ea6\u548c\u6210\u672c\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u4f59\u6570\u7684\u5bbd\u5ea6\uff0c\u8fd8\u53d6\u51b3\u4e8e\u6240\u9009\u62e9\u7684\u6a21\u91cf\u3002\u4f8b\u5982\uff0c\u6211\u4eec\u5df2\u7ecf\u6ce8\u610f\u5230\uff0c2 \u7684\u5e42\u6a21\u7b80\u5316\u4e86\u6240\u9700\u7684\u7b97\u672f\u8fd0\u7b97\uff0c\u56e0\u6b64\u6a21 16 \u53ef\u80fd\u6bd4\u8f83\u5c0f\u7684\u6a21 13 \u66f4\u597d\uff08\u4e5f\u8bb8\u9664\u4e86\u67e5\u8868\u5b9e\u73b0\u4e4b\u5916\uff09\u3002\\(2^a \u2212 1\\) \u5f62\u5f0f\u7684\u6a21\u6570\u4e5f\u662f\u7406\u60f3\u7684\uff0c\u88ab\u79f0\u4e3a\u4f4e\u6210\u672c\u6a21\u6570[Merr64]\uff0c[Parh76]\u3002\u4ece\u6211\u4eec\u5728\u7b2c 2.4 \u8282\u4e2d\u5bf9 1 \u8865\u7801\u7684\u52a0\u6cd5\u7684\u8ba8\u8bba\u4e2d\uff0c\u6211\u4eec\u77e5\u9053\u6a21 \\(2^a \u2212 1\\) \u7684\u52a0\u6cd5\u53ef\u4ee5\u4f7f\u7528\u5e26\u5c3e\u90e8\u8fdb\u4f4d\u7684\u6807\u51c6 a \u4f4d\u4e8c\u8fdb\u5236\u52a0\u6cd5\u5668\u6765\u6267\u884c\u3002</p> <p>Hence, we are motivated to restrict the moduli to a power of 2 and odd numbers of the form 2 a \u2212 1. One can prove (left as exercise) that the numbers 2 a \u2212 1 and 2 b \u2212 1 are relatively prime if and only if  a  and  b  are relatively prime. Thus, any list of relatively prime numbers  ak\u22122  &gt; \u00b7 \u00b7 \u00b7  &gt; a 1  &gt; a 0 can be the basis of the following  k-modulus RNS</p> <p>\u56e0\u6b64\uff0c\u6211\u4eec\u6709\u52a8\u673a\u5c06\u6a21\u9650\u5236\u4e3a 2 \u7684\u5e42\u548c \\(2^a \u2212 1\\) \u5f62\u5f0f\u7684\u5947\u6570\u3002\u53ef\u4ee5\u8bc1\u660e\uff08\u7559\u4f5c\u7ec3\u4e60\uff09\u6570\u5b57 \\(2^a \u2212 1\\) \u548c \\(2^b \u2212 1\\) \u4e92\u8d28\u5f53\u4e14\u4ec5\u5f53 a \u548c b \u4e92\u8d28\u3002\u56e0\u6b64\uff0c\u4efb\u4f55\u76f8\u5bf9\u8d28\u6570\u7684\u5217\u8868 \\(a_{k\u22122} &gt; \u00b7 \u00b7 \u00b7 &gt; a_1 &gt; a_0\\) \u90fd\u53ef\u4ee5\u4f5c\u4e3a\u4ee5\u4e0b k \u6a21 RNS \u7684\u57fa\u7840</p> <p>\u200b        \\(RNS ( 2^{a_{k\u22122}} | 2^{a_{k\u22122}} \u2212 1 | \u00b7 \u00b7 \u00b7 | 2^{a_1} \u2212 1 | 2^{a_0} \u2212 1 )\\)</p> <p>for which the widest residues are  ak\u22122-bit numbers. Note that to maximize the dynamic range with a given residue width, the even modulus is chosen to be as large as possible. </p> <p>\u5176\u4e2d\u6700\u5bbd\u7684\u4f59\u6570\u662f \\(a_{k\u22122}\\) \u4f4d\u6570\u5b57\u3002\u8bf7\u6ce8\u610f\uff0c\u4e3a\u4e86\u6700\u5927\u5316\u7ed9\u5b9a\u4f59\u6570\u5bbd\u5ea6\u7684\u52a8\u6001\u8303\u56f4\uff0c\u5076\u6570\u6a21\u91cf\u88ab\u9009\u62e9\u4e3a\u5c3d\u53ef\u80fd\u5927\u3002</p> <p>Applying this strategy to our desired RNS with the target range [0, 100 000], leads to the following steps:</p> <p>\u5c06\u6b64\u7b56\u7565\u5e94\u7528\u4e8e\u6211\u4eec\u6240\u9700\u7684\u76ee\u6807\u8303\u56f4\u4e3a [0, 100 000] \u7684 RNS\uff0c\u5c06\u5bfc\u81f4\u4ee5\u4e0b\u6b65\u9aa4\uff1a</p> <ul> <li>\\(RNS (2^3 | 2^3 \u2212 1 | 2^2 \u2212 1)\\) Basis: 3, 2                      M =        168</li> <li>\\(RNS (2^4 | 2^4 \u2212 1 | 2^3 \u2212 1)\\) Basis: 4, 3                      M =      1680</li> <li>\\(RNS (2^5 | 2^5 \u2212 1 | 2^3 \u2212 1 | 2^2 \u2212 1)\\) Basis: 5, 3, 2     M =   20 832</li> <li>\\(RNS (2^5 | 2^5 \u2212 1 | 2^4 \u2212 1 | 2^3 \u2212 1)\\) Basis: 5, 4, 3     M = 104 160</li> </ul> <p>This last system, RNS ( 32 | 31 | 15 | 7 ), possesses adequate range. Note that once the number 4 is included in the base list, 2 must be excluded because 4 and 2, and thus 24 \u2212 1 and 22 \u2212 1, are not relatively prime. </p> <p>\u6700\u540e\u4e00\u4e2a\u7cfb\u7edf RNS ( 32 | 31 | 15 | 7 ) \u62e5\u6709\u8db3\u591f\u7684\u8303\u56f4\u3002\u8bf7\u6ce8\u610f\uff0c\u4e00\u65e6\u6570\u5b57 4 \u5305\u542b\u5728\u57fa\u672c\u5217\u8868\u4e2d\uff0c\u5219\u5fc5\u987b\u6392\u9664 2\uff0c\u56e0\u4e3a 4 \u548c 2\uff0c\u4e14 \\(2^4 \u2212 1\\) \u548c \\(2^2 \u2212 1\\) \u4e0d\u662f\u4e92\u8d28\u7684\u3002</p> <p>The derived RNS requires 5 + 5 + 4 + 3 = 17 bits for representing each number, </p> <p>with the largest residues being 5 bits wide. In this case, the representational efficiency is close to 100% and no bit is wasted. In general, the representational efficiency of low-cost RNS is provably better than 50% (yet another exercise!), leading to the waste of no more than 1 bit in number representation. </p> <p>\u5bfc\u51fa\u7684 RNS \u9700\u8981 5 + 5 + 4 + 3 = 17 \u4f4d\u6765\u8868\u793a\u6bcf\u4e2a\u6570\u5b57\uff0c\u6700\u5927\u4f59\u6570\u4e3a 5 \u4f4d\u5bbd\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u8868\u793a\u6548\u7387\u63a5\u8fd1 100%\uff0c\u5e76\u4e14\u6ca1\u6709\u6d6a\u8d39\u4efb\u4f55\u6bd4\u7279\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u4f4e\u6210\u672c RNS \u7684\u8868\u793a\u6548\u7387\u88ab\u8bc1\u660e\u4f18\u4e8e 50%\uff08\u53c8\u4e00\u4e2a\u7ec3\u4e60\uff01\uff09\uff0c\u5bfc\u81f4\u6570\u5b57\u8868\u793a\u4e2d\u4e0d\u8d85\u8fc7 1 \u4f4d\u7684\u6d6a\u8d39\u3002</p> <p>To compare the RNS above to our best result with unrestricted moduli, we list the parameters of the two systems together:</p> <p>\u4e3a\u4e86\u5c06\u4e0a\u9762\u7684 RNS \u4e0e\u6211\u4eec\u4f7f\u7528\u65e0\u9650\u5236\u6a21\u6570\u7684\u6700\u4f73\u7ed3\u679c\u8fdb\u884c\u6bd4\u8f83\uff0c\u6211\u4eec\u5c06\u4e24\u4e2a\u7cfb\u7edf\u7684\u53c2\u6570\u4e00\u8d77\u5217\u51fa\uff1a</p> <ul> <li>RNS \\((15 | 13 | 11 | 2^3 | 7)\\)                        18 bits        M = 120 120</li> <li>RNS \\((2^5 | 2^5 \u2212 1 | 2^4 \u2212 1 | 2^3 \u2212 1|)\\)    17 bits        M = 104 160</li> </ul> <p>Both systems provide the desired range. The latter has wider, but fewer, residues. However, the simplicity of arithmetic with low-cost moduli makes the latter a more attractive choice. In general, restricting the moduli tends to increase the width of the largest residues and the optimal choice is dependent on both the application and the target implementation technology. </p> <p>\u4e24\u79cd\u7cfb\u7edf\u90fd\u63d0\u4f9b\u6240\u9700\u7684\u8303\u56f4\u3002\u540e\u8005\u5177\u6709\u66f4\u5bbd\u4f46\u66f4\u5c11\u7684\u4f59\u6570\u3002\u7136\u800c\uff0c\u7b97\u6cd5\u7684\u7b80\u5355\u6027\u548c\u4f4e\u6210\u672c\u6a21\u6570\u4f7f\u540e\u8005\u6210\u4e3a\u66f4\u5177\u5438\u5f15\u529b\u7684\u9009\u62e9\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u9650\u5236\u6a21\u6570\u5f80\u5f80\u4f1a\u589e\u52a0\u6700\u5927\u4f59\u6570\u7684\u5bbd\u5ea6\uff0c\u6700\u4f73\u9009\u62e9\u53d6\u51b3\u4e8e\u5e94\u7528\u548c\u76ee\u6807\u5b9e\u73b0\u6280\u672f\u3002</p>"},{"location":"Part_01/04/#43","title":"4.3 \u6570\u5b57\u7684\u7f16\u7801\u548c\u89e3\u7801","text":"<p>Since input numbers provided from the outside (machine or human interface) are in standard binary or decimal and outputs must be presented in the same way, conversions between binary/decimal and RNS representations are required. </p> <p>\u7531\u4e8e\u4ece\u5916\u90e8\uff08\u673a\u5668\u6216\u4eba\u673a\u754c\u9762\uff09\u63d0\u4f9b\u7684\u8f93\u5165\u6570\u5b57\u662f\u6807\u51c6\u4e8c\u8fdb\u5236\u6216\u5341\u8fdb\u5236\uff0c\u5e76\u4e14\u8f93\u51fa\u5fc5\u987b\u4ee5\u76f8\u540c\u7684\u65b9\u5f0f\u5448\u73b0\uff0c\u56e0\u6b64\u9700\u8981\u4e8c\u8fdb\u5236/\u5341\u8fdb\u5236\u548c RNS \u8868\u793a\u4e4b\u95f4\u7684\u8f6c\u6362\u3002</p>"},{"location":"Part_01/04/#rns","title":"\u4ece\u4e8c\u8fdb\u5236/\u5341\u8fdb\u5236\u5230 RNS \u7684\u8f6c\u6362","text":"<p>The binary-to-RNS conversion problem is stated as follows: Given an integer  y, find its residues with respect to the moduli  mi, 0 \u2264  i \u2264  k \u2212 1. Let us assume that  y  is an unsigned binary integer. Conversion of signed-magnitude or 2\u2019s-complement numbers can be accomplished by converting the magnitude and then complementing the RNS representation if needed. </p> <p>\u4e8c\u8fdb\u5236\u5230 RNS \u7684\u8f6c\u6362\u95ee\u9898\u8868\u8ff0\u5982\u4e0b\uff1a\u7ed9\u5b9a\u4e00\u4e2a\u6574\u6570 y\uff0c\u6c42\u5176\u76f8\u5bf9\u4e8e\u6a21 \\(m_i, 0 \u2264 i \u2264 k \u2212 1\\) \u7684\u4f59\u6570\u3002\u5047\u8bbe y \u662f\u4e00\u4e2a\u65e0\u7b26\u53f7\u4e8c\u8fdb\u5236\u6574\u6570\u3002\u6709\u7b26\u53f7\u6570\u503c\u6216 2 \u8865\u7801\u7684\u8f6c\u6362\u53ef\u4ee5\u901a\u8fc7\u8f6c\u6362\u5e45\u5ea6\u503c\uff0c\u7136\u540e\u6839\u636e\u9700\u8981\u5bf9 RNS \u6c42\u8865\u6765\u5b8c\u6210\u3002</p> <p>To avoid time-consuming divisions, we take advantage of the following equality:</p> <p>\u4e3a\u4e86\u907f\u514d\u8017\u65f6\u7684\u9664\u6cd5\uff0c\u6211\u4eec\u5229\u7528\u4ee5\u4e0b\u7b49\u5f0f\uff1a </p> <p>$$ \\left \\langle (y_{k-1} \\cdots y_1 y_0)2 \\right \\rangle _{m_i} = \\left \\langle  \\left \\langle 2^{k-1}y \\right \\rangle_{m_i} + \\cdots +  \\left \\langle 2y_1 \\right \\rangle_{m_i} + \\left \\langle y_0 \\right \\rangle_{m_i} \\right \\rangle $$ If we precompute and store 2 j m i  for each  i  and  j, then the residue  x i   of  y (mod  mi ) can be computed by modulo- mi  addition of some of these constants. </p> <p>\u5982\u679c\u6211\u4eec\u4e3a\u6bcf\u4e2a i \u548c j \u9884\u5148\u8ba1\u7b97\u5e76\u5b58\u50a8 \\(\\left \\langle 2^j \\right \\rangle _{m_{i}}\\) \uff0c\u5219y\u7684\u4f59\u6570 \\(x_i\\)    (mod \\(m_i\\) ) \u53ef\u4ee5 \u901a\u8fc7\u5bf9\u4e00\u4e9b\u67e5\u51fa\u5e38\u6570\u7684\u6a21\u52a0\u6cd5\u6765\u8ba1\u7b97\u3002</p> <p>Table 4.1 shows the required lookup table for converting 10-bit binary numbers in the range [0, 839] to RNS(8 | 7 | 5 | 3). Only residues mod 7, mod 5, and mod 3 are given in the table, since the residue mod 8 is directly available as the three least-significant bits of the binary number  y. </p> <p>\u8868 4.1 \u663e\u793a\u4e86\u5c06 [0, 839] \u8303\u56f4\u5185\u7684 10 \u4f4d\u4e8c\u8fdb\u5236\u6570\u8f6c\u6362\u4e3a RNS(8|7|5|3) \u6240\u9700\u7684\u67e5\u627e\u8868\u3002\u8868\u4e2d\u53ea\u7ed9\u51fa\u4e86\u4f59\u6570 mod 7\u3001mod 5 \u548c mod 3\uff0c\u56e0\u4e3a\u4f59\u6570 mod 8 \u53ef\u76f4\u63a5\u7528\u4f5c\u4e8c\u8fdb\u5236\u6570 y \u7684\u4e09\u4e2a\u6700\u4f4e\u6709\u6548\u4f4d\u3002</p> <p></p> <p>EXAMPLE 4.1 Represent  y =  ( 1010 0100 ) two =  ( 164 ) ten in RNS ( 8 | 7 | 5 | 3 ).  The residue of  y  mod 8 is  x 3 =  (y 2 y 1 y 0 ) two =  ( 100 ) two = 4. Since  y = 27 + 25 + 22, the required residues mod 7, mod 5, and mod 3 are obtained by simply adding the values stored in the three rows corresponding to  j = 7, 5, 2 in Table 4.1:</p> <p>\u793a\u4f8b4.1 \u7528\\(RNS (8 | 7 | 5 | 3 )\\) \u8868\u793a\\(y = ( 1010 0100 )_2 = ( 164 )_{10}\\) \u3002</p> <p>y mod 8 \u7684\u4f59\u6570\u4e3a \\(x_3 = (y_2 y_1 y_0 )_2 = (100)_2 = 4\\)\u3002\u7531\u4e8e \\(y = 2^7 + 2^5 + 2^2\\)\uff0c\u53ea\u9700\u5c06\u8868 4.1 \u4e2d j = 7, 5, 2 \u5bf9\u5e94\u7684\u4e09\u884c\u4e2d\u5b58\u50a8\u7684\u503c\u76f8\u52a0\u5373\u53ef\u83b7\u5f97\u6240\u9700\u7684\u4f59\u6570 mod 7\u3001mod 5 \u548c mod 3\uff1a</p> <p>$$ \\begin{array}{c} x_2 = \\left \\langle y \\right \\rangle _7 = \\left \\langle 2 + 4 + 4\\right \\rangle _7 = 3 \\ x_1 = \\left \\langle y \\right \\rangle _5 = \\left \\langle 3 + 2 + 4\\right \\rangle _5 = 4 \\ x_0 = \\left \\langle y \\right \\rangle _3 = \\left \\langle 2 + 2 + 1\\right \\rangle _3 = 2 \\end{array} $$ Therefore, the RNS(8 | 7 | 5 | 3) representation of (164)ten is (4 | 3 | 4 | 2)RNS. </p> <p>\u56e0\u6b64\uff0c\\((164)_{10}\\) \u7684 \\(RNS(8 | 7 | 5 | 3)\\) \u8868\u793a\u4e3a \\((4 | 3 | 4 | 2)_{RNS}\\)\u3002</p> <p>In the worst case,  k  modular additions are required for computing each residue of a k-bit number. To reduce the number of operations, one can view the given input number as a number in a higher radix. For example, if we use radix 4, then storing the residues of 4 i, 2 \u00d7 4 i  and 3 \u00d7 4 i  in a table would allow us to compute each of the required residues using only  k/ 2 modular additions. </p> <p>\u5728\u6700\u574f\u7684\u60c5\u51b5\u4e0b\uff0c\u9700\u8981 k \u4e2a\u6a21\u52a0\u6cd5\u6765\u8ba1\u7b97 k \u4f4d\u6570\u5b57\u7684\u6bcf\u4e2a\u4f59\u6570\u3002\u4e3a\u4e86\u51cf\u5c11\u8fd0\u7b97\u6b21\u6570\uff0c\u53ef\u4ee5\u5c06\u7ed9\u5b9a\u7684\u8f93\u5165\u6570\u5b57\u89c6\u4e3a\u66f4\u9ad8\u57fa\u6570\u7684\u6570\u5b57\u3002\u4f8b\u5982\uff0c\u5982\u679c\u6211\u4eec\u4f7f\u7528\u57fa\u6570 4\uff0c\u90a3\u4e48\u5c06 \\(4^i\u30012 \u00d7 4^i \u548c 3 \u00d7 4^i\\) \u7684\u4f59\u6570\u5b58\u50a8\u5728\u8868\u4e2d\u5c06\u5141\u8bb8\u6211\u4eec\u4ec5\u4f7f\u7528 \\(k/ 2\\) \u6a21\u52a0\u6cd5\u6765\u8ba1\u7b97\u6bcf\u4e2a\u6240\u9700\u7684\u7559\u6570\u3002</p> <p>The conversion for each modulus can be done by repeatedly using a single lookup table and modular adder or by several copies of each arranged into a pipeline. For a low-cost modulus  m = 2 a \u2212 1, the residue can be determined by dividing up  y  into  a-bit segments and adding them modulo 2 a \u2212 1. </p> <p>\u6bcf\u4e2a\u6a21\u6570\u7684\u8f6c\u6362\u53ef\u4ee5\u901a\u8fc7\u91cd\u590d\u4f7f\u7528\u5355\u4e2a\u67e5\u627e\u8868\u548c\u6a21\u52a0\u6cd5\u5668\u6216\u901a\u8fc7\u6392\u5217\u5230\u7ba1\u9053\u4e2d\u7684\u6bcf\u4e2a\u6a21\u6570\u7684\u591a\u4e2a\u526f\u672c\u6765\u5b8c\u6210\u3002\u5bf9\u4e8e\u4f4e\u6210\u672c\u6a21\u6570 \\(m = 2^a \u2212 1\\)\uff0c\u53ef\u4ee5\u901a\u8fc7\u5c06 y \u5206\u6210 a \u4f4d\u6bb5\u5e76\u5c06\u5b83\u4eec\u52a0\u4e0a\u6a21 \\(2^a \u2212 1\\) \u6765\u786e\u5b9a\u4f59\u6570\u3002</p>"},{"location":"Part_01/04/#rns_1","title":"\u4ece RNS \u5230\u6df7\u5408\u57fa\u6570\u5f62\u5f0f\u7684\u8f6c\u6362","text":"<p>Associated with any residue number system RNS (mk\u22121 | \u00b7 \u00b7 \u00b7 | m 2 | m 1 | m 0 ) is a mixed-radix number system MRS (mk\u22121 | \u00b7 \u00b7 \u00b7 | m 2 | m 1 | m 0 ), which is essentially a k-digit positional number system with position weights</p> <p>\u4e0e\u4efb\u4f55\u5269\u4f59\u6570\u6570\u5b57\u7cfb\u7edf RNS \\((m_{k\u22121} | \u00b7 \u00b7 \u00b7 | m_2 | m_1 | m_0 )\\) \u76f8\u5173\u8054\u7684\u662f\u6df7\u5408\u57fa\u6570\u7cfb\u7edf MRS \\((m_{k\u22121} | \u00b7 \u00b7 \u00b7 | m_2 | m_1 | m_0 )\\)\uff0c\u5b83\u672c\u8d28\u4e0a\u662f\u4e00\u4e2ak \u4f4d\u7684\u4f4d\u7f6e\u6570\u5b57\u7cfb\u7edf\uff0c\u5177\u6709\u4f4d\u7f6e\u6743\u91cd\uff1a</p> <p>$$ m_{k\u22122}\\cdots m_2m_1m_0,  \\cdots,   m_2m_1m_0,  m_1m_0,  m_0,  1 $$ and digit sets [0,  mk\u22121 \u2212 1], \u00b7 \u00b7 \u00b7 , [0,  m 2 \u2212 1], [0,  m 1 \u2212 1], and [0,  m 0 \u2212 1] in its  k-digit positions. Hence, the MRS digits are in the same ranges as the RNS digits (residues). For example, the mixed-radix system MRS ( 8 | 7 | 5 | 3 )  has position weights 7 \u00d7 5 \u00d7 3 = 105, 5 \u00d7 3 = 15, 3, and 1, leading to  </p> <p>\u4ee5\u53ca\u5728\u5176 k \u4f4d\u4f4d\u7f6e\u4e0a\u7684\u6570\u5b57\u96c6 [\\(0, m_{k\u22121} \u2212 1\\)]\u3001\u00b7\u00b7\u00b7\u3001[\\(0, m_2 \u2212 1\\)]\u3001[\\(0, m_1 \u2212 1\\)] \u548c [\\(0, m_0 \u2212 1\\)]\u3002\u56e0\u6b64\uff0cMRS \u6570\u5b57\u4e0e RNS \u6570\u5b57\uff08\u4f59\u6570\uff09\u5904\u4e8e\u76f8\u540c\u8303\u56f4\u3002\u4f8b\u5982\uff0c\u6df7\u5408\u57fa\u6570\u7cfb\u7edf MRS ( 8 | 7 | 5 | 3 ) \u7684\u4f4d\u7f6e\u6743\u91cd\u4e3a 7 \u00d7 5 \u00d7 3 =105, 5 \u00d7 3 = 15, 3, 1, \u5bfc\u81f4</p> \\[ ( 0 | 3 | 1 | 0 )_{MRS ( 8|7|5|3 )} = ( 0 \u00d7 105 ) + ( 3 \u00d7 15 ) + ( 1 \u00d7 3 ) + ( 0 \u00d7 1 ) = 48 \\] <p>The RNS-to-MRS conversion problem is that of determining the  zi  digits of MRS, given the  xi  digits of RNS, so that</p> <p>RNS \u5230 MRS \u7684\u8f6c\u6362\u95ee\u9898\u662f\u5728\u7ed9\u5b9a RNS \u7684 \\(x_i\\) \u6570\u5b57\u7684\u60c5\u51b5\u4e0b\u786e\u5b9a MRS \u7684 \\(z_i\\) \u6570\u5b57\uff0c\u4ee5\u4fbf</p> \\[ y = (x_{k\u22121}| \u00b7 \u00b7 \u00b7 | x_2 | x_1 | x_0 ) _{RNS} = (z_{k\u22121} | \u00b7 \u00b7 \u00b7 | z_2 | z_1 | z_0 ) _{MRS} \\] <p>From the definition of MRS, we have</p> <p>\u6839\u636eMRS\u7684\u5b9a\u4e49\uff0c\u6211\u4eec\u6709</p> \\[ y = z_{k\u22121} (m_{k\u22122} \\cdots m_2 m_1 m_0 ) + \\cdots + z_2 (m_1 m_0 ) + z_1 (m_0 ) + z_0 \\] <p>It is thus immediately obvious that  z 0 =  x 0. Subtracting  z 0 =  x 0 from both the RNS and MRS representations, we get</p> <p>\u56e0\u6b64\u5f88\u660e\u663e \\(z_0 = x_0\\)\u3002\u4ece RNS \u548c MRS \u8868\u793a\u4e2d\u51cf\u53bb \\(z_0 = x_0\\)\uff0c\u6211\u4eec\u5f97\u5230</p> \\[ y - x_0 = (x'_{k\u22121}| \u00b7 \u00b7 \u00b7 | x'_2 | x'_1 | 0 ) _{RNS} = (z_{k\u22121} | \u00b7 \u00b7 \u00b7 | z_2 | z_1 | 0 ) _{MRS} \\] <p>\u5176\u4e2d\\(x'_j=\\left \\langle x_j - x_0 \\right \\rangle_{m_j}\\)\u200b. </p> <p>If we now divide both representations by  m*0, we get the following in the reduced RNS and MRS from which *m 0 has been removed:</p> <p>\u5982\u679c\u6211\u4eec\u73b0\u5728\u5c06\u4e24\u4e2a\u8868\u793a\u9664\u4ee5 \\(m_0\\)\uff0c\u5f97\u5230\u7ed3\u679c \u662f\u5df2\u5220\u9664 \\(m_0\\) \u7684\u7b80\u5316 RNS \u548c MRS \uff1a</p> <p>$$ (x''{k\u22121}| \u00b7 \u00b7 \u00b7 | x''_2 | x''_1) _{RNS} = (z | \u00b7 \u00b7 \u00b7 | z_2 | z_1) _{MRS} $$ Thus, if we demonstrate how to divide the number  y =  (x| \u00b7 \u00b7 \u00b7 |  x |  x | 0 *)*RNS by m0 to obtain (xk\u22121 | \u00b7 \u00b7 \u00b7 | x2 | x1)RNS, we have converted the original problem to a similar problem with one fewer modulus. Repeating the same process then leads to the determination of all the zi digits in turn. </p> <p>\u56e0\u6b64\uff0c\u5982\u679c\u6211\u4eec\u6f14\u793a\u5982\u4f55\u5c06 \\(y\u2019 = (x\u2019_{k-1}|\\cdots|x\u2019_2|x\u2019_1|0)_{RNS}\\) \u9664\u4ee5\u6570\u5b57\\(m_0\\) \u6765\u5f97\u5230 \\((x''_{k\u22121}| \u00b7 \u00b7 \u00b7 | x''_2 | x''_1) _{RNS}\\)\uff0c \u6211\u4eec\u5df2\u7ecf\u5c06\u539f\u59cb\u95ee\u9898\u8f6c\u6362\u4e3a\u5c11\u4e00\u4e2a\u6a21\u6570\u7684\u7c7b\u4f3c\u95ee\u9898\u3002\u91cd\u590d\u76f8\u540c\u7684\u8fc7\u7a0b\u5373\u53ef\u4f9d\u6b21\u786e\u5b9a\u6240\u6709\u7684 \\(z_i\\) \u6570\u5b57\u3002</p> <p>Dividing y, which is a multiple of m 0, by a given constant (in this case m 0) is known as scaling and is much simpler than general division in RNS. Division by m 0 can be accomplished by multiplying each residue by the multiplicative inverse of m 0 with respect to the associated modulus. For example, the multiplicative inverses of 3 relative to 8, 7, and 5 are 3, 5, and 2, respectively, because</p> <p>\u5c06 y\uff08\u662f\\(m_0\\)\u7684\u500d\u6570\uff09\u9664\u4ee5\u7ed9\u5b9a\u5e38\u6570\uff08\u5728\u672c\u4f8b\u4e2d\u4e3a \\(m_0\\)\uff09\u79f0\u4e3a\u7f29\u653e\uff0c\u5e76\u4e14\u6bd4 RNS \u4e2d\u7684\u4e00\u822c\u9664\u6cd5\u7b80\u5355\u5f97\u591a\u3002\u9664\u4ee5\\(m_0\\) \u53ef\u4ee5\u901a\u8fc7\u5c06\u6bcf\u4e2a\u4f59\u6570\u4e58\u4ee5\\(m_0\\) \u76f8\u5bf9\u4e8e\u76f8\u5173\u6a21\u6570\u7684*\u4e58\u6cd5\u9006\u5143*\u6765\u5b8c\u6210\u3002\u4f8b\u5982\uff0c3 \u76f8\u5bf9\u4e8e 8\u30017 \u548c 5 \u7684*\u4e58\u6cd5\u9006\u5143*\u5206\u522b\u4e3a 3\u30015 \u548c 2\uff0c\u56e0\u4e3a</p> <p>$$ \\left \\langle 3 \\times 3 \\right \\rangle _8 = \\left \\langle 3 \\times 5 \\right \\rangle _7 = \\left \\langle 3 \\times 2 \\right \\rangle _5 = 1 $$ \u56e0\u6b64\uff0c\u6570\u5b57 \\(y = ( 0 | 6 | 3 | 0 )_{RNS}\\) \u53ef\u4ee5\u901a\u8fc7\u4e58\u4ee5 \\(( 3 | 5 | 2 | \u2212 ) _{RNS}\\) \u6765\u9664\u4ee5 3\uff1a</p> <p>$$ \\frac{( 0 | 6 | 3 | 0 ){RNS}}{3}=( 0 | 6 | 3 | 0 )\\times ( 3 | 5 | 2 | \u2212 ) {RNS} =  (0 | 2 | 1 | \u2212) $$ Multiplicative inverses of the moduli can be precomputed and stored in tables to facilitate RNS-to-MRS conversion.</p> <p>\u6a21\u7684\u4e58\u6cd5\u9006\u53ef\u4ee5\u9884\u5148\u8ba1\u7b97\u5e76\u5b58\u50a8\u5728\u8868\u4e2d\uff0c\u4ee5\u65b9\u4fbf RNS \u5230 MRS \u7684\u8f6c\u6362\u3002</p> <p>EXAMPLE 4.2 Convert y = ( 0 | 6 | 3 | 0 ) RNS to mixed-radix representation. We have z 0 = x 0 = 0. Based on the preceding discussion, dividing y by 3 yields: ( 0 | 6 | 3 | 0 ) RNS = ( 0 | 6 | 3 | 0 ) RNS \u00d7 ( 3 | 5 | 2 | \u2212 ) RNS</p> <p>\u793a\u4f8b4.2 \u5c06\\(y = ( 0 | 6 | 3 | 0 ) _{RNS}\\) \u8f6c\u6362\u4e3a\u6df7\u5408\u57fa\u6570\u8868\u793a\u3002</p> <p>\u6211\u4eec\u6709 \\(z_0 = x_0 = 0\\)\u3002\u6839\u636e\u524d\u9762\u7684\u8ba8\u8bba\uff0c\u5c06 y \u9664\u4ee5 3 \u5f97\u5230\uff1a </p> \\[ \\frac{( 0 | 6 | 3 | 0 )_{RNS}}{3}=( 0 | 6 | 3 | 0 )_{RNS}\\times ( 3 | 5 | 2 | \u2212 ) _{RNS} =  (0 | 2 | 1 | \u2212)_{RNS} \\] <p>Thus we have z 1 = 1. Subtracting 1 and dividing by 5, we get:</p> <p>\u56e0\u6b64\u6211\u4eec\u6709 \\(z_1 = 1\\)\u3002\u51cf\u53bb 1 \u518d\u9664\u4ee5 5\uff0c\u6211\u4eec\u5f97\u5230\uff1a</p> \\[ \\frac{(7|1|0|-)_{RNS}}{5} = (7|1|0|-)_{RNS} \\times (5|3|-|-)_{RNS}=(0|-|-|-)_{RNS} \\] <p>Next, we get z 2 = 3. Subtracting 3 and dividing by 7, we find:</p> <p>\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5f97\u5230 \\(z_2 = 3\\)\u3002\u51cf\u53bb 3 \u518d\u9664\u4ee5 7\uff0c\u6211\u4eec\u53d1\u73b0\uff1a</p> \\[ \\frac{(0|0|-|-)_{RNS}}{7} = (0|0|-|-)_{RNS} \\times (7|-|-|-)_{RNS} = (0|-|-|-)_{RNS} \\] <p>We conclude by observing that z 3 = 0. The conversion is now complete:</p> <p>\u6211\u4eec\u901a\u8fc7\u89c2\u5bdf \u5f97\u51fa\u7ed3\u8bba\\(z_3 = 0\\) \u3002\u8f6c\u6362\u73b0\u5df2\u5b8c\u6210\uff1a</p> \\[ y = (0 | 6 | 3 | 0)_{RNS} = (0 | 3 | 1 | 0)_{MRS} = 48 \\] <p>Mixed-radix representation allows us to compare the magnitudes of two RNS numbers or to detect the sign of a number. For example, the RNS representations ( 0 | 6 | 3 | 0 ) RNS and ( 5 | 3 | 0 | 0 ) RNS of 48 and 45 provide no clue to their relative magnitudes, whereas the equivalent mixed-radix representations ( 0 | 3 | 1 | 0 ) MRS and ( 0 | 3 | 0 | 0 ) MRS, or ( 000 | 011 | 001 | 00 ) MRS and ( 000 | 011 | 000 | 00 ) MRS, when coded in binary, can be compared as ordinary numbers.</p> <p>\u6df7\u5408\u57fa\u6570\u8868\u793a\u5141\u8bb8\u6211\u4eec\u6bd4\u8f83\u4e24\u4e2aRNS\u6570\u5b57\u7684\u5927\u5c0f\u6216\u68c0\u6d4b\u6570\u5b57\u7684\u7b26\u53f7\u3002\u4f8b\u5982\uff0c48 \u548c 45 \u7684 RNS \u8868\u793a \\(( 0 | 6 | 3 | 0 )_{RNS}\\) \u548c \\(( 5 | 3 | 0 | 0 ) _{RNS}\\) \u6ca1\u6709\u63d0\u4f9b\u5b83\u4eec\u76f8\u5bf9\u5927\u5c0f\u7684\u7ebf\u7d22\uff0c\u800c\u7b49\u6548\u7684\u6df7\u5408\u57fa\u6570\u8868\u793a \\(( 0 | 3 | 1 | 0 ) _{MRS}\\)</p> <p>\u548c\\(( 0 | 3 | 0 | 0 ) _{MRS}\\)\uff0c\u6216\\(( 000 | 011 | 001 | 00 )_{MRS}\\) \u548c\\(( 000 | 011 | 000 | 00 ) _{MRS}\\)\uff0c\u5f53\u4ee5\u4e8c\u8fdb\u5236\u7f16\u7801\u65f6\uff0c\u53ef\u4ee5\u50cf\u666e\u901a\u6570\u5b57\u4e00\u6837\u8fdb\u884c\u6bd4\u8f83\u3002</p>"},{"location":"Part_01/04/#rns_2","title":"RNS \u5230\u4e8c\u8fdb\u5236/\u5341\u8fdb\u5236\u7684\u8f6c\u6362","text":"<p>One method for RNS-to-binary conversion is to first derive the mixed-radix representation of the RNS number and then use the weights of the mixed-radix positions to complete the conversion. We can also derive position weights for the RNS directly based on the Chinese remainder theorem (CRT), as discussed below.</p> <p>RNS \u5230\u4e8c\u8fdb\u5236\u8f6c\u6362\u7684\u4e00\u79cd\u65b9\u6cd5\u662f\u9996\u5148\u5bfc\u51fa RNS \u6570\u7684\u6df7\u5408\u57fa\u8868\u793a\uff0c\u7136\u540e\u4f7f\u7528\u6df7\u5408\u57fa\u4f4d\u7f6e\u7684\u6743\u91cd\u6765\u5b8c\u6210\u8f6c\u6362\u3002\u6211\u4eec\u8fd8\u53ef\u4ee5\u76f4\u63a5\u57fa\u4e8e\u4e2d\u56fd\u5269\u4f59\u5b9a\u7406 (CRT) \u5bfc\u51fa RNS \u7684\u4f4d\u7f6e\u6743\u91cd\uff0c\u5982\u4e0b\u6240\u8ff0\u3002</p> <p>Consider the conversion of y = ( 3 | 2 | 4 | 2 ) RNS from RNS ( 8 | 7 | 5 | 3 ) to decimal. Based on RNS properties, we can write</p> <p>\u8003\u8651\u5c06 y = ( 3 | 2 | 4 | 2 ) RNS \u4ece RNS ( 8 | 7 | 5 | 3 ) \u8f6c\u6362\u4e3a\u5341\u8fdb\u5236\u3002\u57fa\u4e8e RNS \u5c5e\u6027\uff0c\u6211\u4eec\u53ef\u4ee5\u5199\u505a</p> \\[ \\begin{array}{l} (3 | 2 | 4 | 2)_{RNS} &amp;= (3 | 0 | 0 | 0)_{RNS} + (0 | 2 | 0 | 0)_{RNS} + (0 | 0 | 4 | 0)_{RNS} + (0 | 0 | 0 | 2)_{RNS} \\\\ &amp;= 3 \u00d7 (1 | 0 | 0 | 0)_{RNS} + 2 \u00d7 (0 | 1 | 0 | 0)_{RNS} + 4 \u00d7 (0 | 0 | 1 | 0)_{RNS} + 2 \u00d7 (0 | 0 | 0 | 1)_{RNS} \\end{array} \\] <p>Thus, knowing the values of the following four constants (the RNS position weights) would allow us to convert any number from RNS ( 8 | 7 | 5 | 3 ) to decimal using four multiplications and three additions.</p> <p>\u56e0\u6b64\uff0c\u77e5\u9053\u4ee5\u4e0b\u56db\u4e2a\u5e38\u91cf\uff08RNS \u4f4d\u7f6e\u6743\u91cd\uff09\u7684\u503c\u5c06\u5141\u8bb8\u6211\u4eec\u4f7f\u7528\u56db\u6b21\u4e58\u6cd5\u548c\u4e09\u6b21\u52a0\u6cd5\u5c06\u4efb\u4f55\u6570\u5b57\u4ece RNS (8 | 7 | 5 | 3 ) \u8f6c\u6362\u4e3a\u5341\u8fdb\u5236\u3002</p> \\[ \\begin{array}{c} (1 | 0 | 0 | 0)_{RNS} = 105 \\\\ (0 | 1 | 0 | 0)_{RNS} = 120 \\\\ (0 | 0 | 1 | 0)_{RNS} = 336 \\\\ (0 | 0 | 0 | 1)_{RNS} = 280 \\end{array} \\] <p>\u6240\u4ee5\u6211\u4eec\u53ef\u4ee5\u53d1\u73b0</p> \\[ (3 | 2 | 4 | 2)RNS = \\left \\langle (3 \u00d7 105) + (2 \u00d7 120) + (4 \u00d7 336) + (2 \u00d7 280)\\right \\rangle _{840} = 779 \\] <p>It only remains to show how the preceding weights were derived. How, for example, did we determine that w 3 = ( 1 | 0 | 0 | 0 ) RNS = 105? To determine the value of w 3, we note that it is divisible by 3, 5, and 7, since its last three residues are 0s. Hence, w 3 must be a multiple of 105. We must then pick the appropriate multiple of 105 such that its residue with respect to 8 is 1. This is done by multiplying 105 by its multiplicative inverse with respect to 8. Based on the preceding discussion, the conversion process can be formalized in the form of CRT.</p> <p>\u53ea\u9700\u8981\u8bf4\u660e\u524d\u9762\u7684\u6743\u91cd\u662f\u5982\u4f55\u5f97\u51fa\u7684\u3002\u4f8b\u5982\uff0c\u6211\u4eec\u5982\u4f55\u786e\u5b9a \\(w_3 = ( 1 | 0 | 0 | 0 ) _{RNS} = 105\\)\uff1f \u4e3a\u4e86\u786e\u5b9a \\(w_3\\) \u7684\u503c\uff0c\u6211\u4eec\u6ce8\u610f\u5230\u5b83\u53ef\u4ee5\u88ab 3\u30015 \u548c 7 \u6574\u9664\uff0c\u56e0\u4e3a\u5b83\u7684\u6700\u540e\u4e09\u4e2a\u4f59\u6570\u662f 0\u3002\u56e0\u6b64\uff0cw 3 \u5fc5\u987b\u662f 105 \u7684\u500d\u6570\u3002\u7136\u540e\u6211\u4eec\u5fc5\u987b\u9009\u62e9 105 \u7684\u9002\u5f53\u500d\u6570\uff0c\u4f7f\u5176\u76f8\u5bf9\u4e8e 8 \u7684\u4f59\u6570\u4e3a 1\u3002\u8fd9\u662f\u901a\u8fc7\u5c06 105 \u4e58\u4ee5\u5b83\u76f8\u5bf9\u4e8e 8 \u7684\u4e58\u6cd5\u9006\u5143\u6765\u5b8c\u6210\u7684\u3002\u57fa\u4e8e\u524d\u9762\u7684\u8ba8\u8bba\uff0c\u8f6c\u6362\u8fc7\u7a0b\u53ef\u4ee5\u4ee5 CRT \u7684\u5f62\u5f0f\u5f62\u5f0f\u5316\u3002</p> <p>THEOREM 4.1 (The Chinese remainder theorem) The magnitude of an RNS number can be obtained from the CRT formula:</p> <p>\u5b9a\u7406 4.1\uff08\u4e2d\u56fd\u5269\u4f59\u5b9a\u7406\uff09RNS \u6570\u5b57\u7684\u5927\u5c0f\u53ef\u4ee5\u4eceCRT\u516c\u5f0f\u4e2d\u83b7\u5f97\uff1a</p> <p>$$ x = (x_{k\u22121} | \u00b7 \u00b7 \u00b7 | x_2 | x_1 | x_0 ) {RNS} = \\left \\langle \\sum^{k-1}M_i \\left \\langle \\alpha_i x_i\\right \\rangle_{m_i} \\right \\rangle_M $$ \u5176\u4e2d \\(M_i=M/m_i\\), \u800c \\(\\alpha_i=\\left \\langle M_i^{-1}\\right \\rangle _{m_i}\\) \u662f\\(M_i\\)\u76f8\u5bf9\u4e8e\\(m_i\\)\u7684\u4e58\u6cd5\u9006\u5143\u3002</p> <p>To avoid multiplications in the conversion process, we can store the values of</p> <p>\u4e3a\u4e86\u907f\u514d\u8f6c\u6362\u8fc7\u7a0b\u4e2d\u7684\u4e58\u6cd5\uff0c\u6211\u4eec\u53ef\u4ee5\u5b58\u50a8\u5bf9\u4e8e\u6240\u6709\u53ef\u80fd\u7684\\(i\\) \u548c\\(x_i\\)\u5bf9\u5e94\u7684\\(\\left \\langle M_i \\left \\langle \\alpha_i x_i\\right \\rangle_{m_i} \\right \\rangle_M\\)\u7684\u503c\u5230\u4e00\u4e2a\u8868\u4e2d\uff0c\u8868\u5927\u5c0f\u6709\\(\\sum_{i=0}^{k-1}m_i\\)\u4e2aword\u3002</p> <p></p> <p>\u8868 4.2 \u5e94\u7528\u4e2d\u56fd\u4f59\u6570\u5b9a\u7406\u5230RNS(8|7|5|3)\u6240\u9700\u7684\u503c</p> <p>shows the required values for RNS ( 8 | 7 | 5 | 3 ). Conversion is then performed exclusively by table lookups and modulo- M additions.</p> <p>\u8868 4.2\u663e\u793a RNS ( 8 | 7 | 5 | 3 ) \u6240\u9700\u7684\u503c\u3002\u4ec5\u901a\u8fc7\u8868\u67e5\u627e\u548c\u6a21 M \u52a0\u6cd5\u5c31\u53ef\u4ee5\u6267\u884c\u8f6c\u6362\u3002</p>"},{"location":"Part_01/04/#44-rns","title":"4.4 \u56f0\u96be\u7684 RNS \u7b97\u672f\u8fd0\u7b97","text":"<p>In this section, we discuss algorithms and hardware designs for sign test, magnitude comparison, overflow detection, and general division in RNS. The first three of these operations are essentially equivalent in that if an RNS with dynamic range  M  is used for representing signed numbers in the range [\u2212 N ,  P], with  M =  N +  P + 1, then sign test is the same as comparison with  P  and overflow detection can be performed based on the signs of the operands and that of the result. Thus, it suffices to discuss magnitude comparison and general division. </p> <p>\u5728\u672c\u8282\u4e2d\uff0c\u6211\u4eec\u5c06\u8ba8\u8bba RNS \u4e2d\u7b26\u53f7\u6d4b\u8bd5\u3001\u5e45\u5ea6\u6bd4\u8f83\u3001\u6ea2\u51fa\u68c0\u6d4b\u548c\u4e00\u822c\u9664\u6cd5\u7684\u7b97\u6cd5\u548c\u786c\u4ef6\u8bbe\u8ba1\u3002\u524d\u4e09\u4e2a\u64cd\u4f5c\u672c\u8d28\u4e0a\u662f\u7b49\u4ef7\u7684\uff0c\u5982\u679c\u4f7f\u7528\u52a8\u6001\u8303\u56f4\u4e3a \\(M\\) \u7684 RNS \u6765\u8868\u793a \\([\u2212 N , P]\\) \u8303\u56f4\u5185\u7684\u6709\u7b26\u53f7\u6570\uff0c\u5176\u4e2d \\(M = N + P + 1\\)\uff0c\u5219\u7b26\u53f7\u6d4b\u8bd5\u4e0e\u4e0e \\(P\\) \u7684\u6bd4\u8f83\u76f8\u540c\uff0c\u5e76\u4e14\u53ef\u4ee5\u6839\u636e\u64cd\u4f5c\u6570\u7684\u7b26\u53f7\u548c\u7ed3\u679c\u7684\u7b26\u53f7\u8fdb\u884c\u6ea2\u51fa\u68c0\u6d4b\u3002\u56e0\u6b64\uff0c\u8ba8\u8bba\u5927\u5c0f\u6bd4\u8f83\u548c\u4e00\u822c\u9664\u6cd5\u5c31\u8db3\u591f\u4e86\u3002</p> <p>To compare the magnitudes of two RNS numbers, we can convert both to binary</p> <p>or mixed-radix form. However, this would involve a great deal of overhead. A moreefficient approach is through approximate CRT decoding. Dividing the equality in the statement of Theorem 4.1 by  M , we obtain the following expression for the scaled value of  x  in [0, 1):</p> <p>\u4e3a\u4e86\u6bd4\u8f83\u4e24\u4e2a RNS \u6570\u5b57\u7684\u5927\u5c0f\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u4e24\u8005\u8f6c\u6362\u4e3a\u4e8c\u8fdb\u5236\u6216\u6df7\u5408\u57fa\u6570\u5f62\u5f0f\u3002\u7136\u800c\uff0c\u8fd9\u5c06\u6d89\u53ca\u5927\u91cf\u7684\u5f00\u9500\u3002\u4e00\u4e2a\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u662f\u901a\u8fc7\u8fd1\u4f3c CRT \u89e3\u7801\u3002\u5c06\u5b9a\u7406 4.1 \u7684\u9648\u8ff0\u4e2d\u7684\u7b49\u5f0f\u9664\u4ee5 M \uff0c\u6211\u4eec\u5f97\u5230 [0, 1) \u4e2d x \u7684\u7f29\u653e\u503c\u7684\u4ee5\u4e0b\u8868\u8fbe\u5f0f\uff1a</p> <p>$$ \\frac{x}{M} = \\frac{(x_{k\u22121} | \u00b7 \u00b7 \u00b7 | x_2 | x_1 | x_0 ) {RNS}}{M} = \\left \\langle \\sum{k-1}m_i \\left \\langle \\alpha_i x_i\\right \\rangle_{m_i} \\right \\rangle_1 $$ Here, the addition of terms is performed modulo 1, meaning that in adding the terms \\(m_i^{-1} \\left \\langle \\alpha_i x_i\\right \\rangle_{m_i}\\), each of which is in [0, 1), the whole part of the result is discarded and only the fractional part is kept; this is much simpler than the modulo- M  addition needed in conventional CRT decoding. </p> <p>\u8fd9\u91cc\uff0c\u9879\u7684\u76f8\u52a0\u662f\u4ee5\u6a21 1 \u8fdb\u884c\u7684\uff0c\u8fd9\u610f\u5473\u7740\u5728\u76f8\u52a0\u9879 \\(m_i^{-1} \\left \\langle \\alpha_i x_i\\right \\rangle_{m_i}\\) \u6bcf\u4e00\u4e2a\u90fd\u5728[0, 1)\u4e2d\uff0c\u7ed3\u679c\u6574\u6570\u4e22\u5f03\uff0c\u53ea\u4fdd\u7559\u5c0f\u6570\u90e8\u5206\uff1b\u8fd9\u6bd4\u4f20\u7edf CRT \u89e3\u7801\u4e2d\u6240\u9700\u7684\u6a21 M \u52a0\u6cd5\u7b80\u5355\u5f97\u591a\u3002</p> <p>Again, the terms  \\(m_i^{-1} \\left \\langle \\alpha_i x_i\\right \\rangle_{m_i}\\) can be precomputed for all possible  i  and  *x*i and stored in tables of total size \u0007k i=\u221201 mi words. Table 4.3 shows the required lookup table for approximate CRT decoding in RNS(8 | 7 | 5 | 3). Conversion is then performed exclusively by table lookups and modulo-1 additions (i.e., fractional addition, with the carry-out simply ignored).</p> <p>\u540c\u6837\u7684\uff0c\u53ef\u4ee5\u9884\u5148\u8ba1\u7b97\u6240\u6709\u53ef\u80fd\u7684 \\(i\\) \u548c \\(x_i\\)\u5bf9\u5e94\u7684\u9879 \\(m_i^{-1} \\left \\langle \\alpha_i x_i\\right \\rangle_{m_i}\\) \u653e\u5728\u4e00\u4e2a\u6709\\(\\sum_{i=0}^{k-1}m_i\\)\u4e2aword\u7684\u8868\u4e2d\u3002\u8868 4.3 \u663e\u793a\u4e86\u8fd1\u4f3c\u4e2d\u56fd\u5269\u4f59\u5b9a\u7406\u8ba1\u7b97RNS(8|7|5|3)\u6240\u9700\u7684\u67e5\u627e\u8868\uff0c \u7136\u540e\u4ec5\u6839\u636e\u8868 4.3 \u5e94\u7528\u6240\u9700\u7684\u503c\u8fdb\u884c\u8f6c\u6362\uff0c \u8868\u67e5\u627e\u548c\u6a21 1 \u52a0\u6cd5\uff08\u5373\u5c0f\u6570\u52a0\u6cd5\uff0c\u5ffd\u7565\u8fdb\u4f4d\uff09</p> <p></p> <p>\u88684.3 \u5c06\u8fd1\u4f3c\u4e2d\u56fd\u5269\u4f59\u5b9a\u7406\u89e3\u7801\u5e94\u7528\u4e8e RNS(8|7|5|3) \u6240\u9700\u7684\u503c </p> <p>EXAMPLE 4.3 Use approximate CRT decoding to determine the larger of the two numbers x = ( 0 | 6 | 3 | 0 ) RNS and y = ( 5 | 3 | 0 | 0 ) RNS. Reading values from Table 4.3, we get:</p> <p>\u793a\u4f8b4.3 \u4f7f\u7528\u8fd1\u4f3cCRT \u89e3\u7801\u6765\u786e\u5b9a\u4e24\u4e2a\u6570\u5b57\\(x = ( 0 | 6 | 3 | 0 ) _{RNS}\\) \u548c\\(y = ( 5 | 3 | 0 | 0 ) _{RNS}\\) \u4e2d\u8f83\u5927\u7684\u4e00\u4e2a\u3002\u4ece\u8868 4.3 \u4e2d\u8bfb\u53d6\u503c\uff0c\u6211\u4eec\u5f97\u5230\uff1a</p> \\[ \\begin{array}{c} \\frac{x}{M} \\approx \\left \\langle .0000 + .8571 + .2000 + .0000 \\right \\rangle _1 =  .0571 \\\\ \\frac{y}{M} \\approx \\left \\langle .6250 + .4286 + .0000 + .0000 \\right \\rangle _1 =  .0536 \\end{array} \\] <p>Thus, we can conclude that  x &gt; y, subject to approximation errors to be discussed next. </p> <p>\u56e0\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u51fa\u7ed3\u8bba\uff0cx &gt; y\uff0c\u4f46\u4f1a\u53d7\u5230\u63a5\u4e0b\u6765\u8ba8\u8bba\u7684\u8fd1\u4f3c\u8bef\u5dee\u7684\u5f71\u54cd\u3002</p> <p>If the maximum error in each table entry is  \u03b5, then approximate CRT decoding yields the scaled value of an RNS number with an error of no more than  k\u03b5. In Example 4.3, assuming that the table entries have been rounded to four decimal digits, the maximum error in each entry is  \u03b5 = 0.000 05 and the maximum error in the scaled value is 4 \u03b5 = 0.0002. The conclusion  x &gt; y  is, therefore, safe. </p> <p>\u5982\u679c\u6bcf\u4e2a\u8868\u6761\u76ee\u4e2d\u7684\u6700\u5927\u8bef\u5dee\u4e3a\u03b5\uff0c\u5219\u8fd1\u4f3cCRT\u89e3\u7801\u4ea7\u751f\u8bef\u5dee\u4e0d\u8d85\u8fc7k\u03b5\u7684RNS\u6570\u7684\u7f29\u653e\u503c\u3002\u5728\u4f8b 4.3 \u4e2d\uff0c\u5047\u8bbe\u8868\u683c\u6761\u76ee\u5df2\u56db\u820d\u4e94\u5165\u4e3a\u56db\u4f4d\u5c0f\u6570\uff0c\u5219\u6bcf\u4e2a\u6761\u76ee\u7684\u6700\u5927\u8bef\u5dee\u4e3a \u03b5 = 0.000 05\uff0c\u6362\u7b97\u503c\u7684\u6700\u5927\u8bef\u5dee\u4e3a 4 \u03b5 = 0.0002\u3002\u56e0\u6b64\uff0c\u7ed3\u8bba x &gt; y \u662f\u5b89\u5168\u7684\u3002</p> <p>Of course we can use highly precise table entries to avoid the possibility of erroneous conclusions altogether. But this would defeat the advantage of approximate CRT decoding in simplicity and speed. Thus, in practice, a two-stage process might be envisaged: a quick approximate decoding process is performed first, with the resulting scaled value(s) and error bound(s) used to decide whether a more precise or exact decoding is needed for arriving at a conclusion. </p> <p>\u5f53\u7136\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u9ad8\u7cbe\u5ea6\u7684\u8868\u683c\u6761\u76ee\u6765\u5b8c\u5168\u907f\u514d\u5f97\u51fa\u9519\u8bef\u7ed3\u8bba\u7684\u53ef\u80fd\u6027\u3002\u4f46\u8fd9\u4f1a\u62b5\u6d88\u8fd1\u4f3c CRT \u89e3\u7801\u5728\u7b80\u5355\u6027\u548c\u901f\u5ea6\u65b9\u9762\u7684\u4f18\u52bf\u3002\u56e0\u6b64\uff0c\u5728\u5b9e\u8df5\u4e2d\uff0c\u53ef\u4ee5\u8bbe\u60f3\u4e00\u4e2a\u4e24\u9636\u6bb5\u7684\u8fc7\u7a0b\uff1a\u9996\u5148\u6267\u884c\u5feb\u901f\u8fd1\u4f3c\u89e3\u7801\u8fc7\u7a0b\uff0c\u4f7f\u7528\u5f97\u5230\u7684\u7f29\u653e\u503c\u548c\u8bef\u5dee\u754c\u9650\u6765\u51b3\u5b9a\u662f\u5426\u9700\u8981\u66f4\u7cbe\u786e\u6216\u66f4\u7cbe\u786e\u7684\u89e3\u7801\u6765\u5f97\u51fa\u7ed3\u8bba\u3002</p> <p>In many practical situations, an exact comparison of  x  and  y  might not be required and a ternary decision result  x &lt; y,  x \u2248  y (i.e., too close to call), or  x &gt; y  might do. In such cases, approximate CRT decoding is just the right tool. For example, in certain division algorithms (to be discussed in Chapter 14), the sign and the magnitude of the partial remainder  s  are used to choose the next quotient digit  qj  from the redundant digit set [\u22121, 1] according to the following:</p> <p>\u5728\u8bb8\u591a\u5b9e\u9645\u60c5\u51b5\u4e0b\uff0c\u53ef\u80fd\u4e0d\u9700\u8981\u5bf9 x \u548c y \u8fdb\u884c\u7cbe\u786e\u6bd4\u8f83\uff0c\u800c\u53ef\u80fd\u9700\u8981\u4e09\u5143\u51b3\u7b56\u7ed3\u679c x &lt; y\u3001x \u2248 y\uff08\u5373\uff0c\u592a\u63a5\u8fd1\u800c\u65e0\u6cd5\u51b3\u5b9a\uff09\u6216 x &gt; y\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u8fd1\u4f3c CRT \u89e3\u7801\u6b63\u662f\u6b63\u786e\u7684\u5de5\u5177\u3002\u4f8b\u5982\uff0c\u5728\u67d0\u4e9b\u9664\u6cd5\u7b97\u6cd5\u4e2d\uff08\u5c06\u5728\u7b2c14\u7ae0\u4e2d\u8ba8\u8bba\uff09\uff0c\u90e8\u5206\u4f59\u6570s\u7684\u7b26\u53f7\u548c\u5927\u5c0f\u7528\u4e8e\u6839\u636e\u4ee5\u4e0b\u516c\u5f0f\u4ece\u5197\u4f59\u6570\u5b57\u96c6[\u22121, 1]\u4e2d\u9009\u62e9\u4e0b\u4e00\u4e2a\u5546\u6570\u5b57qj\uff1a</p> <pre><code>       s &lt; 0       quotient digit = \u22121\n       s \u2248 0       quotient digit = 0\n       s &gt; 0       quotient digit = 1\n</code></pre> <p>In this case, the algorithm\u2019s built-in tolerance to imprecision allows us to use it for RNS division. Once the quotient digit in [\u22121, 1] has been chosen, the value  qjd , where  d is the divisor, is subtracted from the partial remainder to obtain the new partial remainder for the next iteration. Also, the quotient, derived in positional radix-2 format using the digit set [\u22121, 1], is converted to RNS on the fly. </p> <p>\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u7b97\u6cd5\u5185\u7f6e\u7684\u5bf9\u4e0d\u7cbe\u786e\u6027\u7684\u5bb9\u5fcd\u5ea6\u5141\u8bb8\u6211\u4eec\u5c06\u5176\u7528\u4e8e RNS \u9664\u6cd5\u3002\u4e00\u65e6\u9009\u62e9\u4e86 [\u22121, 1] \u4e2d\u7684\u5546\u6570\u5b57\uff0c\u5c31\u4ece\u90e8\u5206\u4f59\u6570\u4e2d\u51cf\u53bb\u503c \\(q_jd\\) \uff08\u5176\u4e2d d \u662f\u9664\u6570\uff09\u4ee5\u83b7\u5f97\u4e0b\u4e00\u6b21\u8fed\u4ee3\u7684\u65b0\u90e8\u5206\u4f59\u6570\u3002\u6b64\u5916\uff0c\u4f7f\u7528\u6570\u5b57\u96c6 [\u22121, 1] \u4ee5\u4f4d\u7f6e\u57fa 2 \u683c\u5f0f\u5bfc\u51fa\u7684\u5546\u4f1a\u5373\u65f6\u8f6c\u6362\u4e3a RNS\u3002</p> <p>In other division algorithms, to be discussed in Chapters 14 and 15, approximate comparison of the partial remainder  s  and divisor  d  is used to choose a radix- r  quotient digit in [\u2212 \u03b1,  \u03b2]. An example includes radix-4 division with the redundant quotient digit set [\u22122, 2]. In these cases, too, approximate CRT decoding can be used to facilitate RNS division [Hung94]. </p> <p>\u5728\u7b2c 14 \u7ae0\u548c\u7b2c 15 \u7ae0\u8ba8\u8bba\u7684\u5176\u4ed6\u9664\u6cd5\u7b97\u6cd5\u4e2d\uff0c\u90e8\u5206\u4f59\u6570 s \u548c\u9664\u6570 d \u7684\u8fd1\u4f3c\u6bd4\u8f83\u7528\u4e8e\u9009\u62e9 [\u2212 \u03b1, \u03b2] \u4e2d\u7684\u57fa\u6570 r \u5546\u4f4d\u3002\u4e00\u4e2a\u793a\u4f8b\u5305\u62ec\u5177\u6709\u5197\u4f59\u5546\u6570\u5b57\u96c6 [\u22122, 2] \u7684\u57fa 4 \u9664\u6cd5\u3002\u5728\u8fd9\u4e9b\u60c5\u51b5\u4e0b\uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528\u8fd1\u4f3c CRT \u89e3\u7801\u6765\u4fc3\u8fdb RNS\u9664\u6cd5 [Hung94]\u3002</p>"},{"location":"Part_01/04/#45-rns","title":"4.5 \u5197\u4f59 RNS \u8868\u793a","text":"<p>Just as the digits in a positional radix- r  number system do not have to be restricted to the set [0,  r \u2212 1], we are not obliged to limit the residue digits for the modulus  mi  to the set [0,  mi \u2212 1]. Instead, we can agree to use the digit set [0,  \u03b2i] for the mod- mi  residue, provided  \u03b2i \u2265  mi \u2212 1. If  \u03b2i \u2265  mi, then the resulting RNS is redundant. </p> <p>\u6b63\u5982\u4f4d\u7f6e\u57fa\u6570 r \u6570\u7cfb\u4e2d\u7684\u6570\u5b57\u4e0d\u5fc5\u9650\u5236\u5728\u96c6\u5408 [\\(0, r \u2212 1\\)] \u4e2d\u4e00\u6837\uff0c\u6211\u4eec\u4e5f\u6ca1\u6709\u4e00\u5b9a\u9700\u8981\u5c06\u6a21 \\(m_i\\) \u7684\u4f59\u6570\u6570\u5b57\u9650\u5236\u5728\u96c6\u5408 [\\(0, m_i \u2212 1\\)] \u4e2d\u3002\u76f8\u53cd\uff0c\u6211\u4eec\u53ef\u4ee5\u540c\u610f\u4f7f\u7528\u6570\u5b57\u96c6 [\\(0, \u03b2_i\\)] \u4f5c\u4e3a mod-\\(m_i\\) \u4f59\u6570\uff0c\u524d\u63d0\u662f \\(\u03b2_i \u2265 m_i \u2212 1\\)\u3002\u5982\u679c \\(\u03b2_i \u2265 m_i\\)\uff0c\u5219\u751f\u6210\u7684 RNS \u662f\u5197\u4f59\u7684\u3002</p> <p>One reason to use redundant residues is to simplify the modular reduction step needed after each arithmetic operation. Consider, for example, the representation of mod-13 residues using 4-bit binary numbers. Instead of using residues in [0, 12], we can use pseudoresidues in [0, 15]. Residues 0, 1, and 2 will then have two representations, since 13 = 0 mod 13, 14 = 1 mod 13, and 15 = 2 mod 13. Addition of such a pseudoresidue y  to an ordinary residue  x, producing a pseudoresidue  z, can be performed by a 4-bit binary adder. If the carry-out is 0, the addition result is kept intact; otherwise, the carry-out, which is worth 16 units, is dropped and 3 is added to the result. Thus, the required mod-13 addition unit is as shown in Fig. 4.3. Addition of two pseudoresidues is possible in a similar way [Parh01]. </p> <p>\u4f7f\u7528\u5197\u4f59\u4f59\u6570\u7684\u539f\u56e0\u4e4b\u4e00\u662f\u7b80\u5316\u6bcf\u6b21\u7b97\u672f\u8fd0\u7b97\u540e\u6240\u9700\u7684\u6a21\u5f52\u7ea6\u6b65\u9aa4\u3002\u4f8b\u5982\uff0c\u8003\u8651 mod-13 \u7684\u8868\u793a\u4f7f\u7528 4 \u4f4d\u4e8c\u8fdb\u5236\u6570\u7684\u4f59\u6570\u3002\u6211\u4eec\u53ef\u4ee5\u5728 [0, 15] \u4e2d\u4f7f\u7528\u4f2a\u4f59\u6570\uff0c\u800c\u4e0d\u662f\u5728 [0, 12] \u4e2d\u3002\u4f59\u6570 0\u30011 \u548c 2 \u5c06\u6709\u4e24\u79cd\u8868\u793a\uff0c\u56e0\u4e3a 13 = 0 mod 13\u300114 = 1 mod 13 \u548c 15 = 2 mod 13\u3002\u5c06\u8fd9\u6837\u7684\u4f2a\u4f59\u6570 y \u6dfb\u52a0\u5230\u666e\u901a\u4f59\u6570 x\uff0c\u4ea7\u751f\u4f2a\u4f59\u6570 z\uff0c\u53ef\u4ee5\u7531 4 \u4f4d\u4e8c\u8fdb\u5236\u52a0\u6cd5\u5668\u6267\u884c\u3002\u5982\u679c\u8fdb\u4f4d\u4e3a0\uff0c\u5219\u52a0\u6cd5\u7ed3\u679c\u4fdd\u6301\u4e0d\u53d8\uff1b\u5426\u5219\uff0c\u503c 16 \u4e2a\u5355\u4f4d\u7684\u8fdb\u4f4d\u5c06\u88ab\u4e22\u5f03\uff0c\u7ed3\u679c\u5c06\u6dfb\u52a0 3\u3002\u56e0\u6b64\uff0c\u6240\u9700\u7684mod-13\u52a0\u6cd5\u5355\u5143\u5982\u56fe4.3\u6240\u793a\u3002\u53ef\u4ee5\u7528\u7c7b\u4f3c\u7684\u65b9\u5f0f\u6dfb\u52a0\u4e24\u4e2a\u4f2a\u4f59\u6570[Parh01]\u3002</p> <p></p> <p>One can go even further and make the pseudoresidues 2 h  bits wide, where normal mod- m  residues would be only  h  bits wide. This simplifies a multiply-accumulate operation, which is done by adding the 2 h-bit product of two normal residues to a 2 h-bit running total, reducing the (2 h + 1)-bit result to a 2 h-bit pseudoresidue for the next step by subtracting 2 hm  from it if needed (Fig. 4.4). Reduction to a standard  h-bit residue is then done only once at the end of accumulation. </p> <p>\u6211\u4eec\u53ef\u4ee5\u66f4\u8fdb\u4e00\u6b65\uff0c\u4f7f\u4f2a\u4f59\u6570\u4e3a \\(2 h\\) \u4f4d\u5bbd\uff0c\u800c\u6b63\u5e38\u7684 mod-m \u4f59\u6570\u53ea\u6709 \\(h\\) \u4f4d\u5bbd\u3002\u8fd9\u7b80\u5316\u4e86\u4e58\u6cd5\u7d2f\u52a0\u8fd0\u7b97\uff0c\u8be5\u8fd0\u7b97\u662f\u901a\u8fc7\u5c06\u4e24\u4e2a\u6b63\u5e38\u6b8b\u6570\u7684 \\(2 h\\) \u4f4d\u4e58\u79ef\u6dfb\u52a0\u5230 \\(2 h\\) \u4f4d\u8fd0\u884c\u603b\u6570\u4e2d\u6765\u5b8c\u6210\u7684\uff0c\u5982\u679c\u9700\u8981\u7684\u8bdd\uff0c\u901a\u8fc7\u4ece\u4e2d\u51cf\u53bb \\(2^hm\\) \u5c06 \\((2 h + 1)\\) \u4f4d\u7ed3\u679c\u51cf\u5c11\u4e3a \\(2 h\\) \u4f4d\u4f2a\u4f59\u6570\uff08\u56fe 4.4\uff09\u3002\u7136\u540e\uff0c\u4ec5\u5728\u7d2f\u52a0\u7ed3\u675f\u65f6\u5c06\u5176\u51cf\u5c11\u5230\u6807\u51c6 h \u4f4d\u4f59\u6570\u3002</p>"},{"location":"Part_01/04/#46-rns","title":"4.6 RNS \u4e2d\u5feb\u901f\u7b97\u672f\u7684\u9650\u5236","text":"<p>How much faster is RNS arithmetic than conventional (say, binary) arithmetic? We will see later in Chapters 6 and 7 that addition of binary numbers in the range \\([0,  M \u2212 1]\\)\u200b can be done in O(log log  M ) time and with O(log  M ) cost using a variety of methods such as carry-lookahead, conditional-sum, or multilevel carry-select. Both these are optimal to within constant factors, given the fixed-radix positional representation. For example, one can use the constant fan-in argument to establish that the circuit depth of an adder must be at least logarithmic in the number  k = log r M  of digits. Redundant representations allow O(1)-time, O(log  M )-cost addition. What is the best one can do with RNS arithmetic? </p> <p>RNS \u7b97\u672f\u6bd4\u4f20\u7edf\uff08\u4f8b\u5982\u4e8c\u8fdb\u5236\uff09\u7b97\u672f\u5feb\u591a\u5c11\uff1f\u6211\u4eec\u7a0d\u540e\u5c06\u5728\u7b2c 6 \u7ae0\u548c\u7b2c 7 \u7ae0\u4e2d\u770b\u5230 [\\(0, M \u2212 1\\)] \u8303\u56f4\u5185\u7684\u4e8c\u8fdb\u5236\u6570\u7684\u52a0\u6cd5\u53ef\u4ee5\u4f7f\u7528\u5404\u79cd\u65b9\u6cd5\uff08\u4f8b\u5982\u8fdb\u4f4d\u524d\u77bb\u3001\u6761\u4ef6\u548c\u6216\u591a\u7ea7\u8fdb\u4f4d\u9009\u62e9\uff09\u5728 \\(O(log log M )\\) \u65f6\u95f4\u5185\u4ee5 \\(O(log M )\\) \u6210\u672c\u5b8c\u6210\u3002\u8003\u8651\u5230\u56fa\u5b9a\u57fa\u6570\u4f4d\u7f6e\u8868\u793a\uff0c\u8fd9\u4e24\u8005\u5728\u5e38\u6570\u56e0\u5b50\u5185\u90fd\u662f\u6700\u4f73\u7684\u3002\u4f8b\u5982\uff0c\u53ef\u4ee5\u4f7f\u7528\u6052\u5b9a\u6247\u5165\u53c2\u6570\u6765\u786e\u5b9a\u52a0\u6cd5\u5668\u7684\u7535\u8def\u6df1\u5ea6\u5fc5\u987b\u81f3\u5c11\u662f\u6570\u5b57 \\(k = log_r M\\) \u7684\u5bf9\u6570\u3002\u5269\u4f59\u6570\u8868\u793a\u5141\u8bb8 O(1) \u65f6\u95f4\u3001O(log M) \u6210\u672c\u76f8\u52a0\u3002\u4f7f\u7528 RNS \u7b97\u6cd5\u53ef\u4ee5\u505a\u7684\u6700\u597d\u7684\u4e8b\u60c5\u662f\u4ec0\u4e48\uff1f</p> <p>Consider the residue number system RNS( mk\u22121 | \u00b7 \u00b7 \u00b7 |  m 1 |  m 0). Assume that the moduli are chosen as the smallest possible prime numbers to minimize the size of the moduli, and thus maximize computation speed. The following theorems from number theory help us in figuring out the complexity. </p> <p>\u8003\u8651\u4f59\u6570\u7cfb\u7edf \\(RNS(m_{k\u22121} | \u00b7 \u00b7 \u00b7 | m_1 | m_0)\\)\u3002\u5047\u8bbe\u6a21\u6570\u88ab\u9009\u62e9\u4e3a\u5c3d\u53ef\u80fd\u5c0f\u7684\u7d20\u6570\uff0c\u4ee5\u6700\u5c0f\u5316\u6a21\u6570\u7684\u5927\u5c0f\uff0c\u4ece\u800c\u6700\u5927\u5316\u8ba1\u7b97\u901f\u5ea6\u3002\u4ee5\u4e0b\u6570\u8bba\u5b9a\u7406\u5e2e\u52a9\u6211\u4eec\u8ba1\u7b97\u590d\u6742\u6027\u3002</p> <p>THEOREM 4.2 The  i th prime  pi  is asymptotically equal to  i  ln  i. </p> <p>\u5b9a\u7406 4.2 \u7b2c i \u4e2a\u7d20\u6570 \\(p_i\\) \u6e10\u8fd1\u7b49\u4e8e \\(i \\ln i\\)\u3002</p> <p>THEOREM 4.3 The number of primes in [1,  n] is asymptotically equal to n/(ln  n). </p> <p>\u5b9a\u7406 4.3 [\\(1, n\\)] \u4e2d\u7684\u7d20\u6570\u4e2a\u6570\u6e10\u8fd1\u7b49\u4e8e \\(n/(\\ln n)\\)\u3002</p> <p>THEOREM 4.4 The product of all primes in [1,  n] is asymptotically equal to  en. </p> <p>\u5b9a\u7406 4.4 [\\(1, n\\)] \u4e2d\u6240\u6709\u7d20\u6570\u7684\u4e58\u79ef\u6e10\u8fd1\u7b49\u4e8e \\(e^n\\)\u3002</p> <p>Table 4.4 lists some numerical values that can help us understand the asymptotic approximations given in Theorems 4.2 and 4.3. </p> <p>\u88684.4\u5217\u51fa\u4e86\u4e00\u4e9b\u6570\u503c\uff0c\u53ef\u4ee5\u5e2e\u52a9\u6211\u4eec\u7406\u89e3\u5b9a\u74064.2\u548c4.3\u4e2d\u7ed9\u51fa\u7684\u6e10\u8fd1\u8fd1\u4f3c\u3002</p> <p></p> <p>Armed with these results from number theory, we can derive an interesting limit on the speed of RNS arithmetic. </p> <p>\u501f\u52a9\u6570\u8bba\u7684\u8fd9\u4e9b\u7ed3\u679c\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u51fa RNS \u7b97\u672f\u901f\u5ea6\u7684\u6709\u8da3\u9650\u5236\u3002</p> <p>THEOREM 4.5 It is possible to represent all  k-bit binary numbers in RNS with O( k/log  k) moduli such that the largest modulus has O(log  k) bits. </p> <p>\u5b9a\u7406 4.5 \u53ef\u4ee5\u7528 \\(O(k/\\log k)\\) \u6a21\u6765\u8868\u793a RNS \u4e2d\u7684\u6240\u6709 k \u4f4d\u4e8c\u8fdb\u5236\u6570\uff0c\u4f7f\u5f97\u6700\u5927\u6a21\u6570\u5177\u6709 \\(O(\\log k)\\) \u4f4d\u3002</p> <p>Proof: If the largest needed prime is  n, by Theorem 4.4, we must have  en \u2248 2 k . This equality implies  n &lt; k. The number of moduli required is the number of primes less than  n, which by Theorem 4.3 is O( n/log  n) = O( k/log  k). </p> <p>\u8bc1\u660e\uff1a\u5982\u679c\u6240\u9700\u7684\u6700\u5927\u7d20\u6570\u662fn\uff0c\u6839\u636e\u5b9a\u74064.4\uff0c\u6211\u4eec\u5fc5\u987b\u6709\\(e^n \u2248 2^k\\) \u3002\u8fd9\u4e2a\u7b49\u5f0f\u610f\u5473\u7740 \\(n &lt; k\\)\u3002\u6240\u9700\u7684\u6a21\u6570\u662f\u5c0f\u4e8e n \u7684\u7d20\u6570\u7684\u4e2a\u6570\uff0c\u6839\u636e\u5b9a\u7406 4.3 \u4e3a \\(O( n/\\log n)\\) = \\(O( k/\\log k)\\)\u3002</p> <p>As a result, addition of such residue numbers can be performed in O(log log log  M ) time and with O(log  M ) cost. So, the cost of addition is asymptotically comparable to that of binary representation whereas the delay is much smaller, though not constant. </p> <p>\u7ed3\u679c\uff0c\u53ef\u4ee5\u5728 \\(O(\\log \\log \\log M )\\) \u65f6\u95f4\u5185\u4ee5 \\(O(\\log M )\\) \u6210\u672c\u6267\u884c\u6b64\u7c7b\u4f59\u6570\u7684\u52a0\u6cd5\u3002\u56e0\u6b64\uff0c\u52a0\u6cd5\u7684\u6210\u672c\u4e0e\u4e8c\u8fdb\u5236\u8868\u793a\u7684\u6210\u672c\u6e10\u8fd1\u76f8\u5f53\uff0c\u800c\u5ef6\u8fdf\u8981\u5c0f\u5f97\u591a\uff0c\u5c3d\u7ba1\u4e0d\u662f\u6052\u5b9a\u7684\u3002</p> <p>If for implementation ease, we limit ourselves to moduli of the form 2 a  or 2 a \u2212 1, the following results from number theory are applicable. </p> <p>\u5982\u679c\u4e3a\u4e86\u4fbf\u4e8e\u5b9e\u73b0\uff0c\u6211\u4eec\u5c06\u6a21\u6570\u9650\u5236\u4e3a \\(2^a\\) \u6216 \\(2^a \u2212 1\\) \u5f62\u5f0f\uff0c\u5219\u9002\u7528\u4ee5\u4e0b\u6570\u8bba\u7ed3\u679c\u3002</p> <p>THEOREM 4.6 The numbers 2 a \u2212 1 and 2 b \u2212 1 are relatively prime if and only if  a  and  b  are relatively prime. </p> <p>\u5b9a\u7406 4.6 \u5f53\u4e14\u4ec5\u5f53 a \u548c b \u4e92\u8d28\u65f6\uff0c\u6570 \\(2^a \u2212 1\\) \u548c \\(2^b \u2212 1\\) \u4e92\u8d28\u3002</p> <p>THEOREM 4.7 The sum of the first  i  primes is asymptotically O( i 2 ln  i). </p> <p>\u5b9a\u7406 4.7 \u524d \\(i\\) \u4e2a\u7d20\u6570\u4e4b\u548c\u6e10\u8fd1\u4e3a \\(O( i^2 \\ln i)\\) \u3002</p> <p>These theorems allow us to prove the following asymptotic result for low-cost residue number systems. </p> <p>\u8fd9\u4e9b\u5b9a\u7406\u4f7f\u6211\u4eec\u80fd\u591f\u8bc1\u660e\u4f4e\u6210\u672c\u5269\u4f59\u6570\u7cfb\u7edf\u7684\u4ee5\u4e0b\u6e10\u8fd1\u7ed3\u679c\u3002</p> <p>THEOREM 4.8 It is possible to represent all  k-bit binary numbers in RNS with O( (k/  log  k) 1 / 2) low-cost moduli of the form 2 a \u22121 such that the largest modulus has O( (k  log  k) 1 / 2) bits. </p> <p>\u5b9a\u7406 4.8 \u53ef\u4ee5\u7528 \\(2^a \u22121\\) \u5f62\u5f0f\u7684 \\(O( (k/ \\log k)^ {1 / 2})\\) \u4f4e\u6210\u672c\u6a21\u6765\u8868\u793a RNS \u4e2d\u7684\u6240\u6709 k \u4f4d\u4e8c\u8fdb\u5236\u6570\uff0c\u4f7f\u5f97\u6700\u5927\u6a21\u6570\u5177\u6709 \\(O( (k \\log k)^{1 / 2})\\) \u4f4d\u3002</p> <p>Proof: If the largest modulus that we need is 2 l \u2212 1, by Theorem, 4.7, we must have $ l^2 \\ln  l \u2248  k$. This implies that  l = O ((k/  log  k) 1 / 2 ). By Theorem 4.2, the l th prime is approximately  pl \u2248  l  ln  l \u2248 O ((k  log  k) 1 / 2 ). The proof is complete upon noting that to minimize the size of the moduli, we pick the  i th modulus to be 2 pi \u2212 1. </p> <p>\u8bc1\u660e\uff1a\u5982\u679c\u6211\u4eec\u9700\u8981\u7684\u6700\u5927\u6a21\u6570\u662f \\(2^l \u2212 1\\)\uff0c\u6839\u636e\u5b9a\u7406 4.7\uff0c\u6211\u4eec\u5fc5\u987b\u6709 l 2 ln l \u2248 k\u3002\u8fd9\u610f\u5473\u7740 \\(l = O ((k/ \\log k)^{1 / 2} )\\)\u3002\u6839\u636e\u5b9a\u7406 4.2\uff0c\u7b2c \\(l\\)\u4e2a\u7d20\u6570\u8fd1\u4f3c\u4e3a \\(p_l \u2248 l ln l \u2248 O ((k \\log k)^{1 / 2} )\\)\u3002\u8bc1\u660e\u5b8c\u6210\u540e\u6ce8\u610f\u5230\uff0c\u4e3a\u4e86\u6700\u5c0f\u5316\u6a21\u6570\u7684\u5927\u5c0f\uff0c\u6211\u4eec\u9009\u62e9\u7b2c \\(i\\) \u4e2a\u6a21\u6570\u4e3a \\(2^{p_i} \u2212 1\\)\u3002</p> <p>As a result, addition of low-cost residue numbers can be performed in O(log log  M ) time with O(log  M ) cost and thus, asymptotically, offers little advantage over binary representation. </p> <p>\u56e0\u6b64\uff0c\u4f4e\u6210\u672c\u4f59\u6570\u7684\u52a0\u6cd5\u53ef\u4ee5\u5728 O(log log M ) \u65f6\u95f4\u5185\u4ee5 O(log M ) \u6210\u672c\u6267\u884c\uff0c\u56e0\u6b64\u6e10\u8fd1\u5730\u4e0e\u4e8c\u8fdb\u5236\u8868\u793a\u76f8\u6bd4\u51e0\u4e4e\u6ca1\u6709\u4f18\u52bf\u3002</p>"},{"location":"Part_01/04/#_1","title":"\u95ee\u9898\uff08\u7565\uff09","text":""},{"location":"Part_01/04/#_2","title":"\u53c2\u8003\u6587\u732e\u548c\u8fdb\u4e00\u6b65\u9605\u8bfb","text":"<pre><code>[Garn59] Garner, H. L., \u201cThe Residue Number System,\u201d IRE Trans. Electronic Computers, Vol.\n         8, pp. 140\u2013147, 1959.\n[Hung94] Hung, C. Y., and B. Parhami, \u201cAn Approximate Sign Detection Method for Residue\n         Numbers and Its Application to RNS Division,\u201d Computers &amp; Mathematics with\n         Applications, Vol. 27, No. 4, pp. 23\u201335, 1994.\n[Hung95] Hung, C. Y., and B. Parhami, \u201cError Analysis of Approximate Chinese-RemainderTheorem Decoding,\u201d IEEE Trans.                 Computers, Vol. 44, No. 11, pp. 1344\u20131348, 1995.\n[Jenk93] Jenkins, W. K., \u201cFinite Arithmetic Concepts,\u201d in Handbook for Digital Signal\n         Processing, S. K. Mitra and J. F. Kaiser (eds.), Wiley, 1993, pp. 611\u2013675.\n[Merr64] Merrill, R.D., \u201cImproving Digital Computer Performance Using Residue Number\n         Theory,\u201d IEEE Trans. Electronic Computers, Vol. 13, No. 2, pp. 93\u2013101, 1964.\n[Omon07] Omondi, A., and B. Premkumar, Residue Number Systems: Theory and\n         Implementation, Imperial College Press, 2007.\n[Parh76] Parhami, B., \u201cLow-Cost Residue Number Systems for Computer Arithmetic,\u201d\n         AFIPS Conf. Proc., Vol. 45 (1976 National Computer Conference), AFIPS Press,\n         1976, pp. 951\u2013956.\n[Parh93] Parhami, B., and H.-F. Lai, \u201cAlternate Memory Compression Schemes for Modular\n         Multiplication,\u201d IEEE Trans. Signal Processing, Vol. 41, pp. 1378\u20131385, 1993.\n[Parh96] Parhami, B., \u201cA Note on Digital Filter Implementation Using Hybrid RNS-Binary\n         Arithmetic,\u201d Signal Processing, Vol. 51, pp. 65-67, 1996.\n[Parh01] Parhami, B., \u201cRNS Representations with Redundant Residues,\u201d Proc. 35th Asilomar\n         Conf. Signals, Systems, and Computers, pp. 1651\u20131655, 2001.\n[Sode86] Soderstrand, M. A., W. K. Jenkins, G. A. Jullien, and F. J. Taylor (eds.), Residue\n         Number System Arithmetic, IEEE Press, 1986.\n[Szab67] Szabo, N. S., and R. I. Tanaka, Residue Arithmetic and Its Applications to Computer\n         Technology, McGraw-Hill, 1967.\n[Verg08] Vergos, H. T., \u201cA Unifying Approach for Weighted and Diminished-1 Modulo 2n + 1\n         Addition,\u201d IEEE Trans. Circuits and Systems II, Vol. 55, No. 10, pp. 1041\u20131045, 2008.\n</code></pre>"},{"location":"Part_02/","title":"\u52a0\u6cd5\u4e0e\u51cf\u6cd5","text":"<p>ADDITION/SUBTRACTION</p> <p>\u201cIn the arithmetic of love, one plus one equals everything, and two minus one equals nothing.\u201d                \u2014  MIGNON MCLAUGHLIN</p> <p>\u201c\u5728\u7231\u60c5\u7684\u7b97\u672f\u4e2d\uff0c\u4e00\u52a0\u4e00\u7b49\u4e8e\u4e00\u5207\uff0c\u4e8c\u51cf\u4e00\u7b49\u4e8e\u96f6\u3002\u201d               \u2014  \u7c73\u683c\u519c.\u9ea6\u514b\u52b3\u683c\u6797</p> <p>\u201cA man has one hundred dollars and you leave him with two dollars, that\u2019s subtraction.\u201d                \u2014  MAE WEST, MY LITTLE CHICKADEE , 1940</p> <p>\u201c\u4e00\u4e2a\u4eba\u6709\u4e00\u767e\u7f8e\u5143\uff0c\u4f60\u7559\u7ed9\u4ed6\u4e24\u7f8e\u5143\uff0c\u8fd9\u5c31\u662f\u51cf\u6cd5\u3002\u201d               \u2014 \u6885.\u97e6\u65af\u7279\uff0c\u6211\u7684\u5c0f\u5c71\u96c0\uff0c1940</p> <p>ADDITION IS THE MOST COMMON ARITHMETIC OPERATION AND ALSO SERVES AS a building block for synthesizing many other operations. Within digital computers, addition is performed extensively both in explicitly specified computation steps and as a part of implicit ones dictated by indexing and other forms of address arithmetic. In simple arithmetic/logic units that lack dedicated hardware for fast multiplication and division, these latter operations are performed as sequences of additions. A review of fast addition schemes is thus an apt starting point in investigating arithmetic algorithms. Subtraction is normally performed by negating the subtrahend and adding the result to the minuend. This is quite natural,given that an adder must handle signed numbers anyway. Even when implemented directly, a subtractor is quite similar to an adder. Thus, in the following four chapters that constitute this part,we focus almost exclusively on addition:</p> <p>\u52a0\u6cd5\u662f\u6700\u5e38\u89c1\u7684\u7b97\u672f\u8fd0\u7b97\uff0c\u4e5f\u53ef\u4ee5\u4f5c\u4e3a\u8bb8\u591a\u5176\u4ed6\u8fd0\u7b97\u7684\u6784\u5efa\u5757\u3002 \u5728\u6570\u5b57\u8ba1\u7b97\u673a\u4e2d\uff0c\u52a0\u6cd5\u5728\u660e\u786e\u6307\u5b9a\u7684\u8ba1\u7b97\u6b65\u9aa4\u4e2d\u5e7f\u6cdb\u6267\u884c\uff0c\u5e76\u4e14\u4f5c\u4e3a\u7531\u7d22\u5f15\u548c\u5176\u4ed6\u5f62\u5f0f\u7684\u5730\u5740\u7b97\u672f\u6307\u793a\u7684\u9690\u5f0f\u8ba1\u7b97\u6b65\u9aa4\u7684\u4e00\u90e8\u5206\u3002 \u5728\u7f3a\u4e4f\u7528\u4e8e\u5feb\u901f\u4e58\u6cd5\u548c\u9664\u6cd5\u7684\u4e13\u7528\u786c\u4ef6\u7684\u7b80\u5355\u7b97\u672f/\u903b\u8f91\u5355\u5143\u4e2d\uff0c\u8fd9\u4e9b\u8fd0\u7b97\u901a\u5e38\u4f5c\u4e3a\u52a0\u6cd5\u5e8f\u5217\u6267\u884c\u3002 \u56e0\u6b64\uff0c\u5bf9\u5feb\u901f\u52a0\u6cd5\u65b9\u6848\u7684\u56de\u987e\u662f\u7814\u7a76\u7b97\u672f\u7b97\u6cd5\u7684\u4e00\u4e2a\u5408\u9002\u7684\u8d77\u70b9\u3002 \u51cf\u6cd5\u901a\u5e38\u662f\u901a\u8fc7\u5bf9\u88ab\u51cf\u6570\u53d6\u8d1f\u5e76\u5c06\u7ed3\u679c\u4e0e\u88ab\u51cf\u6570\u76f8\u52a0\u6765\u6267\u884c\u7684\u3002 \u8fd9\u662f\u5f88\u81ea\u7136\u7684\uff0c\u56e0\u4e3a\u52a0\u6cd5\u5668\u65e0\u8bba\u5982\u4f55\u90fd\u5fc5\u987b\u5904\u7406\u5e26\u7b26\u53f7\u7684\u6570\u5b57\u3002 \u5373\u4f7f\u76f4\u63a5\u5b9e\u73b0\uff0c\u51cf\u6cd5\u5668\u4e5f\u4e0e\u52a0\u6cd5\u5668\u975e\u5e38\u76f8\u4f3c\u3002 \u56e0\u6b64\uff0c\u5728\u6784\u6210\u8fd9\u4e00\u90e8\u5206\u7684\u4ee5\u4e0b\u56db\u7ae0\u4e2d\uff0c\u6211\u4eec\u51e0\u4e4e\u5b8c\u5168\u5173\u6ce8\u52a0\u6cd5\uff1a</p> <ul> <li>\u7b2c\u4e94\u7ae0 \u57fa\u7840\u7684\u52a0\u6cd5\u4e0e\u8ba1\u6570\u65b9\u6848 Basic Addition and Counting</li> <li>\u7b2c\u516d\u7ae0 \u8d85\u524d\u8fdb\u4f4d\u52a0\u6cd5\u5668 Cary-Lookahead Adders</li> <li>\u7b2c\u4e03\u7ae0 \u5176\u5b83\u9ad8\u901f\u52a0\u6cd5\u5668 Variations in Fast Adders</li> <li>\u7b2c\u516b\u7ae0 \u591a\u64cd\u4f5c\u6570\u52a0\u6cd5 Multi-operand Addition</li> </ul>"},{"location":"Part_02/05/","title":"5. \u57fa\u7840\u7684\u52a0\u6cd5\u4e0e\u8ba1\u6570\u65b9\u6848","text":"<p>Basic Addition and Counting</p> <p>\u201cNot everything that can be counted counts,and not everything that counts can be counted.\u201d               \u2014 ALBERT EINSTEIN</p> <p>\u201c\u4e0d\u662f\u6240\u6709\u53ef\u4ee5\u8ba1\u7b97\u7684\u4e1c\u897f\u90fd\u91cd\u8981\uff0c\u4e5f\u4e0d\u662f\u6240\u6709\u91cd\u8981\u7684\u4e1c\u897f\u90fd\u53ef\u4ee5\u8ba1\u7b97\u3002\u201d               \u2014 \u827e\u5c14\u4f2f\u7279\u7231\u56e0\u65af\u5766</p> <p>As stated in Section 3.1, propagation of carries is a major impediment to high speed addition with fixed-radix positional number representations. Before exploring various ways of speeding up the carry-propagation process, however, we need to examine simple ripple-carry adders, the building blocks used in their construction, the nature of the carry-propagation process, and the special case of counting.Chapter topics include:</p> <p>\u5982\u7b2c 3.1 \u8282\u6240\u8ff0\uff0c\u8fdb\u4f4d\u4f20\u64ad\u662f\u56fa\u5b9a\u57fa\u6570\u4f4d\u7f6e\u6570\u8868\u793a\u6cd5\u505a\u9ad8\u901f\u52a0\u6cd5\u7684\u4e3b\u8981\u969c\u788d\u3002 \u7136\u800c\uff0c\u5728\u63a2\u7d22\u52a0\u901f\u8fdb\u4f4d\u4f20\u64ad\u8fc7\u7a0b\u7684\u5404\u79cd\u65b9\u6cd5\u4e4b\u524d\uff0c\u6211\u4eec\u9700\u8981\u7814\u7a76\u7b80\u5355\u7684\u8109\u52a8\u8fdb\u4f4d\u52a0\u6cd5\u5668\u3001\u5176\u6784\u9020\u4e2d\u4f7f\u7528\u7684\u6784\u5efa\u5757\u3001\u8fdb\u4f4d\u4f20\u64ad\u8fc7\u7a0b\u7684\u6027\u8d28\u4ee5\u53ca\u8ba1\u6570\u7684\u7279\u6b8a\u60c5\u51b5\u3002 \u4e3b\u9898\u5305\u62ec\uff1a</p> <ul> <li>5.1 \u4f4d\u4e32\u884c\u52a0\u6cd5\u5668\u4e0e\u9010\u4f4d\u8fdb\u4f4d\u52a0\u6cd5\u5668 BIT SERIAL AND RIPPLE-CARRY ADDERS</li> <li>5.2 \u6761\u4ef6\u4e0e\u5f02\u5e38 CONDITIONS AND EXCEPTIONS</li> <li>5.3 \u8fdb\u4f4d\u4f20\u64ad\u5206\u6790 ANALYSIS OF CARRY PROPAGATION</li> <li>5.4 \u8fdb\u4f4d\u5b8c\u6210\u7684\u68c0\u6d4b CARRY-COMPLETION DETECTION</li> <li>5.5 \u52a0\u4e0a\u4e00\u4e2a\u5e38\u6570:\u8ba1\u6570\u5668 ADDITION OF A CONSTANT: COUNTERS</li> <li>5.6 \u66fc\u5f7b\u65af\u7279\u8fdb\u4f4d\u94fe\u4e0e\u52a0\u6cd5\u5668 MANCHESTER CARRY CHAINS AND ADDERS</li> </ul>"},{"location":"Part_02/05/#51","title":"5.1 \u4f4d\u4e32\u884c\u52a0\u6cd5\u5668\u4e0e\u9010\u4f4d\u8fdb\u4f4d\u52a0\u6cd5\u5668","text":"<p>Single-bit half-adders (HAs) and full adders (FAs) are versatile building blocks that are used in synthesizing adders and many other arithmetic circuits. A HA receives two input bits x and y, producing a sum bit s = x \u2295 y = xy \u2228 xy and a carry bit c = xy. Figure 5.1 depicts three of the many possible logic realizations of a HA. A HA can be viewed as a single-bit binary adder that produces the 2-bit sum of its 1-bit inputs, namely, \\(x + y = (c_{out}\\ s)_{two}\\), where the plus sign in this expression stands for arithmetic sum rather than logical OR.</p> <p>\u5355\u6bd4\u7279\u534a\u52a0\u5668 (HA) \u548c\u5168\u52a0\u5668 (FA) \u662f\u901a\u7528\u6784\u5efa\u6a21\u5757\uff0c\u7528\u4e8e\u5408\u6210\u52a0\u6cd5\u5668\u548c\u8bb8\u591a\u5176\u4ed6\u7b97\u672f\u7535\u8def\u3002 HA \u63a5\u6536\u4e24\u4e2a\u8f93\u5165\u4f4d x \u548c y\uff0c\u4ea7\u751f\u548c \\(s = x \u2295 y = xy \u2228 xy\\) \u4e0e\u8fdb\u4f4d \\(c = xy\\)\u3002\u56fe 5.1 \u63cf\u8ff0\u4e86 HA \u7684\u591a\u79cd\u53ef\u80fd\u903b\u8f91\u5b9e\u73b0\u4e2d\u7684\u4e09\u79cd\u3002 HA \u53ef\u4ee5\u88ab\u89c6\u4e3a\u4e00\u4f4d\u4e8c\u8fdb\u5236\u52a0\u6cd5\u5668\uff0c\u5b83\u4ea7\u751f 1 \u4f4d\u8f93\u5165\u7684 2 \u4f4d\u548c\uff0c\u5373 \\(x + y = (c_{out}\\ s)_2\\)\uff0c\u5176\u4e2d\u8be5\u8868\u8fbe\u5f0f\u4e2d\u7684\u52a0\u53f7\u4ee3\u8868\u7b97\u672f\u548c\u800c\u4e0d\u662f\u903b\u8f91\u6216\u3002</p> <p></p> <p>\u4e00\u6bd4\u7279\u7684\u5168\u52a0\u5668 FA\u5b9a\u4e49\u4e3a\uff1a</p> \\[ \\begin{array}{l} \\text{\u8f93\u5165: } &amp;\\text{\u64cd\u4f5c\u6570 x, y \u548c\u8f93\u5165\u8fdb\u4f4d }c_{in} &amp;(\\text{\u6216\u7b2ci\u7ea7\u7684 }x_i, y_i, c_i)\\\\ \\text{\u8f93\u51fa: } &amp;\\text{\u52a0\u6cd5\u7684\u548c s \u548c\u8f93\u51fa\u8fdb\u4f4d}c_{out} &amp;(\\text{\u6216\u7b2ci\u7ea7\u7684 }s_i, c_{i+1}) \\\\ &amp; s=x \\oplus y \\oplus c_{in} &amp;(\\text{\u5947\u6570\u6821\u9a8c\u51fd\u6570 odd parity function}) \\\\ &amp; \\ \\ = xyc_{in} \\vee \\bar{x}\\bar{y}c_{in} \\vee \\bar{x}y\\bar{c_{in}} \\vee x\\bar{y}\\bar{c_{in}} \\\\ &amp; c_{out}=xy \\vee xc_{in} \\vee yc_{in} &amp;(\\text{\u591a\u6570\u51fd\u6570 majority function}) \\end{array} \\] <p>An FA can be implemented by using two HAs and an OR gate as shown in Fig. 5.2a. The OR gate in Fig. 5.2a can be replaced with a NAND gate if the two HAs are NAND-gate HAs with complemented carry outputs. Alternatively, one can implement an FA as two-level AND-OR/NAND-NAND circuits according to the preceding logic equations for  s  and  c out (Fig. 5.2b). Because of the importance of the FA as an arithmetic building block, many optimized FA designs exist for a variety of implementation technologies. Figure 5.2c shows an FA, built of seven inverters and two 4-to-1 multiplexers (mux), that is suitable for complementary metal-oxide semiconductor (CMOS) transmission-gate logic implementation. </p> <p>FA \u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528\u4e24\u4e2a HA \u548c\u4e00\u4e2a OR \u95e8\u6765\u5b9e\u73b0\uff0c\u5982\u56fe 5.2a \u6240\u793a\u3002 \u5982\u679c\u4e24\u4e2a HA \u662f\u5177\u6709\u4e92\u8865\u8fdb\u4f4d\u8f93\u51fa\u7684 NAND \u95e8 HA\uff0c\u5219\u56fe 5.2a \u4e2d\u7684 OR \u95e8\u53ef\u4ee5\u7528 NAND \u95e8\u4ee3\u66ff\u3002 \u6216\u8005\uff0c\u53ef\u4ee5\u6839\u636e\u524d\u9762\u7684 s \u548c c out \u903b\u8f91\u65b9\u7a0b\u5c06 FA \u5b9e\u73b0\u4e3a\u4e24\u7ea7 AND-OR/NAND-NAND \u7535\u8def\uff08\u56fe 5.2b\uff09\u3002 \u7531\u4e8e FA \u4f5c\u4e3a\u7b97\u672f\u6784\u5efa\u6a21\u5757\u7684\u91cd\u8981\u6027\uff0c\u56e0\u6b64\u9488\u5bf9\u5404\u79cd\u5b9e\u73b0\u6280\u672f\u5b58\u5728\u8bb8\u591a\u4f18\u5316\u7684 FA \u8bbe\u8ba1\u3002 \u56fe 5.2c \u663e\u793a\u4e86\u7531\u4e03\u4e2a\u53cd\u76f8\u5668\u548c\u4e24\u4e2a 4 \u9009 1 \u591a\u8def\u590d\u7528\u5668 (mux) \u6784\u6210\u7684 FA\uff0c\u9002\u7528\u4e8e\u4e92\u8865\u91d1\u5c5e\u6c27\u5316\u7269\u534a\u5bfc\u4f53 (CMOS) \u4f20\u8f93\u95e8\u903b\u8f91\u5b9e\u73b0\u3002</p> <p></p> <p>Full and half-adders can be used for realizing a variety of arithmetic functions. We will see many examples in this and the following chapters. For instance, a bit-serial adder can be built from an FA and a carry flip-flop, as shown in Fig. 5.3a. The operands are supplied to the FA 1 bit per clock cycle, beginning with the least-significant bit, from a pair of shift registers, and the sum is shifted into a result register. Addition of k-bit numbers can thus be completed in  k  clock cycles. A  k-bit ripple-carry binary adder requires  k  FAs, with the carry-out of the  i th FA connected to the carry-in input of the ( i + 1)th FA. The resulting  k-bit adder produces a  k-bit sum output and a carry-out; alternatively,  c out can be viewed as the most-significant bit of a ( k + 1)-bit sum. Figure 5.3b shows a ripple-carry adder for 4-bit operands, producing a 4-bit or 5-bit sum. </p> <p>\u5168\u52a0\u5668\u548c\u534a\u52a0\u5668\u53ef\u7528\u4e8e\u5b9e\u73b0\u591a\u79cd\u7b97\u672f\u529f\u80fd\u3002\u6211\u4eec\u5c06\u5728\u672c\u7ae0\u548c\u540e\u7eed\u7ae0\u8282\u4e2d\u770b\u5230\u8bb8\u591a\u793a\u4f8b\u3002\u4f8b\u5982\uff0c\u4f4d\u4e32\u884c\u52a0\u6cd5\u5668\u53ef\u4ee5\u7531 FA \u548c\u8fdb\u4f4d\u89e6\u53d1\u5668\u6784\u5efa\uff0c\u5982\u56fe 5.3a \u6240\u793a\u3002\u6bcf\u4e2a\u65f6\u949f\u5468\u671f\u4ece\u6700\u4f4e\u6709\u6548\u4f4d\u5f00\u59cb\uff0c\u4ece\u4e00\u5bf9\u79fb\u4f4d\u5bc4\u5b58\u5668\u5411 FA \u63d0\u4f9b 1 \u4f4d\u64cd\u4f5c\u6570\uff0c\u5e76\u5c06\u603b\u548c\u79fb\u5165\u7ed3\u679c\u5bc4\u5b58\u5668\u3002\u56e0\u6b64\uff0ck\u4f4d\u6570\u7684\u52a0\u6cd5\u53ef\u4ee5\u5728k\u4e2a\u65f6\u949f\u5468\u671f\u5185\u5b8c\u6210\u3002 k \u4f4d\u7eb9\u6ce2\u8fdb\u4f4d\u4e8c\u8fdb\u5236\u52a0\u6cd5\u5668\u9700\u8981 k \u4e2a FA\uff0c\u7b2c i \u4e2a FA \u7684\u8fdb\u4f4d\u8f93\u51fa\u8fde\u63a5\u5230\u7b2c ( i + 1) \u4e2a FA \u7684\u8fdb\u4f4d\u8f93\u5165\u3002\u7531\u6b64\u4ea7\u751f\u7684 k \u4f4d\u52a0\u6cd5\u5668\u4ea7\u751f k \u4f4d\u548c\u8f93\u51fa\u548c\u8fdb\u4f4d\u8f93\u51fa\uff1b\u6216\u8005\uff0cc out \u53ef\u4ee5\u88ab\u89c6\u4e3a ( k + 1) \u4f4d\u548c\u7684\u6700\u9ad8\u6709\u6548\u4f4d\u3002\u56fe 5.3b \u663e\u793a\u4e86 4 \u4f4d\u64cd\u4f5c\u6570\u7684\u7eb9\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\uff0c\u4ea7\u751f 4 \u4f4d\u6216 5 \u4f4d\u548c\u3002</p> <p></p> <p>The ripple-carry adder shown in Fig. 5.3b leads directly to a CMOS implementation with transmission-gate logic using the FA design of Fig. 5.2c. A possible layout is depicted in Fig. 5.4, which also shows the approximate area requirements for the 4-bit ripple-carry adder in units of \u03bb (half the minimum feature size). For details of this particular design, refer to [Puck94, pp. 213\u2013223].</p> <p>\u56fe 5.3b \u6240\u793a\u7684\u7eb9\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\u76f4\u63a5\u5bfc\u81f4\u4f7f\u7528\u56fe 5.2c \u7684 FA \u8bbe\u8ba1\u7684\u5e26\u6709\u4f20\u8f93\u95e8\u903b\u8f91\u7684 CMOS \u5b9e\u73b0\u3002\u56fe 5.4 \u63cf\u8ff0\u4e86\u4e00\u79cd\u53ef\u80fd\u7684\u5e03\u5c40\uff0c\u5176\u4e2d\u8fd8\u663e\u793a\u4e86 4 \u4f4d\u7eb9\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\u7684\u5927\u81f4\u9762\u79ef\u8981\u6c42\uff0c\u5355\u4f4d\u4e3a \u03bb\uff08\u6700\u5c0f\u7279\u5f81\u5c3a\u5bf8\u7684\u4e00\u534a\uff09\u3002\u6709\u5173\u6b64\u7279\u5b9a\u8bbe\u8ba1\u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605 [Puck94\uff0c\u7b2c 213\u2013223 \u9875]\u3002</p> <p></p> <p>The latency of a  k-bit ripple-carry adder can be derived by considering the worst-case signal propagation path. As shown in Fig. 5.5, the critical path usually begins at the  x 0 or  y 0 input, proceeds through the carry-propagation chain to the leftmost FA, and terminates at the  sk\u22121 output. Of course, it is possible that for some FA implementations, the critical path might begin at  c 0 and/or terminate at  ck . However, given that the delay from carry-in to carry-out is more important than from  x  to carry-out or from carry-in to s, FA designs often minimize the delay from carry-in to carry-out, making the path shown in Fig. 5.5 the one with the largest delay. </p> <p>\\(k\\) \u4f4d\u7eb9\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\u7684\u5ef6\u8fdf\u53ef\u4ee5\u901a\u8fc7\u8003\u8651\u6700\u574f\u60c5\u51b5\u7684\u4fe1\u53f7\u4f20\u64ad\u8def\u5f84\u6765\u5f97\u51fa\u3002\u5982\u56fe 5.5 \u6240\u793a\uff0c\u5173\u952e\u8def\u5f84\u901a\u5e38\u4ece x 0 \u6216 y 0 \u8f93\u5165\u5f00\u59cb\uff0c\u901a\u8fc7\u8fdb\u4f4d\u4f20\u64ad\u94fe\u5230\u8fbe\u6700\u5de6\u8fb9\u7684 FA\uff0c\u5e76\u5728 \\(s_{k\u22121}\\) \u8f93\u51fa\u5904\u7ec8\u6b62\u3002\u5f53\u7136\uff0c\u5bf9\u4e8e\u67d0\u4e9b FA \u5b9e\u73b0\uff0c\u5173\u952e\u8def\u5f84\u53ef\u80fd\u59cb\u4e8e \\(c_0\\) \u4e0e/\u6216\u7ec8\u6b62\u4e8e \\(c_k\\) \u3002\u7136\u800c\uff0c\u8003\u8651\u5230\u4ece\u8fdb\u4f4d\u5230\u8fdb\u4f4d\u7684\u5ef6\u8fdf\u6bd4\u4ecex\u5230\u8fdb\u4f4d\u6216\u4ece\u8fdb\u4f4d\u5230s\u66f4\u91cd\u8981\uff0cFA\u8bbe\u8ba1\u901a\u5e38\u4f1a\u6700\u5c0f\u5316\u4ece\u8fdb\u4f4d\u5230\u8fdb\u4f4d\u7684\u5ef6\u8fdf\uff0c\u4f7f\u56fe5.5\u6240\u793a\u7684\u8def\u5f84\u6210\u4e3a\u5ef6\u8fdf\u6700\u5927\u7684\u8def\u5f84\u3002</p> <p></p> <p>We can thus write the following expression for the latency of a  k-bit ripple-carry adder:</p> <p>\u56e0\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u4e3a k \u4f4d\u7eb9\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\u7684\u5ef6\u8fdf\u7f16\u5199\u4ee5\u4e0b\u8868\u8fbe\u5f0f\uff1a</p> \\[ T_{ripple\u2212add} = T_{FA} (x, y \u2192 c out ) + (k \u2212 2 ) \u00d7 T_{FA} (c_{in} \u2192 c_{out} ) + T_{FA} (c_{in} \u2192 s)  \\] <p>where  \\(T_{FA}(input \u2192 output)\\) represents the latency of an FA on the path between its specified input and output. As an approximation to the foregoing, we can say that the latency of a ripple-carry adder is \\(kT _{FA}\\) </p> <p>\u5176\u4e2d \\(T_{FA}(\u8f93\u5165 \u2192 \u8f93\u51fa)\\) \u8868\u793a FA \u5728\u5176\u6307\u5b9a\u8f93\u5165\u548c\u8f93\u51fa\u4e4b\u95f4\u7684\u8def\u5f84\u4e0a\u7684\u5ef6\u8fdf\u3002\u4f5c\u4e3a\u524d\u8ff0\u7684\u8fd1\u4f3c\uff0c\u6211\u4eec\u53ef\u4ee5\u8bf4\u884c\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\u7684\u5ef6\u8fdf\u4e3a \\(kT _{FA}\\) \u3002</p> <p>We see that the latency grows linearly with  k, making the ripple-carry design undesirable for large  k  or for high-performance arithmetic units. Note that the latency of a bit-serial adder is also O( k), although the constant of proportionality is larger here because of the latching and clocking overheads. </p> <p>\u6211\u4eec\u770b\u5230\u5ef6\u8fdf\u968f k \u7ebf\u6027\u589e\u957f\uff0c\u4f7f\u5f97\u7eb9\u6ce2\u8fdb\u4f4d\u8bbe\u8ba1\u5bf9\u4e8e\u5927 k \u6216\u9ad8\u6027\u80fd\u7b97\u672f\u5355\u5143\u6765\u8bf4\u662f\u4e0d\u53ef\u53d6\u7684\u3002\u8bf7\u6ce8\u610f\uff0c\u4f4d\u4e32\u884c\u52a0\u6cd5\u5668\u7684\u5ef6\u8fdf\u4e5f\u662f \\(O(k)\\)\uff0c\u5c3d\u7ba1\u7531\u4e8e\u9501\u5b58\u548c\u65f6\u949f\u5f00\u9500\uff0c\u6bd4\u4f8b\u5e38\u6570\u5728\u8fd9\u91cc\u8f83\u5927\u3002</p> <p>Full and half-adders, as well as multibit binary adders, are powerful building blocks that can also be used in realizing nonarithmetic functions if the need arises. For example, a 4-bit binary adder with  c in, two 4-bit operand inputs,  c out, and a 4-bit sum output can be used to synthesize the four-variable logic function  w \u2228  xyz  and its complement, as depicted and justified in Fig. 5.6. The logic expressions written next to the arrows in Fig. 5.6 represent the carries between various stages. Note, however, that the 4-bit adder need not be implemented as a ripple-carry adder for the results at the outputs to be valid.</p> <p>\u5168\u52a0\u6cd5\u5668\u548c\u534a\u52a0\u6cd5\u5668\u4ee5\u53ca\u591a\u4f4d\u4e8c\u8fdb\u5236\u52a0\u6cd5\u5668\u662f\u529f\u80fd\u5f3a\u5927\u7684\u6784\u5efa\u5757\uff0c\u5982\u679c\u9700\u8981\uff0c\u4e5f\u53ef\u7528\u4e8e\u5b9e\u73b0\u975e\u7b97\u672f\u51fd\u6570\u3002\u4f8b\u5982\uff0c\u4e00\u4e2a\u5177\u6709 \\(c_{in}\\) \u3001\u4e24\u4e2a 4 \u4f4d\u64cd\u4f5c\u6570\u8f93\u5165, \\(c_{out}\\) \u548c\u4e00\u4e2a 4 \u4f4d\u548c\u8f93\u51fa\u7684 4 \u4f4d\u4e8c\u8fdb\u5236\u52a0\u6cd5\u5668\u53ef\u7528\u4e8e\u5408\u6210\u56db\u53d8\u91cf\u903b\u8f91\u51fd\u6570$ w \u2228 xyz$ \u53ca\u5176\u6c42\u53cd\uff0c\u5982\u56fe 5.6 \u6240\u793a\u548c\u8bc1\u660e\u3002\u7bad\u5934\u65c1\u8fb9\u5199\u7684\u903b\u8f91\u8868\u8fbe\u5f0f\u8868\u793a\u5404\u4e2a\u9636\u6bb5\u4e4b\u95f4\u7684\u8fdb\u4f4d\u3002\u4f46\u8bf7\u6ce8\u610f\u7684\u662f4 \u4f4d\u52a0\u6cd5\u5668\u4e0d\u4e00\u5b9a\u5b9e\u73b0\u4e3a\u7eb9\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\uff0c\u8f93\u51fa\u7ed3\u679c\u8fd8\u662f\u540c\u6837\u6709\u6548\u7684\u3002</p> <p></p>"},{"location":"Part_02/05/#52","title":"5.2 \u6761\u4ef6\u4e0e\u5f02\u5e38","text":"<p>When a  k-bit adder is used in an arithmetic/logic unit (ALU), it is customary to provide the  k-bit sum along with information about the following outcomes, which are associated with flag bits within a condition/exception register:</p> <p>\u5f53\u7b97\u672f/\u903b\u8f91\u5355\u5143 (ALU) \u4e2d\u4f7f\u7528 k \u4f4d\u52a0\u6cd5\u5668\u65f6\uff0c\u901a\u5e38\u4f1a\u63d0\u4f9b k \u4f4d\u548c\u4ee5\u53ca\u6709\u5173\u4ee5\u4e0b\u7ed3\u679c\u7684\u4fe1\u606f\uff0c\u8fd9\u4e9b\u7ed3\u679c\u4e0e\u6761\u4ef6/\u5f02\u5e38\u5bc4\u5b58\u5668\u4e2d\u7684\u6807\u5fd7\u4f4d\u76f8\u5173\u8054\uff1a</p> \\[ \\begin{array}{l} c_{out}  &amp; \\text{\u8868\u793a\u4ea7\u751f\u4e86 1 \u7684\u8fdb\u4f4d\u8f93\u51fa} \\\\ Overflow &amp; \\text{\u8868\u793a\u8f93\u51fa\u7684\u548c\u4e0d\u6b63\u786e} \\\\ Negative &amp; \\text{\u8868\u793a\u76f8\u52a0\u7ed3\u679c\u4e3a\u8d1f} \\\\ Zero     &amp; \\text{\u8868\u793a\u76f8\u52a0\u7ed3\u679c\u4e3a\u96f6} \\\\ \\end{array} \\] <p>When we are adding unsigned numbers,  c out and \u201coverflow\u201d are one and the same, and the \u201csign\u201d condition is obviously irrelevant. For 2\u2019s-complement addition, overflow occurs when two numbers of like sign are added and a result of the opposite sign is produced. Thus</p> <p>\u5f53\u6211\u4eec\u5bf9\u65e0\u7b26\u53f7\u6570\u8fdb\u884c\u52a0\u6cd5\u65f6\uff0c\\(c_{out}\\) \u548c\u201coverflow\u201d\u662f\u4e00\u56de\u4e8b\uff0c\u800c\u201csign\u201d\u6761\u4ef6\u663e\u7136\u662f\u4e0d\u76f8\u5173\u7684\u3002\u5bf9\u4e8e 2 \u7684\u8865\u7801\u52a0\u6cd5\uff0c\u5f53\u4e24\u4e2a\u76f8\u540c\u7b26\u53f7\u7684\u6570\u5b57\u76f8\u52a0\u5e76\u4ea7\u751f\u76f8\u53cd\u7b26\u53f7\u7684\u7ed3\u679c\u65f6\uff0c\u5c31\u4f1a\u53d1\u751f\u6ea2\u51fa\u3002\u56e0\u6b64</p> <p>\u200b       \\(Overflow_{2\u2019s-compl} = x_{k\u22121} y_{k\u22121} \\bar{s}_{k\u22121} \\vee \\bar{x}_{k\u22121} \\bar{y}_{k\u22121} s_{k\u22121}\\)</p> <p>It is fairly easy to show that overflow in 2\u2019s-complement addition can be detected from the leftmost two carries as follows:</p> <p>\u5f88\u5bb9\u6613\u8bc1\u660e\uff0c\u53ef\u4ee5\u4ece\u6700\u5de6\u8fb9\u7684\u4e24\u4e2a\u8fdb\u4f4d\u68c0\u6d4b\u5230 2 \u8865\u7801\u52a0\u6cd5\u4e2d\u7684\u6ea2\u51fa\uff0c\u5982\u4e0b\u6240\u793a\uff1a</p> <p>\u200b       \\(Overflow_{2\u2019s-compl} = c_k \\oplus c_{k\u22121} = c_k\\bar{c}_{k\u22121} \\vee \\bar{c}_kc_{k\u22121}\\)</p> <p>In 2\u2019s-complement addition,  c out has no significance. However, since a single adder is frequently used to add both unsigned and 2\u2019s-complement numbers,  c out is a useful output as well. Figure 5.7 shows a ripple-carry implementation of an unsigned or 2\u2019s-complement adder with auxiliary outputs for conditions and exceptions. Because of the large number of inputs into the NOR gate that tests for 0, it must be implemented as an OR tree followed by an inverter. </p> <p>\u5728 2 \u7684\u8865\u7801\u52a0\u6cd5\u4e2d\uff0c\\(c_{out}\\) \u6ca1\u6709\u610f\u4e49\u3002\u7136\u800c\uff0c\u7531\u4e8e\u5355\u4e2a\u52a0\u6cd5\u5668\u7ecf\u5e38\u7528\u4e8e\u5c06\u65e0\u7b26\u53f7\u6570\u548c 2 \u8865\u7801\u6570\u76f8\u52a0\uff0c\u56e0\u6b64 \\(c_{out}\\) \u4e5f\u662f\u4e00\u4e2a\u6709\u7528\u7684\u8f93\u51fa\u3002\u56fe 5.7 \u663e\u793a\u4e86\u5e26\u6761\u4ef6\u548c\u5f02\u5e38\u8f85\u52a9\u8f93\u51fa\u7684\u65e0\u7b26\u53f7\u6216 2 \u8865\u7801\u52a0\u6cd5\u5668\u7684\u7eb9\u6ce2\u8fdb\u4f4d\u5b9e\u73b0\u3002\u7531\u4e8e\u6d4b\u8bd5 0 \u7684 NOR \u95e8\u6709\u5927\u91cf\u8f93\u5165\uff0c\u56e0\u6b64\u5fc5\u987b\u5c06\u5176\u5b9e\u73b0\u4e3a OR \u6811\uff0c\u540e\u8ddf\u4e00\u4e2a\u53cd\u76f8\u5668\u3002</p> <p></p> <p>When the sum of unsigned input operands is too large for representation in  k  bits, an overflow exception is indicated by the  c out signal in Fig. 5.5 and a \u201cwrapped\u201d value, which is 2 k  less than the correct sum, appears as the output. A similar wrapped value may appear for signed addition in the event of overflow. In certain applications, a \u201csaturated\u201d  value would be more appropriate than a wrapped value because a saturated value at least maintains the proper ordering of various sums. For example, if the numbers being manipulated represent the pixel intensities in an image, then an intensity value that is too large should be represented as the maximum possible intensity level, rather than as a wrapped value that could be much smaller. A saturating unsigned adder can be obtained from any unsigned adder design by using a multiplexer at the output, with its control input tied to the adder\u2019s overflow signal. A signed saturating adder can be similarly designed.</p> <p>\u5f53\u65e0\u7b26\u53f7\u8f93\u5165\u64cd\u4f5c\u6570\u7684\u603b\u548c\u592a\u5927\u800c\u65e0\u6cd5\u7528 k \u4f4d\u8868\u793a\u65f6\uff0c\u56fe 5.5 \u4e2d\u7684 \\(c_{out}\\) \u4fe1\u53f7\u4f1a\u6307\u793a\u6ea2\u51fa\u5f02\u5e38\uff0c\u5e76\u4e14\u8f93\u51fa\u4f1a\u51fa\u73b0\u6bd4\u6b63\u786e\u603b\u548c\u5c0f \\(2^k\\) \u7684\u201c\u7ed5\u56de\u201d\u7684\u622a\u65ad\u503c\u3002\uff0c\u6709\u7b26\u53f7\u52a0\u6cd5\u5982\u679c\u53d1\u751f\u6ea2\u51fa\u4e5f\u53ef\u80fd\u4f1a\u51fa\u73b0\u7c7b\u4f3c\u7684\u7ed5\u56de\u503c\u3002\u5728\u67d0\u4e9b\u5e94\u7528\u4e2d\uff0c\u201c\u9971\u548c\u201d\u503c\u6bd4\u7ed5\u56de\u503c\u66f4\u5408\u9002\uff0c\u56e0\u4e3a\u9971\u548c\u503c\u81f3\u5c11\u7ef4\u6301\u4e86\u7ed3\u679c\u7684\u6b63\u786e\u6392\u5e8f\u3002\u4f8b\u5982\uff0c\u5982\u679c\u6240\u64cd\u4f5c\u7684\u6570\u5b57\u8868\u793a\u56fe\u50cf\u4e2d\u7684\u50cf\u7d20\u5f3a\u5ea6\uff0c\u5219\u592a\u5927\u7684\u5f3a\u5ea6\u503c\u5e94\u8868\u793a\u4e3a\u6700\u5927\u53ef\u80fd\u7684\u5f3a\u5ea6\u7ea7\u522b\uff0c\u800c\u4e0d\u662f\u8868\u793a\u4e3a\u53ef\u80fd\u5c0f\u5f97\u591a\u7684\u7ed5\u56de\u503c\u3002\u901a\u8fc7\u5728\u8f93\u51fa\u5904\u4f7f\u7528\u591a\u8def\u590d\u7528\u5668\uff0c\u5176\u63a7\u5236\u8f93\u5165\u4e0e\u52a0\u6cd5\u5668\u7684\u6ea2\u51fa\u4fe1\u53f7\u76f8\u5173\u8054\uff0c\u53ef\u4ee5\u4ece\u4efb\u4f55\u65e0\u7b26\u53f7\u52a0\u6cd5\u5668\u8bbe\u8ba1\u4e2d\u83b7\u5f97\u9971\u548c\u65e0\u7b26\u53f7\u52a0\u6cd5\u5668\u3002\u6709\u7b26\u53f7\u9971\u548c\u52a0\u6cd5\u5668\u53ef\u4ee5\u7c7b\u4f3c\u5730\u8bbe\u8ba1\u3002</p>"},{"location":"Part_02/05/#53","title":"5.3 \u8fdb\u4f4d\u4f20\u64ad\u5206\u6790","text":"<p>Various ways of dealing with the carry problem were enumerated in Section 3.1. Some of the methods already discussed include limiting the propagation of carries (hybrid signed-digit, residue number system) or eliminating carry propagation altogether (redundant representation). The latter approach, when used for adding a set of numbers in carry-save form, can be viewed as a way of amortizing the propagation delay of the final conversion step over many additions, thus making the per-add contribution of the carry-propagation delay quite small. What remains to be discussed, in this and the following two chapters, is how one can speed up a single addition operation involving conventional (binary) operands. </p> <p>3.1 \u8282\u5217\u4e3e\u4e86\u5904\u7406\u8fdb\u4f4d\u95ee\u9898\u7684\u5404\u79cd\u65b9\u6cd5\u3002\u5df2\u7ecf\u8ba8\u8bba\u7684\u4e00\u4e9b\u65b9\u6cd5\u5305\u62ec\u9650\u5236\u8fdb\u4f4d\u4f20\u64ad\uff08\u6df7\u5408\u6709\u7b26\u53f7\u6570\u5b57\u3001\u5269\u4f59\u6570\u7cfb\u7edf\uff09\u6216\u5b8c\u5168\u6d88\u9664\u8fdb\u4f4d\u4f20\u64ad\uff08\u5197\u4f59\u8868\u793a\uff09\u3002\u540e\u4e00\u79cd\u65b9\u6cd5\uff0c\u5f53\u7528\u4e8e\u4ee5\u8fdb\u4f4d\u4fdd\u5b58\u5f62\u5f0f\u6dfb\u52a0\u4e00\u7ec4\u6570\u5b57\u65f6\uff0c\u53ef\u4ee5\u88ab\u89c6\u4e3a\u4e00\u79cd\u5c06\u6700\u7ec8\u8f6c\u6362\u6b65\u9aa4\u7684\u4f20\u64ad\u5ef6\u8fdf\u5206\u644a\u5230\u591a\u6b21\u52a0\u6cd5\u4e0a\u7684\u65b9\u6cd5\uff0c\u4ece\u800c\u4f7f\u8fdb\u4f4d\u4f20\u64ad\u5ef6\u8fdf\u7684\u6bcf\u6b21\u6dfb\u52a0\u8d21\u732e\u76f8\u5f53\u5c0f\u3002\u5728\u672c\u7ae0\u548c\u63a5\u4e0b\u6765\u7684\u4e24\u7ae0\u4e2d\uff0c\u4ecd\u6709\u5f85\u8ba8\u8bba\u7684\u662f\u5982\u4f55\u52a0\u901f\u6d89\u53ca\u4f20\u7edf\uff08\u4e8c\u8fdb\u5236\uff09\u64cd\u4f5c\u6570\u7684\u5355\u4e2a\u52a0\u6cd5\u8fd0\u7b97\u3002</p> <p>We begin by analyzing how and to what extent carries propagate when adding two binary numbers. Consider the example addition of 16-bit binary numbers depicted in Fig. 5.8, where the carry chains of lengths 2, 3, 6, and 4 are shown. The length of a carry chain is the number of digit positions from where the carry is generated up to and including where it is finally absorbed or annihilated. A carry chain of length 0 thus means \u201cno carry production,\u201d and a chain of length 1 means that the carry is absorbed in the next position. We are interested in the length of the longest propagation chain (6 in Fig. 5.8), which dictates the adder\u2019s latency. </p> <p>\u6211\u4eec\u9996\u5148\u5206\u6790\u6dfb\u52a0\u4e24\u4e2a\u4e8c\u8fdb\u5236\u6570\u65f6\u8fdb\u4f4d\u5982\u4f55\u4f20\u64ad\u4ee5\u53ca\u4f20\u64ad\u5230\u4ec0\u4e48\u7a0b\u5ea6\u3002\u8003\u8651\u56fe 5.8 \u4e2d\u6240\u793a\u7684 16 \u4f4d\u4e8c\u8fdb\u5236\u6570\u52a0\u6cd5\u793a\u4f8b\uff0c\u5176\u4e2d\u663e\u793a\u4e86\u957f\u5ea6\u4e3a 2\u30013\u30016 \u548c 4 \u7684\u8fdb\u4f4d\u94fe\u3002\u8fdb\u4f4d\u94fe\u7684\u957f\u5ea6\u662f\u6307\u4ece\u751f\u6210\u8fdb\u4f4d\u5230\uff08\u5305\u62ec\u8fdb\u4f4d\u6700\u7ec8\u88ab\u5438\u6536\u6216\u6d88\u9664\uff09\u7684\u4f4d\u6570\u4f4d\u7f6e\u3002\u56e0\u6b64\uff0c\u957f\u5ea6\u4e3a 0 \u7684\u8fdb\u4f4d\u94fe\u610f\u5473\u7740\u201c\u65e0\u8fdb\u4f4d\u4ea7\u751f\u201d\uff0c\u957f\u5ea6\u4e3a 1 \u7684\u8fdb\u4f4d\u94fe\u610f\u5473\u7740\u8fdb\u4f4d\u88ab\u5438\u6536\u5230\u4e0b\u4e00\u4e2a\u4f4d\u7f6e\u3002\u6211\u4eec\u611f\u5174\u8da3\u7684\u662f\u6700\u957f\u4f20\u64ad\u94fe\u7684\u957f\u5ea6\uff08\u5982\u56fe 5.8 \u4e2d\u76846\uff09\uff0c\u5b83\u51b3\u5b9a\u4e86\u52a0\u6cd5\u5668\u7684\u5ef6\u8fdf\u3002</p> <p></p> <p>Given binary numbers with random bit values, for each position  i  we have </p> <ul> <li>Probability of carry generation = 1 / 4</li> <li>Probability of carry annihilation = 1 / 4</li> <li>Probability of carry propagation = 1 / 2</li> </ul> <p>\u7ed9\u5b9a\u5177\u6709\u968f\u673a\u4f4d\u503c\u7684\u4e8c\u8fdb\u5236\u6570\uff0c\u5bf9\u4e8e\u6bcf\u4e2a\u4f4d\u7f6e \\(i\\)\uff0c\u6211\u4eec\u6709</p> <ul> <li>\u8fdb\u4f4d\u751f\u6210\u7684\u6982\u7387 = 1 / 4</li> <li>\u8fdb\u4f4d\u6e6e\u6ca1\u7684\u6982\u7387 = 1 / 4 </li> <li>\u8fdb\u4f4d\u4f20\u64ad\u7684\u6982\u7387 = 1 / 2</li> </ul> <p>The probability that a carry generated at position i will propagate up to and including position j \u2212 1 and stop at position j (j &gt; i) is 2\u2212 (j\u22121\u2212 i) \u00d7 1 / 2 = 2\u2212 (j\u2212 i). The expected length of the carry chain that starts at bit position i is, therefore, given by k\u22121</p> <p>\u4f4d\u7f6e \\(i\\) \u751f\u6210\u7684\u8fdb\u4f4d\u4f20\u64ad\u5230\u4f4d\u7f6e \\(j \u2212 1\\)\uff08\u5305\u62ec\u4f4d\u7f6e \\(j \u2212 1\\)\uff09\u5e76\u505c\u6b62\u5728\u4f4d\u7f6e \\(j (j &gt; i)\\) \u7684\u6982\u7387\u4e3a \\(2^{\u2212 (j\u22121\u2212 i)} \u00d7 1 / 2 = 2^{\u2212 (j\u2212 i)}\\)\u3002\u56e0\u6b64\uff0c\u4ece\u4f4d\u4f4d\u7f6e$ i$ \u5f00\u59cb\u7684\u8fdb\u4f4d\u94fe\u7684\u957f\u5ea6\u671f\u671b\u503c\u5982\u4e0b\u7ed9\u51fa</p> \\[ \\begin{array}{l} \\sum_{j=i+1}^{k-1}(j-i)2^{-(j-i)} &amp;+(k-i)2^{-(k-1-i)} = \\\\ \\sum_{l=1}^{k-1-i}l2^{-l} &amp;+(k-i)2^{-(k-1-i)} = \\\\ 2 - (k-i+1)2^{-(k-1-i)}   &amp;+ (k-i)2^{-(k-1-i)} = \\\\ 2 - 2^{-(k-i-1)} \\end{array} \\] <p>\u5176\u4e2d\u7b80\u5316\u662f\u57fa\u4e8e\u7b49\u5f0f \\(\\sum_{l=1}^{p}l2^l=2-(p+2)2^{-p}\\)\u3002</p> <p>preceding derivation, the term  (k \u2212 i)  2\u2212 (k\u22121\u2212 i)  is added to the summation because carry definitely stops at position  k; so we do not multiply the term 2\u2212 (k\u22121\u2212 i)  by \u00bd, as was done for the terms within the summation. </p> <p>\u5728\u524d\u9762\u7684\u63a8\u5bfc\u4e2d\uff0c\u7531\u4e8e\u8fdb\u4f4d\u80af\u5b9a\u5728\u4f4d\u7f6e k \u5904\u505c\u6b62\uff0c\u56e0\u6b64\u5c06 \\((k \u2212 i) 2^{\u2212 (k\u22121\u2212 i)}\\) \u9879\u6dfb\u52a0\u5230\u6c42\u548c\u4e2d\uff1b\u56e0\u6b64\uff0c\u6211\u4eec\u4e0d\u4f1a\u50cf\u5bf9\u6c42\u548c\u4e2d\u7684\u9879\u90a3\u6837\u5c06 \\(2^{\u2212 (k\u22121\u2212 i)}\\) \u9879\u4e58\u4ee5 \u00bd\u3002</p> <p>The preceding result indicates that for  i k, the expected length of the carry chain that starts at position  i  is approximately 2. Note that the formula checks out for the extreme case of  i =  k \u2212 1, since in this case, the exact carry chain length, and thus its expected value, is 1. We conclude that carry chains are usually quite short. </p> <p>\u524d\u9762\u7684\u7ed3\u679c\u8868\u660e\uff0c\u5bf9\u4e8e \\(i \\ll k\\)\uff0c\u4ece\u4f4d\u7f6e i \u5f00\u59cb\u7684\u8fdb\u4f4d\u94fe\u7684\u9884\u671f\u957f\u5ea6\u7ea6\u4e3a 2\u3002\u8bf7\u6ce8\u610f\uff0c\u8be5\u516c\u5f0f\u68c0\u67e5\u4e86 \\(i = k \u2212 1\\) \u7684\u6781\u7aef\u60c5\u51b5\uff0c\u56e0\u4e3a\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u51c6\u786e\u7684\u8fdb\u4f4d\u94fe\u957f\u5ea6\u53ca\u5176\u9884\u671f\u503c\u662f 1\u3002\u6211\u4eec\u5f97\u51fa\u7ed3\u8bba\uff0c\u8fdb\u4f4d\u94fe\u901a\u5e38\u76f8\u5f53\u77ed\u3002</p> <p>On the average, the longest carry chain in adding  k-bit numbers is of length log2  k. This was first observed and proved by Burks, Goldstine, and von Neumann in their classic report defining the structure of a stored-program computer [Burk46]. An interesting analysis based on Kolmogorov complexity theory has been offered in [Beig98]. The latter paper also cites past attempts at providing alternate or more complete proofs of the proposition. </p> <p>\u5e73\u5747\u800c\u8a00\uff0ck \u4f4d\u6570\u5b57\u76f8\u52a0\u65f6\u6700\u957f\u7684\u8fdb\u4f4d\u94fe\u957f\u5ea6\u4e3a \\(\\log_2 k\\)\u3002Burks\u3001Goldstine \u548c von Neumann \u5728\u5b9a\u4e49\u5b58\u50a8\u7a0b\u5e8f\u8ba1\u7b97\u673a\u7ed3\u6784\u7684\u7ecf\u5178\u62a5\u544a\u4e2d\u9996\u6b21\u89c2\u5bdf\u5230\u5e76\u8bc1\u660e\u4e86\u8fd9\u4e00\u70b9 [Burk46]\u3002 [Beig98] \u4e2d\u63d0\u4f9b\u4e86\u57fa\u4e8e \u67ef\u5c14\u83ab\u54e5\u6d1b\u592b\u590d\u6742\u5ea6\u7406\u8bba\u7684\u6709\u8da3\u5206\u6790\u3002\u540e\u4e00\u7bc7\u8bba\u6587\u8fd8\u5f15\u7528\u4e86\u8fc7\u53bb\u4e3a\u8be5\u547d\u9898\u63d0\u4f9b\u66ff\u4ee3\u6216\u66f4\u5b8c\u6574\u8bc1\u660e\u7684\u5c1d\u8bd5\u3002</p> <p>Here is one way to prove the logarithmic average length of the worst-case carry chain. The reader can skip the rest of this section without any loss of continuity. </p> <p>\u8fd9\u662f\u8bc1\u660e\u6700\u574f\u60c5\u51b5\u8fdb\u4f4d\u94fe\u7684\u5bf9\u6570\u5e73\u5747\u957f\u5ea6\u7684\u4e00\u79cd\u65b9\u6cd5\u3002\u8bfb\u8005\u53ef\u4ee5\u8df3\u8fc7\u672c\u8282\u7684\u5176\u4f59\u90e8\u5206\uff0c\u800c\u4e0d\u4f1a\u5931\u53bb\u4efb\u4f55\u8fde\u7eed\u6027\u3002</p> <p>Let  \u03b7k (h)  be the probability that the longest carry chain in a  k-bit addition is of length h  or more. Clearly, the probability of the longest carry chain being of length exactly  h  is \u03b7k(h) \u2212  \u03b7k(h + 1 ). We can use a recursive formulation to find  \u03b7k(h). The longest carry chain can be of length  h  or more in two mutually exclusive ways:</p> <p>a. The least-significant  k \u2212 1 bits have a carry chain of length  h  or more. </p> <p>b. The least-significant  k \u2212 1 bits do not have such a carry chain, but the most significant  h  bits, including the last bit, have a chain of the exact length  h. </p> <p>Thus, we have</p> <p>\u200b        \\(\u03b7_k(h) \u2264 \u03b7_{k\u22121} (h) + 2^{\u2212 (h+1 )}\\) </p> <p>where 2\u2212 (h+1 )  is the product of \u00bc (representing the probability of carry generation) and 2\u2212 (h\u22121 ) (probability that carry propagates across  h \u2212 2 intermediate positions and stops in the last one). The inequality occurs because the second term is not multiplied by a probability as discussed above. Hence, assuming  \u03b7i(h) = 0 for  i &lt; h: </p> <p>\u200b       \\(\\eta_k(h)=\\sum_{i=h}^{k}[\\eta_i(h)-\\eta_{i-1}(h)] \\le (k-h+1)2^{-(h+l)} \\le 2^{-(h+1)}k\\)</p> <p>To complete our derivation of the expected length \u03bb of the longest carry chain, we note that</p> <p>\u4ee4 \\(\u03b7_k (h)\\) \u4e3a k \u4f4d\u52a0\u6cd5\u4e2d\u6700\u957f\u8fdb\u4f4d\u94fe\u957f\u5ea6\u4e3a h \u6216\u66f4\u957f\u7684\u6982\u7387\u3002\u663e\u7136\uff0c\u6700\u957f\u8fdb\u4f4d\u94fe\u7684\u957f\u5ea6\u6070\u597d\u4e3a h \u7684\u6982\u7387\u4e3a \\(\u03b7_k(h) \u2212 \u03b7_k(h + 1 )\\)\u3002\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u9012\u5f52\u516c\u5f0f\u6765\u6c42 \\(\u03b7_k(h)\\)\u3002\u6700\u957f\u7684\u8fdb\u4f4d\u94fe\u53ef\u4ee5\u901a\u8fc7\u4e24\u79cd\u4e92\u65a5\u7684\u65b9\u5f0f\u8fbe\u5230 \\(h\\) \u6216\u66f4\u957f\u7684\u957f\u5ea6\uff1a</p> <p>a. \u6700\u4f4e\u6709\u6548 \\(k \u2212 1\\) \u4f4d\u5177\u6709\u957f\u5ea6\u4e3a h \u6216\u66f4\u957f\u7684\u8fdb\u4f4d\u94fe\u3002</p> <p>b. \u6700\u4f4e\u6709\u6548 \\(k \u2212 1\\) \u4f4d\u6ca1\u6709\u8fd9\u6837\u7684\u8fdb\u4f4d\u94fe\uff0c\u4f46\u6700\u9ad8\u6709\u6548 h \u4f4d\uff08\u5305\u62ec\u6700\u540e\u4e00\u4f4d\uff09\u5177\u6709\u7cbe\u786e\u957f\u5ea6\u4e3a h \u7684\u94fe\u3002</p> <p>\u56e0\u6b64\uff0c\u6211\u4eec\u6709</p> <p>\u200b       \\(\u03b7_k(h) \u2264 \u03b7_{k\u22121} (h) + 2^{\u2212 (h+1 )}\\) </p> <p>\u5176\u4e2d 2^{\u2212 (h+1 )} \u662f \u00bc\uff08\u8868\u793a\u8fdb\u4f4d\u751f\u6210\u7684\u6982\u7387\uff09\u548c 2^{\u2212 (h\u22121 )} \uff08\u8fdb\u4f4d\u4f20\u64ad\u7a7f\u8fc7 \\(h \u2212 2\\) \u4e2a\u4e2d\u95f4\u4f4d\u7f6e\u5e76\u5728\u6700\u540e\u4e00\u4e2a\u4f4d\u7f6e\u505c\u6b62\u7684\u6982\u7387\uff09\u7684\u4e58\u79ef\u3002\u51fa\u73b0\u4e0d\u7b49\u5f0f\u662f\u56e0\u4e3a\u7b2c\u4e8c\u9879\u6ca1\u6709\u4e58\u4ee5\u4e0a\u9762\u8ba8\u8bba\u7684\u6982\u7387\u3002\u56e0\u6b64\uff0c\u5047\u8bbe \\(\u03b7_i(h) = 0\\) for \\(i &lt; h\\): </p> <p>\u200b       \\(\\eta_k(h)=\\sum_{i=h}^{k}[\\eta_i(h)-\\eta_{i-1}(h)] \\le (k-h+1)2^{-(h+l)} \\le 2^{-(h+1)}k\\)</p> <p>\u4e3a\u4e86\u5b8c\u6210\u6700\u957f\u8fdb\u4f4d\u94fe\u7684\u9884\u671f\u957f\u5ea6 \u03bb \u7684\u63a8\u5bfc\uff0c\u6211\u4eec\u8bb0\u4e3a</p> \\[ \\begin{array}{l} \\lambda &amp;= \\sum_{h=1}^{k}h[\\eta_k(h)-\\eta_k(h+1)] \\\\         &amp;= [\\eta_k(1)-\\eta_k(2)]  + 2[\\eta_k(2)-\\eta_k(3)] + \\cdots + k[\\eta_k(k)-0] \\\\         &amp;= \\sum_{h=1}^{k}\\eta_k(h) \\end{array} \\] <p>We next break the final summation above into two parts: the first \u03b3 = log2 k\u2212 1 terms and the remaining k \u2212 \u03b3 terms. Using the upper bound 1 for terms in the first part and 2\u2212 (h+1 )k for terms in the second part, we get</p> <p>\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5c06\u4e0a\u9762\u7684\u6700\u7ec8\u6c42\u548c\u5206\u4e3a\u4e24\u90e8\u5206\uff1a\u7b2c\u4e00\u4e2a \\(\u03b3 = \\left \\lfloor \\log_2 k \\right \\rfloor \u2212 1\\) \u9879\u548c\u5176\u4f59\u7684 \\(k \u2212 \u03b3\\) \u9879\u3002\u5bf9\u7b2c\u4e00\u90e8\u5206\u4e2d\u7684\u9879\u4f7f\u7528\u4e0a\u9650 1\uff0c\u5bf9\u7b2c\u4e8c\u90e8\u5206\u4e2d\u7684\u9879\u4f7f\u7528 \\(2^{\u2212 (h+1 )}k\\)\uff0c\u6211\u4eec\u5f97\u5230</p> <p>\u200b       \\(\\lambda = \\sum_{h=1}^{k}\\eta_k(h) \\le \\sum_{h=1}^{\\gamma}1+\\sum_{h=\\gamma+1}^{k}2^{-(h+1)}k \\lt \\gamma + 2^{-(\\gamma+1)}k\\)</p> <p>Now let  \u03b5 = log2  k \u2212log2  k or  \u03b3 = log2  k \u22121\u2212 \u03b5, where 0 \u2264  \u03b5 &lt;  1. Then, substituting the latter expression for  \u03b3  in the preceding inequality and noting that 2log2  k =  k  and 2 \u03b5 &lt;  1 +  \u03b5, we get  \u03bb &lt;  log2  k \u2212 1 \u2212  \u03b5 + 2 \u03b5 &lt;  log2  k</p> <p>\u73b0\u5728\u4ee4 \\(\u03b5 = \\log_2 k \u2212 \\left \\lfloor \\log_2 k \\right \\rfloor\\) \u6216 \\(\u03b3 = \\log_2 k \u22121\u2212 \u03b5\\)\uff0c\u5176\u4e2d \\(0 \u2264 \u03b5 &lt; 1\\)\u3002\u7136\u540e\uff0c\u5c06\u540e\u4e00\u4e2a\u8868\u8fbe\u5f0f\u66ff\u6362\u524d\u9762\u4e0d\u7b49\u5f0f\u4e2d\u7684 \u03b3\uff0c\u5e76\u6ce8\u610f\u5230 \\(2^{\\log_2 k} = k\\) \u548c \\(2^\u03b5 &lt; 1 + \u03b5\\)\uff0c\u6211\u4eec\u5f97\u5230</p> <p>\u200b       \\(\u03bb &lt; \\log_2 k \u2212 1 \u2212 \u03b5 + 2^\u03b5 &lt; \\log_2 k\\)</p> <p>This concludes our derivation of the result that the expected length of the worst-case carry chain in a  k-bit addition with random operands is upper-bounded by log2  k. Experimental results verify the log2  k  approximation to the length of the worst-case carry chain and suggest that log2(1.25 k) is a better estimate [Hend61]. </p> <p>\u8fd9\u5f97\u51fa\u4e86\u6211\u4eec\u5bf9\u7ed3\u679c\u7684\u63a8\u5bfc\uff0c\u5373\u4e0e\u968f\u673a\u64cd\u4f5c\u6570\u8fdb\u884c k \u4f4d\u52a0\u6cd5\u65f6\u6700\u574f\u60c5\u51b5\u8fdb\u4f4d\u94fe\u7684\u9884\u671f\u957f\u5ea6\u4e0a\u9650\u4e3a \\(\\log_2 k\\)\u3002\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6700\u574f\u60c5\u51b5\u8fdb\u4f4d\u94fe\u957f\u5ea6\u7684 \\(\\log_2 k\\) \u8fd1\u4f3c\u503c\uff0c\u5e76\u8868\u660e \\(\\log_2(1.25 k)\\) \u662f\u66f4\u597d\u7684\u4f30\u8ba1 [Hend61]\u3002</p>"},{"location":"Part_02/05/#54","title":"5.4 \u8fdb\u4f4d\u5b8c\u6210\u7684\u68c0\u6d4b","text":"<p>A ripple-carry adder is the simplest and slowest adder design. For  k-bit operands, both the worst-case delay and the implementation cost of a ripple-carry adder are linear in  k.  However, based on the analysis in Section 5.3, the worst-case carry-propagation chain of length  k  almost never materializes. </p> <p>\u884c\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\u662f\u6700\u7b80\u5355\u4e14\u6700\u6162\u7684\u52a0\u6cd5\u5668\u8bbe\u8ba1\u3002\u5bf9\u4e8e k \u4f4d\u64cd\u4f5c\u6570\uff0c\u6700\u574f\u60c5\u51b5\u7684\u5ef6\u8fdf\u548c\u7eb9\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\u7684\u5b9e\u73b0\u6210\u672c\u4e0e k \u6210\u7ebf\u6027\u5173\u7cfb\u3002\u7136\u800c\uff0c\u6839\u636e 5.3 \u8282\u7684\u5206\u6790\uff0c\u957f\u5ea6\u4e3a k \u7684\u6700\u574f\u60c5\u51b5\u8fdb\u4f4d\u4f20\u64ad\u94fe\u51e0\u4e4e\u6c38\u8fdc\u4e0d\u4f1a\u51fa\u73b0\u3002</p> <p>A carry-completion detection adder takes advantage of the log2  k  average length of the longest carry chain to add two  k-bit binary numbers in O(log  k) time on the average. It is essentially a ripple-carry adder in which a carry of 0 is also explicitly represented and allowed to propagate between stages. The carry into stage  i  is represented by the two-rail code:</p> <p>\u8fdb\u4f4d\u5b8c\u6210\u68c0\u6d4b\u52a0\u6cd5\u5668\u5229\u7528\u6700\u957f\u8fdb\u4f4d\u94fe\u7684 \\(\\log_2 k\\) \u5e73\u5747\u957f\u5ea6\uff0c\u5e73\u5747\u5728 \\(O(\\log k)\\) \u65f6\u95f4\u5185\u5c06\u4e24\u4e2a k \u4f4d\u4e8c\u8fdb\u5236\u6570\u76f8\u52a0\u3002\u5b83\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u6ce2\u7eb9\u8fdb\u4f4d\u52a0\u6cd5\u5668\uff0c\u5176\u4e2d\u4e5f\u660e\u786e\u8868\u793a\u4e86\u8fdb\u4f4d 0 \u5e76\u5141\u8bb8\u5728\u7ea7\u4e4b\u95f4\u4f20\u64ad\u3002\u8fdb\u5165\u9636\u6bb5 i \u7684\u8fdb\u4f4d\u7531\u4e24\u8f68\u7f16\u7801\u8868\u793a\uff1a</p> <p>\\((b_i, c_i) =\\) </p> <p>\u200b       (0, 0) \u8fdb\u4f4d\u672a\u77e5</p> <p>\u200b       (0, 1) \u8fdb\u4f4d\u786e\u5b9a\u4e3a1</p> <p>\u200b       (1, 0) \u8fdb\u4f4d\u786e\u5b9a\u4e3a0</p> <p>Thus, just as two 1s in the operands generate a carry of 1 that propagates to the left, two 0s would produce a carry of 0. Initially, all carries are (0, 0) or unknown.  After initialization, a bit position with  xi =  yi  makes the no-carry/carry determination and injects the appropriate carry ( bi+1,  ci+1 ) =  (xi \u2228  yi,  xiyi)  into the carry-propagation chain of Fig. 5.9 via the OR gates. The carry  (c in,  c in )  is injected at the right end. When every carry has assumed one of the values (0, 1) or (1, 0), carry propagation is complete.  The local \u201cdone\u201d signals  di =  bi \u2228  ci  are combined by a global AND function into alldone, which indicates the end of carry propagation. </p> <p>\u56e0\u6b64\uff0c\u6b63\u5982\u64cd\u4f5c\u6570\u4e2d\u7684\u4e24\u4e2a 1 \u751f\u6210\u5411\u5de6\u4f20\u64ad\u7684\u8fdb\u4f4d 1 \u4e00\u6837\uff0c\u4e24\u4e2a 0 \u5c06\u751f\u6210\u8fdb\u4f4d 0\u3002\u6700\u521d\uff0c\u6240\u6709\u8fdb\u4f4d\u90fd\u662f (0, 0) \u6216\u672a\u77e5\u3002\u521d\u59cb\u5316\u540e\uff0c\\(x_i = y_i\\) \u7684\u4f4d\u4f4d\u7f6e\u53ef\u4ee5\u5224\u5b9a\u662f\u65e0\u8fdb\u4f4d/\u8fdb\u4f4d\uff0c\u5e76\u901a\u8fc7\u6216\u95e8\u5c06\u9002\u5f53\u7684\u8fdb\u4f4d \\((b_{i+1}, c_{i+1}) = (x_i \u2228 y_i, x_iy_i)\\) \u6ce8\u5165\u56fe 5.9 \u7684\u8fdb\u4f4d\u4f20\u64ad\u94fe\u4e2d\u3002\u8fdb\u4f4d \\((\\bar{c} _{in}, c _{in} )\\) \u5728\u53f3\u7aef\u6ce8\u5165\u3002\u5f53\u6bcf\u4e2a\u8fdb\u4f4d\u90fd\u53d6\u503c (0, 1) \u6216 (1, 0) \u4e4b\u4e00\u65f6\uff0c\u8fdb\u4f4d\u4f20\u64ad\u5c31\u5b8c\u6210\u4e86\u3002\u5c40\u90e8\u201cdone\u201d\u4fe1\u53f7 \\(d_i = b_i \u2228 c_i\\) \u901a\u8fc7\u5168\u5c40 AND \u51fd\u6570\u7ec4\u5408\u6210 alldone\uff0c\u8868\u793a\u8fdb\u4f4d\u4f20\u64ad\u7ed3\u675f\u3002</p> <p></p> <p>In designing carry-completion adders, care must be taken to avoid hazards that might lead to a spurious  alldone  signal. Initialization of all carries to 0 through clearing of input bits and simultaneous application of all input data is one way of ensuring hazard-free operation. </p> <p>\u5728\u8bbe\u8ba1\u8fdb\u4f4d\u5b8c\u6210\u52a0\u6cd5\u5668\u65f6\uff0c\u5fc5\u987b\u5c0f\u5fc3\u907f\u514d\u53ef\u80fd\u5bfc\u81f4\u865a\u5047 alldone \u4fe1\u53f7\u7684\u5371\u9669\u3002\u901a\u8fc7\u6e05\u9664\u8f93\u5165\u4f4d\u5e76\u540c\u65f6\u5e94\u7528\u6240\u6709\u8f93\u5165\u6570\u636e\u5c06\u6240\u6709\u8fdb\u4f4d\u521d\u59cb\u5316\u4e3a 0\uff0c\u662f\u786e\u4fdd\u65e0\u5371\u9669\u64cd\u4f5c\u7684\u4e00\u79cd\u65b9\u6cd5\u3002</p> <p>Excluding the initialization and carry-completion detection times, which must be considered and are the same in all cases, the latency of a  k-bit carry-completion adder ranges from 1 gate delay in the best case (no carry propagation at all: i.e., when adding a number to itself) to 2 k + 1 gate delays in the worst case (full carry propagation from  c in to cout), with the average latency being about \\(2 \\log_2  k + 1\\) gate delays. Note that once the final carries have arrived in all bit positions, the derivation of the sum bits is overlapped with completion detection and is thus not accounted for in the preceding latencies. </p> <p>\u6392\u9664\u521d\u59cb\u5316\u548c\u8fdb\u4f4d\u5b8c\u6210\u68c0\u6d4b\u65f6\u95f4\uff08\u5fc5\u987b\u8003\u8651\u8fd9\u4e9b\u65f6\u95f4\u5e76\u4e14\u5728\u6240\u6709\u60c5\u51b5\u4e0b\u90fd\u662f\u76f8\u540c\u7684\uff09\uff0ck \u4f4d\u8fdb\u4f4d\u5b8c\u6210\u52a0\u6cd5\u5668\u7684\u5ef6\u8fdf\u8303\u56f4\u4ece\u6700\u597d\u60c5\u51b5\u4e0b\u7684 1 \u4e2a\u95e8\u5ef6\u8fdf\uff08\u6839\u672c\u6ca1\u6709\u8fdb\u4f4d\u4f20\u64ad\uff1a\u5373\uff0c\u5f53\u5c06\u6570\u5b57\u6dfb\u52a0\u5230\u81ea\u8eab\u65f6\uff09\u5230\u6700\u574f\u60c5\u51b5\u4e0b\u7684 \\(2k + 1\\) \u4e2a\u95e8\u5ef6\u8fdf\uff08\u4ece \\(c_{in}\\) \u5230 \\(c_{out}\\) \u7684\u5168\u8fdb\u4f4d\u4f20\u64ad\uff09\u5e73\u5747\u5ef6\u8fdf\u7ea6\u4e3a \\(2 \\log_2  k + 1\\) \u4e2a\u95e8\u5ef6\u8fdf\u3002\u8bf7\u6ce8\u610f\uff0c\u4e00\u65e6\u6700\u7ec8\u8fdb\u4f4d\u5230\u8fbe\u6240\u6709\u4f4d\u4f4d\u7f6e\uff0c\u548c\u7684\u5bfc\u51fa\u4e0e\u5b8c\u6210\u68c0\u6d4b\u91cd\u53e0\uff0c\u56e0\u6b64\u4e0d\u4f1a\u7b97\u5728\u524d\u9762\u5f97\u5230\u7684\u5ef6\u8fdf\u4e2d\u3002</p> <p>Because the latency of the carry-completion adder is data-dependent, the design of Fig. 5.9 is suitable for use in asynchronous systems. Most modern computers, however, use synchronous logic and thus cannot take advantage of the high average speed of a carry-completion adder. </p> <p>\u7531\u4e8e\u8fdb\u4f4d\u5b8c\u6210\u52a0\u6cd5\u5668\u7684\u5ef6\u8fdf\u53d6\u51b3\u4e8e\u6570\u636e\uff0c\u56e0\u6b64\u56fe 5.9 \u7684\u8bbe\u8ba1\u9002\u5408\u5728\u5f02\u6b65\u7cfb\u7edf\u4e2d\u4f7f\u7528\u3002\u7136\u800c\uff0c\u5927\u591a\u6570\u73b0\u4ee3\u8ba1\u7b97\u673a\u4f7f\u7528\u540c\u6b65\u903b\u8f91\uff0c\u56e0\u6b64\u65e0\u6cd5\u5229\u7528\u8fdb\u4f4d\u5b8c\u6210\u52a0\u6cd5\u5668\u7684\u9ad8\u5e73\u5747\u901f\u5ea6\u3002</p>"},{"location":"Part_02/05/#55","title":"5.5 \u52a0\u4e0a\u4e00\u4e2a\u5e38\u6570:\u8ba1\u6570\u5668","text":"<p>When one input of the addition operation is a constant number, the design can be simplified or optimized compared with that of a general two-operand adder. With binary arithmetic, we can assume that the constant  y  to be added to  x  is odd, since in the addition s =  x +  y even =  x +  (y odd \u00d7 2 h), one can ignore the  h  rightmost bits in  x  and add  y odd to the remaining bits. The special case of  y = 1 corresponds to standard counters, while y = \u00b11 yields an up/down counter. </p> <p>\u5f53\u52a0\u6cd5\u8fd0\u7b97\u7684\u4e00\u4e2a\u8f93\u5165\u4e3a\u5e38\u6570\u65f6\uff0c\u4e0e\u4e00\u822c\u7684\u4e8c\u64cd\u4f5c\u6570\u52a0\u6cd5\u5668\u76f8\u6bd4\uff0c\u53ef\u4ee5\u7b80\u5316\u6216\u4f18\u5316\u8bbe\u8ba1\u3002\u5bf9\u4e8e\u4e8c\u8fdb\u5236\u7b97\u672f\uff0c\u6211\u4eec\u53ef\u4ee5\u5047\u8bbe\u8981\u4e0e x \u76f8\u52a0\u7684\u5e38\u6570 y \u662f\u5947\u6570\uff0c\u56e0\u4e3a\u5728\u52a0\u6cd5 \\(s = x + y_{even} = x + (y_{odd} \u00d7 2^h)\\) \u4e2d\uff0c\u53ef\u4ee5\u5ffd\u7565 x \u4e2d\u6700\u53f3\u8fb9\u7684 h \u4f4d\u5e76\u5c06 \\(y_{odd}\\) \u52a0\u5230\u5176\u4f59\u4f4d\u3002 y = 1 \u7684\u7279\u6b8a\u60c5\u51b5\u5bf9\u5e94\u4e8e\u6807\u51c6\u8ba1\u6570\u5668\uff0c\u800c y = \u00b11 \u5219\u4ea7\u751f\u5411\u4e0a/\u5411\u4e0b\u8ba1\u6570\u5668\u3002</p> <p>Let the constant to be added to  x =  (xk\u22121 \u00b7 \u00b7 \u00b7  x 2 x 1 x 0 ) two be  y =  (yk\u22121 \u00b7 \u00b7 \u00b7  y 2 y 1 1 ) two.  The least-significant bit of the sum is  x 0. The remaining bits of  s  can be determined by a ( k \u2212 1)-bit ripple-carry adder, with  c in =  x 0, each of its cells being a HA ( yi = 0) or a modified HA ( yi = 1). The fast-adder designs to be covered in Chapters 6 and 7 can similarly be optimized to take advantage of the known bits of  y. </p> <p>\u8bbe\u4e0e\\(x = (x_{k\u22121} \u00b7 \u00b7 \u00b7 x _2 x _1 x _0 )_2\\) \u76f8\u52a0\u7684\u5e38\u6570\u4e3a\\(y = (y_{k\u22121} \u00b7 \u00b7 \u00b7 y _2 y _1 1 ) _2\\)\u3002\u548c\u7684\u6700\u4f4e\u6709\u6548\u4f4d\u662f \\(\\bar{x}_0\\)\u3002 s \u7684\u5176\u4f59\u4f4d\u53ef\u4ee5\u7531 \\(( k \u2212 1)\\) \u4f4d\u7eb9\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\u786e\u5b9a\uff0c\u5176\u4e2d \\(c_{in} = x_0\\)\uff0c\u5176\u6bcf\u4e2a\u5355\u5143\u90fd\u662f HA \\(( y_i = 0)\\) \u6216\u4fee\u6539\u7684 \\(HA ( y_i = 1)\\)\u3002\u7b2c 6 \u7ae0\u548c\u7b2c 7 \u7ae0\u4e2d\u4ecb\u7ecd\u7684\u5feb\u901f\u52a0\u6cd5\u5668\u8bbe\u8ba1\u53ef\u4ee5\u7c7b\u4f3c\u5730\u8fdb\u884c\u4f18\u5316\uff0c\u4ee5\u5229\u7528 y \u7684\u5df2\u77e5\u4f4d\u3002</p> <p>When  y = 1 (\u22121 ), the resulting circuit is known as an  incrementer ( decrementer) and is used in the design of up (down) counters. Figure 5.10 depicts an up counter, with parallel load capability, built of a register, an incrementer, and a multiplexer. The design shown in Fig. 5.10 can be easily converted to an up/down counter by using an incrementer/decrementer and an extra control signal. Supplying the details is left as an exercise. </p> <p>\u5f53 y = 1 (\u22121) \u65f6\uff0c\u6240\u5f97\u7535\u8def\u79f0\u4e3a\u589e\u91cf\u5668\uff08\u51cf\u91cf\u5668\uff09\uff0c\u5e76\u7528\u4e8e\u5411\u4e0a\uff08\u5411\u4e0b\uff09\u8ba1\u6570\u5668\u7684\u8bbe\u8ba1\u3002\u56fe 5.10 \u63cf\u8ff0\u4e86\u4e00\u4e2a\u5177\u6709\u5e76\u884c\u52a0\u8f7d\u80fd\u529b\u7684\u5411\u4e0a\u8ba1\u6570\u5668\uff0c\u7531\u5bc4\u5b58\u5668\u3001\u589e\u91cf\u5668\u548c\u591a\u8def\u590d\u7528\u5668\u7ec4\u6210\u3002\u901a\u8fc7\u4f7f\u7528\u589e\u91cf\u5668/\u51cf\u91cf\u5668\u548c\u989d\u5916\u7684\u63a7\u5236\u4fe1\u53f7\uff0c\u56fe 5.10 \u6240\u793a\u7684\u8bbe\u8ba1\u53ef\u4ee5\u8f7b\u677e\u8f6c\u6362\u4e3a\u52a0/\u51cf\u8ba1\u6570\u5668\u3002\u7559\u7ed9\u8bfb\u8005\u7559\u4f5c\u7ec3\u4e60\u3002</p> <p></p> <p>Many designs for fast counters are available [Ober81]. Conventional synchronous designs are based on full carry propagation in each increment/decrement cycle, thus limiting the counter\u2019s operating speed. In some cases, special features of the storage elements used can lead to simplifications. Figure 5.11 depicts an asynchronous counter built of cascaded negative-edge-triggered T (toggle) flip-flops. Each input pulse toggles the flip-flop at the least significant position, each 1-to-0 transition of the least-significant bit flip-flop toggles the next flip-flop, and so on. The next input pulse can be accepted before the carry has propagated all the way to the left. </p> <p>\u8bb8\u591a\u5feb\u901f\u8ba1\u6570\u5668\u7684\u8bbe\u8ba1\u90fd\u662f\u53ef\u7528\u7684[Ober81]\u3002\u4f20\u7edf\u7684\u540c\u6b65\u8bbe\u8ba1\u57fa\u4e8e\u6bcf\u4e2a\u9012\u589e/\u9012\u51cf\u5468\u671f\u4e2d\u7684\u5168\u8fdb\u4f4d\u4f20\u64ad\uff0c\u56e0\u6b64\u9650\u5236\u8ba1\u6570\u5668\u7684\u8fd0\u884c\u901f\u5ea6\u3002\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u6240\u4f7f\u7528\u7684\u5b58\u50a8\u5143\u4ef6\u7684\u7279\u6b8a\u529f\u80fd\u53ef\u4ee5\u5bfc\u81f4\u7b80\u5316\u3002\u56fe 5.11 \u63cf\u8ff0\u4e86\u7531\u7ea7\u8054\u8d1f\u8fb9\u6cbf\u89e6\u53d1 T\uff08\u7ffb\u8f6c\uff09\u89e6\u53d1\u5668\u6784\u5efa\u7684\u5f02\u6b65\u8ba1\u6570\u5668\u3002\u6bcf\u4e2a\u8f93\u5165\u8109\u51b2\u90fd\u4f1a\u5728\u6700\u4f4e\u6709\u6548\u4f4d\u89e6\u53d1\u89e6\u53d1\u5668\uff0c\u6700\u4f4e\u6709\u6548\u4f4d\u89e6\u53d1\u5668\u7684\u6bcf\u4e2a 1 \u5230 0 \u8f6c\u6362\u90fd\u4f1a\u89e6\u53d1\u4e0b\u4e00\u4e2a\u89e6\u53d1\u5668\uff0c\u4f9d\u6b64\u7c7b\u63a8\u3002\u5728\u8fdb\u4f4d\u4e00\u76f4\u5411\u5de6\u4f20\u64ad\u4e4b\u524d\uff0c\u53ef\u4ee5\u63a5\u53d7\u4e0b\u4e00\u4e2a\u8f93\u5165\u8109\u51b2\u3002</p> <p></p> <p>Certain applications require high-speed counting, with the count potentially becoming quite large. In such cases, a high-speed incrementer must be used. Methods of designing fast adders (Chapters 6 and 7) can all be adapted for building fast incrementers. When even the highest-speed incrementer cannot keep up with the input rate or when cost considerations preclude the use of an ultrafast incrementer, the frequency of the input can be reduced by applying it to a prescaler. The lower-frequency output of the prescaler can then be counted with less stringent speed requirements. In the latter case, the resulting count will be approximate. </p> <p>\u67d0\u4e9b\u5e94\u7528\u9700\u8981\u9ad8\u901f\u8ba1\u6570\uff0c\u8ba1\u6570\u53ef\u80fd\u4f1a\u53d8\u5f97\u76f8\u5f53\u5927\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u5fc5\u987b\u4f7f\u7528\u9ad8\u901f\u589e\u91cf\u5668\u3002\u8bbe\u8ba1\u5feb\u901f\u52a0\u6cd5\u5668\u7684\u65b9\u6cd5\uff08\u7b2c 6 \u7ae0\u548c\u7b2c 7 \u7ae0\uff09\u90fd\u53ef\u4ee5\u7528\u4e8e\u6784\u5efa\u5feb\u901f\u589e\u91cf\u5668\u3002\u5f53\u5373\u4f7f\u662f\u6700\u9ad8\u901f\u5ea6\u7684\u589e\u91cf\u5668\u4e5f\u65e0\u6cd5\u8ddf\u4e0a\u8f93\u5165\u901f\u7387\uff0c\u6216\u8005\u5f53\u51fa\u4e8e\u6210\u672c\u8003\u8651\u800c\u65e0\u6cd5\u4f7f\u7528\u8d85\u5feb\u589e\u91cf\u5668\u65f6\uff0c\u53ef\u4ee5\u901a\u8fc7\u5c06\u5176\u5e94\u7528\u4e8e\u9884\u5206\u9891\u5668\u6765\u964d\u4f4e\u8f93\u5165\u9891\u7387\u3002\u7136\u540e\u53ef\u4ee5\u4ee5\u4e0d\u592a\u4e25\u683c\u7684\u901f\u5ea6\u8981\u6c42\u6765\u8ba1\u7b97\u9884\u5206\u9891\u5668\u7684\u8f83\u4f4e\u9891\u7387\u8f93\u51fa\u3002\u5728\u540e\u4e00\u79cd\u60c5\u51b5\u4e0b\uff0c\u6240\u5f97\u8ba1\u6570\u5c06\u662f\u8fd1\u4f3c\u503c\u3002</p> <p>Obviously, the count value can be represented in redundant format, allowing carry-free increment or decrement in constant time [Parh87]. However, with a redundant format, reading out the stored count involves some delay to allow for conversion of the internal representation to standard binary. Alternatively, one can design the counter as a cascade that begins with a very narrow, and thus fast, counter and continues with increasingly wider counters [Vuil91]. The wider counters on the left are incremented only occasionally and thus need not be very fast (their incremented counts can be precomputed by a slow incrementer and then simply loaded into the register when required). Figure 5.12 shows this principle applied to the design of a three-stage counter. Some details of this design, as well as its extension to up/down counting, will be explored in the end-of-chapter problems. </p> <p>\u663e\u7136\uff0c\u8ba1\u6570\u503c\u53ef\u4ee5\u7528\u5197\u4f59\u683c\u5f0f\u8868\u793a\uff0c\u5141\u8bb8\u5728\u6052\u5b9a\u65f6\u95f4\u5185\u8fdb\u884c\u65e0\u8fdb\u4f4d\u9012\u589e\u6216\u9012\u51cf[Parh87]\u3002\u7136\u800c\uff0c\u4f7f\u7528\u5197\u4f59\u683c\u5f0f\u65f6\uff0c\u8bfb\u51fa\u5b58\u50a8\u7684\u8ba1\u6570\u4f1a\u6d89\u53ca\u4e00\u4e9b\u5ef6\u8fdf\uff0c\u4ee5\u5141\u8bb8\u5c06\u5185\u90e8\u8868\u793a\u8f6c\u6362\u4e3a\u6807\u51c6\u4e8c\u8fdb\u5236\u3002\u6216\u8005\uff0c\u53ef\u4ee5\u5c06\u8ba1\u6570\u5668\u8bbe\u8ba1\u4e3a\u7ea7\u8054\uff0c\u4ece\u975e\u5e38\u7a84\u4e14\u56e0\u6b64\u901f\u5ea6\u5feb\u7684\u8ba1\u6570\u5668\u5f00\u59cb\uff0c\u7136\u540e\u4ee5\u8d8a\u6765\u8d8a\u5bbd\u7684\u8ba1\u6570\u5668\u7ee7\u7eed[Vuil91]\u3002\u5de6\u4fa7\u8f83\u5bbd\u7684\u8ba1\u6570\u5668\u4ec5\u5076\u5c14\u9012\u589e\uff0c\u56e0\u6b64\u4e0d\u9700\u8981\u975e\u5e38\u5feb\uff08\u5b83\u4eec\u7684\u9012\u589e\u8ba1\u6570\u53ef\u4ee5\u7531\u6162\u901f\u9012\u589e\u5668\u9884\u5148\u8ba1\u7b97\uff0c\u7136\u540e\u5728\u9700\u8981\u65f6\u7b80\u5355\u5730\u52a0\u8f7d\u5230\u5bc4\u5b58\u5668\u4e2d\uff09\u3002\u56fe 5.12 \u663e\u793a\u4e86\u8be5\u539f\u7406\u5e94\u7528\u4e8e\u4e09\u7ea7\u8ba1\u6570\u5668\u7684\u8bbe\u8ba1\u3002\u8fd9\u4e2a\u8bbe\u8ba1\u7684\u4e00\u4e9b\u7ec6\u8282\uff0c\u4ee5\u53ca\u5b83\u5bf9\u52a0/\u51cf\u8ba1\u6570\u7684\u6269\u5c55\uff0c\u5c06\u5728\u7ae0\u672b\u7684\u95ee\u9898\u4e2d\u63a2\u8ba8\u3002</p> <p></p>"},{"location":"Part_02/05/#56","title":"5.6 \u66fc\u5f7b\u65af\u7279\u8fdb\u4f4d\u94fe\u4e0e\u52a0\u6cd5\u5668","text":"<p>In the next three chapters, we will examine methods for speeding up the addition process for two operands (Chapters 6 and 7) and for multiple operands (Chapter 8). For two operands, the key to fast addition is a low-latency carry network, since once the carry into position  i  is known, the sum digit can be determined from the operand digits  xi  and yi  and the incoming carry  ci  in constant time through modular addtition: si =  (xi +  yi +  ci)  mod  r</p> <p>\u5728\u63a5\u4e0b\u6765\u7684\u4e09\u7ae0\u4e2d\uff0c\u6211\u4eec\u5c06\u7814\u7a76\u52a0\u901f\u4e24\u4e2a\u64cd\u4f5c\u6570\uff08\u7b2c 6 \u7ae0\u548c\u7b2c 7 \u7ae0\uff09\u548c\u591a\u4e2a\u64cd\u4f5c\u6570\uff08\u7b2c 8 \u7ae0\uff09\u7684\u52a0\u6cd5\u8fc7\u7a0b\u7684\u65b9\u6cd5\u3002\u5bf9\u4e8e\u4e24\u4e2a\u64cd\u4f5c\u6570\uff0c\u5feb\u901f\u52a0\u6cd5\u7684\u5173\u952e\u662f\u4f4e\u5ef6\u8fdf\u8fdb\u4f4d\u7f51\u7edc\uff0c\u56e0\u4e3a\u4e00\u65e6\u77e5\u9053\u4f4d\u7f6e i \u7684\u8fdb\u4f4d\uff0c\u5c31\u53ef\u4ee5\u901a\u8fc7\u6a21\u52a0\u6cd5\u5728\u6052\u5b9a\u65f6\u95f4\u5185\u6839\u636e\u64cd\u4f5c\u6570\u4f4d xi \u548c yi \u4ee5\u53ca\u4f20\u5165\u7684\u8fdb\u4f4d ci \u786e\u5b9a\u548c\u4f4d\uff1a </p> <p>\u200b       \\(s_i = (x_i + y_i + c_i) \\mod r\\)</p> <p>In the special case of radix 2, the relation above reduces to</p> <p>\u5728\u57fa\u6570\u4e3a 2 \u7684\u7279\u6b8a\u60c5\u51b5\u4e0b\uff0c\u4e0a\u9762\u7684\u5173\u7cfb\u7b80\u5316\u4e3a</p> <p>\u200b       \\(s_i = x_i \u2295 y_i \u2295 c_i\\)</p> <p>So, the primary problem in the design of two-operand adders is the computation of the k  carries  ci+1 based on the 2 k  operand digits  xi  and  yi, 0 \u2264  i &lt; k. </p> <p>\u56e0\u6b64\uff0c\u53cc\u64cd\u4f5c\u6570\u52a0\u6cd5\u5668\u8bbe\u8ba1\u7684\u9996\u8981\u95ee\u9898\u662f\u6839\u636e \\(2 k\\) \u4e2a\u64cd\u4f5c\u6570\u4f4d \\(x_i\\) \u548c \\(y_i\\) \u8ba1\u7b97 \\(k\\) \u4e2a\u8fdb\u4f4d \\(c_{i+1}\\)\uff0c\\(0 \u2264 i &lt; k\\)\u3002</p> <p>From the point of view of carry propagation and the design of a carry network, the actual operand digits are not important. What matters is whether in a given position a carry is generated, propagated, or annihilated (absorbed). In the case of binary addition, the generate,  propagate, and  annihilate ( absorb) signals are characterized by the following logic equations:</p> <p>\u4ece\u8fdb\u4f4d\u4f20\u64ad\u548c\u8fdb\u4f4d\u7f51\u7edc\u8bbe\u8ba1\u7684\u89d2\u5ea6\u6765\u770b\uff0c\u5b9e\u9645\u7684\u64cd\u4f5c\u6570\u5e76\u4e0d\u91cd\u8981\u3002\u91cd\u8981\u7684\u662f\u5728\u7ed9\u5b9a\u4f4d\u7f6e\u662f\u5426\u4ea7\u751f\u3001\u4f20\u64ad\u6216\u6d88\u9664\uff08\u5438\u6536\uff09\u8fdb\u4f4d\u3002\u5728\u4e8c\u8fdb\u5236\u52a0\u6cd5\u7684\u60c5\u51b5\u4e0b\uff0c\u751f\u6210\u3001\u4f20\u64ad\u548c\u6d88\u9664\uff08\u5438\u6536\uff09\u4fe1\u53f7\u7531\u4ee5\u4e0b\u903b\u8f91\u65b9\u7a0b\u8868\u5f81\uff1a</p> <p>\\(g_i = x_iy_i\\)</p> <p>\\(p_i = x_i \u2295 y_i\\)</p> <p>\\(a_i = \\bar{x}_i\\bar{y}_i = \\overline{x_i \u2228 y_i}\\)</p> <p>It is also helpful to define a  transfer  signal corresponding to the event that the carry-out will be 1, given that the carry-in is 1:</p> <p>\u5047\u8bbe\u8fdb\u4f4d\u4e3a 1\uff0c\u5b9a\u4e49\u4e0e\u8fdb\u4f4d\u4e3a 1 \u7684\u4e8b\u4ef6\u76f8\u5bf9\u5e94\u7684\u4f20\u8f93\u4fe1\u53f7\u4e5f\u5f88\u6709\u5e2e\u52a9\uff1a</p> <p>\\(t_i = g_i \u2228 p_i = \\bar a_i = x_i \u2228 y_i\\)</p> <p>More generally, for radix  r, we have</p> <p>\u66f4\u4e00\u822c\u5730\uff0c\u5bf9\u4e8e\u57fa\u6570 r\uff0c\u6211\u4eec\u6709</p> <p>\\(g_i = 1 \\iff x_i + y_i \u2265 r\\)</p> <p>\\(p_i = 1 \\iff x_i + y_i = r \u2212 1\\)</p> <p>\\(a_i = 1 \\iff x_i + y_i &lt; r \u2212 1\\)</p> <p>Thus, assuming that the signals above are produced and made available, the rest of the carry network design can be based on them and becomes completely independent of the operands or even the number representation radix. </p> <p>\u56e0\u6b64\uff0c\u5047\u8bbe\u4e0a\u8ff0\u4fe1\u53f7\u5df2\u4ea7\u751f\u5e76\u53ef\u7528\uff0c\u5219\u8fdb\u4f4d\u7f51\u7edc\u8bbe\u8ba1\u7684\u5176\u4f59\u90e8\u5206\u53ef\u4ee5\u57fa\u4e8e\u5b83\u4eec\uff0c\u5e76\u4e14\u5b8c\u5168\u72ec\u7acb\u4e8e\u64cd\u4f5c\u6570\u751a\u81f3\u6570\u5b57\u8868\u793a\u57fa\u6570\u3002</p> <p>Using the preceding signals, the  carry recurrence  can be written as follows:</p> <p>\u4f7f\u7528\u524d\u9762\u7684\u4fe1\u53f7\uff0c\u8fdb\u4f4d\u9012\u63a8\u53ef\u4ee5\u5199\u6210\u5982\u4e0b\uff1a </p> <p>\\(c_{i+1} = g_i \u2228 c_ip_i\\)</p> <p>The carry recurrence essentially states that a carry will enter stage  i + 1 if it is generated in stage  i  or it enters stage  i  and is propagated by that stage. Since </p> <p>\u8fdb\u4f4d\u9012\u5f52\u672c\u8d28\u4e0a\u662f\u6307\u5982\u679c\u8fdb\u4f4d\u662f\u5728\u9636\u6bb5 i \u4e2d\u751f\u6210\u7684\uff0c\u6216\u8005\u8fdb\u5165\u9636\u6bb5 i \u5e76\u7531\u8be5\u9636\u6bb5\u4f20\u64ad\u7684\uff0c\u5219\u8fdb\u4f4d\u5c06\u8fdb\u5165\u9636\u6bb5 i + 1\u3002\u56e0\u4e3a </p> \\[ c_{i+1} = g_i \u2228 c_ip_i = g_i \u2228 c_ig_i \u2228 c_ip_i \\\\ = g_i \u2228 c_i(g_i \u2228 p_i) = g_i \u2228 c_it_i \\] <p>the carry recurrence can be written in terms of  ti  instead of  pi. This latter version of the carry recurrence leads to slightly faster adders because in binary addition,  ti  is easier to produce than  pi (OR instead of XOR). </p> <p>\u8fdb\u4f4d\u9012\u63a8\u53ef\u4ee5\u7528 \\(t_i\\) \u800c\u4e0d\u662f \\(p_i\\) \u6765\u5199\u3002\u8fdb\u4f4d\u5faa\u73af\u7684\u540e\u4e00\u4e2a\u7248\u672c\u5bfc\u81f4\u52a0\u6cd5\u5668\u7a0d\u5feb\u4e00\u4e9b\uff0c\u56e0\u4e3a\u5728\u4e8c\u8fdb\u5236\u52a0\u6cd5\u4e2d\uff0c\\(t_i\\) \u6bd4 \\(p_i\\) \u66f4\u5bb9\u6613\u751f\u6210\uff08OR \u800c\u4e0d\u662f XOR\uff09\u3002</p> <p>In what follows, we always deal with the carry recurrence in its original form  ci+1 = gi \u2228  cipi, since it is more intuitive, but we keep in mind that in most cases,  pi  can be replaced by  ti  if desired. </p> <p>\u5728\u4e0b\u6587\u4e2d\uff0c\u6211\u4eec\u59cb\u7ec8\u4ee5\u539f\u59cb\u5f62\u5f0f\u5904\u7406\u8fdb\u4f4d\u9012\u63a8 \\(c_{i+1} = g_i \u2228 c_ip_i\\)\uff0c\u56e0\u4e3a\u5b83\u66f4\u76f4\u89c2\uff0c\u4f46\u6211\u4eec\u8bf7\u8bb0\u4f4f\uff0c\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u5982\u679c\u9700\u8981\uff0c\u53ef\u4ee5\u7528 \\(t_i\\) \u4ee3\u66ff \\(p_i\\)\u3002</p> <p>The carry recurrence forms the basis of a simple carry network known as  Manchester carry chain. A  Manchester adder  is one that uses a Manchester carry chain as its carry network. Each stage of a Manchester carry chain can be viewed as consisting of three switches controlled by the signals  pi,  gi, and  ai, so that the switch closes (conducts electricity) when the corresponding control signal is 1. As shown in Fig. 5.13a, the carry-out signal  ci+1 is connected to 0 if  ai = 1, to 1 if  gi = 1, and to  ci  if  pi = 1, thus assuming the correct logical value  ci+1 =  gi \u2228  cipi. Note that one, and only one, of the signals  pi,  gi, and  ai  is 1. </p> <p>\u8fdb\u4f4d\u5faa\u73af\u6784\u6210\u4e86\u79f0\u4e3a*\u66fc\u5f7b\u65af\u7279\u8fdb\u4f4d\u94fe*\u7684\u7b80\u5355\u8fdb\u4f4d\u7f51\u7edc\u7684\u57fa\u7840\u3002\u66fc\u5f7b\u65af\u7279\u52a0\u6cd5\u5668\u662f\u4e00\u79cd\u4f7f\u7528\u66fc\u5f7b\u65af\u7279\u8fdb\u4f4d\u94fe\u4f5c\u4e3a\u5176\u8fdb\u4f4d\u7f51\u7edc\u7684\u52a0\u6cd5\u5668\u3002\u66fc\u5f7b\u65af\u7279\u8fdb\u4f4d\u94fe\u7684\u6bcf\u4e00\u7ea7\u53ef\u4ee5\u770b\u4f5c\u7531\u4fe1\u53f7 \\(p_i\\)\u3001\\(g_i\\) \u548c \\(a_i\\) \u63a7\u5236\u7684\u4e09\u4e2a\u5f00\u5173\u7ec4\u6210\uff0c\u56e0\u6b64\u5f53\u76f8\u5e94\u7684\u63a7\u5236\u4fe1\u53f7\u4e3a 1 \u65f6\uff0c\u5f00\u5173\u95ed\u5408\uff08\u5bfc\u901a\uff09\u3002\u5982\u56fe 5.13a \u6240\u793a\uff0c\u5982\u679c \\(a_i = 1\\)\uff0c\u5219\u8fdb\u4f4d\u4fe1\u53f7 \\(c_{i+1}\\) \u8fde\u63a5\u5230 0\uff0c\u5982\u679c \\(g_i = 1\\)\uff0c\u5219\u8fde\u63a5\u5230 1\uff0c\u5982\u679c \\(p_i = 1\\)\uff0c\u5219\u8fde\u63a5\u5230 \\(c_i\\)\uff0c\u4e5f\u5c31\u5f97\u5230\u6b63\u786e\u7684\u903b\u8f91\u503c \\(c_{i+1} = g_i \u2228 c_ip_i\\)\u3002\u8bf7\u6ce8\u610f\uff0c\u4fe1\u53f7 \\(p_i\u3001g_i \u548c a_i\\) \u4e2d\u53ea\u6709\u4e00\u4e2a\u662f 1\u3002</p> <p>Figure 5.13b shows how a Manchester carry chain might be implemented in CMOS. When the clock is low, the  c  nodes precharge. Then, when the clock goes high, if  gi  is high,  ci+1 is asserted or drawn low. To prevent  gi  from affecting  ci, the signal  pi  must be computed as the XOR (rather than OR) of  xi  and  yi. This is not a problem because we need the XOR of  xi  and  yi  for computing the sum anyway. </p> <p>\u56fe 5.13b \u663e\u793a\u4e86\u5982\u4f55\u5728 CMOS \u4e2d\u5b9e\u73b0\u66fc\u5f7b\u65af\u7279\u8fdb\u4f4d\u94fe\u3002\u5f53\u65f6\u949f\u4e3a\u4f4e\u7535\u5e73\u65f6\uff0cc \u8282\u70b9\u9884\u5145\u7535\u3002\u7136\u540e\uff0c\u5f53\u65f6\u949f\u53d8\u9ad8\u65f6\uff0c\u5982\u679c \\(g_i\\) \u4e3a\u9ad8\uff0c\u5219 \\(c_{i+1}\\) \u88ab\u65ad\u8a00\u6216\u62c9\u4f4e\u3002\u4e3a\u4e86\u9632\u6b62 \\(g_i\\) \u5f71\u54cd \\(c_i\\)\uff0c\u4fe1\u53f7 \\(p_i\\) \u5fc5\u987b\u8ba1\u7b97\u4e3a \\(x_i\\) \u548c \\(y_i\\) \u7684\u5f02\u6216\uff08\u800c\u4e0d\u662f\u6216\uff09\u3002\u8fd9\u4e0d\u662f\u95ee\u9898\uff0c\u56e0\u4e3a\u65e0\u8bba\u5982\u4f55\u6211\u4eec\u90fd\u9700\u8981 \\(x_i\\) \u548c \\(y_i\\) \u7684\u5f02\u6216\u6765\u8ba1\u7b97\u603b\u548c\u3002</p> <p></p> <p>For a  k-bit Manchester carry chain, the total delay consists of three components: </p> <ol> <li> <p>The time to form the switch control signals. </p> </li> <li> <p>The setup time for the switches. </p> </li> <li> <p>Signal propagation delay through  k  switches in the worst case. </p> </li> </ol> <p>\u5bf9\u4e8e k \u4f4d\u66fc\u5f7b\u65af\u7279\u8fdb\u4f4d\u94fe\uff0c\u603b\u5ef6\u8fdf\u7531\u4e09\u4e2a\u90e8\u5206\u7ec4\u6210\uff1a</p> <ol> <li> <p>\u5f62\u6210\u5f00\u5173\u63a7\u5236\u4fe1\u53f7\u7684\u65f6\u95f4\u3002</p> </li> <li> <p>\u5f00\u5173\u7684\u5efa\u7acb\u65f6\u95f4\u3002</p> </li> <li> <p>\u6700\u574f\u60c5\u51b5\u4e0b\u901a\u8fc7 k \u4e2a\u5f00\u5173\u7684\u4fe1\u53f7\u4f20\u64ad\u5ef6\u8fdf\u3002</p> </li> </ol> <p>The first two components of delay are small, constant terms. The delay is thus dominated by the third component, which is at best linear in  k. For modern CMOS technology, the delay is roughly proportional to  k 2 (as  k  pass transistors are connected in series), making the method undesirable for direct realization of fast adders. However, when the delay is in fact linear in  k, speed is gained over gate-based ripple-carry adders because we have one switch delay rather than two gate delays per stage. The linear or superlinear delay of a Manchester carry chain limits its usefulness for wide words or in high-performance designs. Its main application is in implementing short chains (say, up to 8 bits) as building blocks for use with a variety of fast addition schemes and certain hybrid designs. </p> <p>\u5ef6\u8fdf\u7684\u524d\u4e24\u4e2a\u5206\u91cf\u662f\u5c0f\u7684\u5e38\u6570\u9879\u3002\u56e0\u6b64\uff0c\u5ef6\u8fdf\u4e3b\u8981\u7531\u7b2c\u4e09\u4e2a\u5206\u91cf\u51b3\u5b9a\uff0c\u8be5\u5206\u91cf\u81f3\u591a\u4e0e k \u5448\u7ebf\u6027\u5173\u7cfb\u3002\u5bf9\u4e8e\u73b0\u4ee3 CMOS \u6280\u672f\uff0c\u5ef6\u8fdf\u5927\u81f4\u4e0e \\(k^2\\) (\u56e0\u4e3a k \u4e2a\u4f20\u8f93\u6676\u4f53\u7ba1\u4e32\u8054\u8fde\u63a5)\u6210\u6b63\u6bd4\uff0c\u4f7f\u5f97\u8be5\u65b9\u6cd5\u4e0d\u9002\u5408\u76f4\u63a5\u5b9e\u73b0\u5feb\u901f\u52a0\u6cd5\u5668\u3002\u7136\u800c\uff0c\u5f53\u5ef6\u8fdf\u5b9e\u9645\u4e0a\u4ee5 k \u4e3a\u7ebf\u6027\u65f6\uff0c\u901f\u5ea6\u6bd4\u57fa\u4e8e\u95e8\u7684\u7eb9\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\u83b7\u5f97\u4e86\u63d0\u9ad8\uff0c\u56e0\u4e3a\u6211\u4eec\u6bcf\u7ea7\u6709\u4e00\u4e2a\u5f00\u5173\u5ef6\u8fdf\u800c\u4e0d\u662f\u4e24\u4e2a\u95e8\u5ef6\u8fdf\u3002\u66fc\u5f7b\u65af\u7279\u8fdb\u4f4d\u94fe\u7684\u7ebf\u6027\u6216\u8d85\u7ebf\u6027\u5ef6\u8fdf\u9650\u5236\u4e86\u5176\u5728\u5bbd\u5b57\u6216\u9ad8\u6027\u80fd\u8bbe\u8ba1\u4e2d\u7684\u7528\u9014\u3002\u5b83\u7684\u4e3b\u8981\u5e94\u7528\u662f\u5b9e\u73b0\u77ed\u94fe\uff08\u4f8b\u5982\uff0c\u6700\u591a 8 \u4f4d\uff09\u4f5c\u4e3a\u6784\u5efa\u5757\uff0c\u4ee5\u4e0e\u5404\u79cd\u5feb\u901f\u52a0\u6cd5\u65b9\u6848\u548c\u67d0\u4e9b\u6df7\u5408\u8bbe\u8ba1\u4e00\u8d77\u4f7f\u7528\u3002</p> <p>We conclude this chapter by setting the stage for fast addition schemes to follow in Chapters 6 and 7. Taking advantage of generate and propagate signals defined in this section, an adder design can be viewed in the generic form of Fig. 5.14. Any adder will have the two sets of AND and XOR gates at the top to form the  gi  and  pi  signals, and it will have a set of XOR gates at the bottom to produce the sum bits  si. It will differ, however, in the design of its carry network, which is represented by the large oval block in Fig. 5.14. For example, a ripple-carry adder can be viewed as having the carry network shown in Fig. 5.15. Inserting this carry network into the generic design of Fig. 5.14 will produce a complete adder. Thus, in our subsequent discussions, we will focus on different designs for the carry network, and we will compare adders with respect to latency and cost of the carry network only.</p> <p>\u6211\u4eec\u901a\u8fc7\u4e3a\u7b2c 6 \u7ae0\u548c\u7b2c 7 \u7ae0\u4e2d\u7684\u5feb\u901f\u52a0\u6cd5\u65b9\u6848\u5960\u5b9a\u57fa\u7840\u6765\u7ed3\u675f\u672c\u7ae0\u3002\u5229\u7528\u672c\u8282\u4e2d\u5b9a\u4e49\u7684\u751f\u6210\u548c\u4f20\u64ad\u4fe1\u53f7\uff0c\u53ef\u4ee5\u4ee5\u56fe 5.14 \u7684\u901a\u7528\u5f62\u5f0f\u67e5\u770b\u52a0\u6cd5\u5668\u8bbe\u8ba1\u3002\u4efb\u4f55\u52a0\u6cd5\u5668\u90fd\u4f1a\u5728\u9876\u90e8\u5177\u6709\u4e24\u7ec4 AND \u548c XOR \u95e8\u4ee5\u5f62\u6210 \\(g_i\\) \u548c \\(p_i\\) \u4fe1\u53f7\uff0c\u5e76\u4e14\u5728\u5e95\u90e8\u5177\u6709\u4e00\u7ec4 XOR \u95e8\u4ee5\u4ea7\u751f\u548c\u4f4d \\(s_i\\)\u3002\u7136\u800c\uff0c\u5b83\u7684\u8fdb\u4f4d\u7f51\u7edc\u7684\u8bbe\u8ba1\u6709\u6240\u4e0d\u540c\uff0c\u5982\u56fe 5.14 \u4e2d\u7684\u5927\u692d\u5706\u5f62\u5757\u6240\u793a\u3002\u4f8b\u5982\uff0c\u7eb9\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\u53ef\u4ee5\u88ab\u89c6\u4e3a\u5177\u6709\u56fe 5.15 \u6240\u793a\u7684\u8fdb\u4f4d\u7f51\u7edc\u3002\u5c06\u6b64\u8fdb\u4f4d\u7f51\u7edc\u63d2\u5165\u56fe 5.14 \u7684\u901a\u7528\u8bbe\u8ba1\u5c06\u4ea7\u751f\u4e00\u4e2a\u5b8c\u6574\u7684\u52a0\u6cd5\u5668\u3002\u56e0\u6b64\uff0c\u5728\u540e\u7eed\u8ba8\u8bba\u4e2d\uff0c\u6211\u4eec\u5c06\u91cd\u70b9\u5173\u6ce8\u8fdb\u4f4d\u7f51\u7edc\u7684\u4e0d\u540c\u8bbe\u8ba1\uff0c\u5e76\u4e14\u6211\u4eec\u5c06\u4ec5\u6839\u636e\u8fdb\u4f4d\u7f51\u7edc\u7684\u5ef6\u8fdf\u548c\u6210\u672c\u6765\u6bd4\u8f83\u52a0\u6cd5\u5668\u3002</p> <p></p> <p></p>"},{"location":"Part_02/05/#_1","title":"\u95ee\u9898\uff08\u7565\uff09","text":""},{"location":"Part_02/05/#_2","title":"\u53c2\u8003\u6587\u732e\u548c\u8fdb\u4e00\u6b65\u9605\u8bfb","text":"<pre><code>[Beig98] Beigel, R., B. Gasarch, M. Li, and L. Zhang, \u201cAddition in log2n + O(1) Steps on\n         Average: A Simple Analysis,\u201d Theoretical Computer Science, Vol. 191, Nos. 1\u20132,\n         pp. 245\u2013248, 1998.\n[Bui02]  Bui, H. T., Y. Wang, and Y. Jiang, \u201cDesign and Analysis of Low-Power 10-Transistor\n         Full Adders Using Novel XOR-XNOR Gates,\u201d IEEE Trans. Circuits and Systems II,\n         Vol. 49, No. 1, pp. 25\u201330, 2002.\n[Burk46] Burks, A. W., H. H. Goldstine, and J. von Neumann, \u201cPreliminary Discussion of the\n         Logical Design of an Electronic Computing Instrument,\u201d Institute for Advanced\n         Study, Princeton, NJ, 1946.\n[Gilc55] Gilchrist, B., J. H. Pomerene, and S. Y. Wong, \u201cFast Carry Logic for Digital\n         Computers,\u201d IRE Trans. Electronic Computers, Vol. 4, pp. 133\u2013136, 1955.\n[Hend61] Hendrickson, H. C., \u201cFast High-Accuracy Binary Parallel Addition,\u201d IRE Trans.\n         Electronic Computers, Vol. 10, pp. 465\u2013468, 1961.\n[Jian04] Jiang, Y., A. Al-Sheraidah, Y. Wang, E. Sha, and J.-G. Chung, \u201cA Novel\n         Multiplexer-Based Low-Power Full Adder,\u201d IEEE Trans. Circuits and Systems II,\n         Vol. 51, No. 7, pp. 345\u2013353, 2004.\n[Kilb60] Kilburn, T., D. B. G. Edwards, and D. Aspinall, \u201cA Parallel Arithmetic Unit Using a\n         Saturated Transistor Fast-Carry Circuit,\u201d Proc. IEE, Vol. 107B, pp. 573\u2013584,\n         1960.\n[Laps97] Lapsley, P., DSP Processor Fundamentals: Architectures and Features, IEEE Press,\n         1997.\n[Lin07]  Lin, J. F., Y.-T. Hwang, M.-H. Sheu, and C.-C. Ho, \u201cA Novel High-Speed and Energy\n         Efficient 10-Transistor Full Adder Design,\u201d IEEE Trans. Circuits and Systems I,\n         Vol. 54, No. 5, pp. 1050\u20131059, 2007.\n[Ober81] Oberman, R. M. M., Counting and Counters, Macmillan, London, 1981.\n[Parh87] Parhami, B., \u201cSystolic Up/Down Counters with Zero and Sign Detection,\u201d Proc.\n         Symp. Computer Arithmetic, pp. 174\u2013178, 1987.\n[Puck94] Pucknell, D. A., and K. Eshraghian, Basic VLSI Design, 3rd ed., Prentice-Hall, 1994.\n[Stel98] Stelling, P. F., C. U. Martel, V. G. Oklobdzija, and R. Ravi, \u201cOptimal Circuits for\n         Parallel Multipliers,\u201d IEEE Trans. Computers, Vol. 47, No. 3, pp. 273\u2013285, 1998.\n[Vuil91] Vuillemin, J. E., \u201cConstant Time Arbitrary Length Synchronous Binary Counters,\u201d\n         Proc. Symp. Computer Arithmetic, pp. 180\u2013183, 1991.\n</code></pre>"},{"location":"Part_02/06/","title":"6. \u8d85\u524d\u8fdb\u4f4d\u52a0\u6cd5\u5668","text":"<p>Cary-Lookahead Adders</p> <p>\u201cComputers can figure out all kinds of problems, except the things in the world that just don\u2019t add up.\u201d               \u2014 ANONYMOUS</p> <p>\u201c\u8ba1\u7b97\u673a\u53ef\u4ee5\u89e3\u51b3\u5404\u79cd\u5404\u6837\u7684\u95ee\u9898\uff0c\u9664\u4e86\u4e16\u754c\u4e0a\u90a3\u4e9b\u4e0d\u5408\u903b\u8f91(\u4e0d\u80fd\u52a0\u8d77\u6765)\u7684\u4e8b\u60c5\u3002\u201d               \u2014 \u533f\u540d</p> <p>Adder designs considered in Chapter 5 have worst-case delays that grow at least linearly with the word width k. Since the most-significant bit of the sum is a function of all the 2k input bits, assuming that the gate fan-in is limited to d, a lower bound on addition latency is logd(2k). An interesting question, therefore, is whether one can add two k-bit binary numbers in O(log k) worst-case time. Carry-lookahead adders, covered in this chapter, represent a commonly used scheme for logarithmic time addition. Other schemes are introduced in Chapter 7.</p> <p>\u7b2c 5 \u7ae0\u4e2d\u8003\u8651\u7684\u52a0\u6cd5\u5668\u8bbe\u8ba1\u5177\u6709\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u5ef6\u8fdf\uff0c\u8be5\u5ef6\u8fdf\u81f3\u5c11\u968f\u5b57\u5bbd k \u7ebf\u6027\u589e\u957f\u3002 \u7531\u4e8e\u548c\u7684\u6700\u9ad8\u6709\u6548\u4f4d\u662f\u6240\u6709 2k \u8f93\u5165\u4f4d\u7684\u51fd\u6570\uff0c\u5047\u8bbe\u95e8\u6247\u5165\u9650\u5236\u4e3a d\uff0c\u52a0\u6cd5\u5ef6\u8fdf\u7684\u4e0b\u9650\u4e3a \\(\\log_d(2k)\\)\u3002 \u56e0\u6b64\uff0c\u4e00\u4e2a\u6709\u8da3\u7684\u95ee\u9898\u662f\uff0c\u662f\u5426\u53ef\u4ee5\u5728 \\(O(\\log k)\\) \u6700\u574f\u60c5\u51b5\u65f6\u95f4\u5185\u5c06\u4e24\u4e2a k \u4f4d\u4e8c\u8fdb\u5236\u6570\u76f8\u52a0\u3002 \u672c\u7ae0\u4ecb\u7ecd\u7684\u8d85\u524d\u8fdb\u4f4d\u52a0\u6cd5\u5668\u4ee3\u8868\u4e86\u5bf9\u6570\u65f6\u95f4\u52a0\u6cd5\u7684\u5e38\u7528\u65b9\u6848\u3002 \u5176\u4ed6\u65b9\u6848\u5c06\u5728\u7b2c 7 \u7ae0\u4e2d\u4ecb\u7ecd\u3002</p> <ul> <li>6.1 \u5c55\u5f00\u8fdb\u4f4d\u9012\u5f52 UNROLLING THE CARRY RECURRENCE</li> <li>6.2 \u8d85\u524d\u8fdb\u4f4d\u52a0\u6cd5\u5668\u7684\u8bbe\u8ba1 CARRY-LOOKAHEAD ADDER DESIGN</li> <li>6.3 LING\u578b\u52a0\u6cd5\u5668\u4e0e\u76f8\u5173\u8bbe\u8ba1 LING ADDER AND RELATED DESIGNS</li> <li>6.4 \u5e76\u884c\u524d\u7f00\u8fdb\u4f4d\u8ba1\u7b97 CARRY DETERMINATION AS PREFIX COMPUTATION</li> <li>6.5 \u6df7\u5408\u7684\u5e76\u884c\u524d\u7f00\u8fdb\u4f4d\u7f51\u7edc ALTERNATIVE PARALLEL PREFIX NETWORKS</li> <li>6.6 VLSI\u5b9e\u73b0\u76f8\u5173 VLSI IMPLEMENTATION ASPECTS</li> </ul>"},{"location":"Part_02/06/#61","title":"6.1 \u5c55\u5f00\u8fdb\u4f4d\u9012\u5f52","text":"<p>Recall the gi (generate), pi (propagate), ai (annihilate or absorb), and ti (transfer) auxiliary signals introduced in Section 5.6:</p> <p>\u56de\u60f3\u4e00\u4e0b 5.6 \u8282\u4e2d\u4ecb\u7ecd\u7684 \\(g_i\\)\uff08\u751f\u6210\uff09\u3001\\(p_i\\)\uff08\u4f20\u64ad\uff09\u3001\\(a_i\\)\uff08\u6d88\u706d\u6216\u5438\u6536\uff09\u548c \\(t_i\\)\uff08\u8f6c\u79fb\uff09\u8f85\u52a9\u4fe1\u53f7\uff1a</p> \\[ \\begin{array}{l} g_i = 1 \\iff x_i + y_i \u2265 r     &amp; \\text{\u8fdb\u4f4d\u5fc5\u7136\u4ea7\u751f} &amp; \\text{Carry is generated}\\\\ p_i = 1 \\iff x_i + y_i = r \u2212 1 &amp; \\text{\u8fdb\u4f4d\u8f93\u5165\u53ef\u4ee5\u4f20\u9012\u5230\u8f93\u51fa} &amp; \\text{Carry is propagated} \\\\ t_i = \\bar a_i = g_i \\vee p_i  &amp; \\text{\u8fdb\u4f4d\u4e0d\u4f1a\u88ab\u5438\u6536} &amp; \\text{Carry is not annihilated} \\\\ \\end{array} \\] <p>These signals, along with the carry recurrence</p> <p>\u8fd9\u4e9b\u4fe1\u53f7\u4ee5\u53ca\u8fdb\u4f4d\u9012\u5f52</p> <p>\\(c_{i+1} = g_i \\vee p_ic_i = g_i \\vee t_ic_i\\)</p> <p>allow us to decouple the problem of designing a fast carry network from details of the number system (radix, digit set). In fact it does not even matter whether we are adding or subtracting; any carry network can be used as a borrow network if we simply redefine the preceding signals to correspond to borrow generation, borrow propagation, and so on. </p> <p>\u8ba9\u6211\u4eec\u80fd\u591f\u5c06\u8bbe\u8ba1\u5feb\u901f\u8fdb\u4f4d\u7f51\u7edc\u7684\u95ee\u9898\u4e0e\u6570\u5b57\u7cfb\u7edf\u7684\u7ec6\u8282\uff08\u57fa\u6570\u3001\u6570\u5b57\u96c6\uff09\u89e3\u8026\u3002\u4e8b\u5b9e\u4e0a\uff0c\u6211\u4eec\u662f\u52a0\u8fd8\u662f\u51cf\u5e76\u4e0d\u91cd\u8981\uff1b\u5982\u679c\u6211\u4eec\u7b80\u5355\u5730\u91cd\u65b0\u5b9a\u4e49\u524d\u9762\u7684\u4fe1\u53f7\u4ee5\u5bf9\u5e94\u501f\u4f4d\u751f\u6210\u3001\u501f\u4f4d\u4f20\u64ad\u7b49\uff0c\u5219\u4efb\u4f55\u8fdb\u4f4d\u7f51\u7edc\u90fd\u53ef\u4ee5\u7528\u4f5c\u501f\u4f4d\u7f51\u7edc\u3002</p> <p>The carry recurrence  ci+1 =  gi \u2228  pici  states that a carry will enter stage  i + 1 if it is generated in stage  i  or it enters stage  i  and is propagated by that stage. One can easily unroll this recurrence, eventually obtaining each carry  ci  as a logical function of the operand bits and  c in. Here are three steps of the unrolling process for  :</p> <p>\u8fdb\u4f4d\u5faa\u73af \\(c_{i+1} = g_i \u2228 p_ic_i\\) \u8868\u660e\uff0c\u5982\u679c\u8fdb\u4f4d\u5728\u7b2c i \u9636\u6bb5\u751f\u6210\uff0c\u6216\u8005\u8fdb\u5165\u7b2c i \u9636\u6bb5\u5e76\u7531\u8be5\u9636\u6bb5\u4f20\u64ad\uff0c\u5219\u8fdb\u4f4d\u5c06\u8fdb\u5165\u7b2c i + 1 \u9636\u6bb5\u3002\u4eba\u4eec\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u5c55\u5f00\u8fd9\u4e2a\u9012\u5f52\u5f0f\uff0c\u6700\u7ec8\u83b7\u5f97\u6bcf\u4e2a\u8fdb\u4f4d \\(c_i\\) \u4f5c\u4e3a\u64cd\u4f5c\u6570\u4f4d\u548c \\(c_{in}\\) \u7684\u903b\u8f91\u51fd\u6570\u3002\u4ee5\u4e0b\u662f \\(c_i\\) \u5c55\u5f00\u8fc7\u7a0b\u7684\u4e09\u4e2a\u6b65\u9aa4\uff1a</p> <p>\\(c_i = g_{i\u22121} \u2228 c_{i\u22121} p_{i\u22121}\\)</p> <p>\\(\\ = g_{i\u22121} \u2228 (g_{i\u22122} \u2228 c_{i\u22122}p_{i\u22122})p_{i\u22121} = g_{i\u22121} \u2228 g_{i\u22122}p_{i\u22121} \u2228 c_{i\u22122}p_{i\u22122}p_{i\u22121}\\)</p> <p>\\(\\ =g_{i\u22121} \u2228 g_{i\u22122}p_{i\u22121} \u2228 g_{i\u22123}p_{i\u22122}p_{i\u22121} \u2228 c_{i\u22123}p_{i\u22123}p_{i\u22122}p_{i\u22121}\\)</p> <p>\\(\\ = g_{i\u22121} \u2228 g_{i\u22122}p_{i\u22121} \u2228 g_{i\u22123}p_{i\u22122}p_{i\u22121} \u2228 g_{i\u22124}p_{i\u22123}p_{i\u22122}p_{i\u22121} \u2228 c_{i\u22124}p_{i\u22124}p_{i\u22123}p_{i\u22122}p_{i\u22121}\\)</p> <p>The unrolling can be continued until the last product term contains  c 0 =  c in. The unrolled version of the carry recurrence has the following simple interpretation: carry enters into position  i  if and only if a carry is generated in position  i \u2212 1  (gi\u22121 ), or a carry generated in position  i \u2212 2 is propagated by position  i \u2212 1  (gi\u22122 pi\u22121 ), or a carry generated in position  i \u2212 3 is propagated at  i \u2212 2 and  i \u2212 1  (gi\u22123 pi\u22122 pi\u22121 ), etc. </p> <p>\u53ef\u4ee5\u7ee7\u7eed\u5c55\u5f00\uff0c\u76f4\u5230\u6700\u540e\u4e00\u4e2a\u4e58\u79ef\u9879\u5305\u542b \\(c_0 = c_{in}\\)\u3002\u8fdb\u4f4d\u9012\u5f52\u7684\u5c55\u5f00\u7248\u672c\u5177\u6709\u4ee5\u4e0b\u7b80\u5355\u89e3\u91ca\uff1a\u8fdb\u4f4d\u8fdb\u5165\u4f4d\u7f6e \\(i\\) \u5f53\u4e14\u4ec5\u5f53\u5728\u4f4d\u7f6e \\(i \u2212 1\\) \u751f\u6210\u8fdb\u4f4d\\((g_i\u22121 )\\) \uff0c\u6216\u8005\u5728\u4f4d\u7f6e \\(i \u2212 2\\) \u751f\u6210\u7684\u8fdb\u4f4d\u7531\u4f4d\u7f6e \\(i \u2212 1\\)  \u4f20\u64ad\\((g_{i\u22122} p_{i\u22121} )\\)\uff0c\u6216\u8005\u5728\u4f4d\u7f6e \\(i \u2212 3\\) \u751f\u6210\u7684\u8fdb\u4f4d\u5728 \\(i \u2212 2\\) \u548c \\(i \u2212 1\\) \u4f20\u64ad($g_{i\u22123} p_{i\u22122} p_{i\u22121} $) \u7b49</p> <p>After full unrolling, we can compute all the carries in a  k-bit adder directly from the auxiliary signals ( gi,  pi) and  c in, using two-level AND-OR logic circuits with maximum gate fan-in of  k + 1. For  k = 4, the logic expressions are as follows: </p> <p>\u5b8c\u5168\u5c55\u5f00\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u6700\u5927\u95e8\u6247\u5165\u4e3a k + 1 \u7684\u4e24\u7ea7 AND-OR \u903b\u8f91\u7535\u8def\uff0c\u76f4\u63a5\u6839\u636e\u8f85\u52a9\u4fe1\u53f7 ( gi, pi) \u548c c in \u8ba1\u7b97 k \u4f4d\u52a0\u6cd5\u5668\u4e2d\u7684\u6240\u6709\u8fdb\u4f4d\u3002\u5bf9\u4e8e k = 4\uff0c\u903b\u8f91\u8868\u8fbe\u5f0f\u5982\u4e0b\uff1a</p> <p>\\(c_4 = g_3 \u2228 g_2p_3 \u2228 g_1p_2p_3 \u2228 g_0p_1p_2p_3 \u2228 c_0p_0p_1p_2p_3\\) \\(c_3 = g_2 \u2228 g_1p_2 \u2228 g_0p_1p_2 \u2228 c_0p_0p_1p_2\\) \\(c_2 = g_1 \u2228 g_0p_1 \u2228 c_0p_0p_1\\) \\(c_1 = g_0 \u2228 c_0p_0\\)</p> <p>Here,  c 0 and  c 4 are the 4-bit adder\u2019s  c in and  c out, respectively. A carry network based on the preceding equations can be used in conjunction with two-input ANDs, producing the gi  signals, and two-input XORs, producing the  pi  and sum bits, to build a 4-bit binary adder. Such an adder is said to have  full carry lookahead. </p> <p>\u8fd9\u91cc\uff0cc 0 \u548cc 4 \u5206\u522b\u662f4\u4f4d\u52a0\u6cd5\u5668\u7684\\(c_{in}\\) \u548c\\(c_{out}\\)\u3002\u57fa\u4e8e\u524d\u8ff0\u65b9\u7a0b\u7684\u8fdb\u4f4d\u7f51\u7edc\u53ef\u4ee5\u4e0e\u4ea7\u751f \\(g_i\\) \u4fe1\u53f7\u7684\u53cc\u8f93\u5165 AND \u548c\u4ea7\u751f \\(p_i\\) \u548c\u548c\u4f4d\u7684\u53cc\u8f93\u5165 XOR \u7ed3\u5408\u4f7f\u7528\uff0c\u4ee5\u6784\u5efa 4 \u4f4d\u4e8c\u8fdb\u5236\u52a0\u6cd5\u5668\u3002\u8fd9\u6837\u7684\u52a0\u6cd5\u5668\u88ab\u79f0\u4e3a\u662f\u6709*\u5b8c\u5168\u8fdb\u4f4d\u8d85\u524d\u8fdb\u4f4d*\u3002</p> <p>Note that since  c 4 does not affect the computation of the sum bits, it can be derived based on the simpler equation</p> <p>\u6ce8\u610f\uff0c\u7531\u4e8ec 4 \u4e0d\u5f71\u54cd\u548c\u4f4d\u7684\u8ba1\u7b97\uff0c\u56e0\u6b64\u53ef\u4ee5\u57fa\u4e8e\u66f4\u7b80\u5355\u7684\u65b9\u7a0b\u63a8\u5bfc</p> <p>\\(c_4 = g_3 \u2228 c_3 p_3\\)</p> <p>with little or no speed penalty. The resulting carry network is depicted in Fig. 6.1. </p> <p>\u51e0\u4e4e\u6ca1\u6709\u901f\u5ea6\u635f\u5931\u3002\u7531\u6b64\u4ea7\u751f\u7684\u8fdb\u4f4d\u7f51\u7edc\u5982\u56fe 6.1 \u6240\u793a\u3002</p> <p></p> <p>Clearly, full carry lookahead is impractical for wide words. The fully unrolled carry equation for  c 31, for example, consists of 32 product terms, the largest of which contains 32 literals. Thus, the required AND and OR functions must be realized by tree networks, leading to increased latency and cost. Two schemes for managing this complexity immediately suggest themselves:</p> <ul> <li> <p>High-radix addition (i.e., radix \\(2^h\\))</p> </li> <li> <p>Multilevel lookahead</p> </li> </ul> <p>\u663e\u7136\uff0c\u5168\u8fdb\u4f4d\u8d85\u524d\u5bf9\u4e8e\u5bbd\u5b57\u6765\u8bf4\u662f\u4e0d\u5207\u5b9e\u9645\u7684\u3002\u4f8b\u5982\uff0c\\(c_{31}\\) \u7684\u5b8c\u5168\u5c55\u5f00\u8fdb\u4f4d\u65b9\u7a0b\u7531 32 \u4e2a\u4e58\u79ef\u9879\u7ec4\u6210\uff0c\u5176\u4e2d\u6700\u5927\u7684\u5305\u542b32 \u4e2a\u6587\u5b57\u3002\u56e0\u6b64\uff0c\u6240\u9700\u7684\u201c\u4e0e\u201d\u548c\u201c\u6216\u201d\u529f\u80fd\u5fc5\u987b\u901a\u8fc7\u6811\u5f62\u7f51\u7edc\u6765\u5b9e\u73b0\uff0c\u4ece\u800c\u5bfc\u81f4\u5ef6\u8fdf\u548c\u6210\u672c\u589e\u52a0\u3002\u7ba1\u7406\u8fd9\u79cd\u590d\u6742\u6027\u7684\u4e24\u79cd\u65b9\u6848\u7acb\u5373\u51fa\u73b0\uff1a</p> <ul> <li>\u9ad8\u57fa\u6570\u52a0\u6cd5\uff08\u5373\u57fa\u6570 \\(2^h\\)\uff09</li> <li>\u591a\u7ea7\u524d\u77bb</li> </ul> <p>High-radix addition increases the latency for generating the auxiliary signals and sum digits but simplifies the carry network. Depending on the implementation method and technology, an optimal radix might exist. Multilevel lookahead is the technique used in practice and is covered in Section 6.2. </p> <p>\u9ad8\u57fa\u6570\u52a0\u6cd5\u589e\u52a0\u4e86\u751f\u6210\u8f85\u52a9\u4fe1\u53f7\u548c\u548c\u6570\u5b57\u7684\u5ef6\u8fdf\uff0c\u4f46\u7b80\u5316\u4e86\u8fdb\u4f4d\u7f51\u7edc\u3002\u6839\u636e\u5b9e\u73b0\u65b9\u6cd5\u548c\u6280\u672f\uff0c\u53ef\u80fd\u5b58\u5728\u6700\u4f73\u57fa\u6570\u3002\u591a\u7ea7\u524d\u77bb\u662f\u5b9e\u8df5\u4e2d\u4f7f\u7528\u7684\u6280\u672f\uff0c\u5728 6.2 \u8282\u4e2d\u8fdb\u884c\u4e86\u4ecb\u7ecd\u3002</p>"},{"location":"Part_02/06/#62","title":"6.2 \u8d85\u524d\u8fdb\u4f4d\u52a0\u6cd5\u5668\u7684\u8bbe\u8ba1","text":"<p>Consider radix-16 addition of two binary numbers that are characterized by their  gi  and pi  signals. For each radix-16 digit position, extending from bit position  i  to bit position i + 3 of the original binary numbers (where  i  is a multiple of 4), \u201cblock generate\u201d and \u201cblock propagate\u201d signals can be derived as follows:</p> <p>\u8003\u8651\u4ee5 \\(g_i\\) \u548c \\(p_i\\) \u4fe1\u53f7\u4e3a\u7279\u5f81\u7684\u4e24\u4e2a\u4e8c\u8fdb\u5236\u6570\u7684\u57fa 16 \u52a0\u6cd5\u3002\u5bf9\u4e8e\u6bcf\u4e2a\u57fa\u6570 16 \u4f4d\u4f4d\u7f6e\uff0c\u4ece\u539f\u59cb\u4e8c\u8fdb\u5236\u6570\u7684\u4f4d\u4f4d\u7f6e \\(i\\) \u5ef6\u4f38\u5230\u4f4d\u4f4d\u7f6e \\(i + 3\\)\uff08\u5176\u4e2d \\(i\\) \u662f 4 \u7684\u500d\u6570\uff09\uff0c\u201c\u5757\u751f\u6210\u201d\u548c \u201c\u5757\u4f20\u64ad\u201d\u4fe1\u53f7\u53ef\u4ee5\u5982\u4e0b\u5bfc\u51fa\uff1a</p> <p>\\(g_{[ i, i+3]} = g_{i+3} \u2228 g_{i+2} p_{i+3} \u2228 g_{i+1} p_{i+2} p_{i+3} \u2228 g_ip_{i+1} p_{i+2} p_{i+3}\\)</p> <p>\\(p_{[ i, i+3]} = p_ip_{i+1} p_{i+2} p_{i+3}\\)</p> <p>The preceding equations can be interpreted in the same way as unrolled carry equations: the four bit positions collectively propagate an incoming carry  ci  if and only if each of the four positions propagates; they collectively generate a carry if a carry is produced in position  i + 3, or it is produced in position  i + 2 and propagated by position i + 3, etc. </p> <p>\u524d\u9762\u7684\u65b9\u7a0b\u53ef\u4ee5\u7528\u4e0e\u5c55\u5f00\u8fdb\u4f4d\u65b9\u7a0b\u76f8\u540c\u7684\u65b9\u5f0f\u89e3\u91ca\uff1a\u5f53\u4e14\u4ec5\u5f53\u56db\u4e2a\u4f4d\u7f6e\u4e2d\u7684\u6bcf\u4e00\u4e2a\u90fd\u4f20\u64ad\u65f6\uff0c\u56db\u4e2a\u4f4d\u4f4d\u7f6e\u5171\u540c\u4f20\u64ad\u4f20\u5165\u8fdb\u4f4d ci\uff1b\u5982\u679c\u5728\u4f4d\u7f6e \\(i + 3\\) \u4ea7\u751f\u8fdb\u4f4d\uff0c\u6216\u8005\u5728\u4f4d\u7f6e \\(i + 2\\) \u4ea7\u751f\u8fdb\u4f4d\u5e76\u901a\u8fc7\u4f4d\u7f6e \\(i + 3\\) \u4f20\u64ad\uff0c\u7b49\u7b49\uff0c\u5219\u5b83\u4eec\u5171\u540c\u4ea7\u751f\u8fdb\u4f4d\u3002</p> <p>If we replace the  c 4 portion of the carry network of Fig. 6.1 with circuits that produce the block generate and propagate signals  g[ i,  i+3] and  p[ i,  i+3], the 4-bit  lookahead carry generator  of Fig. 6.2a is obtained. Figure 6.2b shows the 4-bit lookahead carry generator in schematic form. We will see shortly that such a block can be used in a multilevel structure to build a carry network of any desired width. </p> <p>\u5982\u679c\u6211\u4eec\u7528\u4ea7\u751f\u5757\u751f\u6210\u548c\u4f20\u64ad\u4fe1\u53f7 \\(g_{[i, i+3]}\\)\u548c \\(p_{[i, i+3]}\\) \u7684\u7535\u8def\u66ff\u6362\u56fe 6.1 \u8fdb\u4f4d\u7f51\u7edc\u7684 \\(c_4\\) \u90e8\u5206\uff0c\u5219\u83b7\u5f97\u56fe 6.2a \u7684 4 \u4f4d\u5148\u884c\u8fdb\u4f4d\u751f\u6210\u5668\u3002\u56fe 6.2b \u4ee5\u539f\u7406\u56fe\u5f62\u5f0f\u663e\u793a\u4e86 4 \u4f4d\u5148\u884c\u8fdb\u4f4d\u751f\u6210\u5668\u3002\u6211\u4eec\u5f88\u5feb\u5c31\u4f1a\u770b\u5230\uff0c\u8fd9\u6837\u7684\u5757\u53ef\u4ee5\u5728\u591a\u5c42\u7ed3\u6784\u4e2d\u4f7f\u7528\uff0c\u4ee5\u6784\u5efa\u4efb\u4f55\u6240\u9700\u5bbd\u5ea6\u7684\u8fdb\u4f4d\u7f51\u7edc\u3002</p> <p></p> <p>First, however, let us take a somewhat more general view of the block generate and propagate signals. Assuming  i 0  &lt; i 1  &lt; i 2, we can write </p> <p>\u7136\u800c\uff0c\u9996\u5148\u8ba9\u6211\u4eec\u5bf9\u6a21\u5757\u751f\u6210\u548c\u4f20\u64ad\u4fe1\u53f7\u6709\u4e00\u4e2a\u66f4\u4e00\u822c\u7684\u770b\u6cd5\u3002\u5047\u8bbe \\(i_0 &lt; i_1 &lt; i_2\\)\uff0c\u6211\u4eec\u53ef\u4ee5\u5199\u51fa\u4e0b\u9762\u7b49\u5f0f</p> <p>\\(g_{[ i_0, i_2\u22121]} = g_{[i_1, i_2\u22121]} \u2228 g_{[i_0, i_1\u22121]} p_{[ i_1, i_2\u22121]}\\)</p> <p>This equation essentially says that a carry is generated by the block of positions from  i 0 to  i 2 \u2212 1 if and only if a carry is generated by the [ i 1,  i 2 \u2212 1] block or a carry generated p[ i,  i+3] by the [i0, i1 \u2212 1] block is propagated by the [i1, i2 \u2212 1] block. Similarly</p> <p>\u8be5\u7b49\u5f0f\u672c\u8d28\u4e0a\u8868\u793a\u8fdb\u4f4d\u662f\u7531 \\(i_0\\) \u5f00\u59cb\u7684\u4f4d\u7f6e\u5757\u751f\u6210\u7684\u5230 \\(i_2 \u2212 1\\) \u5f53\u4e14\u4ec5\u5f53 \\([ i_1, i_2 \u2212 1]\\) \u5757\u751f\u6210\u8fdb\u4f4d\u6216\u7531 \\([ i_0, i_1 \u2212 1]\\) \u5757\u751f\u6210\u8fdb\u4f4d\u7136\u540e\u7531 \\([ i_1, i_2 \u2212 1]\\) \u5757\u4f20\u64ad\u3002\u7c7b\u4f3c\u7684\u6709\u4e0b\u9762\u7b49\u5f0f</p> <p>\\(p[i_0,i_2\u22121] = p[i_0,i_1\u22121]p[i_1,i_2\u22121]\\)</p> <p>In fact the two blocks being merged into a larger block do not have to be contiguous; they can also be overlapping. In other words, for the possibly overlapping blocks [ i 1,  j 1] and [ i 0,  j 0],  i 0 \u2264  i 1 \u2212 1 \u2264  j 0  &lt; j 1, we have </p> <p>\u4e8b\u5b9e\u4e0a\uff0c\u5408\u5e76\u6210\u4e00\u4e2a\u66f4\u5927\u5757\u7684\u4e24\u4e2a\u5757\u4e0d\u5fc5\u662f\u8fde\u7eed\u7684\uff1b\u5b83\u4eec\u4e5f\u53ef\u4ee5\u91cd\u53e0\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u5bf9\u4e8e\u53ef\u80fd\u91cd\u53e0\u7684\u5757 \\([ i_1, j_1]\\)  \u548c \\([ i_0, j_0]\\), \\(i_0 \u2264 i_1 \u2212 1 \u2264 j_0 &lt; j_1\\)\uff0c\u6211\u4eec\u6709</p> <p>\\(g[i_0,j_1] = g[i_1,j_1] \u2228 g[i_0,j_0]p[i_1,j_1]\\)</p> <p>\\(p[i_0,j_1] = p[i_0,j_0]p[i_1,j_1]\\)</p> <p>Figure 6.3 shows that a 4-bit lookahead carry generator can be used to combine the g  and  p  signals from adjacent or overlapping blocks into the  p  and  g  signals for the combined block. </p> <p>\u56fe 6.3 \u663e\u793a 4 \u4f4d\u5148\u884c\u8fdb\u4f4d\u53d1\u751f\u5668\u53ef\u7528\u4e8e\u5c06\u6765\u81ea\u76f8\u90bb\u6216\u91cd\u53e0\u5757\u7684 g \u548c p \u4fe1\u53f7\u7ec4\u5408\u6210\u7ec4\u5408\u5757\u7684 p \u548c g \u4fe1\u53f7\u3002</p> <p></p> <p>Given the 4-bit lookahead carry generator of Fig. 6.2, it is an easy matter to synthesize wider adders based on a multilevel carry-lookahead scheme. For example, to construct a two-level 16-bit carry-lookahead adder, we need four 4-bit adders and a 4-bit lookahead carry generator, connected together as shown on the upper right quadrant of Fig. 6.4. </p> <p>\u7ed9\u5b9a\u56fe 6.2 \u6240\u793a\u7684 4 \u4f4d\u8d85\u524d\u8fdb\u4f4d\u751f\u6210\u5668\uff0c\u57fa\u4e8e\u591a\u7ea7\u8d85\u524d\u8fdb\u4f4d\u65b9\u6848\u5408\u6210\u66f4\u5bbd\u7684\u52a0\u6cd5\u5668\u662f\u4e00\u4ef6\u5bb9\u6613\u7684\u4e8b\u3002\u4f8b\u5982\uff0c\u8981\u6784\u5efa\u4e00\u4e2a\u4e24\u7ea716\u4f4d\u5148\u884c\u8fdb\u4f4d\u52a0\u6cd5\u5668\uff0c\u6211\u4eec\u9700\u8981\u56db\u4e2a4\u4f4d\u52a0\u6cd5\u5668\u548c\u4e00\u4e2a4\u4f4d\u8d85\u524d\u8fdb\u4f4d\u53d1\u751f\u5668\uff0c\u5982\u56fe6.4\u53f3\u4e0a\u8c61\u9650\u6240\u793a\u8fde\u63a5\u5728\u4e00\u8d77\u3002</p> <p></p> <p>The 4-bit lookahead carry generator in this case can be viewed as predicting the three intermediate carries in a 4-digit radix-16 addition. The latency through this 16-bit adder consists of the time required for:</p> <ul> <li>Producing the  g  and  p  signals for individual bit positions (1 gate level). </li> <li>Producing the  g  and  p  signals for 4-bit blocks (2 gate levels). </li> <li>Predicting the carry-in signals  c 4,  c 8, and  c 12 for the blocks (2 gate levels). </li> <li>Predicting the internal carries within each 4-bit block (2 gate levels). </li> <li>Computing the sum bits (2 gate levels). </li> </ul> <p>Thus the total latency for the 16-bit adder is 9 gate levels, which is much better than the 32 gate levels required by a 16-bit ripple-carry adder. </p> <p>\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c4 \u4f4d\u5148\u884c\u8d85\u524d\u751f\u6210\u5668\u53ef\u4ee5\u88ab\u89c6\u4e3a\u9884\u6d4b 4 \u4f4d\u57fa 16 \u52a0\u6cd5\u4e2d\u7684\u4e09\u4e2a\u4e2d\u95f4\u8fdb\u4f4d\u3002\u901a\u8fc7\u8be5 16 \u4f4d\u52a0\u6cd5\u5668\u7684\u5ef6\u8fdf\u5305\u62ec\u4ee5\u4e0b\u6240\u9700\u7684\u65f6\u95f4\uff1a</p> <ul> <li>\u4e3a\u5404\u4e2a\u4f4d\u4f4d\u7f6e\uff081 \u4e2a\u95e8\u7ea7\uff09\u751f\u6210 g \u548c p \u4fe1\u53f7\u3002</li> <li>\u751f\u6210 4 \u4f4d\u5757\uff082 \u4e2a\u95e8\u7ea7\uff09\u7684 g \u548c p \u4fe1\u53f7\u3002\u9884\u6d4b\u5757\uff082 \u4e2a\u95e8\u7ea7\uff09\u7684\u8fdb\u4f4d\u4fe1\u53f7 c 4\u3001c 8 \u548c c 12\u3002</li> <li>\u9884\u6d4b\u6bcf\u4e2a 4 \u4f4d\u5757\uff082 \u4e2a\u95e8\u7ea7\uff09\u5185\u7684\u5185\u90e8\u8fdb\u4f4d\u3002</li> <li>\u8ba1\u7b97\u603b\u548c\u4f4d\uff082 \u4e2a\u95e8\u7ea7\uff09\u3002</li> </ul> <p>\u56e0\u6b64\uff0c16 \u4f4d\u52a0\u6cd5\u5668\u7684\u603b\u5ef6\u8fdf\u4e3a 9 \u4e2a\u95e8\u7ea7\uff0c\u8fd9\u6bd4 16 \u4f4d\u7eb9\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\u6240\u9700\u7684 32 \u4e2a\u95e8\u7ea7\u8981\u597d\u5f97\u591a\u3002</p> <p>Similarly, to construct a three-level 64-bit carry-lookahead adder, we can use four of the 16-bit adders above plus one 4-bit lookahead carry generator, connected together as shown in Fig. 6.4. The delay will increase by four gate levels with each additional level of lookahead: two levels in the downward movement of the  g  and  p  signals, and two levels for the upward propagation of carries through the extra level. Thus, the delay of a  k-bit carry-lookahead adder based on 4-bit lookahead blocks is</p> <p>\u540c\u6837\uff0c\u8981\u6784\u9020\u4e00\u4e2a\u4e09\u7ea7 64 \u4f4d\u5148\u884c\u8fdb\u4f4d\u52a0\u6cd5\u5668\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u4e0a\u9762\u7684 4 \u4e2a 16 \u4f4d\u52a0\u6cd5\u5668\u52a0\u4e0a 1 \u4e2a 4 \u4f4d\u5148\u884c\u8fdb\u4f4d\u53d1\u751f\u5668\uff0c\u8fde\u63a5\u5728\u4e00\u8d77\u5982\u56fe 6.4 \u6240\u793a\u3002\u6bcf\u589e\u52a0\u4e00\u4e2a\u8d85\u524d\u7ea7\u522b\uff0c\u5ef6\u8fdf\u5c06\u589e\u52a0\u56db\u4e2a\u95e8\u7ea7\u522b\uff1ag \u548c p \u4fe1\u53f7\u5411\u4e0b\u79fb\u52a8\u7684\u4e24\u4e2a\u7ea7\u522b\uff0c\u4ee5\u53ca\u901a\u8fc7\u989d\u5916\u7ea7\u522b\u7684\u8fdb\u4f4d\u5411\u4e0a\u4f20\u64ad\u7684\u4e24\u4e2a\u7ea7\u522b\u3002\u56e0\u6b64\uff0c\u57fa\u4e8e 4 \u4f4d\u5148\u884c\u5757\u7684 k \u4f4d\u8fdb\u4f4d\u5148\u884c\u52a0\u6cd5\u5668\u7684\u5ef6\u8fdf\u4e3a</p> <p>\\(\\begin{equation} T_{Lookahead\u2212add} = 4 \\log_4 k + 1 \\text{ gate levels} \\end{equation}\\)</p> <p>Hence, the 64-bit carry-lookahead adder of Fig. 6.4 has a latency of 13 gate levels. </p> <p>\u56e0\u6b64\uff0c\u56fe 6.4 \u7684 64 \u4f4d\u8fdb\u4f4d\u8d85\u524d\u52a0\u6cd5\u5668\u5177\u6709 13 \u4e2a\u95e8\u7ea7\u7684\u5ef6\u8fdf\u3002</p> <p>One can of course use 6-bit or 8-bit lookahead blocks to reduce the number of lookahead levels for a given word width. But this may not be worthwhile in view of the longer delays introduced by gates with higher fan-in. When the word width is not a power of 4, some of the inputs and/or outputs of the lookahead carry generators remain unused, and the latency formula becomes 4 log4  k + 1. </p> <p>\u5f53\u7136\u53ef\u4ee5\u4f7f\u7528 6 \u4f4d\u6216 8 \u4f4d\u5148\u884c\u5757\u6765\u51cf\u5c11\u7ed9\u5b9a\u5b57\u5bbd\u7684\u5148\u884c\u7ea7\u522b\u3002\u4f46\u8003\u8651\u5230\u6247\u5165\u8f83\u9ad8\u7684\u95e8\u4f1a\u5e26\u6765\u66f4\u957f\u7684\u5ef6\u8fdf\uff0c\u8fd9\u53ef\u80fd\u4e0d\u503c\u5f97\u3002\u5f53\u5b57\u5bbd\u4e0d\u662f 4 \u7684\u5e42\u65f6\uff0c\u5148\u884c\u8fdb\u4f4d\u751f\u6210\u5668\u7684\u4e00\u4e9b\u8f93\u5165\u548c/\u6216\u8f93\u51fa\u4fdd\u6301\u672a\u4f7f\u7528\uff0c\u5e76\u4e14\u5ef6\u8fdf\u516c\u5f0f\u53d8\u4e3a \\(4 \\left \\lceil \\log_4 k \\right \\rceil + 1\\)\u3002</p> <p>One final point about the design depicted in Fig. 6.4: this 64-bit adder does not produce a carry-out signal (\\(c_{64}\\)), which would be needed in many applications. There are two ways to remedy this problem in carry-lookahead adders. One is to generate   \\(c_{out}\\) externally based on auxiliary signals or the operand and sum bits in position  k \u2212 1: </p> <p>\u5173\u4e8e\u56fe 6.4 \u4e2d\u6240\u793a\u8bbe\u8ba1\u7684\u6700\u540e\u4e00\u70b9\uff1a\u8be5 64 \u4f4d\u52a0\u6cd5\u5668\u4e0d\u4f1a\u4ea7\u751f\u8bb8\u591a\u5e94\u7528\u4e2d\u9700\u8981\u7684\u8fdb\u4f4d\u4fe1\u53f7 (\\(c_{64}\\))\u3002\u5728\u8d85\u524d\u8fdb\u4f4d\u52a0\u6cd5\u5668\u4e2d\uff0c\u6709\u4e24\u79cd\u65b9\u6cd5\u53ef\u4ee5\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002\u4e00\u79cd\u662f\u6839\u636e\u8f85\u52a9\u4fe1\u53f7\u6216\u4f4d\u7f6e \\(k \u2212 1\\) \u7684\u64cd\u4f5c\u6570\u548c\u548c\u4f4d\u5728\u5916\u90e8\u751f\u6210 \\(c_{out}\\)\uff1a </p> <p>\\(c_{out} = g[0, k\u22121] \u2228 c_0 p[0, k\u22121] = x_{k\u22121} y_{k\u22121} \u2228 \\bar{s}_{k\u22121} (x_{k\u22121} \u2228 y_{k\u22121} )\\) </p> <p>Another is to design the adder to be 1 bit wider than needed (e.g., 61 bits instead of 60), using the additional sum bit as  \\(c_{out}\\). </p> <p>\u53e6\u4e00\u79cd\u65b9\u6cd5\u662f\u4f7f\u7528\u9644\u52a0\u548c\u5c06\u52a0\u6cd5\u5668\u8bbe\u8ba1\u4e3a\u6bd4\u6240\u9700\u5bbd 1 \u4f4d\uff08\u4f8b\u5982\uff0c61 \u4f4d\u800c\u4e0d\u662f 60 \u4f4d\uff09\u4f4d\u4e3a\\(c_{out}\\)\u3002</p>"},{"location":"Part_02/06/#63-ling","title":"6.3 LING\u578b\u52a0\u6cd5\u5668\u4e0e\u76f8\u5173\u8bbe\u8ba1","text":"<p>The Ling adder is a type of carry-lookahead adder that achieves significant hardware savings. Consider the carry recurrence and its unrolling by four steps:</p> <p>Ling \u52a0\u6cd5\u5668\u662f\u4e00\u79cd\u8d85\u524d\u8fdb\u4f4d\u52a0\u6cd5\u5668\uff0c\u53ef\u663e\u7740\u8282\u7701\u786c\u4ef6\u6210\u672c\u3002\u8003\u8651\u8fdb\u4f4d\u9012\u5f52\u5c06\u5176\u5c55\u5f00\u56db\u6b65\uff1a</p> <p>\\(\\begin{array}{l} c_i &amp;= g_{i\u22121} \u2228 c_{i\u22121}p_{i\u22121} = g_{i\u22121} \u2228 c_{i\u22121}t_{i\u22121} \\\\ &amp;= g_{i\u22121} \u2228 g_{i\u22122}t_{i\u22121} \u2228 g_{i\u22123}t_{i\u22122}t_{i\u22121} \u2228 g_{i\u22124}t_{i\u22123}t_{i\u22122}t_{i\u22121} \u2228 c_{i\u22124}t_{i\u22124}t_{i\u22123}t_{i\u22122}t_{i\u22121} \\end{array}\\)</p> <p>Ling\u2019s modification consists of propagating hi = ci \u2228 ci\u22121 instead of ci. To understand the following derivations, we note that gi\u22121 implies ci (ci = 1 if gi\u22121 = 1 ), which in turn implies hi.</p> <p>Ling \u7684\u4fee\u6539\u5305\u62ec\u4f20\u64ad hi = \\(c_i \u2228 c_{i\u22121}\\) \u800c\u4e0d\u662f ci\u3002\u4e3a\u4e86\u7406\u89e3\u4ee5\u4e0b\u63a8\u5bfc\uff0c\u6211\u4eec\u6ce8\u610f\u5230 \\(g_{i\u22121}\\) \u8574\u542b \\(c_i\\) \uff08\u5982\u679c \\(g_{i\u22121} = 1\\) \u5219 \\(c_i = 1\\) \uff09\uff0c\u8fd9\u53c8\u8574\u542b \\(h_i\\)\u3002</p> \\[ \\begin{array}{rl} c_{i\u22121}p_{i\u22121} &amp;= c_{i\u22121}p_{i\u22121} \u2228 g_{i\u22121}p_{i\u22121} \\text{ \\{zero\\} } \u2228 p_{i\u22121}c_{i\u22121}p_{i\u22121} \\text{ \\{repeated term\\} } \\\\                &amp;= c_{i\u22121}p_{i\u22121} \u2228 (g_{i\u22121} \u2228 p_{i\u22121}c_{i\u22121})p_{i\u22121} \\\\                &amp;= (c_{i\u22121} \u2228 c_i)p_{i\u22121} = h_ip_{i\u22121} \\\\ c_i &amp;= g_{i\u22121} \u2228 c_{i\u22121}p_{i\u22121} \\\\    &amp;= h_ig_{i\u22121} \\text{ \\{ since } g_{i\u22121} \\text{ implies } h_i \\text{\\} } \u2228 h_ip_{i\u22121} \\text{ \\{ from above \\} } \\\\    &amp;= h_i(g_{i\u22121} \u2228 p_{i\u22121}) = h_i t_{i\u22121} \\\\ h_i &amp;= c_i \u2228 c_{i\u22121} = (g_{i\u22121} \u2228 c_{i\u22121}p_{i\u22121}) \u2228 c_{i\u22121} \\\\    &amp;= g_{i\u22121} \u2228 c_{i\u22121} = g_{i\u22121} \u2228 h_{i\u22121}t_{i\u22122} \\text{ \\{from above\\} } \\end{array} \\] <p>Unrolling the preceding recurrence for hi, we get</p> <p>\u5c55\u5f00 \\(h_i\\) \u7684\u524d\u9762\u7684\u9012\u5f52\uff0c\u6211\u4eec\u5f97\u5230 $$ \\begin{array}{l} h_i &amp;= g_{i\u22121} \u2228 t_{i\u22122} h_{i\u22121} = g_{i\u22121} \u2228 t_{i\u22122}(g_{i\u22122} \u2228 h_{i\u22122} t_{i\u22123}) \\    &amp;= g_{i\u22121} \u2228 g_{i\u22122} \u2228 h_{i\u22122} t_{i\u22122} t_{i\u22123} \\text{ { since } t_{i\u22122} g_{i\u22122} = g_{i\u22122} \\text{ }} \\    &amp;= g_{i\u22121} \u2228 g_{i\u22122} \u2228 g_{i\u22123} t_{i\u22123} t_{i\u22122} \u2228 h_{i\u22123} t_{i\u22124} t_{i\u22123} t_{i\u22122} \\    &amp;= g_{i\u22121} \u2228 g_{i\u22122} \u2228 g_{i\u22123} t_{i\u22122} \u2228 g_{i\u22124} t_{i\u22123} t_{i\u22122} \u2228 h_{i\u22124} t_{i\u22124} t_{i\u22123} t_{i\u22122}  \\end{array} $$ We see that expressing  hi  in terms of  hi\u22124 needs five product terms, with a maximum four-input AND gate, and a total of 14 gate inputs. By contrast, expressing  ci  as </p> <p>\u6211\u4eec\u770b\u5230\uff0c\u7528 \\(h_{i\u22124}\\) \u8868\u8fbe \\(h_i\\) \u9700\u8981 5 \u4e2a\u4e58\u79ef\u9879\uff0c\u6700\u591a\u6709 4 \u4e2a\u8f93\u5165\u4e0e\u95e8\uff0c\u603b\u5171 14 \u4e2a\u95e8\u8f93\u5165\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u5c06 ci \u8868\u793a\u4e3a</p> <p>\\(c_i = g_{i\u22121} \u2228 g_{i\u22122} t_{i\u22121} \u2228 g_{i\u22123} t_{i\u22122} t_{i\u22121} \u2228 g_{i\u22124} t_{i\u22123} t_{i\u22122} t_{i\u22121} \u2228 c_{i\u22124} t_{i\u22124} t_{i\u22123} t_{i\u22122} t_{i\u22121}\\)</p> <p>requires five terms, with a maximum five-input AND gate, and a total of 19 gate inputs. The advantage of  hi  over  ci  is even greater if we can use wired-OR (3 gates with 9 inputs vs. 4 gates with 14 inputs). Once  hi  is known, however, the sum is obtained by a slightly more complex expression compared with  si =  pi \u2295  ci:</p> <p>\u9700\u8981 5 \u9879\uff0c\u6700\u591a\u6709 5 \u4e2a\u8f93\u5165\u4e0e\u95e8\uff0c\u603b\u5171 19 \u4e2a\u95e8\u8f93\u5165\u3002\u5982\u679c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u7ebf\u6216\uff08\u5177\u6709 9 \u4e2a\u8f93\u5165\u7684 3 \u4e2a\u95e8\u4e0e\u5177\u6709 14 \u4e2a\u8f93\u5165\u7684 4 \u4e2a\u95e8\uff09\uff0c\u5219 \\(h_i\\) \u76f8\u5bf9\u4e8e \\(c_i\\) \u7684\u4f18\u52bf\u4f1a\u66f4\u5927\u3002\u7136\u800c\uff0c\u4e00\u65e6 \\(h_i\\) \u5df2\u77e5\uff0c\u4e0e \\(s_i = p_i \u2295 c_i\\) \u76f8\u6bd4\uff0c\u53ef\u4ee5\u901a\u8fc7\u7a0d\u5fae\u590d\u6742\u7684\u8868\u8fbe\u5f0f\u83b7\u5f97\u603b\u548c\uff1a</p> <p>\\(s_i = p_i \u2295 c_i = p_i \u2295 h_it_{i\u22121}\\)</p> <p>This concludes our presentation of Ling\u2019s improved carry-lookahead adder. The reader can skip the rest of this section with no harm to continuity. </p> <p>\u6211\u4eec\u5bf9 Ling \u6539\u8fdb\u7684\u8d85\u524d\u8fdb\u4f4d\u52a0\u6cd5\u5668\u7684\u4ecb\u7ecd\u5230\u6b64\u7ed3\u675f\u3002\u8bfb\u8005\u53ef\u4ee5\u8df3\u8fc7\u672c\u8282\u7684\u5176\u4f59\u90e8\u5206\uff0c\u8fd9\u4e0d\u4f1a\u5f71\u54cd\u8fde\u7eed\u6027\u3002</p> <p>A number of related designs have been developed based on ideas similar to Ling\u2019s. For example, Doran [Dora88] suggests that one can in general propagate \\(\u03b7\\) instead of \\(c\\) where</p> <p>\u57fa\u4e8e\u4e0e\u51cc\u7c7b\u4f3c\u7684\u60f3\u6cd5\uff0c\u5df2\u7ecf\u5f00\u53d1\u51fa\u8bb8\u591a\u76f8\u5173\u8bbe\u8ba1\u3002\u4f8b\u5982\uff0cDoran [Dora88] \u5efa\u8bae\u4e00\u822c\u53ef\u4ee5\u4f20\u64ad \\(\u03b7\\) \u800c\u4e0d\u662f \\(c\\)\uff0c\u5176\u4e2d</p> <p>\\(\u03b7_{i+1} = f (x_i, y_i, c_i) = \u03c8(x_i, y_i)c_i \u2228 \\phi(x_i, y_i)\\bar{c}_i\\)</p> <p>The residual functions \u03c8 and \u03c6 in the preceding Shannon expansion of f around ci must be symmetric, and there are but eight symmetric functions of the two variables xi and yi. Doran shows that not all 8 \u00d7 8 = 64 possibilities are valid choices for \u03c8 and \u03c6, since in some cases the sum cannot be computed based on the \u03b7i values. Dividing the eight symmetric functions of xi and yi into the two disjoint subsets {0, \u00af ti, gi, \u00af pi} and {1, ti, \u00af gi, pi}, Doran proves that \u03c8 and \u03c6 cannot both belong to the same subset. Thus, there are only 32 possible adders. Four of these 32 possible adders have the desirable properties of Ling\u2019s adder, which represents the special case of \u03c8(xi, yi) = 1 and \u03c6(xi, yi) = gi = xiyi.</p> <p>\u524d\u9762 \\(f\\) \u56f4\u7ed5 \\(c_i\\) \u8fdb\u884c\u7684\u9999\u519c\u5c55\u5f00\u4e2d\u7684\u6b8b\u5dee\u51fd\u6570 \\(\u03c8\\) \u548c \\(\\phi\\) \u5fc5\u987b\u662f\u5bf9\u79f0\u7684\uff0c\u5e76\u4e14\u4e24\u4e2a\u53d8\u91cf \\(x_i\\) \u548c \\(y_i\\) \u7684\u5bf9\u79f0\u51fd\u6570\u53ea\u6709 8 \u4e2a\u3002 Doran \u8868\u660e\uff0c\u5e76\u975e\u6240\u6709 8 \u00d7 8 = 64 \u79cd\u53ef\u80fd\u6027\u90fd\u662f \\(\u03c8\\) \u548c \\(\\phi\\) \u7684\u6709\u6548\u9009\u62e9\uff0c\u56e0\u4e3a\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u65e0\u6cd5\u6839\u636e \\(\u03b7_i\\) \u503c\u8ba1\u7b97\u603b\u548c\u3002\u5c06 \\(x_i\\) \u548c \\(y_i\\) \u7684\u516b\u4e2a\u5bf9\u79f0\u51fd\u6570\u5206\u4e3a\u4e24\u4e2a\u4e0d\u76f8\u4ea4\u7684\u5b50\u96c6 {\\(0, \\bar{t}_i, g_i, \\bar{p}_i\\)} \u548c {\\(1, t_i, \\bar{g}_i, p_i\\)}\uff0cDoran\u8bc1\u660e \\(\u03c8\\) \u548c \\(\\phi\\) \u4e0d\u80fd\u540c\u65f6\u5c5e\u4e8e\u540c\u4e00\u4e2a\u5b50\u96c6\u3002\u56e0\u6b64\uff0c\u53ea\u6709 32 \u4e2a\u53ef\u80fd\u7684\u52a0\u6cd5\u5668\u3002\u8fd9 32 \u4e2a\u53ef\u80fd\u7684\u52a0\u6cd5\u5668\u4e2d\u6709 4 \u4e2a\u5177\u6709 Ling \u52a0\u6cd5\u5668\u7684\u7406\u60f3\u5c5e\u6027\uff0c\u5b83\u4ee3\u8868 \\(\u03c8(x_i, y_i) = 1\\) \u548c \\(\\phi(x_i, y_i) = g_i = x_iy_i\\) \u7684\u7279\u6b8a\u60c5\u51b5\u3002</p>"},{"location":"Part_02/06/#64","title":"6.4 \u5e76\u884c\u524d\u7f00\u8fdb\u4f4d\u8ba1\u7b97","text":"<p>Consider two contiguous or overlapping blocks B and B and their associated generate and propagate signal pairs ( g,  p) and ( g,  p), respectively. As shown in Fig. 6.5, the generate and propagate signals for the merged block B can be obtained from the equations:</p> <p>\u8003\u8651\u4e24\u4e2a\u8fde\u7eed\u6216\u91cd\u53e0\u7684\u5757 \\(B'\\) \u548c \\(B''\\) \u53ca\u5176\u5173\u8054\u7684\u5206\u522b\u751f\u6210\u548c\u4f20\u64ad\u4fe1\u53f7\u5bf9 \\((g', p')\\) \u548c \\((g'', p'')\\)\u3002\u5982\u56fe 6.5 \u6240\u793a\uff0c\u5408\u5e76\u5757 B \u7684\u751f\u6210\u548c\u4f20\u64ad\u4fe1\u53f7\u53ef\u7531\u4ee5\u4e0b\u7b49\u5f0f\u83b7\u5f97\uff1a</p> <p>\\(g = g'' \u2228 g' p''\\)</p> <p>\\(p = p' p''\\)</p> <p>That is, carry generation in the larger group takes place if the left group generates a carry or the right group generates a carry and the left one propagates it, while propagation occurs if both groups propagate the carry. </p> <p>\u4e5f\u5c31\u662f\u8bf4\uff0c\u5982\u679c\u5de6\u4fa7\u7ec4\u751f\u6210\u8fdb\u4f4d\u6216\u53f3\u4fa7\u7ec4\u751f\u6210\u8fdb\u4f4d\u5e76\u4e14\u5de6\u4fa7\u7ec4\u4f20\u64ad\u8fdb\u4f4d\uff0c\u5219\u8f83\u5927\u7ec4\u4e2d\u4f1a\u53d1\u751f\u8fdb\u4f4d\u751f\u6210\uff0c\u800c\u5982\u679c\u4e24\u4e2a\u7ec4\u90fd\u4f20\u64ad\u8fdb\u4f4d\uff0c\u5219\u4f1a\u53d1\u751f\u4f20\u64ad\u3002</p> <p></p> <p>We note that in the discussion above, the indices  i 0,  j 0,  i 1, and  j 1 defining the two contiguous or overlapping blocks are in fact immaterial, and the same expressions can be written for any two adjacent groups of any width. Let us define the \u201ccarry\u201d operator c /  on (g,  p) signal pairs as follows (right side of Fig. 6.5):</p> <p>\u6211\u4eec\u6ce8\u610f\u5230\uff0c\u5728\u4e0a\u9762\u7684\u8ba8\u8bba\u4e2d\uff0c\u5b9a\u4e49\u4e24\u4e2a\u8fde\u7eed\u6216\u91cd\u53e0\u5757\u7684\u7d22\u5f15 \\(i_0 \u3001j_0 \u3001i_1 \u548c j_1\\) \u5b9e\u9645\u4e0a\u662f\u65e0\u5173\u7d27\u8981\u7684\uff0c\u5e76\u4e14\u53ef\u4ee5\u4e3a\u4efb\u4f55\u5bbd\u5ea6\u7684\u4efb\u4f55\u4e24\u4e2a\u76f8\u90bb\u7ec4\u7f16\u5199\u76f8\u540c\u7684\u8868\u8fbe\u5f0f\u3002\u8ba9\u6211\u4eec\u5b9a\u4e49\u201c\u8fdb\u4f4d\u201d\u8fd0\u7b97\u7b26 \\(\\not{c}\\) \u5728( g, p) \u4fe1\u53f7\u5bf9\u5982\u4e0b\uff08\u56fe 6.5 \u53f3\u4fa7\uff09\uff1a</p> <p>$(g, p) = (g', p' ) \\not{c} (g'', p'' ) \\text{ \u4ee3\u8868 } g = g'' \u2228 g' p'', p = p' p'' $</p> <p>The carry operator c /  is  associative, meaning that the order of evaluation does not affect the value of the expression  (g,  p )  c / (g,  p )  c / (g,  p ), but it is not  commutative, since g \u2228  g p is in general not equal to  g \u2228  g p. </p> <p>\u8fdb\u4f4d\u8fd0\u7b97\u7b26 \\(\\not{c}\\) \u6ee1\u8db3\u7ed3\u5408\u5f8b\uff0c\u8fd9\u610f\u5473\u7740\u6c42\u503c\u987a\u5e8f\u4e0d\u4f1a\u5f71\u54cd\u8868\u8fbe\u5f0f \\((g', p' ) \\not{c} (g'', p'' ) \\not{c} (g''', p''' )\\) \u7684\u503c\uff0c\u4f46\u5b83\u4e0d\u53ef\u4ea4\u6362\uff0c\u56e0\u4e3a \\(g'' \u2228 g' p''\\) \u901a\u5e38\u4e0d\u7b49\u4e8e \\(g' \u2228 g'' p'\\)\u3002</p> <p>Observe that in an adder with no  c in, we have  ci+1 =  g[0,  i]; that is, a carry enters position  i+1 if and only if one is generated by the block [0,  i]. In an adder with  c in, a carryin of 1 can be viewed as a carry generated by stage \u22121; we thus set  p\u22121 = 0,  g\u22121 =  c in and compute  g[\u22121,  i] for all  i. So, the problem remains the same, but with an extra stage ( k + 1 rather than  k). The problem of carry determination can, therefore, be formulated as follows:</p> <p>\u89c2\u5bdf\u5230\u5728\u6ca1\u6709 \\(c_{in}\\) \u7684\u52a0\u6cd5\u5668\u4e2d\uff0c\u6211\u4eec\u6709 \\(c_{i+1}\\) = \\(g[0, i]\\)\uff1b\u4e5f\u5c31\u662f\u8bf4\uff0c\u5f53\u4e14\u4ec5\u5f53\u5757 \\([0, i]\\) \u751f\u6210\u4e00\u4e2a\u8fdb\u4f4d\u65f6\uff0c\u8fdb\u4f4d\u624d\u4f1a\u8fdb\u5165\u4f4d\u7f6e \\(i+1\\)\u3002\u5728\u6709\\(c_{in}\\)\u7684\u52a0\u6cd5\u5668\u4e2d\uff0c\u8fdb\u4f4d\u4e3a1\u53ef\u4ee5\u770b\u4f5c\u662f\u7ea7-1\u4ea7\u751f\u7684\u8fdb\u4f4d\uff1b\u56e0\u6b64\uff0c\u6211\u4eec\u8bbe\u7f6e \\(p_{\u22121} = 0, g_{\u22121} = c_{in}\\) \u5e76\u8ba1\u7b97\u6240\u6709 \\(i\\) \u7684 \\(g[\u22121, i]\\)\u3002\u56e0\u6b64\uff0c\u95ee\u9898\u4ecd\u7136\u76f8\u540c\uff0c\u4f46\u6709\u4e00\u4e2a\u989d\u5916\u7684\u9636\u6bb5\uff08 \\(k + 1\\) \u800c\u4e0d\u662f \\(k\\)\uff09\u3002\u56e0\u6b64\uff0c\u8fdb\u4f4d\u786e\u5b9a\u95ee\u9898\u53ef\u4ee5\u8868\u8ff0\u5982\u4e0b\uff1a</p> <p>\u7ed9\u5b9a</p> <p>\\((g_0, p_0) \\  (g_1, p_1) \\cdots (g_{k\u22122}, p_{k\u22122})\\ (g_{k\u22121}, p_{k\u22121})\\)</p> <p>\u627e\u5230</p> <p>\\((g[0,0], p[0,0]) (g[0,1], p[0,1]) \u00b7 \u00b7 \u00b7 (g[0,k\u22122], p[0,k\u22122]) (g[0,k\u22121], p[0,k\u22121])\\)</p> <p>The desired signal pairs can be obtained by evaluating all the prefixes of</p> <p>\u53ef\u4ee5\u901a\u8fc7\u8bc4\u4f30\u6240\u6709\u524d\u7f00\u6765\u83b7\u5f97\u6240\u9700\u7684\u4fe1\u53f7\u5bf9</p> <p>$(g_0, p_0 ) \\not{c}  (g_1, p_1 ) \\not{c} \\cdots \\not{c} (g_{k\u22122}, p_{k\u22122} ) \\not{c} (g_{k\u22121}, p_{k\u22121} ) $</p> <p>in parallel. In this way, the carry problem is converted to a parallel prefix computation, and any prefix computation scheme can be used to find all the carries. </p> <p>\u5e76\u884c\u8fdb\u884c\u3002\u8fd9\u6837\uff0c\u8fdb\u4f4d\u95ee\u9898\u5c31\u8f6c\u5316\u4e3a\u5e76\u884c\u7684\u524d\u7f00\u8ba1\u7b97\uff0c\u5e76\u4e14\u53ef\u4ee5\u4f7f\u7528\u4efb\u4f55\u524d\u7f00\u8ba1\u7b97\u65b9\u6848\u6765\u67e5\u627e\u6240\u6709\u8fdb\u4f4d\u3002</p> <p>A parallel prefix computation can be defined with any associative operator. In the following, we use the addition operator with integer operands, in view of its simplicity and familiarity, to illustrate the methods. The  parallel prefix sums  problem is defined as follows:</p> <p>\u5e76\u884c\u524d\u7f00\u8ba1\u7b97\u53ef\u4ee5\u4f7f\u7528\u4efb\u4f55\u5173\u8054\u8fd0\u7b97\u7b26\u6765\u5b9a\u4e49\u3002\u9274\u4e8e\u5176\u7b80\u5355\u6027\u548c\u719f\u6089\u6027\uff0c\u4e0b\u9762\u6211\u4eec\u4f7f\u7528\u5e26\u6709\u6574\u6570\u64cd\u4f5c\u6570\u7684\u52a0\u6cd5\u8fd0\u7b97\u7b26\u6765\u8bf4\u660e\u8be5\u65b9\u6cd5\u3002\u5e76\u884c\u524d\u7f00\u548c\u95ee\u9898\u5b9a\u4e49\u5982\u4e0b\uff1a</p> \\[ \\begin{array}{l} \\text{\u7ed9\u5b9a\uff1a} &amp;x_0 &amp;x_1       &amp;x_2          &amp;x_3                &amp;\\cdots &amp;x_{k\u22121} \\\\ \\text{\u627e\u5230\uff1a} &amp;x_0 &amp;x_0 + x_1 &amp;x_0 + x_1 + x_2 &amp;x_0 + x_1 + x_2 + x_3 &amp;\\cdots &amp;x_0 + x_1 + \u00b7 \u00b7 \u00b7 + x_{k\u22121} \\end{array} \\] <p>Any design for this parallel prefix sums problem can be converted to a carry computation network by simply replacing each adder cell with the carry operator of Fig. 6.5. There is one difference worth mentioning, though. Addition is commutative. So if prefix sums are obtained by computing and combining the partial sums in an arbitrary manner, the resulting design may be unsuitable for a carry network. However, as long as blocks whose sums we combine are always contiguous and we do not change their ordering, no problem arises. </p> <p>\u901a\u8fc7\u7b80\u5355\u5730\u5c06\u6bcf\u4e2a\u52a0\u6cd5\u5668\u5355\u5143\u66ff\u6362\u4e3a\u56fe 6.5 \u4e2d\u7684\u8fdb\u4f4d\u8fd0\u7b97\u7b26\uff0c\u9488\u5bf9\u6b64\u5e76\u884c\u524d\u7f00\u548c\u95ee\u9898\u7684\u4efb\u4f55\u8bbe\u8ba1\u90fd\u53ef\u4ee5\u8f6c\u6362\u4e3a\u8fdb\u4f4d\u8ba1\u7b97\u7f51\u7edc\u3002\u4e0d\u8fc7\uff0c\u6709\u4e00\u4e2a\u5dee\u5f02\u503c\u5f97\u4e00\u63d0\u3002\u52a0\u6cd5\u662f\u53ef\u4ea4\u6362\u7684\u3002\u56e0\u6b64\uff0c\u5982\u679c\u901a\u8fc7\u4ee5\u4efb\u610f\u65b9\u5f0f\u8ba1\u7b97\u548c\u7ec4\u5408\u90e8\u5206\u548c\u6765\u83b7\u5f97\u524d\u7f00\u548c\uff0c\u5219\u6240\u5f97\u8bbe\u8ba1\u53ef\u80fd\u4e0d\u9002\u5408\u8fdb\u4f4d\u7f51\u7edc\u3002\u7136\u800c\uff0c\u53ea\u8981\u6211\u4eec\u5408\u5e76\u7684\u5757\u603b\u662f\u8fde\u7eed\u7684\u5e76\u4e14\u6211\u4eec\u4e0d\u6539\u53d8\u5b83\u4eec\u7684\u987a\u5e8f\uff0c\u5c31\u4e0d\u4f1a\u51fa\u73b0\u95ee\u9898\u3002</p> <p>Just as one can group numbers in any way to add them, ( g,  p) signal pairs can be grouped in any way for combining them into block signals. In fact, ( g,  p) signals give us an additional flexibility in that overlapping groups can be combined without affecting the outcome, whereas in addition, use of overlapping groups would lead to incorrect sums. </p> <p>\u6b63\u5982\u4eba\u4eec\u53ef\u4ee5\u4ee5\u4efb\u4f55\u65b9\u5f0f\u5bf9\u6570\u5b57\u8fdb\u884c\u5206\u7ec4\u4ee5\u5c06\u5b83\u4eec\u76f8\u52a0\u4e00\u6837\uff0c\uff08g\uff0cp\uff09\u4fe1\u53f7\u5bf9\u4e5f\u53ef\u4ee5\u4ee5\u4efb\u4f55\u65b9\u5f0f\u5206\u7ec4\u4ee5\u5c06\u5b83\u4eec\u7ec4\u5408\u6210\u5757\u4fe1\u53f7\u3002\u4e8b\u5b9e\u4e0a\uff0c( g, p) \u4fe1\u53f7\u4e3a\u6211\u4eec\u63d0\u4f9b\u4e86\u989d\u5916\u7684\u7075\u6d3b\u6027\uff0c\u56e0\u4e3a\u53ef\u4ee5\u7ec4\u5408\u91cd\u53e0\u7684\u7ec4\u800c\u4e0d\u5f71\u54cd\u7ed3\u679c\uff0c\u800c\u6b64\u5916\uff0c\u4f7f\u7528\u91cd\u53e0\u7684\u7ec4\u4f1a\u5bfc\u81f4\u4e0d\u6b63\u786e\u7684\u603b\u548c\u3002</p> <p>Figure 6.6a depicts a four-input prefix sums network composed of four adder blocks, arranged in two levels. It produces the prefix sums 5, 7, 6, and 12 when supplied with the inputs 5, 2, \u22121, and 6, going from right to left. Note that we use the right-to-left ordering of inputs and outputs on diagrams, because this corresponds to how we index digit positions in positional number representation. So, what we are computing really constitutes postfix sums of the expression x 3 + x 2 + x 1 + x 0. However, we will continue to use the terms \u201cprefix sums\u201d and \u201cparallel prefix networks\u201d in accordance with the common usage. As long as we remember that the indexing in carry network diagrams goes from right to left, no misinterpretation will arise. Figure 6.6b shows the carry network derived from the prefix sums network of Fig. 6.6a by replacing each adder with a carry operator. It also shows how the outputs of this carry network are related to carries that we need to complete a 4-bit addition.</p> <p>\u56fe 6.6a \u63cf\u8ff0\u4e86\u7531\u56db\u4e2a\u52a0\u6cd5\u5668\u5757\u7ec4\u6210\u7684\u56db\u8f93\u5165\u524d\u7f00\u548c\u7f51\u7edc\uff0c\u8fd9\u4e9b\u52a0\u6cd5\u5668\u5757\u5e03\u7f6e\u5728\u4e24\u7ea7\u4e2d\u3002\u5f53\u63d0\u4f9b\u8f93\u5165 5\u30012\u3001-1 \u548c 6\uff08\u4ece\u53f3\u5230\u5de6\uff09\u65f6\uff0c\u5b83\u4f1a\u751f\u6210\u524d\u7f00\u548c 5\u30017\u30016 \u548c 12\u3002\u8bf7\u6ce8\u610f\uff0c\u6211\u4eec\u5728\u56fe\u8868\u4e0a\u4f7f\u7528\u4ece\u53f3\u5230\u5de6\u7684\u8f93\u5165\u548c\u8f93\u51fa\u6392\u5e8f\uff0c\u56e0\u4e3a\u8fd9\u5bf9\u5e94\u4e8e\u6211\u4eec\u5728\u4f4d\u7f6e\u6570\u5b57\u8868\u793a\u4e2d\u7d22\u5f15\u6570\u5b57\u4f4d\u7f6e\u7684\u65b9\u5f0f\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u8ba1\u7b97\u7684\u5b9e\u9645\u4e0a\u662f\u8868\u8fbe\u5f0f \\(x_3 + x_2 + x_1 + x_0\\) \u7684\u540e\u7f00\u548c\u3002\u4f46\u662f\uff0c\u6211\u4eec\u5c06\u7ee7\u7eed\u6309\u7167\u5e38\u89c1\u7528\u6cd5\u4f7f\u7528\u672f\u8bed\u201c\u524d\u7f00\u548c\u201d\u548c\u201c\u5e76\u884c\u524d\u7f00\u7f51\u7edc\u201d\u3002\u53ea\u8981\u6211\u4eec\u8bb0\u4f4f\u8fdb\u4f4d\u7f51\u7edc\u56fe\u4e2d\u7684\u7d22\u5f15\u662f\u4ece\u53f3\u5230\u5de6\uff0c\u5c31\u4e0d\u4f1a\u4ea7\u751f\u8bef\u89e3\u3002\u56fe 6.6b \u663e\u793a\u4e86\u901a\u8fc7\u7528\u8fdb\u4f4d\u8fd0\u7b97\u7b26\u66ff\u6362\u6bcf\u4e2a\u52a0\u6cd5\u5668\u800c\u4ece\u56fe 6.6a \u7684\u524d\u7f00\u548c\u7f51\u7edc\u5bfc\u51fa\u7684\u8fdb\u4f4d\u7f51\u7edc\u3002\u5b83\u8fd8\u663e\u793a\u4e86\u8be5\u8fdb\u4f4d\u7f51\u7edc\u7684\u8f93\u51fa\u5982\u4f55\u4e0e\u6211\u4eec\u5b8c\u6210 4 \u4f4d\u52a0\u6cd5\u6240\u9700\u7684\u8fdb\u4f4d\u76f8\u5173\u3002</p> <p></p>"},{"location":"Part_02/06/#65","title":"6.5 \u6df7\u5408\u7684\u5e76\u884c\u524d\u7f00\u8fdb\u4f4d\u7f51\u7edc","text":"<p>Now, focusing on the problem of computing prefix sums, we can use several strategies to synthesize a parallel prefix sum network. Figure 6.7 is based on a divide-and-conquer approach as proposed by Ladner and Fischer [Ladn80]. The low-order k/2 inputs are processed by the subnetwork at the right to compute the prefix sums s 0, s 1, . . . , sk/ 2\u22121. Partial prefix sums are computed for the high-order k/2 values (the left subnetwork) and sk/ 2\u22121 (the leftmost output of the first subnetwork) is added to them to complete the computation. Such a network is characterized by the following recurrences for its delay (in terms of adder levels) and cost (number of adder cells):</p> <p>\u73b0\u5728\uff0c\u5173\u6ce8\u8ba1\u7b97\u524d\u7f00\u548c\u7684\u95ee\u9898\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u591a\u79cd\u7b56\u7565\u6765\u5408\u6210\u5e76\u884c\u524d\u7f00\u548c\u7f51\u7edc\u3002\u56fe 6.7 \u57fa\u4e8e Ladner \u548c Fischer [Ladn80] \u63d0\u51fa\u7684\u5206\u800c\u6cbb\u4e4b\u65b9\u6cd5\u3002\u4f4e\u9636 k/2 \u8f93\u5165\u7531\u53f3\u4fa7\u7684\u5b50\u7f51\u7edc\u5904\u7406\uff0c\u4ee5\u8ba1\u7b97\u524d\u7f00\u548c \\(s_0, s_1, ...\uff0cs_{k/2\u22121}\\)\u3002\u8ba1\u7b97\u9ad8\u9636 \\(k/2\\) \u503c\uff08\u5de6\u4fa7\u5b50\u7f51\uff09\u7684\u90e8\u5206\u524d\u7f00\u548c\uff0c\u5e76\u5c06 \\(s_{k/2\u22121}\\) \uff08\u7b2c\u4e00\u4e2a\u5b50\u7f51\u7684\u6700\u5de6\u4fa7\u8f93\u51fa\uff09\u6dfb\u52a0\u5230\u5176\u4e2d\u4ee5\u5b8c\u6210\u8ba1\u7b97\u3002\u8fd9\u79cd\u7f51\u7edc\u7684\u7279\u70b9\u662f\u5176\u5ef6\u8fdf\uff08\u5c31\u52a0\u6cd5\u5668\u7ea7\u522b\u800c\u8a00\uff09\u548c\u6210\u672c\uff08\u52a0\u6cd5\u5668\u5355\u5143\u7684\u6570\u91cf\uff09\u5177\u6709\u4ee5\u4e0b\u9012\u5f52\uff1a</p> <p>$\\text{\u5ef6\u8fdf\u9012\u5f52\uff1a} D(k) = D(k/2) + 1 = \\log_2 k $</p> <p>\\(\\text{\u6210\u672c\u9012\u5f52\uff1a}C(k) = 2C(k/2) + k/2 = (k/2) \\log_2 k\\)</p> <p></p> <p>A second divide-and-conquer design for computing prefix sums, proposed by Brent and Kung [Bren82], is depicted in Fig. 6.8. Here, the inputs are first combined pairwise to obtain the following sequence of length k/2:</p> <p>Brent \u548c Kung [Bren82] \u63d0\u51fa\u7684\u7528\u4e8e\u8ba1\u7b97\u524d\u7f00\u548c\u7684\u7b2c\u4e8c\u79cd\u5206\u6cbb\u8bbe\u8ba1\u5982\u56fe 6.8 \u6240\u793a\u3002\u8fd9\u91cc\uff0c\u9996\u5148\u5c06\u8f93\u5165\u4e24\u4e24\u7ec4\u5408\u4ee5\u83b7\u5f97\u4ee5\u4e0b\u957f\u5ea6\u4e3a k/2 \u7684\u5e8f\u5217\uff1a</p> <p>\\(\\begin{matrix}x_0 + x_1 &amp;x_2 + x_3 &amp;x_4 + x_5 &amp;\u00b7 \u00b7 \u00b7 &amp;x_{k\u22124} + x_{k\u22123} &amp;x_{k\u22122} + x_{k\u22121}\\end{matrix}\\)</p> <p>Parallel prefix sum computation on this new sequence yields the odd-indexed prefix sums s 1,  s 3,  s 5,  . . .  for the original sequence. Even-indexed prefix sums are then computed by using  s 2 j =  s 2 j\u22121 +  x 2 j. The cost and delay recurrences for the design of Fig. 6.8 are: Delay recurrence:</p> <p>\u5bf9\u6b64\u65b0\u5e8f\u5217\u7684\u5e76\u884c\u524d\u7f00\u548c\u8ba1\u7b97\u4ea7\u751f\u5947\u6570\u7d22\u5f15\u524d\u7f00\u548c \\(s_1, s_3, s_5,...\\)\u4e3a\u539f\u59cb\u5e8f\u5217\u3002\u7136\u540e\u4f7f\u7528 \\(s_{2 j} = s_{2 j\u22121} + x_{2 j}\\) \u8ba1\u7b97\u5076\u7d22\u5f15\u524d\u7f00\u548c\u3002\u56fe 6.8 \u8bbe\u8ba1\u7684\u6210\u672c\u548c\u5ef6\u8fdf\u9012\u5f52\u4e3a\uff1a</p> <p>$\\text{\u5ef6\u8fdf\u9012\u5f52\uff1a} D(k) = D(k/2) + 2 = 2\\log_2 k-1 $</p> <p>\u200b             \u4e8b\u5b9e\u4e0a\u540e\u9762\u6211\u4eec\u53ef\u4ee5\u770b\u5230\u662f\\(D(k) = 2 \\log_2 k \u2212 2\\)</p> <p>\\(\\text{\u6210\u672c\u9012\u5f52\uff1a}C(k) = C(k/2) + k - 1 = 2k-2- \\log_2 k\\)</p> <p>So, the Ladner\u2013Fischer design is faster than the Brent\u2013Kung design (log2  k  as opposed to 2 log2  k \u2212 2 adder levels) but also much more expensive [ (k/ 2 )  log2  k  as opposed to 2 k \u2212 2 \u2212 log2  k  adder cells]. The Ladner\u2013Fischer design also leads to large fan-out requirements if implemented directly in hardware. In other words, the output of one of the adders in the right part must feed the inputs of  k/2 adders in the left part. </p> <p>\u56e0\u6b64\uff0cLadner\u2013Fischer \u8bbe\u8ba1\u6bd4 Brent\u2013Kung \u8bbe\u8ba1\u66f4\u5feb\uff08\\(\\log_2 k\\) \u76f8\u5bf9\u4e8e \\(2 \\log_2 k \u2212 2\\) \u4e2a\u52a0\u6cd5\u5668\u7ea7\u522b\uff09\uff0c\u4f46\u4e5f\u66f4\u6602\u8d35 [ \\((k/ 2 ) \\log_2 k\\) \u76f8\u5bf9\u4e8e \\(2 k \u2212 2 \u2212 log2 k\\) \u52a0\u6cd5\u5668\u5355\u5143]\u3002\u5982\u679c\u76f4\u63a5\u5728\u786c\u4ef6\u4e2d\u5b9e\u73b0\uff0cLadner-Fischer \u8bbe\u8ba1\u8fd8\u4f1a\u5bfc\u81f4\u8f83\u5927\u7684\u6247\u51fa\u8981\u6c42\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u53f3\u4fa7\u90e8\u5206\u4e2d\u7684\u4e00\u4e2a\u52a0\u6cd5\u5668\u7684\u8f93\u51fa\u5fc5\u987b\u9988\u9001\u5230\u5de6\u4fa7\u90e8\u5206\u4e2d\u7684 k/2 \u4e2a\u52a0\u6cd5\u5668\u7684\u8f93\u5165\u3002</p> <p></p> <p>The 16-input instance of the Brent\u2013Kung design of Fig. 6.8 is depicted in Fig. 6.9.Note that even though the graph of Fig. 6.9 appears to have seven levels, two of the levels near the middle are independent, thus implying a single level of delay. In general, a k-input Brent\u2013Kung parallel prefix graph will have a delay of 2 log2 k \u2212 2 levels and a cost of 2 k \u2212 2 \u2212 log2 k cells.</p> <p>\u56fe 6.8 \u7684 Brent-Kung \u8bbe\u8ba1\u7684 16 \u8f93\u5165\u5b9e\u4f8b\u5982\u56fe 6.9 \u6240\u793a\u3002\u8bf7\u6ce8\u610f\uff0c\u5373\u4f7f\u56fe 6.9 \u7684\u56fe\u8868\u770b\u8d77\u6765\u6709\u4e03\u7ea7\uff0c\u4f46\u4e2d\u95f4\u9644\u8fd1\u7684\u4e24\u4e2a\u7ea7\u522b\u662f\u72ec\u7acb\u7684\uff0c\u56e0\u6b64\u610f\u5473\u7740\u5355\u4e2a\u5ef6\u8fdf\u7ea7\u522b\u3002\u4e00\u822c\u6765\u8bf4\uff0ck \u8f93\u5165\u7684 Brent-Kung \u5e76\u884c\u524d\u7f00\u56fe\u5c06\u5177\u6709 \\(2 \\log_2 k \u2212 2\\) \u4e2a\u7ea7\u522b\u7684\u5ef6\u8fdf\u548c \\(2 k \u2212 2 \u2212 log2 k\\) \u4e2a\u5355\u5143\u7684\u6210\u672c\u3002</p> <p></p> <p>Figure 6.10 depicts a Kogge\u2013Stone parallel prefix graph that has the same delay as the design shown in Fig. 6.7 but avoids its fan-out problem by distributing the computations. A k-input Kogge\u2013Stone parallel prefix graph has a delay of log2 k levels and a cost of k log2 k \u2212 k + 1 cells. The Kogge\u2013Stone parallel prefix graph represents the fastest possible implementation of a parallel prefix computation if only two-input blocks are allowed. However, its cost can be prohibitive for large  k, in terms of both the number of cells and the dense wiring between them. </p> <p>\u56fe 6.10 \u63cf\u7ed8\u4e86\u4e00\u4e2a Kogge-Stone \u5e76\u884c\u524d\u7f00\u56fe\uff0c\u5b83\u4e0e\u56fe 6.7 \u6240\u793a\u7684\u8bbe\u8ba1\u5177\u6709\u76f8\u540c\u7684\u5ef6\u8fdf\uff0c\u4f46\u901a\u8fc7\u5206\u5e03\u8ba1\u7b97\u907f\u514d\u4e86\u6247\u51fa\u95ee\u9898\u3002 k \u8f93\u5165 Kogge-Stone \u5e76\u884c\u524d\u7f00\u56fe\u5177\u6709 \\(\\log_2 k\\) \u7ea7\u522b\u7684\u5ef6\u8fdf\u548c \\(k \\log_2 k \u2212 k + 1\\) \u4e2a\u5355\u5143\u7684\u6210\u672c\u3002 \u5982\u679c\u53ea\u5141\u8bb8\u4e24\u4e2a\u8f93\u5165\u5757\uff0c\u5219Kogge-Stone \u5e76\u884c\u524d\u7f00\u56fe\u4ee3\u8868\u6700\u5feb\u53ef\u80fd\u5b9e\u73b0\u5e76\u884c\u524d\u7f00\u8ba1\u7b97\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u5927 k \u7684\u5355\u5143\u6570\u91cf\u548c\u5355\u5143\u4e4b\u95f4\u7684\u5bc6\u96c6\u5e03\u7ebf\u800c\u8a00\uff0c\u5176\u6210\u672c\u53ef\u80fd\u4ee4\u4eba\u671b\u800c\u5374\u6b65\u3002</p> <p></p> <p>Many other parallel prefix network designs are possible. For example, it has been suggested that the Brent\u2013Kung and Kogge\u2013Stone approaches be combined to form hybrid designs [Sugl90]. In Fig. 6.11, the middle four of the six levels in the design of Fig. 6.9 (representing an eight-input parallel prefix computation) have been replaced by the eight-input Kogge\u2013Stone network. The resulting design has five levels and 32 cells, placing it between the pure Brent\u2013Kung (six levels, 26 cells) and pure Kogge\u2013Stone (four levels, 49 cells) designs. </p> <p>\u8bb8\u591a\u5176\u4ed6\u5e76\u884c\u524d\u7f00\u7f51\u7edc\u8bbe\u8ba1\u4e5f\u662f\u53ef\u80fd\u7684\u3002\u4f8b\u5982\uff0c\u6709\u4eba\u5efa\u8bae\u5c06 Brent-Kung \u548c Kogge-Stone \u65b9\u6cd5\u7ed3\u5408\u8d77\u6765\u5f62\u6210\u6df7\u5408\u8bbe\u8ba1 [Sugl90]\u3002\u5728\u56fe6.11\u4e2d\uff0c\u56fe6.9\u7684\u8bbe\u8ba1\u4e2d\u7684\u516d\u4e2a\u7ea7\u522b\u4e2d\u7684\u4e2d\u95f4\u56db\u4e2a\uff08\u4ee3\u8868\u516b\u8f93\u5165\u5e76\u884c\u524d\u7f00\u8ba1\u7b97\uff09\u5df2\u88ab\u516b\u8f93\u5165 Kogge-Stone \u7f51\u7edc\u53d6\u4ee3\u3002\u6700\u7ec8\u7684\u8bbe\u8ba1\u6709\u4e94\u5c42\u548c 32 \u4e2a\u5355\u5143\uff0c\u4ecb\u4e8e\u7eaf Brent-Kung\uff08\u516d\u5c42\uff0c26 \u4e2a\u5355\u5143\uff09\u548c\u7eaf Kogge-Stone\uff08\u56db\u5c42\uff0c49 \u4e2a\u5355\u5143\uff09\u8bbe\u8ba1\u4e4b\u95f4\u3002</p> <p></p> <p>More generally, if a single Brent\u2013Kung level is used along with a  k/2-input Kogge\u2013Stone design, delay and cost of the hybrid network become log2  k + 1 and ( k/2)log2  k, respectively. The resulting design is thus close to minimum in terms of delay (only one level more than Kogge\u2013Stone) but costs roughly half as much. </p> <p>\u66f4\u4e00\u822c\u5730\uff0c\u5982\u679c\u5355\u4e2a Brent\u2013Kung \u7ea7\u522b\u4e0e k/2 \u8f93\u5165 Kogge\u2013Stone\u8bbe\u8ba1\u4e00\u8d77\u4f7f\u7528 \uff0c\u6df7\u5408\u7f51\u7edc\u7684\u65f6\u5ef6\u548c\u6210\u672c\u5206\u522b\u53d8\u4e3a\\(\\log_2k+1\\)\u548c\\((k/2)\\log_2k\\)\u3002\u56e0\u6b64\uff0c\u6700\u7ec8\u7684\u8bbe\u8ba1\u5728\u5ef6\u8fdf\u65b9\u9762\u63a5\u8fd1\u6700\u4f4e\u6c34\u5e73\uff08\u4ec5\u6bd4 Kogge-Stone \u591a\u4e00\u7ea7\uff09\uff0c\u4f46\u6210\u672c\u5927\u7ea6\u662f\u540e\u8005\u7684\u4e00\u534a\u3002</p> <p>The theory of parallel prefix graphs is quite rich and well developed. There exist both theoretical bounds and actual designs with different restrictions on fan-in/fan-out and with various optimality criteria in terms of cost and delay (see, e.g., Chapters 5\u20137, pp. 133\u2013211, of [Laks94]). </p> <p>\u5e76\u884c\u524d\u7f00\u56fe\u7684\u7406\u8bba\u76f8\u5f53\u4e30\u5bcc\u4e14\u53d1\u8fbe\u3002\u7406\u8bba\u754c\u9650\u548c\u5b9e\u9645\u8bbe\u8ba1\u90fd\u5b58\u5728\uff0c\u5bf9\u6247\u5165/\u6247\u51fa\u6709\u4e0d\u540c\u7684\u9650\u5236\uff0c\u5e76\u4e14\u5728\u6210\u672c\u548c\u5ef6\u8fdf\u65b9\u9762\u6709\u4e0d\u540c\u7684\u6700\u4f18\u6807\u51c6\uff08\u4f8b\u5982\uff0c\u53c2\u89c1[Laks94]\u7684\u7b2c5-7\u7ae0\uff0c\u7b2c133-211\u9875\uff09\u3002</p> <p>In devising their design, Brent and Kung [Bren82] were motivated by the need to reduce the chip area in very large-scale integration (VLSI) layout of the carry network. Other performance or hardware limitations may also be considered. The nice thing about formulating the problem of carry determination as a parallel prefix computation is that theoretical results and a wealth of design strategies carry over with virtually no effort.  Not all such relationships between carry networks and parallel prefix networks, or the virtually unlimited hybrid combinations, have been explored in full. </p> <p>\u5728\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\uff0cBrent \u548c Kung [Bren82] \u7684\u52a8\u673a\u662f\u9700\u8981\u51cf\u5c11\u8fdb\u4f4d\u7f51\u7edc\u5728\u8d85\u5927\u89c4\u6a21\u96c6\u6210 (VLSI) \u5e03\u5c40\u4e2d\u7684\u82af\u7247\u9762\u79ef\u3002\u8fd8\u53ef\u4ee5\u8003\u8651\u5176\u4ed6\u6027\u80fd\u6216\u786c\u4ef6\u9650\u5236\u3002\u5c06\u8fdb\u4f4d\u786e\u5b9a\u95ee\u9898\u8868\u8ff0\u4e3a\u5e76\u884c\u524d\u7f00\u8ba1\u7b97\u7684\u597d\u5904\u5728\u4e8e\uff0c\u7406\u8bba\u7ed3\u679c\u548c\u5927\u91cf\u8bbe\u8ba1\u7b56\u7565\u51e0\u4e4e\u53ef\u4ee5\u6beb\u4e0d\u8d39\u529b\u5730\u5ef6\u7eed\u4e0b\u53bb\u3002\u8fdb\u4f4d\u7f51\u7edc\u548c\u5e76\u884c\u524d\u7f00\u7f51\u7edc\u4e4b\u95f4\u7684\u6240\u6709\u6b64\u7c7b\u5173\u7cfb\uff0c\u6216\u51e0\u4e4e\u65e0\u9650\u7684\u6df7\u5408\u7ec4\u5408\uff0c\u5e76\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002</p>"},{"location":"Part_02/06/#66-vlsi","title":"6.6 VLSI\u5b9e\u73b0\u76f8\u5173","text":"<p>The carry network of Fig. 6.9 is quite suitable for VLSI implementation, but it might be deemed too slow for high-performance designs and/or wide words. Many designers have proposed alternate networks that offer reduced latency by using features of particular technologies and taking advantage of related optimizations. We review one example here that is based on radix-256 addition of 56-bit numbers as implemented in the Advanced Micro Devices Am29050 microprocessor. The following description is based on a 64-bit version of the adder. </p> <p>\u56fe 6.9 \u7684\u8fdb\u4f4d\u7f51\u7edc\u975e\u5e38\u9002\u5408 VLSI \u5b9e\u73b0\uff0c\u4f46\u5bf9\u4e8e\u9ad8\u6027\u80fd\u8bbe\u8ba1\u548c/\u6216\u5bbd\u5b57\u6765\u8bf4\u53ef\u80fd\u4f1a\u88ab\u8ba4\u4e3a\u592a\u6162\u3002\u8bb8\u591a\u8bbe\u8ba1\u4eba\u5458\u63d0\u51fa\u4e86\u66ff\u4ee3\u7f51\u7edc\uff0c\u901a\u8fc7\u4f7f\u7528\u7279\u5b9a\u6280\u672f\u7684\u529f\u80fd\u5e76\u5229\u7528\u76f8\u5173\u4f18\u5316\u6765\u51cf\u5c11\u5ef6\u8fdf\u3002\u6211\u4eec\u5728\u6b64\u56de\u987e\u4e00\u4e2a\u57fa\u4e8e 56 \u4f4d\u6570\u5b57\u7684 radix-256 \u52a0\u6cd5\u7684\u793a\u4f8b\uff0c\u8be5\u793a\u4f8b\u5728 Advanced Micro Devices Am29050 \u5fae\u5904\u7406\u5668\u4e2d\u5b9e\u73b0\u3002\u4ee5\u4e0b\u63cf\u8ff0\u57fa\u4e8e 64 \u4f4d\u7248\u672c\u7684\u52a0\u6cd5\u5668\u3002</p> <p>In radix-256 addition of 64-bit numbers, only the carries  c 8,  c 16,  c 24,  c 32,  c 40,  c 48, and  c 56 need to be computed. First, 4-bit Manchester carry chains (MCCs) of the type shown in Fig. 6.12a are used to derive  g  and  p  signals for 4-bit blocks. These signals, denoted by [0, 3], [4, 7], [8, 11], etc. on the left side of Fig. 6.13, then form the inputs to one 5-bit and three 4-bit MCCs that in turn feed two more MCCs in the third level. The six MCCs in levels 2 and 3 in Fig. 6.13 are of the type shown in Fig. 6.12b; that is, they also produce intermediate  g  and  p  signals. For example, the MCC with inputs [16, 19], [20, 23], [24, 27], and [28, 31] yields the intermediate outputs [16, 23] and [16, 27], in addition to the signal pair [16, 31] for the entire group. </p> <p>\u5728 64 \u4f4d\u6570\u5b57\u7684\u57fa 256 \u52a0\u6cd5\u4e2d\uff0c\u4ec5\u9700\u8981\u8ba1\u7b97\u8fdb\u4f4d \\(c_8\u3001c_16\u3001c_24\u3001c_32\u3001c_40\u3001c_48 \u548c c_56\\)\u3002\u9996\u5148\uff0c\u56fe 6.12a \u6240\u793a\u7c7b\u578b\u7684 4 \u4f4d\u66fc\u5f7b\u65af\u7279\u8fdb\u4f4d\u94fe (MCC) \u7528\u4e8e\u5bfc\u51fa 4 \u4f4d\u5757\u7684 g \u548c p \u4fe1\u53f7\u3002\u8fd9\u4e9b\u4fe1\u53f7\u5728\u56fe 6.13 \u5de6\u4fa7\u7528 [0, 3]\u3001[4, 7]\u3001[8, 11] \u7b49\u8868\u793a\uff0c\u7136\u540e\u5f62\u6210\u4e00\u4e2a 5 \u4f4d MCC \u548c\u4e09\u4e2a 4 \u4f4d MCC \u7684\u8f93\u5165\uff0c\u8fd9\u4e9b MCC \u53c8\u4e3a\u7b2c\u4e09\u7ea7\u4e2d\u7684\u53e6\u5916\u4e24\u4e2a MCC \u63d0\u4f9b\u4fe1\u53f7\u3002\u56fe 6.13 \u4e2d\u7b2c 2 \u5c42\u548c\u7b2c 3 \u5c42\u7684 6 \u4e2a MCC \u7684\u7c7b\u578b\u5982\u56fe 6.12b \u6240\u793a\uff1b\u4e5f\u5c31\u662f\u8bf4\uff0c\u5b83\u4eec\u8fd8\u4ea7\u751f\u4e2d\u95f4 g \u548c p \u4fe1\u53f7\u3002\u4f8b\u5982\uff0c\u5177\u6709\u8f93\u5165 [16, 19]\u3001 [20, 23]\u3001[24, 27] \u548c [28, 31]\u7684 MCC\uff0c\u9664\u4e86\u6574\u4e2a\u7ec4\u7684\u4fe1\u53f7\u5bf9 [16, 31] \u4e4b\u5916\uff0c \u8fd8\u751f\u6210\u4e2d\u95f4\u8f93\u51fa [16, 23] \u548c [16, 27]\u3002</p> <p>Various parallel-prefix adders, all with minimum-latency designs when only node delays are considered, may turn out quite different when the effects of interconnects (including fan-in, fan-out, and signal propagation delay on wires) are considered[Beau01], [Huan00], [Know99].</p> <p>\u5f53\u4ec5\u8003\u8651\u8282\u70b9\u5ef6\u8fdf\u65f6\uff0c\u5404\u79cd\u5e76\u884c\u524d\u7f00\u52a0\u6cd5\u5668\u90fd\u91c7\u7528\u6700\u5c0f\u5ef6\u8fdf\u8bbe\u8ba1\uff0c\u4f46\u5f53\u8003\u8651\u4e92\u8fde\u7684\u5f71\u54cd\uff08\u5305\u62ec\u7ebf\u8def\u4e0a\u7684\u6247\u5165\u3001\u6247\u51fa\u548c\u4fe1\u53f7\u4f20\u64ad\u5ef6\u8fdf\uff09\u65f6\uff0c\u7ed3\u679c\u53ef\u80fd\u4f1a\u5927\u4e0d\u76f8\u540c [Beau01], [Huan00], [Know99]\u3002</p> <p></p> <p></p>"},{"location":"Part_02/06/#_1","title":"\u95ee\u9898\uff08\u7565\uff09","text":""},{"location":"Part_02/06/#_2","title":"\u53c2\u8003\u6587\u732e\u548c\u8fdb\u4e00\u6b65\u9605\u8bfb","text":"<pre><code>[Bayo83] Bayoumi, M. A., G. A. Jullien, and W. C. Miller, \u201cAn Area-Time Efficient NMOS\n         Adder,\u201d Integration: The VLSI Journal, Vol. 1, pp. 317\u2013334, 1983.\n[Beau01] Beaumont-Smith, A., and C.-C. Lim, \u201cParallel Prefix Adder Design,\u201d Proc. 15th\n         Symp. Computer Arithmetic, pp. 218\u2013225, 2001.\n[Bren82] Brent, R. P., and H. T. Kung, \u201cA Regular Layout for Parallel Adders,\u201d IEEE Trans.\n         Computers, Vol. 31, pp. 260\u2013264, 1982.\n[Burg99] Burgess, N., and S. Knowles, \"Efficient Implementation of Rounding Units\", Proc.\n         33rd Asilomar Conf. Signals Systems and Computers, pp. 1489\u20131493, 1999.\n[Burg05] Burgess, N., \u201cNew Models of Prefix Adder Topologies,\u201d J. VLSI Signal Processing,\n         Vol. 40, pp. 125\u2013141, 2005.\n[Dimi05] Dimitrakopoulos, G., and D. Nikolos, \u201cHigh-Speed Parallel-Prefix VLSI Ling\n         Adders,\u201d IEEE Trans. Computers, Vol. 54, No. 2, pp. 225\u2013231, 2005.\n[Dora88] Doran, R. W., \u201cVariants of an Improved Carry Look-Ahead Adder,\u201d IEEE Trans.\n         Computers, Vol. 37, No. 9, pp. 1110\u20131113, 1988.\n[Han87] Han, T., and D. A. Carlson, \u201cFast Area-Efficient Adders,\u201d Proc. 8th Symp. Computer\n         Arithmetic, pp. 49\u201356, 1987.\n[Harr03] Harris, D., \u201cA Taxonomy of Parallel Prefix Networks,\u201d Proc. 37th Asilomar Conf.\n         Signals, Systems, and Computers, Vol. 2, pp. 2213\u20132217, 2003.\n[Huan00] Huang, Z., and M. D. Ercegovac, \u201cEffect of Wire Delay on the Design of Prefix\n         Adders in Deep-Submicron Technology,\u201d Proc. 34th Asilomar Conf. Signals, Systems,\n         and Computers, October 2000, pp. 1713\u20131717, 2000.\n[Kant93] Kantabutra, V., \u201cA Recursive Carry-Lookahead/Carry-Select Hybrid Adder,\u201d IEEE\n         Trans. Computers, Vol. 42, No. 12, pp. 1495\u20131499, 1993.\n[Know99] Knowles, S., \u201cA Family of Adders,\u201d Proc. 14th Symp. Computer Arithmetic, 1999,\n         printed at the end of ARITH-15 Proceedings, pp. 277\u2013284, 2001.\n[Kogg73] Kogge, P. M. and H. S. Stone, \u201cA Parallel Algorithm for the Efficient Solution of a\n         General Class of Recurrences,\u201d IEEE Trans. Computers, Vol. 22, pp. 786\u2013793, 1973.\n[Ladn80] Ladner, R. E., and M. J. Fischer, \u201cParallel Prefix Computation,\u201d J. ACM, Vol. 27,\n         No. 4, pp. 831\u2013838, 1980.\n[Laks94] Lakshmivarahan, S., and S. K. Dhall, Parallel Computing Using the Prefix Problem,\n         Oxford University Press, 1994.\n[Ling81] Ling, H., \u201cHigh-Speed Binary Adder,\u201d IBM J. Research and Development, Vol. 25,\n         No. 3, pp. 156\u2013166, 1981.\n[Lync92] Lynch, T., and E. Swartzlander, \u201cA Spanning Tree Carry Lookahead Adder,\u201d IEEE\n         Trans. Computers, Vol. 41, No. 8, pp. 931\u2013939, 1992.\n[Mano98] Manohar, R., and J. A. Tierno, \"Asynchronous Parallel Prefix Computation,\" IEEE\n         Trans. Computers, Vol. 47, No. 11, pp. 1244\u20131252, 1998.\n[Ngai84] Ngai, T. F., M. J. Irwin, and S. Rawat, \u201cRegular Area-Time Efficient Carry-Lookahead\n         Adders,\u201d J. Parallel and Distributed Computing, Vol. 3, No. 3, pp. 92\u2013105, 1984.\n[Sugl90] Sugla, B., and D. A. Carlson, \u201cExtreme Area-Time Tradeoffs in VLSI,\u201d IEEE Trans.\n         Computers, Vol. 39, No. 2, pp. 251\u2013257, 1990.\n[Wei90] Wei, B. W. Y., and C. D. Thompson, \u201cArea-Time Optimal Adder Design,\u201d IEEE\n         Trans. Computers, Vol. 39, No. 5, pp. 666\u2013675, 1990.\n[Wein56] Weinberger, A., and J. L. Smith, \u201cA One-Microsecond Adder Using One-Megacycle\n         Circuitry,\u201d IRE Trans. Computers, Vol. 5, pp. 65\u201373, 1956.\n</code></pre>"},{"location":"Part_02/07/","title":"7. \u5176\u5b83\u9ad8\u901f\u52a0\u6cd5\u5668","text":"<p>Variations in Fast Adders</p> <p>\u201cThe most constant difficulty in contriving the engine has arisen from the desire to reduce the time in which the calculations were executed to the shortest which is possible.\u201d               \u2014 CHARLES BABBAGE , ON THE MATHEMATICAL POWERS OF THE CALCULATING ENGINE</p> <p>\u201c\u8bbe\u8ba1\u5f15\u64ce\u7684\u6700\u6301\u7eed\u7684\u56f0\u96be\u6e90\u4e8e\u5e0c\u671b\u5c06\u6267\u884c\u8ba1\u7b97\u7684\u65f6\u95f4\u51cf\u5c11\u5230\u5c3d\u53ef\u80fd\u77ed\u7684\u65f6\u95f4\u3002\u201d               \u2014 \u67e5\u5c14\u65af\u00b7\u5df4\u8d1d\u5947,\u8bba\u8ba1\u7b97\u5f15\u64ce\u7684\u6570\u5b66\u80fd\u529b</p> <p>The carry-lookahead method of Chapter 6 represents the most widely used design for high-speed adders in modern computers. Certain alternative designs, however, either are quite competitive with carry-lookahead adders or offer advantages with particular hardware realizations or technology constraints. The most important of these alternative designs, and various hybrid combinations, are discussed in this chapter.</p> <p>\u7b2c 6 \u7ae0\u7684\u8d85\u524d\u8fdb\u4f4d\u65b9\u6cd5\u4ee3\u8868\u4e86\u73b0\u4ee3\u8ba1\u7b97\u673a\u4e2d\u9ad8\u901f\u52a0\u6cd5\u5668\u6700\u5e7f\u6cdb\u4f7f\u7528\u7684\u8bbe\u8ba1\u3002 \u7136\u800c\uff0c\u67d0\u4e9b\u66ff\u4ee3\u8bbe\u8ba1\u8981\u4e48\u4e0e\u8d85\u524d\u8fdb\u4f4d\u52a0\u6cd5\u5668\u5177\u6709\u76f8\u5f53\u7684\u7ade\u4e89\u529b\uff0c\u8981\u4e48\u5728\u7279\u5b9a\u7684\u786c\u4ef6\u5b9e\u73b0\u6216\u6280\u672f\u9650\u5236\u65b9\u9762\u63d0\u4f9b\u4f18\u52bf\u3002 \u672c\u7ae0\u8ba8\u8bba\u4e86\u8fd9\u4e9b\u66ff\u4ee3\u8bbe\u8ba1\u4e2d\u6700\u91cd\u8981\u7684\u4ee5\u53ca\u5404\u79cd\u6df7\u5408\u7ec4\u5408\u3002</p> <ul> <li>7.1 \u7b80\u5355\u7684\u8fdb\u4f4d\u8df3\u8dc3\u52a0\u6cd5\u5668 SIMPLE CARRY SKIP ADDERS</li> <li>7.2 \u591a\u5c42\u6b21\u7684\u8fdb\u4f4d\u8df3\u8dc3\u52a0\u6cd5\u5668 MULTILEVEL CARRY SKIP ADDERS</li> <li>7.3 \u8fdb\u4f4d\u9009\u62e9\u52a0\u6cd5\u5668 CARRY-SELECT ADDERS</li> <li>7.4 \u6761\u4ef6\u548c\u52a0\u6cd5\u5668 CONDITIONAL-SUM ADDER</li> <li>7.5 \u6df7\u5408\u8bbe\u8ba1\u4e0e\u4f18\u5316 HYBRID DESIGNS AND OPTIMIZATIONS</li> <li>7.6 \u4e8c\u64cd\u4f5c\u6570\u6a21\u52a0\u6cd5\u5668 MODULAR TWO-OPERAND ADDERS</li> </ul>"},{"location":"Part_02/07/#71","title":"7.1 \u7b80\u5355\u8fdb\u4f4d\u8df3\u8dc3\u52a0\u6cd5\u5668","text":"<p>Consider a 4-bit group or block in a ripple-carry adder, from stage  i  to stage  i + 3, where i  is a multiple of 4 (Fig. 7.1a). A carry into stage  i  propagates through this group of 4 bits if and only if it propagates through all four of its stages. Thus, a  group propagate signal is defined as  p[ i,  i+3] =  pipi+1  pi+2  pi+3, which is computable from individual propagate signals by a single four-input AND gate. To speed up carry propagation, one can establish bypass or skip paths around 4-bit blocks, as shown in Fig. 7.1b. </p> <p>\u8003\u8651\u7eb9\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\u4e2d\u7684 4 \u4f4d\u7ec4\u6216\u5757\uff0c\u4ece\u9636\u6bb5 \\(i\\) \u5230\u9636\u6bb5 \\(i + 3\\)\uff0c\u5176\u4e2d \\(i\\) \u662f 4 \u7684\u500d\u6570\uff08\u56fe 7.1a\uff09\u3002\u8fdb\u5165\u9636\u6bb5 \\(i\\) \u7684\u8fdb\u4f4d\u80fd\u901a\u8fc7\u8fd9\u7ec4 4 \u4f4d\u4f20\u64ad\uff0c\u5f53\u4e14\u4ec5\u5f53\u5b83\u4f20\u64ad\u901a\u8fc7\u6240\u6709\u56db\u4e2a\u9636\u6bb5\u65f6\u3002\u56e0\u6b64\uff0c\u7ec4\u4f20\u64ad\u4fe1\u53f7\u5b9a\u4e49\u4e3a \\(p[i, i+3] = p_ip_{i+1} p_{i+2} p_{i+3}\\)\uff0c\u5b83\u53ef\u4ee5\u901a\u8fc7\u5355\u4e2a\u56db\u8f93\u5165 AND \u95e8\u6839\u636e\u5404\u4e2a\u4f20\u64ad\u4fe1\u53f7\u8fdb\u884c\u8ba1\u7b97\u3002\u4e3a\u4e86\u52a0\u901f\u8fdb\u4f4d\u4f20\u64ad\uff0c\u53ef\u4ee5\u5728 4 \u4f4d\u5757\u5468\u56f4\u5efa\u7acb\u65c1\u8def\u6216\u8df3\u8fc7\u8def\u5f84\uff0c\u5982\u56fe 7.1b \u6240\u793a\u3002</p> <p></p> <p>Let us assume that the delay of the skip multiplexer (mux) is equal to carry-propagation delay through one-bit position. Then, the worst-case propagation delay through the carry-skip adder of Fig. 7.1b corresponds to a carry that is generated in stage 0, ripples through stages 1\u20133, goes through the multiplexer, skips the middle two groups, and ripples in the last group from stage 12 to stage 15. This leads to 9 stages of propagation (18 gate levels) compared to 16 stages (32 gate levels) for a 16-bit ripple-carry adder.</p> <p>\u8ba9\u6211\u4eec\u5047\u8bbe\u8df3\u8dc3\u591a\u8def\u590d\u7528\u5668 (mux) \u7684\u5ef6\u8fdf\u7b49\u4e8e\u8fdb\u4f4d\u901a\u8fc7\u4e00\u4f4d\u4f4d\u7f6e\u7684\u4f20\u64ad\u5ef6\u8fdf\u3002\u7136\u540e\uff0c\u6700\u574f\u60c5\u51b5\u7684\u4f20\u64ad\u5ef6\u8fdf\u901a\u8fc7\u56fe 7.1b \u7684\u8df3\u8fc7\u8fdb\u4f4d\u52a0\u6cd5\u5668\u7684\u8fdb\u4f4d\u5bf9\u5e94\u4e8e\u7b2c 0 \u7ea7\u4e2d\u751f\u6210\u7684\u8fdb\u4f4d\uff0c\u7ecf\u8fc7\u7b2c 1-3 \u7ea7\u8109\u52a8\uff0c\u7ecf\u8fc7\u591a\u8def\u590d\u7528\u5668\uff0c\u8df3\u8fc7\u4e2d\u95f4\u4e24\u7ec4\uff0c\u6700\u540e\u4e00\u7ec4\u4ece\u7b2c 12 \u7ea7\u8109\u52a8\u5230\u7b2c 15 \u7ea7\u3002\u4e0e 16 \u4f4d\u8109\u52a8\u8fdb\u4f4d\u52a0\u6cd5\u5668\u7684 16 \u4e2a\u7ea7\uff0832 \u4e2a\u95e8\u7ea7\uff09\u76f8\u6bd4\uff0c\u8fd9\u5bfc\u81f4 9 \u4e2a\u4f20\u64ad\u7ea7\uff0818 \u4e2a\u95e8\u7ea7\uff09\u3002</p> <p>Generalizing from the preceding example, the worst-case carry-propagation delay in a k-bit carry-skip adder with fixed block width b, assuming that one stage of ripple has the same delay as one skip, can be derived:</p> <p>\u4ece\u524d\u9762\u7684\u793a\u4f8b\u8fdb\u884c\u6982\u62ec\uff0c\u5047\u8bbe\u4e00\u7ea7\u7eb9\u6ce2\u5177\u6709\u4e0e\u4e00\u7ea7\u8df3\u8dc3\u76f8\u540c\u7684\u5ef6\u8fdf\uff0c\u5219\u53ef\u4ee5\u5f97\u51fa\u5177\u6709\u56fa\u5b9a\u5757\u5bbd\u5ea6 b \u7684 k \u4f4d\u8df3\u8dc3\u8fdb\u4f4d\u52a0\u6cd5\u5668\u4e2d\u6700\u574f\u60c5\u51b5\u7684\u8fdb\u4f4d\u4f20\u64ad\u5ef6\u8fdf\uff1a</p> \\[ \\begin{matrix} T_{fixed-skip-add} &amp;= &amp;(b \u2212 1) &amp;+ &amp;1 &amp;+ &amp;(k/b \u2212 2) &amp;+ &amp;(b \u2212 1) \\\\ &amp;&amp;\\text{in block 0} &amp;&amp;\\text{mux} &amp;&amp;\\text{skips} &amp;&amp;\\text{in last block} \\\\ &amp;\u2248 &amp;2b + k/b \u2212 3 \\text{ stages} &amp; &amp; &amp; \\end{matrix} \\] <p>The optimal fixed block size can be derived by equating dT fixed-skip-add /db with 0: dT</p> <p>\u6700\u4f73\u56fa\u5b9a\u5757\u5927\u5c0f\u53ef\u4ee5\u901a\u8fc7\u6c42\u5bfc\u5c06 \\(\\mathrm{d}T_{fixed-skip-add} / \\mathrm{d}b\\) \u7b49\u4e8e 0 \u5f97\u51fa\uff1a</p> <p>\\(\\frac{\\mathrm{d}T_{fixed-skip-add}}{\\mathrm{d}b}=2-k/b^2=0 \\Rightarrow b^{opt}=\\sqrt{k/2}\\)</p> <p>The adder delay with the optimal block size above is</p> <p>\u4e0a\u8ff0\u6700\u4f73\u5757\u5927\u5c0f\u7684\u52a0\u6cd5\u5668\u5ef6\u8fdf\u4e3a</p> <p>\\(T^{opt}_{fixed\u2212skip\u2212add} = 2\\sqrt{k/2}+\\frac{k}{\\sqrt{k/2}}-3=2\\sqrt{2k}-3\\)</p> <p>For example, to construct a 32-bit carry-skip adder with fixed-size blocks, we set  k = 32 in the preceding equations to obtain  b opt = 4 bits and  T opt fixed\u2212skip\u2212add= 13 stages (26 gate levels). By comparison, the propagation delay of a 32-bit ripple-carry adder is about 2.5 times as long. </p> <p>\u4f8b\u5982\uff0c\u8981\u6784\u9020\u4e00\u4e2a\u5177\u6709\u56fa\u5b9a\u5927\u5c0f\u5757\u7684 32 \u4f4d\u8df3\u8fdb\u4f4d\u52a0\u6cd5\u5668\uff0c\u6211\u4eec\u8bbe\u7f6e \u524d\u9762\u7b49\u5f0f\u4e2d\u7684 k = 32 \u4ee5\u83b7\u5f97 \\(b_{opt} = 4\\) \u4f4d\u548c</p> <p>\\(T^{opt}_{fixed\u2212skip\u2212add}=13\\) \u7ea7\uff0826 \u4e2a\u95e8\u7ea7\u522b\uff09\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c32 \u4f4d\u7eb9\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\u7684\u4f20\u64ad\u5ef6\u8fdf\u7ea6\u4e3a 2.5 \u500d\u3002</p> <p>Clearly, a carry that is generated in, or absorbed by, one of the inner blocks travels a shorter distance through the skip blocks. We can thus afford to allow more ripple stages for such a carry without increasing the overall adder delay. This leads to the idea of variable skip-block sizes. </p> <p>\u663e\u7136\uff0c\u5728\u5185\u90e8\u5757\u4e4b\u4e00\u4e2d\u751f\u6210\u6216\u5438\u6536\u7684\u8fdb\u4f4d\u901a\u8fc7\u8df3\u8dc3\u5757\u884c\u8fdb\u8f83\u77ed\u7684\u8ddd\u79bb\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u5728\u4e0d\u589e\u52a0\u603b\u4f53\u52a0\u6cd5\u5668\u5ef6\u8fdf\u7684\u60c5\u51b5\u4e0b\u4e3a\u6b64\u7c7b\u8fdb\u4f4d\u5141\u8bb8\u66f4\u591a\u7eb9\u6ce2\u7ea7\u3002\u8fd9\u5bfc\u81f4\u4e86\u53ef\u53d8\u8df3\u8fc7\u5757\u5927\u5c0f\u7684\u60f3\u6cd5\u3002</p> <p>Let there be  t  blocks of widths  b 0,  b 1, \u00b7 \u00b7 \u00b7 ,  bt\u22121 going from right to left (Fig. 7.2). Consider the two carry paths (1) and (2) in Fig. 7.2, both starting in block 0, one ending in block t \u2212 1 and the other in block t \u2212 2. Carry path (2) goes through one fewer skip than (1), so block t \u2212 2 can be 1 bit wider than block t \u2212 1 without increasing the total adder delay. Similarly, by comparing carry paths (1) and (3), we conclude that block 1 can be 1 bit wider than block 0. So, assuming for ease of analysis that b 0 = bt\u22121 = b and that the number t of blocks is even, the optimal block widths are</p> <p>\u8bbe\\(t\\)\u4e2a\u5757\u7684\u5bbd\u5ea6\u4e3a\\(b_0 \u3001b_1 \u3001\u00b7\u00b7\u00b7\u00b7\u3001b_{t\u22121}\\) \u4ece\u53f3\u5230\u5de6\uff08\u56fe7.2\uff09\u3002\u8003\u8651\u56fe 7.2 \u4e2d\u7684\u4e24\u6761\u8fdb\u4f4d\u8def\u5f84 (1) \u548c (2)\uff0c\u5747\u4ece\u5757 0 \u5f00\u59cb\uff0c\u5176\u4e2d\u4e00\u4e2a\u7ed3\u675f\u5728\u5757 t-1 \u4e2d\uff0c\u53e6\u4e00\u4e2a\u5728\u5757 t-2 \u4e2d\u3002\u8fdb\u4f4d\u8def\u5f84 (2) \u6bd4 (1) \u5c11\u7ecf\u8fc7\u4e00\u6b21\u8df3\u8dc3\uff0c\u56e0\u6b64\u5757 t-2 \u53ef\u4ee5\u6bd4\u5757 t-1 \u5bbd 1 \u4f4d\uff0c\u800c\u4e0d\u4f1a\u589e\u52a0\u603b\u52a0\u6cd5\u5668\u5ef6\u8fdf\u3002\u7c7b\u4f3c\u5730\uff0c\u901a\u8fc7\u6bd4\u8f83\u8fdb\u4f4d\u8def\u5f84\uff081\uff09\u548c\uff083\uff09\uff0c\u6211\u4eec\u5f97\u51fa\u7ed3\u8bba\uff1a\u5757 1\u53ef\u4ee5\u6bd4\u5757 0 \u5bbd 1 \u4f4d\u3002\u56e0\u6b64\uff0c\u4e3a\u4e86\u4fbf\u4e8e\u5206\u6790\uff0c\u5047\u8bbe \\(b_0 = b_{t\u22121} = b\\) \u5e76\u4e14\u5757\u7684\u6570\u91cf t \u4e3a\u5076\u6570\uff0c\u5219\u6700\u4f73\u5757\u5bbd\u5ea6\u4e3a</p> <p>\\(\\begin{matrix} b &amp;b+1 &amp;\\cdots &amp;b+\\frac{t}{2}-1 &amp;b+\\frac{t}{2}-1 &amp;\\cdots &amp;b+1 &amp;b\\end{matrix}\\)</p> <p></p> <p>The first assumption  (b 0 =  bt\u22121 )  is justified because the total delay is a function of b 0 +  bt\u22121 rather than their individual values and the second one ( t  even) does not affect the results significantly. </p> <p>\u7b2c\u4e00\u4e2a\u5047\u8bbe \\((b_0 = b_{t\u22121})\\) \u662f\u5408\u7406\u7684\uff0c\u56e0\u4e3a\u603b\u5ef6\u8fdf\u662f \\(b_0 + b_{t\u22121}\\) \u7684\u51fd\u6570\uff0c\u800c\u4e0d\u662f\u5b83\u4eec\u5404\u81ea\u7684\u503c\uff0c\u800c\u7b2c\u4e8c\u4e2a\u5047\u8bbe ( t \u4e3a\u5076\u6570 ) \u4e0d\u4f1a\u663e\u7740\u5f71\u54cd\u7ed3\u679c\u3002</p> <p>Based on the preceding block widths, the total number of bits in the  t  blocks is</p> <p>\u6839\u636e\u524d\u9762\u7684\u5757\u5bbd\u5ea6\uff0ct \u4e2a\u5757\u4e2d\u7684\u603b\u4f4d\u6570\u4e3a</p> <p>$2[ b + (b + 1 ) + \u00b7 \u00b7 \u00b7 + (b + t/ 2 \u2212 1 )] = t(b + t/ 4 \u2212 1 / 2 ) $</p> <p>Equating the total above with  k  yields</p> <p>\u5c06\u4e0a\u8ff0\u603b\u6570\u5bf9k\u505a\u7b49\u5f0f\u5316\u7b80\uff0c\u5f97\u5230</p> <p>\\(b = k/t \u2212 t/4 + 1/2\\)</p> <p>The adder delay with the preceding assumptions is</p> <p>\u524d\u9762\u5047\u8bbe\u7684\u52a0\u6cd5\u5668\u5ef6\u8fdf\u4e3a</p> \\[ T_{var\u2212skip\u2212add} = 2(b \u2212 1) + 1 + t \u2212 2 = \\frac{2k}{t}+\\frac{t}{2}-2 \\] <p>The optimal number of blocks is thus obtained as follows:</p> <p>\u7531\u6b64\u83b7\u5f97\u6700\u4f73\u5757\u6570\u5982\u4e0b\uff1a</p> \\[ \\frac{\\mathrm{d}T_{fixed-skip-add}}{\\mathrm{d}t}=\\frac{-2k}{t^2}+\\frac{1}{2}=0 \\Rightarrow t^{opt}=2\\sqrt{k} \\] <p>Note that the optimal number of blocks with variable-size blocks is \\(\\sqrt{2}\\) times that obtained with fixed-size blocks. Note also that with the optimal number of blocks,  b becomes \u00bd; thus we take it to be 1. The adder delay with  t opt blocks is</p> <p>\u8bf7\u6ce8\u610f\uff0c\u5177\u6709\u53ef\u53d8\u5927\u5c0f\u5757\u7684\u5757\u7684\u6700\u4f73\u6570\u91cf\u662f\u56fa\u5b9a\u5927\u5c0f\u5757\u7684\\(\\sqrt{2}\\)\u500d\u3002\u8fd8\u8981\u6ce8\u610f\uff0c\u5bf9\u4e8e\u6700\u4f73\u5757\u6570\uff0c\\(b\\) \u53d8\u4e3a \u00bd\uff1b\u56e0\u6b64\u6211\u4eec\u5c06\u5176\u8bbe\u4e3a 1\u3002\\(t^{opt}\\) \u5757\u7684\u52a0\u6cd5\u5668\u5ef6\u8fdf\u4e3a</p> \\[ T^{opt}_{var\u2212skip\u2212add} \\approx 2 \\sqrt{k} - 2 \\] <p>which is roughly a factor of \\(\\sqrt{2}\\) smaller than that obtained with optimal fixed-size skip-blocks.</p> <p>\u8fd9\u5927\u7ea6\u662f\u4e00\u4e2a\u56e0\u7d20\\(\\sqrt{2}\\)\u6bd4\u6700\u4f73\u56fa\u5b9a\u5c3a\u5bf8\u83b7\u5f97\u7684\u5c0f\u8df3\u8fc7\u5757\u3002</p> <p>The preceding analyses were based on a number of simplifying assumptions. For example, skip and ripple delays were assumed to be equal and ripple delay was assumed to be linearly proportional to the block width. These may not be true in practice. With complementary metal-oxide semiconductor implementation, for example, the ripple delay in a Manchester carry chain grows as the square of the block width. The analyses for obtaining the optimal fixed or variable block size carry-skip adder must be appropriately modified in such cases. A number of researchers have used various assumptions about technology-dependent parameters to deal with this optimization problem. Some of these variations are explored in the end-of-chapter problems.</p> <p>\u524d\u9762\u7684\u5206\u6790\u57fa\u4e8e\u4e00\u4e9b\u7b80\u5316\u7684\u5047\u8bbe\u3002\u4f8b\u5982\uff0c\u5047\u8bbe\u8df3\u8dc3\u5ef6\u8fdf\u548c\u7eb9\u6ce2\u5ef6\u8fdf\u76f8\u7b49\uff0c\u5e76\u4e14\u5047\u8bbe\u7eb9\u6ce2\u5ef6\u8fdf\u4e0e\u5757\u5bbd\u5ea6\u6210\u7ebf\u6027\u6bd4\u4f8b\u3002\u8fd9\u4e9b\u5728\u5b9e\u8df5\u4e2d\u53ef\u80fd\u5e76\u4e0d\u6b63\u786e\u3002\u4f8b\u5982\uff0c\u5728\u4e92\u8865\u91d1\u5c5e\u6c27\u5316\u7269\u534a\u5bfc\u4f53\u5b9e\u73b0\u4e2d\uff0c\u66fc\u5f7b\u65af\u7279\u8fdb\u4f4d\u94fe\u4e2d\u7684\u7eb9\u6ce2\u5ef6\u8fdf\u968f\u7740\u5757\u5bbd\u5ea6\u7684\u5e73\u65b9\u800c\u589e\u957f\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u5fc5\u987b\u9002\u5f53\u4fee\u6539\u7528\u4e8e\u83b7\u5f97\u6700\u4f73\u56fa\u5b9a\u6216\u53ef\u53d8\u5757\u5927\u5c0f\u8df3\u8fdb\u4f4d\u52a0\u6cd5\u5668\u7684\u5206\u6790\u3002\u8bb8\u591a\u7814\u7a76\u4eba\u5458\u4f7f\u7528\u4e86\u5173\u4e8e\u6280\u672f\u76f8\u5173\u53c2\u6570\u7684\u5404\u79cd\u5047\u8bbe\u6765\u5904\u7406\u8fd9\u4e2a\u4f18\u5316\u95ee\u9898\u3002\u5176\u4e2d\u4e00\u4e9b\u53d8\u5316\u5c06\u5728\u672c\u7ae0\u672b\u5c3e\u7684\u95ee\u9898\u4e2d\u8fdb\u884c\u63a2\u8ba8\u3002</p>"},{"location":"Part_02/07/#72","title":"7.2 \u591a\u5c42\u6b21\u7684\u8fdb\u4f4d\u8df3\u8dc3\u52a0\u6cd5\u5668","text":"<p>A (single-level) carry-skip adder of the types discussed in Section 7.1 can be represented schematically as in Fig. 7.3. In our subsequent discussions, we continue to assume that the ripple and skip delays are equal, although the analyses can be easily modified to account for different ripple and skip delays. We thus equate the carry-skip adder delay with the worst-case sum, over all possible carry paths, of the number of ripple stages and the number of skip stages. </p> <p>\u7b2c 7.1 \u8282\u4e2d\u8ba8\u8bba\u7684\u7c7b\u578b\u7684\uff08\u5355\u7ea7\uff09\u8df3\u8fdb\u4f4d\u52a0\u6cd5\u5668\u53ef\u4ee5\u5982\u56fe 7.3 \u6240\u793a\u793a\u610f\u6027\u8868\u793a\u3002\u5728\u6211\u4eec\u968f\u540e\u7684\u8ba8\u8bba\u4e2d\uff0c\u6211\u4eec\u7ee7\u7eed\u5047\u8bbe\u7eb9\u6ce2\u548c\u8df3\u8dc3\u5ef6\u8fdf\u662f\u76f8\u7b49\u7684\uff0c\u5c3d\u7ba1\u53ef\u4ee5\u8f7b\u677e\u4fee\u6539\u5206\u6790\u4ee5\u8003\u8651\u4e0d\u540c\u7684\u7eb9\u6ce2\u548c\u8df3\u8dc3\u5ef6\u8fdf\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u5c06\u8df3\u8dc3\u8fdb\u4f4d\u52a0\u6cd5\u5668\u5ef6\u8fdf\u7b49\u540c\u4e8e\u6240\u6709\u53ef\u80fd\u7684\u8fdb\u4f4d\u8def\u5f84\u4e0a\u7eb9\u6ce2\u7ea7\u6570\u548c\u8df3\u8dc3\u7ea7\u6570\u7684\u6700\u574f\u60c5\u51b5\u603b\u548c\u3002</p> <p></p> <p>Multilevel carry-skip adders are obtained if we allow a carry to skip over several blocks at once. Figure 7.4 depicts a two-level carry-skip adder in which second-level skip logic has been provided for the leftmost three blocks. The signal controlling this second-level skip logic is derived as the logical AND of the first-level skip signals. A carry that would need 3 time units to skip these three blocks in a single-level carry-skip adder can now do so in 1 time unit. </p> <p>\u5982\u679c\u6211\u4eec\u5141\u8bb8\u8fdb\u4f4d\u4e00\u6b21\u8df3\u8fc7\u591a\u4e2a\u5757\uff0c\u5219\u83b7\u5f97\u591a\u7ea7\u8fdb\u4f4d\u8df3\u8dc3\u52a0\u6cd5\u5668\u3002\u56fe 7.4 \u63cf\u8ff0\u4e86\u4e00\u4e2a\u4e8c\u7ea7\u8df3\u8fc7\u8fdb\u4f4d\u52a0\u6cd5\u5668\uff0c\u5176\u4e2d\u4e3a\u6700\u5de6\u8fb9\u7684\u4e09\u4e2a\u5757\u63d0\u4f9b\u4e86\u4e8c\u7ea7\u8df3\u8fc7\u903b\u8f91\u3002\u63a7\u5236\u8be5\u7b2c\u4e8c\u7ea7\u8df3\u8dc3\u903b\u8f91\u7684\u4fe1\u53f7\u662f\u4f5c\u4e3a\u7b2c\u4e00\u7ea7\u8df3\u8dc3\u4fe1\u53f7\u7684\u903b\u8f91\u4e0e\u800c\u5bfc\u51fa\u7684\u3002\u5728\u5355\u7ea7\u8fdb\u4f4d\u8df3\u8dc3\u52a0\u6cd5\u5668\u4e2d\u9700\u8981 3 \u4e2a\u65f6\u95f4\u5355\u4f4d\u6765\u8df3\u8fc7\u8fd9\u4e09\u4e2a\u5757\u7684\u8fdb\u4f4d\u73b0\u5728\u53ea\u9700 1 \u4e2a\u65f6\u95f4\u5355\u4f4d\u5373\u53ef\u5b8c\u6210\u3002</p> <p></p> <p>If the rightmost/leftmost block in a carry-skip adder is short, skipping it may not yield any advantage over allowing the carry to ripple through the block. In this case,  the carry-skip adder of Fig. 7.4 can be simplified by removing such inefficient skip circuits. Figure 7.5 shows the resulting two-level carry-skip adder. With our simplifying assumption about ripple and skip delays being equal, the first-level skip circuit should be eliminated only for 1-bit, and possibly 2-bit, blocks (remember that generating the skip control signal also takes some time). </p> <p>\u5982\u679c\u8fdb\u4f4d\u8df3\u8dc3\u52a0\u6cd5\u5668\u4e2d\u6700\u53f3/\u6700\u5de6\u7684\u5757\u5f88\u77ed\uff0c\u5219\u8df3\u8fc7\u5b83\u53ef\u80fd\u4e0d\u4f1a\u6bd4\u5141\u8bb8\u8fdb\u4f4d\u7eb9\u6ce2\u901a\u8fc7\u8be5\u5757\u4ea7\u751f\u4efb\u4f55\u4f18\u52bf\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u901a\u8fc7\u53bb\u9664\u8fd9\u79cd\u4f4e\u6548\u7684\u8df3\u8dc3\u7535\u8def\uff0c\u53ef\u4ee5\u7b80\u5316\u56fe 7.4 \u7684\u8df3\u8dc3\u8fdb\u4f4d\u52a0\u6cd5\u5668\u3002\u56fe 7.5 \u663e\u793a\u4e86\u6700\u7ec8\u7684\u4e24\u7ea7\u8df3\u8fdb\u4f4d\u52a0\u6cd5\u5668\u3002\u901a\u8fc7\u6211\u4eec\u5173\u4e8e\u7eb9\u6ce2\u548c\u8df3\u8dc3\u5ef6\u8fdf\u76f8\u7b49\u7684\u7b80\u5316\u5047\u8bbe\uff0c\u5e94\u8be5\u4ec5\u9488\u5bf9 1 \u4f4d\u548c\u53ef\u80fd\u7684 2 \u4f4d\u5757\u6d88\u9664\u7b2c\u4e00\u7ea7\u8df3\u8dc3\u7535\u8def\uff08\u8bf7\u8bb0\u4f4f\uff0c\u751f\u6210\u8df3\u8dc3\u63a7\u5236\u4fe1\u53f7\u4e5f\u9700\u8981\u4e00\u4e9b\u65f6\u95f4\uff09\u3002</p> <p></p> <p>\u25a0 EXAMPLE 7.1 Assume that each of the following operations takes 1 unit of time: generation of  gi  and  pi  signals, generation of a level- i  skip signal from level-( i \u2212 1) skip signals, ripple, skip, and computation of sum bit once the incoming carry is known. Build the widest possible single-level carry-skip adder with a total delay not exceeding 8 time units. </p> <p>Let  bi  be the width of block  i. The numbers given on the adder diagram of Fig. 7.6 denote the time steps when the various signals stabilize, assuming that  c in is available at time 0. At the right end, block width is limited by the output timing requirement. For example,  b 1 cannot be more than 3 bits if its output is to be available at time 3 (1 time unit is taken by gi,  pi  generation at the rightmost bit, plus 2 time units for propagation across the other 2 bits).  Block 0 is an exception, because to accommodate  c in, its width must be reduced by 1 bit. At the left end, block width is limited by input timing. For example,  b 4 cannot be more than 3 bits, given that its input becomes available at time 5 and the total adder delay is to be 8 units. Based on this analysis, the maximum possible adder width is 1+3+4+4+3+2+1 = 18 bits. </p> <p>\u25a0 \u793a\u4f8b7.1 \u5047\u8bbe\u4ee5\u4e0b\u6bcf\u4e2a\u64cd\u4f5c\u9700\u8981 1 \u4e2a\u65f6\u95f4\u5355\u4f4d\uff1a\u751f\u6210 \\(g_i\\) \u548c \\(p_i\\) \u4fe1\u53f7\u3001\u4ece level-\\((i \u2212 1)\\) \u4e2a\u8df3\u8dc3\u4fe1\u53f7\u751f\u6210 level- \\(i\\) \u8df3\u8dc3\u4fe1\u53f7\u3001\u7eb9\u6ce2\u3001skip \uff0c\u548c\u8ba1\u7b97\u548c\u4f4d(\u6709\u4f20\u5165\u8fdb\u4f4d)\u3002 \u6784\u5efa\u5c3d\u53ef\u80fd\u5bbd\u7684\u5355\u7ea7\u8df3\u8fdb\u4f4d\u52a0\u6cd5\u5668\uff0c\u603b\u5ef6\u8fdf\u4e0d\u8d85\u8fc7 8 \u4e2a\u65f6\u95f4\u5355\u4f4d\u3002</p> <p>\u4ee4 \\(b_i\\) \u4e3a\u5757 \\(i\\) \u7684\u5bbd\u5ea6\u3002 \u56fe 7.6 \u7684\u52a0\u6cd5\u5668\u56fe\u4e0a\u7ed9\u51fa\u7684\u6570\u5b57\u8868\u793a\u5404\u79cd\u4fe1\u53f7\u7a33\u5b9a\u65f6\u7684\u65f6\u95f4\u6b65\u957f\uff0c\u5047\u8bbe \\(c_{in}\\) \u5728\u65f6\u95f4 0 \u53ef\u7528\u3002\u5728\u53f3\u7aef\uff0c\u5757\u5bbd\u5ea6\u53d7\u5230\u8f93\u51fa\u65f6\u5e8f\u8981\u6c42\u7684\u9650\u5236\u3002 \u4f8b\u5982\uff0c\u5982\u679c \\(b_1\\) \u7684\u8f93\u51fa\u5728\u65f6\u95f4 3 \u53ef\u7528\uff08\u6700\u53f3\u8fb9\u4f4d\u7684 \\(g_i\u3001p_i\\) \u751f\u6210\u5360\u7528 1 \u4e2a\u65f6\u95f4\u5355\u4f4d\uff0c\u52a0\u4e0a 2 \u4e2a\u65f6\u95f4\u5355\u4f4d\u7528\u4e8e\u4f20\u64ad\uff09\uff0c\u5219 \\(b_1\\) \u4e0d\u80fd\u8d85\u8fc7 3 \u4f4d\u3002 \u5176\u4ed6 2 \u4f4d\uff09\u3002 \u57570\u662f\u4e00\u4e2a\u4f8b\u5916\uff0c\u56e0\u4e3a\u8981\u5bb9\u7eb3\\(c_{in}\\)\uff0c\u5b83\u7684\u5bbd\u5ea6\u5fc5\u987b\u51cf\u5c111\u4f4d\u3002 \u5728\u5de6\u7aef\uff0c\u5757\u5bbd\u5ea6\u53d7\u5230\u8f93\u5165\u65f6\u5e8f\u7684\u9650\u5236\u3002 \u4f8b\u5982\uff0c\\(b_4\\) \u4e0d\u80fd\u8d85\u8fc7 3 \u4f4d\uff0c\u5047\u8bbe\u5176\u8f93\u5165\u5728\u65f6\u95f4 5 \u53ef\u7528\u5e76\u4e14\u603b\u52a0\u6cd5\u5668\u5ef6\u8fdf\u4e3a 8 \u4e2a\u5355\u4f4d\u3002 \u6839\u636e\u6b64\u5206\u6790\uff0c\u6700\u5927\u53ef\u80fd\u7684\u52a0\u6cd5\u5668\u5bbd\u5ea6\u4e3a \\(1+3+4+4+3+2+1 = 18\\) \u4f4d\u3002</p> <p></p> <p>\u25a0 EXAMPLE 7.2 With the same assumptions as in Example 7.1, build the widest possible two-level carry-skip adder with a total delay not exceeding 8 time units. </p> <p>We begin with an analysis of skip paths at level 2. In Fig. 7.7a, the notation { \u03b2,  \u03b1} for a block means that the block\u2019s carry-out must become available no later than  T produce =  \u03b2 and that the block\u2019s carry-in can take  T assimilate =  \u03b1  time units to propagate within the block without exceeding the overall time limit of 8 units. The remaining problem is to construct single-level carry-skip adders with the parameters  T produce =  \u03b2  and  T assimilate =  \u03b1. Given the delay pair { \u03b2,  \u03b1}, the number of first-level blocks (subblocks) will be  \u03b3 = min (\u03b2 \u22121,  \u03b1), with the width of the  i th subblock, 0 \u2264  i \u2264  \u03b3 \u2212 1, given by  bi = min (\u03b2 \u2212  \u03b3 +  i + 1,  \u03b1 \u2212  i); the only exception is subblock 0 in block A, which has 1 fewer bit (why?). So, the total widthof such a block is \u03b3\u22121 min (\u03b2 \u2212  \u03b3 +  i + 1,  \u03b1 \u2212  i). Table 7.1 summarizes our analyses i=0 for the second-level blocks A\u2013F. Note that the second skip level has increased the adder width from 18 bits (in Example 7.1) to 30 bits. Figure 7.7b shows the resulting two-level carry-skip adder. </p> <p>\u25a0 \u4f8b7.2 \u91c7\u7528\u4e0e\u4f8b7.1 \u76f8\u540c\u7684\u5047\u8bbe\uff0c\u6784\u5efa\u5c3d\u53ef\u80fd\u5bbd\u7684\u4e24\u7ea7\u8df3\u8fdb\u4f4d\u52a0\u6cd5\u5668\uff0c\u603b\u5ef6\u8fdf\u4e0d\u8d85\u8fc78 \u4e2a\u65f6\u95f4\u5355\u4f4d\u3002</p> <p>\u6211\u4eec\u4ece\u7b2c 2 \u5c42\u7684\u8df3\u8dc3\u8def\u5f84\u5206\u6790\u5f00\u59cb\u3002\u5728\u56fe 7.7a \u4e2d\uff0c\u5757\u7684\u8bb0\u53f7 {\\(\u03b2, \u03b1\\)} \u610f\u5473\u7740\u8be5\u5757\u7684\u8fdb\u4f4d\u8f93\u51fa\u5fc5\u987b\u5728\u4e0d\u665a\u4e8e \\(T_{Produce} = \u03b2\\) \u65f6\u53ef\u7528\u3002\u5e76\u4e14\u5757\u7684\u8fdb\u4f4d\u53ef\u4ee5\u82b1\u8d39 \\(T_{assimilate} = \u03b1\\) \u65f6\u95f4\u5355\u4f4d\u5728\u5757\u5185\u4f20\u64ad\uff0c\u800c\u4e0d\u8d85\u8fc7 8 \u4e2a\u5355\u4f4d\u7684\u603b\u65f6\u95f4\u9650\u5236\u3002\u5269\u4e0b\u7684\u95ee\u9898\u662f\u6784\u5efa\u5355\u7ea7\u8df3\u8fdb\u4f4d\u52a0\u6cd5\u5668\uff0c\u5176\u53c2\u6570\\(T_{Produce} = \u03b2\\) \u4e14 \\(T_{assimilate} = \u03b1\\) \u3002\u7ed9\u5b9a\u5ef6\u8fdf\u5bf9\\(\\{\u03b2\uff0c\u03b1\\}\\)\uff0c\u7b2c\u4e00\u7ea7\u5757\uff08\u5b50\u5757\uff09\u7684\u6570\u91cf\u4e3a\\(\u03b3 = min(\u03b2\u22121\uff0c\u03b1)\\)\uff0c\u7b2c\\(i\\)\u4e2a\u5b50\u5757\u7684\u5bbd\u5ea6\u4e3a\\(0\u2264i\u2264\u03b3\u22121\\)\uff0c\u7531\\(b_i = min(\u03b2\u2212\u03b3+i+1\uff0c\u03b1\u2212i)\\)\u7ed9\u51fa\uff1b\u552f\u4e00\u7684\u4f8b\u5916\u662f\u5757 A \u4e2d\u7684\u5b50\u5757 0\uff0c\u5b83\u5c11\u4e86 1 \u4f4d\uff08\u4e3a\u4ec0\u4e48\uff1f\uff09\u3002\u56e0\u6b64\uff0c\u8fd9\u6837\u4e00\u4e2a\u5757\u7684\u603b\u5bbd\u5ea6\u662f\\(\\sum_{i=0}^{\\gamma-1}min(\\beta-\\gamma+i+1, \\alpha-i)\\)\u3002\u8868 7.1 \u603b\u7ed3\u4e86\u6211\u4eec\u5bf9\u4e8e\u4e8c\u7ea7\u5757 A\u2013F\u7684\u5206\u6790\u3002\u8bf7\u6ce8\u610f\uff0c\u7b2c\u4e8c\u4e2a\u8df3\u8dc3\u7ea7\u5df2\u5c06\u52a0\u6cd5\u5668\u5bbd\u5ea6\u4ece 18 \u4f4d\uff08\u4f8b 7.1 \u4e2d\uff09\u589e\u52a0\u5230 30 \u4f4d\u3002\u56fe 7.7b \u663e\u793a\u4e86\u6700\u7ec8\u7684\u4e24\u7ea7\u8df3\u8fdb\u4f4d\u52a0\u6cd5\u5668\u3002</p> <p></p> <p></p> <p>The preceding analyses of one- and two-level carry-skip adders are based on many simplifying assumptions. If these assumptions are relaxed, the problem may no longer lend itself to analytical solution. Chan et al. [Chan92] use dynamic programming to obtain optimal configurations of carry-skip adders for which the various worst-case delays in a block of  b  full-adder units are characterized by arbitrary given functions (Fig. 7.8). These delays include: </p> <ul> <li> <p>I (b) Internal carry-propagate delay for the block</p> </li> <li> <p>G(b)  Carry-generate delay for the block</p> </li> <li> <p>A(b) Carry-assimilate delay for the block</p> </li> </ul> <p>\u524d\u9762\u5bf9\u4e00\u7ea7\u548c\u4e8c\u7ea7\u8df3\u8fdb\u4f4d\u52a0\u6cd5\u5668\u7684\u5206\u6790\u57fa\u4e8e\u8bb8\u591a\u7b80\u5316\u5047\u8bbe\u3002\u5982\u679c\u653e\u5bbd\u8fd9\u4e9b\u5047\u8bbe\uff0c\u95ee\u9898\u53ef\u80fd\u4e0d\u518d\u9002\u5408\u89e3\u6790\u89e3\u3002\u9648\u7b49\u4eba\u3002 [Chan92]\u4f7f\u7528\u52a8\u6001\u89c4\u5212\u6765\u83b7\u5f97\u8df3\u8fdb\u4f4d\u52a0\u6cd5\u5668\u7684\u6700\u4f73\u914d\u7f6e\uff0c\u5176\u4e2db \u4e2a\u5168\u52a0\u5668\u5355\u5143\u5757\u4e2d\u5404\u79cd\u6700\u574f\u60c5\u51b5\u7684\u5ef6\u8fdf\u7531\u4efb\u610f\u7ed9\u5b9a\u51fd\u6570\u8868\u5f81\uff08\u56fe 7.8\uff09\u3002\u8fd9\u4e9b\u5ef6\u8bef\u5305\u62ec\uff1a</p> <ul> <li>\\(I(b)\\)\u200b : \u5757\u7684\u5185\u90e8\u8fdb\u4f4d\u4f20\u64ad\u5ef6\u8fdf</li> <li>\\(G(b)\\): \u5757\u7684\u8fdb\u4f4d\u751f\u6210\u5ef6\u8fdf</li> <li>\\(A(b)\\): \u5757\u7684\u8fdb\u4f4d\u5438\u6536\u5ef6\u8fdf</li> </ul> <p></p> <p>In addition, skip and enable delay functions,  Sh(b)  and  Eh(b), are defined for each skip level  h. In terms of this general model, our preceding analysis can be characterized as corresponding to  I (b) =  b \u2212 1,  G(b) =  b,  A(b) =  b,  Sh(b) = 1, and  Eh(b) =  h + 1. This is the model assumed by Turrini [Turr89]. Similar methods can be used to derive optimal block widths in variable-block carry-lookahead adders [Chan92]. </p> <p>\u6b64\u5916\uff0c\u8fd8\u4e3a\u6bcf\u4e2a\u8df3\u8dc3\u7ea7\u522b \\(h\\) \u5b9a\u4e49\u4e86\u8df3\u8dc3\u548c\u542f\u7528\u5ef6\u8fdf\u51fd\u6570 \\(S_h(b)\\) \u548c \\(E_h(b)\\)\u3002\u6839\u636e\u8fd9\u4e2a\u901a\u7528\u6a21\u578b\uff0c\u6211\u4eec\u524d\u9762\u7684\u5206\u6790\u53ef\u4ee5\u8868\u5f81\u4e3a\u5bf9\u5e94\u4e8e\\(I(b) = b \u2212 1\\)\u3001\\(G(b) = b\\)\u3001\\(A(b) = b\\)\u3001\\(S_h(b) = 1\\) \u548c \\(E_h(b) = h + 1\\)\u3002\u8fd9\u662f Turrini [Turr89] \u5047\u8bbe\u7684\u6a21\u578b\u3002\u7c7b\u4f3c\u7684\u65b9\u6cd5\u53ef\u7528\u4e8e\u5bfc\u51fa\u53ef\u53d8\u5757\u8d85\u524d\u8fdb\u4f4d\u52a0\u6cd5\u5668\u4e2d\u7684\u6700\u4f73\u5757\u5bbd\u5ea6[Chan92]\u3002</p>"},{"location":"Part_02/07/#73","title":"7.3 \u8fdb\u4f4d\u9009\u62e9\u52a0\u6cd5\u5668","text":"<p>One of the earliest logarithmic time adder designs is based on the conditional-sum addition algorithm. In this scheme, blocks of bits are added in two ways: assuming an incoming carry of 0 or of 1, with the correct outputs selected later as the block\u2019s true carry-in becomes known. With each level of selection, the number of known output bits doubles, leading to a logarithmic number of levels and thus logarithmic time addition. Underlying the building of conditional-sum adders is the carry-select principle, which is described in this section. </p> <p>\u6700\u65e9\u7684\u5bf9\u6570\u65f6\u95f4\u52a0\u6cd5\u5668\u8bbe\u8ba1\u4e4b\u4e00\u662f\u57fa\u4e8e\u6761\u4ef6\u548c\u52a0\u6cd5\u7b97\u6cd5\u3002\u5728\u6b64\u65b9\u6848\u4e2d\uff0c\u4f4d\u5757\u4ee5\u4e24\u79cd\u65b9\u5f0f\u76f8\u52a0\uff1a\u5047\u8bbe\u4f20\u5165\u8fdb\u4f4d\u4e3a 0 \u6216 1\uff0c\u7a0d\u540e\u5f53\u77e5\u9053\u8be5\u5757\u7684\u771f\u5b9e\u8fdb\u4f4d\u65f6\u9009\u62e9\u6b63\u786e\u7684\u8f93\u51fa\u3002\u5bf9\u4e8e\u6bcf\u4e2a\u7ea7\u522b\u7684\u9009\u62e9\uff0c\u5df2\u77e5\u8f93\u51fa\u4f4d\u6570\u52a0\u500d\uff0c\u5bfc\u81f4\u7ea7\u522b\u6570\u4e3a\u5bf9\u6570\uff0c\u4ece\u800c\u5bfc\u81f4\u65f6\u95f4\u76f8\u52a0\u4e3a\u5bf9\u6570\u3002\u6784\u5efa\u6761\u4ef6\u548c\u52a0\u6cd5\u5668\u7684\u57fa\u7840\u662f\u8fdb\u4f4d\u9009\u62e9\u539f\u7406\uff0c\u672c\u8282\u5c06\u5bf9\u6b64\u8fdb\u884c\u63cf\u8ff0\u3002</p> <p>A (single-level) carry-select adder is one that combines three  k/2-bit adders of any design into a  k-bit adder (Fig. 7.9). One  k/2-bit adder is used to compute the lower half of the  k-bit sum directly. Two  k/2-bit adders are used to compute the upper  k/2 bits of the sum and the carry-out under two different scenarios:  ck/ 2 = 0 or  ck/ 2 = 1. The correct values for the adder\u2019s carry-out signal and the sum bits in positions  k/2 through  k \u2212 1 are selected when the value of  ck/ 2 becomes known. The delay of the resulting  k-bit adder is two gate levels more than that of the  k/2-bit adders that are used in its construction. </p> <p>\uff08\u5355\u7ea7\uff09\u8fdb\u4f4d\u9009\u62e9\u52a0\u6cd5\u5668\u662f\u5c06\u4efb\u610f\u8bbe\u8ba1\u7684\u4e09\u4e2a \\(k/2\\) \u4f4d\u52a0\u6cd5\u5668\u7ec4\u5408\u6210\u4e00\u4e2a \\(k\\) \u4f4d\u52a0\u6cd5\u5668\uff08\u56fe 7.9\uff09\u3002\u4f7f\u7528\u4e00\u4e2a\\(k/2\\)\u4f4d\u52a0\u6cd5\u5668\u76f4\u63a5\u8ba1\u7b97k\u4f4d\u548c\u7684\u4e0b\u534a\u90e8\u5206\u3002\u4e24\u4e2a \\(k/2\\) \u4f4d\u52a0\u6cd5\u5668\u7528\u4e8e\u5728\u4e24\u79cd\u4e0d\u540c\u60c5\u51b5\u4e0b\u8ba1\u7b97\u603b\u548c\u548c\u8fdb\u4f4d\u7684\u9ad8 \\(k/2\\) \u4f4d\uff1a\\(c_{k/2} = 0\\) \u6216 \\(c_{k/2} = 1\\)\u3002\u5f53 \\(c_{k/2}\\) \u7684\u503c\u5df2\u77e5\u65f6\uff0c\u5c31\u4f1a\u9009\u62e9\u52a0\u6cd5\u5668\u8fdb\u4f4d\u8f93\u51fa\u4fe1\u53f7\u4ee5\u53ca\u4f4d\u7f6e \\(k/2\\) \u5230 \\(k\u22121\\) \u4e2d\u7684\u548c\u4f4d\u7684\u6b63\u786e\u503c\u3002\u7531\u6b64\u4ea7\u751f\u7684 \\(k\\) \u4f4d\u52a0\u6cd5\u5668\u7684\u5ef6\u8fdf\u6bd4\u5176\u6784\u9020\u4e2d\u4f7f\u7528\u7684 \\(k/2\\) \u4f4d\u52a0\u6cd5\u5668\u7684\u5ef6\u8fdf\u591a\u4e24\u4e2a\u95e8\u7ea7\u3002</p> <p></p> <p>The following simple analysis demonstrates the cost-effectiveness of the carry-select method. Let us take the cost and delay of a single-bit 2-to-1 multiplexer as our units and assume that the cost and delay of a  k-bit adder are  C add (k)  and  T add (k), respectively. Then, the cost and delay of the carry-select adder of Fig. 7.9 are</p> <p>\u4e0b\u9762\u7684\u7b80\u5355\u5206\u6790\u8bf4\u660e\u4e86\u8fdb\u4f4d\u9009\u62e9\u65b9\u6cd5\u7684\u6210\u672c\u6548\u76ca\u3002\u8ba9\u6211\u4eec\u4ee5\u5355\u6bd4\u72792\u5bf91\u590d\u7528\u5668\u7684\u6210\u672c\u548c\u5ef6\u8fdf\u4e3a\u5355\u4f4d\uff0c\u5e76\u5047\u8bbek\u4f4d\u52a0\u6cd5\u5668\u7684\u6210\u672c\u548c\u5ef6\u8fdf\u5206\u522b\u4e3a\\(C_{add}(k)\\)\u548c\\(T_{add}(k)\\)\u3002\u90a3\u4e48\uff0c\u56fe 7.9 \u7684\u8fdb\u4f4d\u9009\u62e9\u52a0\u6cd5\u5668\u7684\u6210\u672c\u548c\u5ef6\u8fdf\u4e3a</p> \\[ \\begin{array}{l} C_{select\u2212add}(k) = 3C_{add}(k/2) + k/2 + 1 \\\\ T_{select\u2212add}(k) = T_{add}(k/2) + 1 \\end{array} \\] <p>If we take the product of cost and delay as our measure of cost-effectiveness, the carry-select scheme of Fig. 7.9 is more cost-effective than the scheme used in synthesizing its component adders if and only if</p> <p>\u5982\u679c\u6211\u4eec\u5c06\u6210\u672c\u548c\u5ef6\u8fdf\u7684\u4e58\u79ef\u4f5c\u4e3a\u6210\u672c\u6548\u76ca\u7684\u8861\u91cf\u6807\u51c6\uff0c\u5219\u56fe 7.9 \u7684\u8fdb\u4f4d\u9009\u62e9\u65b9\u6848\u8981\u60f3\u6bd4\u7528\u4e8e\u5408\u6210\u5176\u5206\u91cf\u52a0\u6cd5\u5668\u7684\u65b9\u6848\u66f4\u5177\u6210\u672c\u6548\u76ca\uff0c\u53ea\u6709\u5f53\u4e14\u4ec5\u5f53</p> <p>\\([3 C_{add} (k/2) + k/ 2 + 1][ T_{add} (k/2) + 1] &lt; C_{add}(k) T_{add}(k)\\)</p> <p>For ripple-carry adders, we have C add (k) = \u03b1k and T add (k) = \u03c4 k. To simplify the analysis, assume \u03c4 = \u03b1/ 2 &gt; 1. Then, it is easy to show that the carry-select method is more cost-effective than the ripple-carry scheme if k &gt; 16 /(\u03b1 \u2212 1 ). For \u03b1 = 4 and \u03c4 = 2, say, the carry-select approach is almost always preferable to ripple-carry. Similar analyses can be carried out to compare the carry-select method against other addition schemes.</p> <p>\u5bf9\u4e8e\u7eb9\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\uff0c\u6211\u4eec\u6709 \\(C_{add}(k) = \u03b1k\\) \u548c \\(T_{add}(k) = \u03c4 k\\)\u3002\u4e3a\u4e86\u7b80\u5316\u5206\u6790\uff0c\u5047\u8bbe \\(\u03c4 = \u03b1/ 2 &gt; 1\\)\u3002\u7136\u540e\uff0c\u5f88\u5bb9\u6613\u8bc1\u660e\uff0c\u5982\u679c \\(k &gt; 16 /(\u03b1 \u2212 1)\\)\uff0c\u8fdb\u4f4d\u9009\u62e9\u65b9\u6cd5\u6bd4\u7eb9\u6ce2\u8fdb\u4f4d\u65b9\u6848\u66f4\u5177\u6210\u672c\u6548\u76ca\u3002\u4f8b\u5982\uff0c\u5bf9\u4e8e \u03b1 = 4 \u548c \u03c4 = 2\uff0c\u8fdb\u4f4d\u9009\u62e9\u65b9\u6cd5\u51e0\u4e4e\u603b\u662f\u4f18\u4e8e\u7eb9\u6ce2\u8fdb\u4f4d\u3002\u53ef\u4ee5\u8fdb\u884c\u7c7b\u4f3c\u7684\u5206\u6790\u6765\u5c06\u8fdb\u4f4d\u9009\u62e9\u65b9\u6cd5\u4e0e\u5176\u4ed6\u52a0\u6cd5\u65b9\u6848\u8fdb\u884c\u6bd4\u8f83\u3002</p> <p>Note that in the preceding analysis, the use of three complete k/2-bit adders was assumed. With some adder types, the two k/2-bit adders at the left of Fig. 7.9 can share some hardware, thus leading to even greater cost-effectiveness. For example, if the component adders used are of the carry-lookahead variety, much of the carry network can be shared between the two adders computing the sum bits with ck/ 2 = 0 and ck/ 2 = 1(how?).</p> <p>\u8bf7\u6ce8\u610f\uff0c\u5728\u524d\u9762\u7684\u5206\u6790\u4e2d\uff0c\u5047\u8bbe\u4f7f\u7528\u4e09\u4e2a\u5b8c\u6574\u7684 k/2 \u4f4d\u52a0\u6cd5\u5668\u3002\u5bf9\u4e8e\u67d0\u4e9b\u52a0\u6cd5\u5668\u7c7b\u578b\uff0c\u56fe 7.9 \u5de6\u4fa7\u7684\u4e24\u4e2a k/2 \u4f4d\u52a0\u6cd5\u5668\u53ef\u4ee5\u5171\u4eab\u4e00\u4e9b\u786c\u4ef6\uff0c\u4ece\u800c\u5e26\u6765\u66f4\u5927\u7684\u6210\u672c\u6548\u76ca\u3002\u4f8b\u5982\uff0c\u5982\u679c\u6240\u4f7f\u7528\u7684\u5206\u91cf\u52a0\u6cd5\u5668\u5c5e\u4e8e\u5148\u884c\u8fdb\u4f4d\u7c7b\u578b\uff0c\u5219\u53ef\u4ee5\u5728\u8ba1\u7b97 ck/ 2 = 0 \u548c ck/ 2 = 1 \u7684\u603b\u548c\u4f4d\u7684\u4e24\u4e2a\u52a0\u6cd5\u5668\u4e4b\u95f4\u5171\u4eab\u5927\u90e8\u5206\u8fdb\u4f4d\u7f51\u7edc\uff08\u5982\u4f55\u505a\uff1f\uff09\u3002</p> <p>Note that the carry-select method works just as well when the component adders have different widths. For example, Fig. 7.9 could have been drawn with one a-bit and two b-bit adders used to form an ( a + b)-bit adder. Then ca would be used to select the upper b bits of the sum through a ( b + 1)-bit multiplexer. Unequal widths for the component adders is appropriate when the delay in deriving the selection signal ca is different from that of the sum bits.</p> <p>\u8bf7\u6ce8\u610f\uff0c\u8fdb\u4f4d\u9009\u62e9\u65b9\u6cd5\u5728\u6709\u4e0d\u540c\u7684\u5bbd\u5ea6\u5206\u91cf\u52a0\u6cd5\u5668\u65f6\u4e5f\u540c\u6837\u6709\u6548\u3002\u4f8b\u5982\uff0c\u56fe 7.9 \u53ef\u4ee5\u7528\u4e00\u4e2a a \u4f4d\u52a0\u6cd5\u5668\u548c\u4e24\u4e2a b \u4f4d\u52a0\u6cd5\u5668\u6765\u7ed8\u5236\uff0c\u7528\u4e8e\u5f62\u6210 \\((a + b)\\) \u4f4d\u52a0\u6cd5\u5668\u3002\u7136\u540e\uff0c\\(c_a\\) \u5c06\u7528\u4e8e\u901a\u8fc7 \\((b + 1)\\) \u4f4d\u591a\u8def\u590d\u7528\u5668\u9009\u62e9\u548c\u7684\u9ad8 \\(b\\) \u4f4d\u3002\u5f53\u5bfc\u51fa\u9009\u62e9\u4fe1\u53f7\\(c_a\\)\u7684\u5ef6\u8fdf\u4e0e\u6c42\u548c\u4f4d\u7684\u5ef6\u8fdf\u4e0d\u540c\u65f6\uff0c\u5206\u91cf\u52a0\u6cd5\u5668\u7684\u4e0d\u7b49\u5bbd\u5ea6\u662f\u5408\u9002\u7684\u3002</p> <p>Figure 7.10 depicts how the carry-select idea can be carried one step further to obtain a two-level carry-select adder. Sum and carry-out bits are computed for each k/4-bit block (except for the rightmost one) under two scenarios. The three first-level multiplexers, each of which is  k/ 4 + 1 bits wide, merge the results of  k/4-bit blocks into those of k/2-bit blocks. Note how the carry-out signals of the adders spanning bit positions  k/2 through 3 k/ 4 \u2212 1 are used to select the most-significant  k/4 bits of the sum under the two scenarios of  ck/ 2 = 0 or  ck/ 2 = 1. At this stage,  k/2 bits of the final sum are known. The second-level multiplexer, which is  k/ 2 + 1 bits wide, is used to select appropriate values for the upper  k/2 bits of the sum (positions  k/2 through  k \u2212 1) and the adder\u2019s carry-out. </p> <p>\u56fe 7.10 \u63cf\u8ff0\u4e86\u5982\u4f55\u5c06\u8fdb\u4f4d\u9009\u62e9\u601d\u60f3\u8fdb\u4e00\u6b65\u63a8\u8fdb\u4ee5\u83b7\u5f97\u4e24\u7ea7\u8fdb\u4f4d\u9009\u62e9\u52a0\u6cd5\u5668\u3002\u4e3a\u6bcf\u4e2a \\(k/4\\) \u4f4d\u5757\u8ba1\u7b97\u603b\u548c\u548c\u8fdb\u4f4d\u4f4d\uff08\u9664\u4e86\u6700\u53f3\u8fb9\u7684\uff09\u4e24\u79cd\u60c5\u51b5\u4e0b\u3002\u4e09\u4e2a\u7b2c\u4e00\u7ea7\u591a\u8def\u590d\u7528\u5668\uff0c\u6bcf\u4e2a\u90fd\u662f \\(k/ 4 + 1\\) \u4f4d\u5bbd\uff0c\u5c06 \\(k/4\\) \u4f4d\u5757\u7684\u7ed3\u679c\u5408\u5e76\u5230 \\(k/2\\) \u4f4d\u5757\u7684\u7ed3\u679c\u4e2d\u3002\u6ce8\u610f\u52a0\u6cd5\u5668\u7684\u8fdb\u4f4d\u4fe1\u53f7\u5982\u4f55\u8de8\u8d8a\u4f4d\u4f4d\u7f6e \\(k/2\\)\u5230\\(3 k/ 4 \u2212 1\\)\u7528\u4e8e\u5728\\(c_k/ 2 = 0\\)\u6216\\(c_k/ 2 = 1\\)\u4e24\u79cd\u60c5\u51b5\u4e0b\u9009\u62e9\u548c\u7684\u6700\u9ad8\u6709\u6548\\(k/4\\)\u4f4d\u3002\u6b64\u65f6\uff0c\u6700\u7ec8\u548c\u7684\\(k/2\\)\u4f4d\u662f\u5df2\u77e5\u7684\u3002\u7b2c\u4e8c\u7ea7\u591a\u8def\u590d\u7528\u5668\u7684\u5bbd\u5ea6\u4e3a \\(k/ 2 + 1\\) \u4f4d\uff0c\u7528\u4e8e\u4e3a\u548c\u7684\u9ad8 \\(k/2\\) \u4f4d\uff08\u4f4d\u7f6e \\(k/2\\) \u5230 \\(k \u2212 1\\)\uff09\u548c\u52a0\u6cd5\u5668\u7684\u8fdb\u4f4d\u9009\u62e9\u9002\u5f53\u7684\u503c\u3002</p> <p></p> <p>Comparing the two-level carry-select adder of Fig. 7.10 with a similar two-level carry-lookahead adder (Fig. 6.4, but with 2-bit, rather than 4-bit, lookahead carry generators), we note that the one-directional top-to-bottom data flow in Fig. 7.10 makes pipelining easier and more efficient. Of course, from Section 6.5 and the example in Fig. 6.13, we know that carry-lookahead adders can also be implemented to possess one-directional data flow. In such cases, comparison is somewhat more difficult, inso-far as carry-select adders have a more complex upper structure (the small adders) and simpler lower structure (the multiplexers). </p> <p>\u5c06\u56fe 7.10 \u7684\u4e24\u7ea7\u8fdb\u4f4d\u9009\u62e9\u52a0\u6cd5\u5668\u4e0e\u7c7b\u4f3c\u7684\u4e24\u7ea7\u8fdb\u4f4d\u8d85\u524d\u52a0\u6cd5\u5668\uff08\u56fe 6.4\uff0c\u4f46\u4f7f\u7528 2 \u4f4d\u800c\u4e0d\u662f 4 \u4f4d\u8d85\u524d\u8fdb\u4f4d\u751f\u6210\u5668\uff09\u8fdb\u884c\u6bd4\u8f83\uff0c\u6211\u4eec\u6ce8\u610f\u5230\u56fe 7.10 \u4e2d\u7684\u5355\u5411\u4ece\u4e0a\u5230\u4e0b\u6570\u636e\u6d41\u4f7f\u6d41\u6c34\u7ebf\u64cd\u4f5c\u66f4\u5bb9\u6613\u3001\u66f4\u9ad8\u6548\u3002\u5f53\u7136\uff0c\u4ece6.5\u8282\u548c\u56fe6.13\u4e2d\u7684\u4f8b\u5b50\uff0c\u6211\u4eec\u77e5\u9053\u8d85\u524d\u8fdb\u4f4d\u52a0\u6cd5\u5668\u4e5f\u53ef\u4ee5\u5b9e\u73b0\u4e3a\u62e5\u6709\u5355\u5411\u6570\u636e\u6d41\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6bd4\u8f83\u6709\u70b9\u56f0\u96be\uff0c\u56e0\u4e3a\u8fdb\u4f4d\u9009\u62e9\u52a0\u6cd5\u5668\u5177\u6709\u66f4\u590d\u6742\u7684\u4e0a\u90e8\u7ed3\u6784\uff08\u5c0f\u52a0\u6cd5\u5668\uff09\u548c\u66f4\u7b80\u5355\u7684\u4e0b\u90e8\u7ed3\u6784\uff08\u591a\u8def\u590d\u7528\u5668\uff09\u3002</p> <p>Which design comes out ahead for a given word width depends on the implementation technology, performance requirements, and other design constraints. Very often, the best choice is a hybrid combination of carry-select and carry-lookahead (see Section 7.5). </p> <p>\u5bf9\u4e8e\u7ed9\u5b9a\u7684\u5b57\u5bbd\uff0c\u54ea\u79cd\u8bbe\u8ba1\u9886\u5148\u53d6\u51b3\u4e8e\u5b9e\u73b0\u6280\u672f\u3001\u6027\u80fd\u8981\u6c42\u548c\u5176\u4ed6\u8bbe\u8ba1\u7ea6\u675f\u3002\u901a\u5e38\uff0c\u6700\u597d\u7684\u9009\u62e9\u662f\u8fdb\u4f4d\u9009\u62e9\u548c\u8fdb\u4f4d\u524d\u77bb\u7684\u6df7\u5408\u7ec4\u5408\uff08\u53c2\u89c1\u7b2c 7.5 \u8282\uff09\u3002</p> <p>To understand the similarities between carry-select and carry-lookahead adders, consider a design similar to Fig. 7.9 in which only carry signals, rather than the final sum bits, are of interest. Clearly, once all carries are known, the sum bits can be generated rapidly by means of  k  XOR gates. Thus, the upper half of the new circuit derived from Fig. 7.9 will be responsible for generating two versions of the carries, rather than two versions of the sum bits. The carry  ci+1 into position  i + 1 (i \u2265  k/ 2 )  is  g[ k/ 2,  i] when  ck/ 2 = 0, and it is  t[ k/ 2,  i] when  ck/ 2 = 1. Recall that  t[ k/ 2,  i] =  g[ k/ 2,  i] \u2228  p[ k/ 2,  i]. Thus, the pair of adders spanning positions  k/ 2 through  k \u2212 1 in Fig. 7.9 become a parallel prefix carry network that uses the signal pair  (g,  t)  instead of the usual  (g,  p). The entire structure of the modified design based on producing carries rather than sum bits is thus quite similar to the Ladner-Fischer carry network of Fig. 6.7. It even suffers from the same drawback of large fan-out for  ck/ 2, which is used as the selection signal for  k/ 2 + 1 two-way multiplexers. </p> <p>\u4e3a\u4e86\u7406\u89e3\u8fdb\u4f4d\u9009\u62e9\u52a0\u6cd5\u5668\u548c\u8fdb\u4f4d\u8d85\u524d\u52a0\u6cd5\u5668\u4e4b\u95f4\u7684\u76f8\u4f3c\u4e4b\u5904\uff0c\u8bf7\u8003\u8651\u7c7b\u4f3c\u4e8e\u56fe 7.9 \u7684\u8bbe\u8ba1\uff0c\u5176\u4e2d\u4ec5\u5bf9\u8fdb\u4f4d\u4fe1\u53f7\u800c\u4e0d\u662f\u6700\u7ec8\u7684\u548c\u4f4d\u611f\u5174\u8da3\u3002\u663e\u7136\uff0c\u4e00\u65e6\u77e5\u9053\u4e86\u6240\u6709\u8fdb\u4f4d\uff0c\u5c31\u53ef\u4ee5\u901a\u8fc7 k \u4e2a\u5f02\u6216\u95e8\u5feb\u901f\u751f\u6210\u548c\u4f4d\u3002\u56e0\u6b64\uff0c\u4ece\u56fe 7.9 \u5bfc\u51fa\u7684\u65b0\u7535\u8def\u7684\u4e0a\u534a\u90e8\u5206\u5c06\u8d1f\u8d23\u751f\u6210\u4e24\u4e2a\u7248\u672c\u7684\u8fdb\u4f4d\uff0c\u800c\u4e0d\u662f\u4e24\u4e2a\u7248\u672c\u7684\u548c\u4f4d\u3002\u5f53\\(c_{k/2} = 0\\)\uff0c\u8fdb\u4f4d \\(c_{i+1}\\) \u5230\u4f4d\u7f6e \\(i + 1 (i \u2265 k/ 2)\\) \u662f \\(g[ k/ 2, i]\\)\uff0c\u5f53 \\(c_{k/2} = 1\\) \u65f6\u4e3a \\(t[k/2, i]\\)\u3002\u56de\u60f3\u4e00\u4e0b \\(t[ k/ 2, i] = g[ k/ 2, i] \u2228 p[ k/ 2, i]\\)\u3002\u56e0\u6b64\uff0c\u56fe 7.9 \u4e2d\u8de8\u8d8a\u4f4d\u7f6e \\(k/2\\) \u5230 \\(k-1\\) \u7684\u4e00\u5bf9\u52a0\u6cd5\u5668\u6210\u4e3a\u5e76\u884c\u524d\u7f00\u8fdb\u4f4d\u7f51\u7edc\uff0c\u5b83\u4f7f\u7528\u4fe1\u53f7\u5bf9 \\((g, t)\\) \u800c\u4e0d\u662f\u901a\u5e38\u7684 \\((g, p)\\)\u3002\u56e0\u6b64\uff0c\u57fa\u4e8e\u4ea7\u751f\u8fdb\u4f4d\u800c\u4e0d\u662f\u548c\u4f4d\u7684\u4fee\u6539\u8bbe\u8ba1\u7684\u6574\u4e2a\u7ed3\u6784\u4e0e\u56fe 6.7 \u7684 Ladner-Fischer \u8fdb\u4f4d\u7f51\u7edc\u975e\u5e38\u76f8\u4f3c\u3002\u5b83\u751a\u81f3\u906d\u53d7\u540c\u6837\u7684\u7f3a\u70b9\uff0c\u5373 \\(c_{k/2}\\) \u7684\u5927\u6247\u51fa\uff0c\u7528\u4f5c \\(k/2 + 1\\) \u53cc\u5411\u591a\u8def\u590d\u7528\u5668\u7684\u9009\u62e9\u4fe1\u53f7\u3002</p>"},{"location":"Part_02/07/#74","title":"7.4 \u6761\u4ef6\u548c\u52a0\u6cd5\u5668","text":"<p>The process that led to the two-level carry-select adder of Fig. 7.10 can be continued to derive a three-level k-bit adder built of k/8-bit adders, a four-level adder composed of k/16-bit adders, and so on. A logarithmic time conditional-sum adder results if we proceed to the extreme of having 1-bit adders at the very top. Thus, taking the cost and delay of a 1-bit 2-to-1 multiplexer as our units, the cost and delay of a conditional-sum adder are characterized by the following recurrences:</p> <p>\u4ea7\u751f\u56fe7.10\u7684\u4e24\u7ea7\u8fdb\u4f4d\u9009\u62e9\u52a0\u6cd5\u5668\u7684\u8fc7\u7a0b\u53ef\u4ee5\u7ee7\u7eed\u63a8\u5bfc\u51fa\u7531\\(k/8\\)\u4f4d\u52a0\u6cd5\u5668\u6784\u6210\u7684\u4e09\u7ea7k\u4f4d\u52a0\u6cd5\u5668\u3001\u7531\\(k/16\\)\u4f4d\u52a0\u6cd5\u5668\u7ec4\u6210\u7684\u56db\u7ea7\u52a0\u6cd5\u5668\u7b49\u7b49\u3002\u5982\u679c\u6211\u4eec\u7ee7\u7eed\u5728\u6700\u9876\u90e8\u4f7f\u7528 1 \u4f4d\u52a0\u6cd5\u5668\uff0c\u5219\u4f1a\u4ea7\u751f\u5bf9\u6570\u65f6\u95f4\u6761\u4ef6\u548c\u52a0\u6cd5\u5668\u3002\u56e0\u6b64\uff0c\u4ee5 1 \u4f4d 2\u6bd41\u591a\u8def\u590d\u7528\u5668\u7684\u6210\u672c\u548c\u5ef6\u8fdf\u4e3a\u5355\u4f4d\uff0c\u6761\u4ef6\u548c\u52a0\u6cd5\u5668\u7684\u6210\u672c\u548c\u5ef6\u8fdf\u7531\u4ee5\u4e0b\u9012\u5f52\u5f0f\u8868\u5f81\uff1a</p> \\[ \\begin{array}{l} C(k) \\approx 2 C(k/2) + k + 2 \\approx k( \\log_2 k + 2 ) + kC( 1 ) \\\\ T(k) = T(k/2) + 1 = \\log_2 k + T(1) \\end{array} \\] <p>where C(1) and T (1) are the cost and delay of the circuit of Fig. 7.11 used at the top to derive the sum and carry bits with a carry-in of 0 and 1. The term k + 2 in the first recurrence represents an upper bound on the number of single-bit 2-to-1 multiplexers needed for combining two k/2-bit adders into a k-bit adder.</p> <p>\u5176\u4e2d \\(C(1)\\) \u548c \\(T (1)\\) \u662f\u56fe 7.11 \u9876\u90e8\u7535\u8def\u7684\u6210\u672c\u548c\u5ef6\u8fdf\uff0c\u7528\u4e8e\u5bfc\u51fa\u8fdb\u4f4d\u8f93\u5165\u4e3a 0 \u548c 1 \u7684\u548c\u548c\u8fdb\u4f4d\u4f4d\u3002\u7b2c\u4e00\u4e2a\u9012\u5f52\u4e2d\u7684 2 \u8868\u793a\u5c06\u4e24\u4e2a \\(k/2\\) \u4f4d\u52a0\u6cd5\u5668\u7ec4\u5408\u6210 \\(k\\) \u4f4d\u52a0\u6cd5\u5668\u6240\u9700\u7684\u5355\u4f4d2\u52301\u591a\u8def\u590d\u7528\u5668\u7684\u6570\u91cf\u4e0a\u9650\u3002</p> <p></p> <p>The recurrence for cost is approximate, since for simplicity, we have ignored the fact that the right half of Fig. 7.10 is less complex than its left half. In other words, we have assumed that two parallel ( b + 1)-bit multiplexers are needed to combine the outputs from b-bit adders, although in some cases, one is enough.</p> <p>\u6210\u672c\u7684\u9012\u63a8\u662f\u8fd1\u4f3c\u7684\uff0c\u56e0\u4e3a\u4e3a\u4e86\u7b80\u5355\u8d77\u89c1\uff0c\u6211\u4eec\u5ffd\u7565\u4e86\u56fe 7.10 \u7684\u53f3\u534a\u90e8\u5206\u6bd4\u5de6\u534a\u90e8\u5206\u590d\u6742\u7684\u4e8b\u5b9e\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u6211\u4eec\u5047\u8bbe\u9700\u8981\u4e24\u4e2a\u5e76\u884c (b + 1) \u4f4d\u591a\u8def\u590d\u7528\u5668\u6765\u7ec4\u5408 b \u4f4d\u52a0\u6cd5\u5668\u7684\u8f93\u51fa\uff0c\u5c3d\u7ba1\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u4e00\u4e2a\u5c31\u8db3\u591f\u4e86\u3002</p> <p>An exact analysis leads to a comparable count for the number of 1-bit multiplexers needed in a conditional-sum adder. Assuming that k is a power of 2, the required number of multiplexers for a k-bit adder is</p> <p>\u7cbe\u786e\u5206\u6790\u5f97\u51fa\u6761\u4ef6\u548c\u52a0\u6cd5\u5668\u4e2d\u6240\u9700\u7684 1 \u4f4d\u591a\u8def\u590d\u7528\u5668\u6570\u91cf\u7684\u53ef\u6bd4\u8ba1\u6570\u3002\u5047\u8bbek\u662f2\u7684\u5e42\uff0c\u5219k \u4f4d\u52a0\u6cd5\u5668\u7684\u591a\u8def\u590d\u7528\u5668\u7684\u6240\u9700\u6570\u91cf\u4e3a</p> <p>\\((k/2 + 1) + 3(k/4 + 1) + 7(k/8 + 1) + \u00b7 \u00b7 \u00b7 + (k \u2212 1)2 = (k \u2212 1)(\\log_2 k + 1)\\)</p> <p>leading to an overall cost of \\((k \u2212 1)(\\log_2 k + 1 ) + kC(1)\\).</p> <p>\u5bfc\u81f4\u603b\u6210\u672c\u4e3a \\((k \u2212 1)(\\log_2 k + 1 ) + kC(1)\\)\u3002</p> <p>The conditional-sum algorithm can be visualized by the 16-bit addition example shown in Table 7.2.</p> <p>\u6761\u4ef6\u548c\u7684\u7b97\u6cd5\u53ef\u4ee5\u901a\u8fc7 16 \u4f4d\u52a0\u6cd5\u793a\u4f8b\u6765\u53ef\u89c6\u5316\uff0c\u5982\u8868 7.2 \u6240\u793a\u3002</p> <p></p> <p>\u8868 7.2 \u4e24\u4e2a 16 \u4f4d\u6570\u5b57\u7684\u6761\u4ef6\u548c\u52a0\u6cd5\uff1a\u5df2\u77e5\u548c\u548c\u8fdb\u4f4d\u4f4d\u7684\u5757\u7684\u5bbd\u5ea6\u968f\u7740\u6bcf\u4e2a\u9644\u52a0\u7ea7\u522b\u800c\u52a0\u500d\uff0c\u5bfc\u81f4\u52a0\u6cd5\u65f6\u95f4\u968f\u7740\u5b57\u5bbd k \u7684\u5bf9\u6570\u800c\u589e\u957f</p> <p>Given that a conditional-sum adder is actually a (log2 k)-level carry-select adder, the comparisons and trade-offs between carry-select adders and carry-lookahead adders, as discussed at the end of Section 7.3, are relevant here as well.</p> <p>\u9274\u4e8e\u6761\u4ef6\u548c\u52a0\u6cd5\u5668\u5b9e\u9645\u4e0a\u662f (\\(\\log_2 k\\)) \u7ea7\u8fdb\u4f4d\u9009\u62e9\u52a0\u6cd5\u5668\uff0c\u8fdb\u4f4d\u9009\u62e9\u52a0\u6cd5\u5668\u548c\u8fdb\u4f4d\u8d85\u524d\u52a0\u6cd5\u5668\u4e4b\u95f4\u7684\u6bd4\u8f83\u548c\u6743\u8861\uff08\u5982\u7b2c 7.3 \u8282\u672b\u5c3e\u6240\u8ba8\u8bba\u7684\uff09\u4e5f\u4e0e\u6b64\u76f8\u5173\u3002</p>"},{"location":"Part_02/07/#75","title":"7.5 \u6df7\u5408\u8bbe\u8ba1\u4e0e\u4f18\u5316","text":"<p>Hybrid adders are obtained by combining elements of two or more \u201cpure\u201d design methods to obtain adders with higher performance, greater cost-effectiveness, lower power consumption, and so on. Since any two or more pure design methods can be combined in a variety of ways, the space of possible designs for hybrid adders is immense. This leads to a great deal of flexibility in matching the design to given requirements and constraints. It also makes the designer\u2019s search for an optimal design nontrivial. In this section, we review several possible hybrid adders as representative examples.</p> <p>\u6df7\u5408\u52a0\u6cd5\u5668\u662f\u901a\u8fc7\u5c06\u4e24\u79cd\u6216\u591a\u79cd\u201c\u7eaf\u201d\u8bbe\u8ba1\u65b9\u6cd5\u7684\u5143\u7d20\u7ed3\u5408\u8d77\u6765\u83b7\u5f97\u7684\uff0c\u4ee5\u83b7\u5f97\u5177\u6709\u66f4\u9ad8\u6027\u80fd\u3001\u66f4\u5927\u6210\u672c\u6548\u76ca\u3001\u66f4\u4f4e\u529f\u8017\u7b49\u7684\u52a0\u6cd5\u5668\u3002\u7531\u4e8e\u4efb\u4f55\u4e24\u79cd\u6216\u591a\u79cd\u7eaf\u8bbe\u8ba1\u65b9\u6cd5\u90fd\u53ef\u4ee5\u4ee5\u591a\u79cd\u65b9\u5f0f\u7ec4\u5408\uff0c\u56e0\u6b64\u6df7\u5408\u52a0\u6cd5\u5668\u7684\u53ef\u80fd\u8bbe\u8ba1\u7a7a\u95f4\u662f\u5de8\u5927\u7684\u3002\u8fd9\u4f7f\u5f97\u8bbe\u8ba1\u4e0e\u7ed9\u5b9a\u8981\u6c42\u548c\u7ea6\u675f\u7684\u5339\u914d\u5177\u6709\u5f88\u5927\u7684\u7075\u6d3b\u6027\u3002\u8fd9\u4e5f\u4f7f\u5f97\u8bbe\u8ba1\u5e08\u5bf9\u6700\u4f73\u8bbe\u8ba1\u7684\u5bfb\u627e\u53d8\u5f97\u975e\u5e38\u91cd\u8981\u3002\u5728\u672c\u8282\u4e2d\uff0c\u6211\u4eec\u5c06\u56de\u987e\u51e0\u79cd\u53ef\u80fd\u7684\u6df7\u5408\u52a0\u6cd5\u5668\u4f5c\u4e3a\u4ee3\u8868\u6027\u793a\u4f8b\u3002</p> <p>The one- and two-level carry-select adders of Figs. 7.9 and 7.10 are essentially hybrid adders, since the top-level k/2- or k/4-bit adders can be of any type. In fact, a common use for the carry-select scheme is in building fast adders whose width would lead to inefficient implementations with certain pure designs. For example, when 4-bit lookahead carry blocks are used, both 16-bit and 64-bit carry-lookahead adders can be synthesized quite efficiently (Fig. 6.4). A 32-bit adder, on the other hand, would require two levels of lookahead and is thus not any faster than the 64-bit adder. Using 16-bit carry-lookahead adders, plus a single carry-select level to double the width, is likely to lead to a faster 32-bit adder. The resulting adder has a hybrid carry-select/carry-lookahead design.</p> <p>\u56fe7.9 \u548c 7.10 \u7684\u4e00\u7ea7\u548c\u4e8c\u7ea7\u8fdb\u4f4d\u9009\u62e9\u52a0\u6cd5\u5668\u672c\u8d28\u4e0a\u662f\u6df7\u5408\u52a0\u6cd5\u5668\uff0c\u56e0\u4e3a\u9876\u7ea7 k/2 \u4f4d\u6216 k/4 \u4f4d\u52a0\u6cd5\u5668\u53ef\u4ee5\u662f\u4efb\u4f55\u7c7b\u578b\u3002\u4e8b\u5b9e\u4e0a\uff0c\u8fdb\u4f4d\u9009\u62e9\u65b9\u6848\u7684\u4e00\u4e2a\u5e38\u89c1\u7528\u9014\u662f\u6784\u5efa\u5feb\u901f\u52a0\u6cd5\u5668\uff0c\u5176\u5bbd\u5ea6\u4f1a\u5bfc\u81f4\u67d0\u4e9b\u7eaf\u8bbe\u8ba1\u7684\u4f4e\u6548\u5b9e\u73b0\u3002\u4f8b\u5982\uff0c\u5f53\u4f7f\u7528 4 \u4f4d\u5148\u884c\u8fdb\u4f4d\u5757\u65f6\uff0c\u53ef\u4ee5\u975e\u5e38\u9ad8\u6548\u5730\u5408\u6210 16 \u4f4d\u548c 64 \u4f4d\u5148\u884c\u8fdb\u4f4d\u52a0\u6cd5\u5668\uff08\u56fe 6.4\uff09\u3002\u53e6\u4e00\u65b9\u9762\uff0c32 \u4f4d\u52a0\u6cd5\u5668\u9700\u8981\u4e24\u7ea7\u8d85\u524d\uff0c\u56e0\u6b64\u5e76\u4e0d\u6bd4 64 \u4f4d\u52a0\u6cd5\u5668\u5feb\u3002\u4f7f\u7528 16 \u4f4d\u8d85\u524d\u8fdb\u4f4d\u52a0\u6cd5\u5668\uff0c\u518d\u52a0\u4e0a\u5355\u4e2a\u8fdb\u4f4d\u9009\u62e9\u7ea7\u522b\u4ee5\u52a0\u500d\u5bbd\u5ea6\uff0c\u53ef\u80fd\u4f1a\u4ea7\u751f\u66f4\u5feb\u7684 32 \u4f4d\u52a0\u6cd5\u5668\u3002\u7531\u6b64\u4ea7\u751f\u7684\u52a0\u6cd5\u5668\u5177\u6709\u6df7\u5408\u8fdb\u4f4d\u9009\u62e9/\u8fdb\u4f4d\u8d85\u524d\u8bbe\u8ba1\u3002</p> <p>The reverse combination (viz., hybrid carry-lookahead/carry-select) is also possible and is in fact used quite widely. An example hybrid carry-lookahead/carry-select adder is depicted in Fig. 7.12. The small adder blocks, shown in pairs, may be based on Manchester carry chains that supply the required g and p signals to the lookahead carry generator and compute the final intermediate carries as well as the sum bits once the block carry-in signals have become known.</p> <p>\u76f8\u53cd\u7684\u7ec4\u5408\uff08\u5373\u6df7\u5408\u8fdb\u4f4d\u8d85\u524d/\u8fdb\u4f4d\u9009\u62e9\uff09\u4e5f\u662f\u53ef\u80fd\u7684\uff0c\u5e76\u4e14\u5b9e\u9645\u4e0a\u4f7f\u7528\u5f97\u76f8\u5f53\u5e7f\u6cdb\u3002\u56fe 7.12 \u63cf\u8ff0\u4e86\u6df7\u5408\u8fdb\u4f4d\u8d85\u524d/\u8fdb\u4f4d\u9009\u62e9\u52a0\u6cd5\u5668\u7684\u793a\u4f8b\u3002\u6210\u5bf9\u663e\u793a\u7684\u5c0f\u52a0\u6cd5\u5668\u5757\u53ef\u4ee5\u57fa\u4e8e\u66fc\u5f7b\u65af\u7279\u8fdb\u4f4d\u94fe\uff0c\u5176\u5411\u5148\u884c\u8fdb\u4f4d\u751f\u6210\u5668\u63d0\u4f9b\u6240\u9700\u7684g\u548cp\u4fe1\u53f7\uff0c\u5e76\u5728\u5757\u8fdb\u4f4d\u4fe1\u53f7\u5df2\u77e5\u540e\u8ba1\u7b97\u6700\u7ec8\u7684\u4e2d\u95f4\u8fdb\u4f4d\u4ee5\u53ca\u548c\u4f4d\u3002</p> <p></p> <p>A wider hybrid carry-lookahead/carry-select adder will likely have a multilevel carry-lookahead network rather than a single lookahead carry generator as depicted in Fig. 7.12. If the needed block g and p signals are produced quickly, the propagation of signals in the carry-lookahead network can be completely overlapped with carry propagation in the small carry-select adders. The carry-lookahead network of Fig. 6.13 was in fact developed for use in such a hybrid scheme, with 8-bit carry-select adders based on Manchester carry chains [Lync92]. The 8-bit adders complete their computation at about the same time that the carries  c 24,  c 32,  c 40,  c 48, and  c 56 become available (Fig. 6.13). Thus, the total adder delay is only two logic levels more than that of the carry-lookahead network. </p> <p>\u66f4\u5bbd\u7684\u6df7\u5408\u5148\u884c\u8fdb\u4f4d/\u8fdb\u4f4d\u9009\u62e9\u52a0\u6cd5\u5668\u53ef\u80fd\u5177\u6709\u591a\u7ea7\u5148\u884c\u8fdb\u4f4d\u7f51\u7edc\uff0c\u800c\u4e0d\u662f\u5982\u56fe 7.12 \u6240\u793a\u7684\u5355\u4e2a\u5148\u884c\u8fdb\u4f4d\u751f\u6210\u5668\u3002\u5982\u679c\u5feb\u901f\u4ea7\u751f\u6240\u9700\u7684\u5757g\u548cp\u4fe1\u53f7\uff0c\u5219\u8fdb\u4f4d\u8d85\u524d\u7f51\u7edc\u4e2d\u7684\u4fe1\u53f7\u4f20\u64ad\u53ef\u4ee5\u4e0e\u5c0f\u578b\u8fdb\u4f4d\u9009\u62e9\u52a0\u6cd5\u5668\u4e2d\u7684\u8fdb\u4f4d\u4f20\u64ad\u5b8c\u5168\u91cd\u53e0\u3002\u56fe 6.13 \u7684\u8d85\u524d\u8fdb\u4f4d\u7f51\u7edc\u5b9e\u9645\u4e0a\u662f\u4e3a\u8fd9\u79cd\u6df7\u5408\u65b9\u6848\u800c\u5f00\u53d1\u7684\uff0c\u5177\u6709\u57fa\u4e8e\u66fc\u5f7b\u65af\u7279\u8fdb\u4f4d\u94fe\u7684 8 \u4f4d\u8fdb\u4f4d\u9009\u62e9\u52a0\u6cd5\u5668 [Lync92]\u3002 8 \u4f4d\u52a0\u6cd5\u5668\u5927\u7ea6\u5728\u8fdb\u4f4d \\(c_{24}\u3001c_{32}\u3001c_{40}\u3001c_{48}\\) \u548c \\(c_{56}\\) \u53d8\u5f97\u53ef\u7528\u540c\u65f6\u5b8c\u6210\u8ba1\u7b97\uff08\u56fe 6.13\uff09\u3002\u56e0\u6b64\uff0c\u603b\u52a0\u6cd5\u5668\u5ef6\u8fdf\u4ec5\u6bd4\u8d85\u524d\u8fdb\u4f4d\u7f51\u7edc\u7684\u5ef6\u8fdf\u591a\u4e24\u4e2a\u903b\u8f91\u6df1\u5ea6\u3002</p> <p>Another interesting hybrid design is the ripple-carry/carry-lookahead adder, an example of which is depicted in Fig. 7.13. This hybrid design is somewhat slower than a pure carry-lookahead scheme, but its simplicity and greater modularity may compensate for this drawback. The analysis of cost and delay for this hybrid design relative to pure ripple-carry and carry-lookahead adders is left as an exercise, as is the development and analysis of the reverse carry-lookahead/ripple-carry hybrid combination. </p> <p>\u53e6\u4e00\u4e2a\u6709\u8da3\u7684\u6df7\u5408\u8bbe\u8ba1\u662f\u7eb9\u6ce2\u8fdb\u4f4d/\u8d85\u524d\u8fdb\u4f4d\u52a0\u6cd5\u5668\uff0c\u5176\u793a\u4f8b\u5982\u56fe 7.13 \u6240\u793a\u3002\u8fd9\u79cd\u6df7\u5408\u8bbe\u8ba1\u6bd4\u7eaf\u7cb9\u7684\u8d85\u524d\u8fdb\u4f4d\u65b9\u6848\u8981\u6162\u4e00\u4e9b\uff0c\u4f46\u5176\u7b80\u5355\u6027\u548c\u66f4\u9ad8\u7684\u6a21\u5757\u5316\u6027\u53ef\u4ee5\u5f25\u8865\u8fd9\u4e00\u7f3a\u70b9\u3002\u8fd9\u79cd\u6df7\u5408\u8bbe\u8ba1\u76f8\u5bf9\u4e8e\u7eaf\u7eb9\u6ce2\u8fdb\u4f4d\u548c\u5148\u884c\u8fdb\u4f4d\u52a0\u6cd5\u5668\u7684\u6210\u672c\u548c\u5ef6\u8fdf\u7684\u5206\u6790\u7559\u4f5c\u7ec3\u4e60\uff0c\u53cd\u5411\u8fdb\u4f4d\u5148\u884c/\u7eb9\u6ce2\u8fdb\u4f4d\u6df7\u5408\u7ec4\u5408\u7684\u5f00\u53d1\u548c\u5206\u6790\u4e5f\u662f\u5982\u6b64\u3002</p> <p></p> <p>Another hybrid adder example uses the hybrid carry-lookahead/conditional-sum combination. One drawback of the conditional-sum adder for wide words is the requirement of large fan-out for the signals controlling the multiplexers at the lower levels (Fig. 7.10). This problem can be alleviated by, for example, using conditional-sum addition in smaller blocks, forming the interblock carries through carry-lookahead. For detailed description of one such adder, used in Manchester University\u2019s MU5 computer, see [Omon94, pp. 104\u2013111]. </p> <p>\u53e6\u4e00\u4e2a\u6df7\u5408\u52a0\u6cd5\u5668\u793a\u4f8b\u4f7f\u7528\u6df7\u5408\u8fdb\u4f4d\u524d\u77bb/\u6761\u4ef6\u548c\u7684\u7ec4\u5408\u3002\u5bbd\u5b57\u6761\u4ef6\u548c\u52a0\u6cd5\u5668\u7684\u4e00\u4e2a\u7f3a\u70b9\u662f\u63a7\u5236\u8f83\u4f4e\u5c42\u591a\u8def\u590d\u7528\u5668\u7684\u4fe1\u53f7\u9700\u8981\u5927\u6247\u51fa\uff08\u56fe 7.10\uff09\u3002\u8fd9\u4e2a\u95ee\u9898\u53ef\u4ee5\u901a\u8fc7\u4f8b\u5982\u5728\u8f83\u5c0f\u7684\u5757\u4e2d\u4f7f\u7528\u6761\u4ef6\u548c\u52a0\u6cd5\u6765\u7f13\u89e3\uff0c\u901a\u8fc7\u8d85\u524d\u8fdb\u4f4d\u5f62\u6210\u5757\u95f4\u8fdb\u4f4d\u3002\u6709\u5173\u66fc\u5f7b\u65af\u7279\u5927\u5b66 MU5 \u8ba1\u7b97\u673a\u4e2d\u4f7f\u7528\u7684\u6b64\u7c7b\u52a0\u6cd5\u5668\u7684\u8be6\u7ec6\u8bf4\u660e\uff0c\u8bf7\u53c2\u9605 [Omon94\uff0c\u7b2c 104\u2013111 \u9875]\u3002</p> <p>A hybrid adder may use more than two different schemes. For example, the 64-bit adder in the Compaq/DEC Alpha 21064 microprocessor is designed using four different methods [Dobb92]. At the lowest level, 8-bit Manchester carry chains are employed.  The lower 32-bits of the sum are derived via carry lookahead at the second level, while conditional-sum addition is used to obtain two versions of the upper 32 bits. Carry-select is used to pick the correct version of the sum\u2019s upper 32 bits. </p> <p>\u6df7\u5408\u52a0\u6cd5\u5668\u53ef\u4ee5\u4f7f\u7528\u4e24\u79cd\u4ee5\u4e0a\u4e0d\u540c\u7684\u65b9\u6848\u3002\u4f8b\u5982\uff0cCompaq/DEC Alpha 21064 \u5fae\u5904\u7406\u5668\u4e2d\u7684 64 \u4f4d\u52a0\u6cd5\u5668\u662f\u4f7f\u7528\u56db\u79cd\u4e0d\u540c\u7684\u65b9\u6cd5\u8bbe\u8ba1\u7684 [Dobb92]\u3002\u5728\u6700\u4f4e\u5c42\uff0c\u91c7\u7528 8 \u4f4d\u66fc\u5f7b\u65af\u7279\u8fdb\u4f4d\u94fe\u3002\u603b\u548c\u7684\u4f4e 32 \u4f4d\u662f\u901a\u8fc7\u7b2c\u4e8c\u7ea7\u7684\u8d85\u524d\u8fdb\u4f4d\u5bfc\u51fa\u7684\uff0c\u800c\u6761\u4ef6\u548c\u52a0\u6cd5\u7528\u4e8e\u83b7\u5f97\u9ad8 32 \u4f4d\u7684\u4e24\u4e2a\u7248\u672c\u3002\u8fdb\u4f4d\u9009\u62e9\u7528\u4e8e\u9009\u62e9\u548c\u7684\u9ad8 32 \u4f4d\u7684\u6b63\u786e\u7248\u672c\u3002</p> <p>Clearly, it is possible to combine ideas from various designs in many different ways, giving rise to a steady stream of new implementations and theoretical proposals for the design of fast adders. Different combinations become attractive with particular technologies in view of their specific cost factors and fundamental constraints [Kant93]. In addition, application requirements, such as low power consumption, may shift the balance in favor of a particular hybrid design. </p> <p>\u663e\u7136\uff0c\u53ef\u4ee5\u4ee5\u591a\u79cd\u4e0d\u540c\u7684\u65b9\u5f0f\u7ed3\u5408\u5404\u79cd\u8bbe\u8ba1\u7684\u601d\u60f3\uff0c\u4ece\u800c\u4e3a\u5feb\u901f\u52a0\u6cd5\u5668\u7684\u8bbe\u8ba1\u5e26\u6765\u6e90\u6e90\u4e0d\u65ad\u7684\u65b0\u5b9e\u73b0\u548c\u7406\u8bba\u5efa\u8bae\u3002\u9274\u4e8e\u7279\u5b9a\u6280\u672f\u7684\u7279\u5b9a\u6210\u672c\u56e0\u7d20\u548c\u57fa\u672c\u9650\u5236\uff0c\u4e0d\u540c\u7684\u7ec4\u5408\u53d8\u5f97\u6709\u5438\u5f15\u529b[Kant93]\u3002\u6b64\u5916\uff0c\u8bf8\u5982\u4f4e\u529f\u8017\u4e4b\u7c7b\u7684\u5e94\u7528\u8981\u6c42\u53ef\u80fd\u4f1a\u6539\u53d8\u5e73\u8861\uff0c\u6709\u5229\u4e8e\u7279\u5b9a\u7684\u6df7\u5408\u8bbe\u8ba1\u3002</p> <p>Just as optimal carry-skip adders have variable block widths, it is often possible to reduce the delay of other (pure or hybrid) adders by optimizing the block widths. For example, depending on the implementation technology, a carry-lookahead adder with fixed blocks may not yield the lowest possible delay [Niga95]. Again, the exact optimal configuration is highly technology-dependent. In fact, with modern very large-scale integration technology, gate count alone is no longer a meaningful measure of implementation cost. Designs that minimize or regularize the interconnection may actually be more cost-effective despite using more gates. The ultimate test of cost-effectiveness for a particular hybrid design or \u201coptimal\u201d configuration is its actual speed and cost when implemented with the target technology.</p> <p>\u6b63\u5982\u6700\u4f73\u8df3\u8fdb\u4f4d\u52a0\u6cd5\u5668\u5177\u6709\u53ef\u53d8\u7684\u5757\u5bbd\u5ea6\u4e00\u6837\uff0c\u901a\u5e38\u53ef\u4ee5\u901a\u8fc7\u4f18\u5316\u5757\u5bbd\u5ea6\u6765\u51cf\u5c11\u5176\u4ed6\uff08\u7eaf\u6216\u6df7\u5408\uff09\u52a0\u6cd5\u5668\u7684\u5ef6\u8fdf\u3002\u4f8b\u5982\uff0c\u6839\u636e\u5b9e\u73b0\u6280\u672f\u7684\u4e0d\u540c\uff0c\u5177\u6709\u56fa\u5b9a\u5757\u7684\u8d85\u524d\u8fdb\u4f4d\u52a0\u6cd5\u5668\u53ef\u80fd\u4e0d\u4f1a\u4ea7\u751f\u5c3d\u53ef\u80fd\u4f4e\u7684\u5ef6\u8fdf[Niga95]\u3002\u540c\u6837\uff0c\u786e\u5207\u7684\u6700\u4f73\u914d\u7f6e\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u6280\u672f\u3002\u4e8b\u5b9e\u4e0a\uff0c\u5229\u7528\u73b0\u4ee3\u8d85\u5927\u89c4\u6a21\u96c6\u6210\u6280\u672f\uff0c\u4ec5\u95e8\u6570\u4e0d\u518d\u662f\u8861\u91cf\u5b9e\u65bd\u6210\u672c\u7684\u6709\u610f\u4e49\u7684\u6307\u6807\u3002\u6700\u5c0f\u5316\u6216\u4f7f\u5f97\u4e92\u8fde\u66f4\u89c4\u8303\u7684\u8bbe\u8ba1\u5c3d\u7ba1\u4f7f\u7528\u66f4\u591a\u7684\u95e8\uff0c\u4f46\u5b9e\u9645\u4e0a\u53ef\u80fd\u66f4\u5177\u6210\u672c\u6548\u76ca\u3002\u5bf9\u7279\u5b9a\u6df7\u5408\u8bbe\u8ba1\u6216\u201c\u6700\u4f73\u201d\u914d\u7f6e\u7684\u6210\u672c\u6548\u76ca\u7684\u6700\u7ec8\u6d4b\u8bd5\u662f\u5176\u4f7f\u7528\u76ee\u6807\u6280\u672f\u5b9e\u65bd\u65f6\u7684\u5b9e\u9645\u901f\u5ea6\u548c\u6210\u672c\u3002</p> <p>So far our discussion of adder delay has been based on the tacit assumption that all input digits are available at the outset, or at time 0, and that all output digits are computed and taken out after worst-case carries have propagated. The other extreme, where input/output digits arrive and leave serially, leads to very simple digit-serial adder designs. In between the two extremes, there are practical situations in which different arrival times are associated with the input digits or certain output digits must be produced earlier than others.</p> <p>\u5230\u76ee\u524d\u4e3a\u6b62\uff0c\u6211\u4eec\u5bf9\u52a0\u6cd5\u5668\u5ef6\u8fdf\u7684\u8ba8\u8bba\u90fd\u662f\u57fa\u4e8e\u9ed8\u8ba4\u5047\u8bbe\uff0c\u5373\u6240\u6709\u8f93\u5165\u6570\u5b57\u5728\u4e00\u5f00\u59cb\u6216\u65f6\u95f4 0 \u65f6\u90fd\u53ef\u7528\uff0c\u5e76\u4e14\u6240\u6709\u8f93\u51fa\u6570\u5b57\u5728\u6700\u574f\u60c5\u51b5\u8fdb\u4f4d\u4f20\u64ad\u540e\u8ba1\u7b97\u5e76\u53d6\u51fa\u3002\u53e6\u4e00\u4e2a\u6781\u7aef\uff0c\u5373\u8f93\u5165/\u8f93\u51fa\u6570\u5b57\u4e32\u884c\u5230\u8fbe\u548c\u79bb\u5f00\uff0c\u5bfc\u81f4\u975e\u5e38\u7b80\u5355\u7684\u6570\u5b57\u4e32\u884c\u52a0\u6cd5\u5668\u8bbe\u8ba1\u3002\u5728\u8fd9\u4e24\u4e2a\u6781\u7aef\u4e4b\u95f4\uff0c\u5b58\u5728\u4e00\u4e9b\u5b9e\u9645\u60c5\u51b5\uff0c\u5176\u4e2d\u4e0d\u540c\u7684\u5230\u8fbe\u65f6\u95f4\u4e0e\u8f93\u5165\u6570\u5b57\u76f8\u5173\u8054\u6216\u8005\u67d0\u4e9b\u8f93\u51fa\u6570\u5b57\u5fc5\u987b\u6bd4\u5176\u4ed6\u6570\u5b57\u66f4\u65e9\u4ea7\u751f\u3002</p> <p>We will later see, for example, that in multiplying two binary numbers, the partial products are reduced to two binary numbers, which are then added in a fast two-operand adder to produce the final product. The individual bits of these two numbers become available at different times in view of the differing logic path depths from primary inputs. Figure 7.14 shows a typical example for the input arrival times at various bit positions of this final fast adder. This information can be used in optimizing the adder design [Oklo96]. A number of details and additional perspective can be found in [Liu03] and [Yeh00].</p> <p>\u4f8b\u5982\uff0c\u6211\u4eec\u7a0d\u540e\u4f1a\u770b\u5230\uff0c\u5728\u5c06\u4e24\u4e2a\u4e8c\u8fdb\u5236\u6570\u76f8\u4e58\u65f6\uff0c\u90e8\u5206\u79ef\u4f1a\u51cf\u5c11\u4e3a\u4e24\u4e2a\u4e8c\u8fdb\u5236\u6570\uff0c\u7136\u540e\u5c06\u5b83\u4eec\u5728\u5feb\u901f\u53cc\u64cd\u4f5c\u6570\u52a0\u6cd5\u5668\u4e2d\u76f8\u52a0\u4ee5\u4ea7\u751f\u6700\u7ec8\u7684\u4e58\u79ef\u3002\u9274\u4e8e\u6765\u81ea\u4e3b\u8f93\u5165\u7684\u4e0d\u540c\u903b\u8f91\u8def\u5f84\u6df1\u5ea6\uff0c\u8fd9\u4e24\u4e2a\u6570\u5b57\u7684\u5404\u4e2a\u4f4d\u5728\u4e0d\u540c\u65f6\u95f4\u53d8\u5f97\u53ef\u7528\u3002\u56fe 7.14 \u663e\u793a\u4e86\u6700\u7ec8\u5feb\u901f\u52a0\u6cd5\u5668\u5404\u4e2a\u4f4d\u4f4d\u7f6e\u7684\u8f93\u5165\u5230\u8fbe\u65f6\u95f4\u7684\u5178\u578b\u793a\u4f8b\u3002\u8be5\u4fe1\u606f\u53ef\u7528\u4e8e\u4f18\u5316\u52a0\u6cd5\u5668\u8bbe\u8ba1[Oklo96]\u3002\u8bb8\u591a\u7ec6\u8282\u548c\u989d\u5916\u7684\u89c2\u70b9\u53ef\u4ee5\u5728[Liu03]\u548c[Yeh00].</p> <p></p>"},{"location":"Part_02/07/#76","title":"7.6 \u4e8c\u64cd\u4f5c\u6570\u6a21\u52a0\u6cd5\u5668","text":"<p>In some applications, with redundant number system arithmetic and cryptographic algorithms being the most notable examples, the sum of input operands  x  and  y  must be computed modulo a given constant  m. In other words, we are interested in deriving (x +  y)  mod  m, rather than  x +  y. An obvious approach would be to perform the required computation in two stages: (1) forming  x +  y, using any of the adder designs described thus far, and (2) reducing  x +  y  modulo  m. Because the latency of the latter  modular reduction  step can be significant for an arbitrary value of  m, direct methods similar to the carry-select approach have been used to combine the two steps. </p> <p>\u5728\u4e00\u4e9b\u5e94\u7528\u4e2d\uff0c\u5197\u4f59\u6570\u5b57\u7cfb\u7edf\u7b97\u672f\u548c\u5bc6\u7801\u7b97\u6cd5\u662f\u6700\u503c\u5f97\u6ce8\u610f\u7684\u4f8b\u5b50\uff0c\u8f93\u5165\u64cd\u4f5c\u6570 x \u548c y \u7684\u603b\u548c\u5fc5\u987b\u4ee5\u7ed9\u5b9a\u5e38\u6570 m \u4e3a\u6a21\u8fdb\u884c\u8ba1\u7b97\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u6211\u4eec\u611f\u5174\u8da3\u7684\u662f\u5bfc\u51fa \\((x + y) \\mod m\\)\uff0c\u800c\u4e0d\u662f \\(x + y\\)\u3002\u4e00\u79cd\u660e\u663e\u7684\u65b9\u6cd5\u662f\u5206\u4e24\u4e2a\u9636\u6bb5\u6267\u884c\u6240\u9700\u7684\u8ba1\u7b97\uff1a</p> <p>(1) \u4f7f\u7528\u8fc4\u4eca\u4e3a\u6b62\u63cf\u8ff0\u7684\u4efb\u4f55\u52a0\u6cd5\u5668\u8bbe\u8ba1\u5f62\u6210 x + y\uff0c\u4ee5\u53ca </p> <p>(2) \u4ee5 m \u4e3a\u6a21\u51cf\u5c11 x + y\u3002\u7531\u4e8e\u540e\u4e00\u4e2a\u6a21\u6570\u5f52\u7ea6\u6b65\u9aa4\u7684\u5ef6\u8fdf\u5bf9\u4e8e m \u7684\u4efb\u610f\u503c\u90fd\u53ef\u80fd\u5f88\u5927\uff0c\u56e0\u6b64\u4f7f\u7528\u7c7b\u4f3c\u4e8e\u8fdb\u4f4d\u9009\u62e9\u65b9\u6cd5\u7684\u76f4\u63a5\u65b9\u6cd5\u6765\u7ec4\u5408\u8fd9\u4e24\u4e2a\u6b65\u9aa4\u3002</p> <p>Let us first focus on unsigned operands and certain special values of  m  that lead to simple modular addition. Clearly, when  m = 2 k , the modulo- m  sum is obtained by simply ignoring the carry-out. We also know that for  m = 2 k \u2212 1, using end-around carry allows us to reduce the sum modulo  m  by means of a conventional binary adder. A third special case pertains to  m = 2 k + 1. Here, we need  k + 1 bits to represent the 2 k + 1 different residues modulo  m. Because we can represent 2 k+1 distinct values with  k + 1 bits, different encodings of the 2 k + 1 residues are possible. An interesting encoding that has been found to be quite efficient is the diminished-1 encoding. With this encoding, 0 is represented by asserting a special flag bit and setting the remaining  k  bits to 0, while a nonzero value  x  is represented by de-asserting the flag bit and appending it with the representation of  x \u2212 1. </p> <p>\u8ba9\u6211\u4eec\u9996\u5148\u5173\u6ce8\u65e0\u7b26\u53f7\u64cd\u4f5c\u6570\u548c\u5bfc\u81f4\u7b80\u5355\u6a21\u52a0\u6cd5\u7684 m \u7684\u67d0\u4e9b\u7279\u6b8a\u503c\u3002\u663e\u7136\uff0c\u5f53 \\(m = 2^k\\) \u65f6\uff0c\u6a21 m \u548c\u662f\u901a\u8fc7\u7b80\u5355\u5730\u5ffd\u7565\u8fdb\u4f4d\u800c\u83b7\u5f97\u7684\u3002\u6211\u4eec\u8fd8\u77e5\u9053\uff0c\u5bf9\u4e8e \\(m = 2^k \u2212 1\\)\uff0c\u4f7f\u7528\u5c3e\u90e8\u8fdb\u4f4d\u5141\u8bb8\u6211\u4eec\u901a\u8fc7\u4f20\u7edf\u7684\u4e8c\u8fdb\u5236\u52a0\u6cd5\u5668\u6765\u51cf\u5c11\u6a21 m \u7684\u548c\u3002\u7b2c\u4e09\u79cd\u7279\u6b8a\u60c5\u51b5\u6d89\u53ca \\(m = 2^k + 1\\)\u3002\u8fd9\u91cc\uff0c\u6211\u4eec\u9700\u8981 \\(k + 1\\) \u4f4d\u6765\u8868\u793a \\(2^k + 1\\)\u6a21 m \u7684\u4e0d\u540c\u4f59\u6570\u3002\u56e0\u4e3a\u6211\u4eec\u53ef\u4ee5\u7528 \\(k + 1\\)\u4f4d\u8868\u793a \\(2^k+1\\) \u4e2a\u4e0d\u540c\u7684\u503c\uff0c\u53ef\u4ee5\u505a\u4e0d\u540c\\(2^k + 1\\) \u4e2a\u4f59\u6570\u7684\u7f16\u7801\u3002\u5df2\u4e00\u79cd\u975e\u5e38\u6709\u6548\u7684\u6709\u8da3\u7f16\u7801\u662f\u51cf 1 \u7f16\u7801\u3002\u901a\u8fc7\u8fd9\u79cd\u7f16\u7801\uff0c\u901a\u8fc7\u7f6e\u4f4d\u7279\u6b8a\u6807\u5fd7\u4f4d\u5e76\u5c06\u5269\u4f59 k \u4f4d\u8bbe\u7f6e\u4e3a 0 \u6765\u8868\u793a0\uff0c\u800c\u975e\u96f6\u503c x \u901a\u8fc7\u590d\u4f4d\u6807\u5fd7\u4f4d\u5e76\u7528 \\(x \u2212 1\\) \u7684\u5f62\u5f0f\u6765\u8868\u793a\u3002</p> <p>\u25a0 EXAMPLE 7.3 Design a modulo-17 adder for unsigned integer operands in the range [0, 16], represented in the diminished-1 format. </p> <p>Each of the input operands  x  and  y  consists of a 0-flag bit and a 4-bit binary magnitude that is one less than its true value, if nonzero. The design described in the following is based on the assumption that both operands are nonzero, as is their modulo-17 sum; that is, we assume  x = 0,  y = 0,  x +  y = 17. Augmenting the design to correctly handle these special cases is left as an exercise. The output should be  x +  y \u2212 1, the diminished-1 representation of  x +  y, if  x +  y \u2264 17, and it should be  x +  y \u2212 18, the diminished-1 representation of x + y \u221217, if  x + y \u2265 18. The desired results above can be rewritten as  (x \u22121 )+ (y \u22121 )+1 if (x\u22121 )+ (y\u22121 ) \u2264 15 and  (x\u22121 )+ (y\u22121 )\u221216 if  (x\u22121 )+ (y\u22121 ) \u2265 16. These observations suggest that adding  x \u2212 1 and  y \u2212 1 with an inverted end-around carry (carry-in set to the complement of carry-out) will produce the desired result in either case. The inverted end-around carry arrangement will add 1 to the sum of  x \u2212 1 and  y \u2212 1 when  c out = 0, that is, (x\u22121 )+ (y\u22121 ) \u2264 15, and will subtract 16 (by dropping the outgoing carry) when  c out = 1, corresponding to the condition  (x \u2212 1 ) +  (y \u2212 1 ) \u2265 16. </p> <p>\u25a0 \u793a\u4f8b7.3 \u4e3a\u8303\u56f4\u5185\u7684\u65e0\u7b26\u53f7\u6574\u6570\u64cd\u4f5c\u6570\u8bbe\u8ba1\u4e00\u4e2a\u6a2117 \u52a0\u6cd5\u5668[0, 16]\uff0c\u4ee5\u51cf 1 \u683c\u5f0f\u8868\u793a\u3002</p> <p>\u6bcf\u4e2a\u8f93\u5165\u64cd\u4f5c\u6570 x \u548c y \u5747\u5305\u542b\u4e00\u4e2a 0 \u6807\u5fd7\u4f4d\u548c\u4e00\u4e2a 4 \u4f4d\u4e8c\u8fdb\u5236\u91cf\u503c\uff08\u5982\u679c\u975e\u96f6\uff09\uff0c\u8be5\u4e8c\u8fdb\u5236\u91cf\u503c\u6bd4\u5176\u771f\u5b9e\u503c\u5c0f 1\u3002\u4e0b\u9762\u63cf\u8ff0\u7684\u8bbe\u8ba1\u57fa\u4e8e\u4e24\u4e2a\u64cd\u4f5c\u6570\u5747\u975e\u96f6\u7684\u5047\u8bbe\uff0c\u5b83\u4eec\u7684\u6a21 17 \u548c\u4e5f\u662f\u975e\u96f6\uff1b\u4e5f\u5c31\u662f\u8bf4\uff0c\u6211\u4eec\u5047\u8bbe \\(x \\ne 0\u3001y \\ne 0\u3001x + y \\ne 17\\)\u3002\u589e\u5f3a\u8bbe\u8ba1\u4ee5\u6b63\u786e\u5904\u7406\u8fd9\u4e9b\u7279\u6b8a\u60c5\u51b5\u7559\u4f5c\u8bfb\u8005\u7ec3\u4e60\u3002\u5982\u679c \\(x + y \\le 17\\)\uff0c\u8f93\u51fa\u5e94\u4e3a \\(x + y \u2212 1\\)\uff0c\u5373 \\(x + y\\) \u7684\u51cf 1 \u8868\u793a\uff1b\\(\u5982\u679c x + y \u2265 18\\)\uff0c\u8f93\u51fa\u5e94\u4e3a \\(x + y \u2212 18\\)\uff0c\u5373 \\(x + y \u221217\\) \u7684\u51cf 1 \u8868\u793a\u3002</p> <p>\u5982\u679c \\((x\u22121 )+ (y\u22121 ) \u2264 15\\) \uff0c\u5219\u4e0a\u8ff0\u6240\u9700\u7ed3\u679c\u53ef\u91cd\u5199\u4e3a \\((x \u22121 )+ (y \u22121 )+1\\)\u3002\u6216\\((x\u22121) + (y\u22121)\u221216\\) \u5982\u679c (x\u22121 )+ (y\u22121) \u2265 16\u3002\u8fd9\u4e9b\u89c2\u5bdf\u7ed3\u679c\u8868\u660e\uff0c\u5c06 \\(x \u2212 1\\) \u4e0e\\(y \u2212 1\\)\u548c\u518d\u52a0\u4e0a\u53cd\u8f6c\u7684\u672b\u7aef\u8fdb\u4f4d\uff08\u8fdb\u4f4d\u8f93\u5165\u8bbe\u7f6e\u4e3a\u8fdb\u4f4d\u8f93\u51fa\u7684\u8865\u7801\uff09\uff0c\u5728\u4efb\u4f55\u4e00\u79cd\u60c5\u51b5\u4e0b\u90fd\u4f1a\u4ea7\u751f\u6240\u9700\u7684\u7ed3\u679c\u3002\u5f53 \\(c_{out}\\) = 0 \u65f6\uff0c\u53cd\u8f6c\u7684\u5faa\u73af\u8fdb\u4f4d\u5b89\u6392\u5c06\u5728 \\(x \u2212 1\\) \u548c \\(y \u2212 1\\) \u4e4b\u548c\u4e0a\u52a0 1\uff0c\u5373 \\((x\u22121)+ (y\u22121) \u2264 15\\)\uff0c\u5e76\u4e14\u5f53 \\(c_{out} = 1\\) \u65f6\u5c06\u51cf\u53bb 16\uff08\u901a\u8fc7\u4e22\u5f03\u4f20\u51fa\u8fdb\u4f4d\uff09\uff0c\u5bf9\u5e94\u4e8e\u6761\u4ef6$ (x \u2212 1 ) + (y \u2212 1 ) \u2265 16$\u3002</p> <p>For a general modulus m, we need to compare the sum x + y to the modulus m, subtracting m from the computed sum if it equals or exceeds m. Because both the comparison and the ensuing subtraction require full carry propagation in the worst case, this approach would add a significant delay to the operation, which may be unacceptable. An alternative is to compute x + y and x + y \u2212 m in parallel and then use the sign of the latter value to decide whether x + y \u2265 m. If so, then x + y \u2212 m is the correct result; otherwise, x + y should be selected as the output. The resulting design, shown in Fig. 7.15, is quite fast, given that it only adds a full-adder level (the carry-save adder) and a multiplexer to the critical path of a conventional adder.</p> <p>\u5bf9\u4e8e\u4e00\u822c\u6a21\u6570 m\uff0c\u6211\u4eec\u9700\u8981\u5c06\u603b\u548c \\(x + y\\) \u4e0e\u6a21\u6570 \\(m\\) \u8fdb\u884c\u6bd4\u8f83\uff0c\u5982\u679c\u7b49\u4e8e\u6216\u8d85\u8fc7 \\(m\\)\uff0c\u5219\u4ece\u8ba1\u7b97\u7684\u603b\u548c\u4e2d\u51cf\u53bb \\(m\\)\u3002\u56e0\u4e3a\u5728\u6700\u574f\u7684\u60c5\u51b5\u4e0b\u6bd4\u8f83\u548c\u968f\u540e\u7684\u51cf\u6cd5\u90fd\u9700\u8981\u5b8c\u5168\u8fdb\u4f4d\u4f20\u64ad\uff0c\u6240\u4ee5\u8fd9\u79cd\u65b9\u6cd5\u4f1a\u7ed9\u64cd\u4f5c\u589e\u52a0\u663e\u7740\u7684\u5ef6\u8fdf\uff0c\u8fd9\u53ef\u80fd\u662f\u4e0d\u53ef\u63a5\u53d7\u7684\u3002\u53e6\u4e00\u79cd\u65b9\u6cd5\u662f\u5e76\u884c\u8ba1\u7b97 \\(x + y\\) \u548c \\(x + y \u2212 m\\)\uff0c\u7136\u540e\u4f7f\u7528\u540e\u4e00\u4e2a\u503c\u7684\u7b26\u53f7\u6765\u786e\u5b9a\u662f\u5426 \\(x + y \u2265 m\\)\u3002\u5982\u679c\u662f\uff0c\u5219 \\(x + y \u2212 m\\) \u4e3a\u6b63\u786e\u7ed3\u679c\uff1b\u5426\u5219\uff0c\u5e94\u9009\u62e9 \\(x + y\\) \u4f5c\u4e3a\u8f93\u51fa\u3002\u7531\u6b64\u4ea7\u751f\u7684\u8bbe\u8ba1\u5982\u56fe 7.15 \u6240\u793a\uff0c\u901f\u5ea6\u76f8\u5f53\u5feb\uff0c\u56e0\u4e3a\u5b83\u4ec5\u5728\u4f20\u7edf\u52a0\u6cd5\u5668\u7684\u5173\u952e\u8def\u5f84\u4e0a\u6dfb\u52a0\u4e86\u4e00\u4e2a\u5168\u52a0\u5668\u7ea7\uff08\u8fdb\u4f4d\u4fdd\u5b58\u52a0\u6cd5\u5668\uff09\u548c\u4e00\u4e2a\u591a\u8def\u590d\u7528\u5668\u3002</p> <p></p>"},{"location":"Part_02/07/#_1","title":"\u95ee\u9898\uff08\u7565\uff09","text":""},{"location":"Part_02/07/#_2","title":"\u53c2\u8003\u6587\u732e\u548c\u8fdb\u4e00\u6b65\u9605\u8bfb","text":"<pre><code>[Bedr62] Bedrij, O. J., \u201cCarry-Select Adder,\u201d IRE Trans. Electronic Computers, Vol. 11,\n         pp. 340\u2013346, 1962.\n[Chan90] Chan, P. K., and M. D. F. Schlag, \u201cAnalysis and Design of CMOS Manchester Adders\n         with Variable Carry Skip,\u201d IEEE Trans. Computers, Vol. 39, pp. 983\u2013992, 1990.\n[Chan92] Chan, P. K., M. D. F. Schlag, C. D. Thomborson, and V. G. Oklobdzija, \u201cDelay\n         Optimization of Carry-Skip Adders and Block Carry-Lookahead Adders Using\n         Multidimensional Dynamic Programming,\u201d IEEE Trans. Computers, Vol. 41, No. 8,\n         pp. 920\u2013930, 1992.\n[Dobb92] Dobberpuhl, D., et al., \u201cA 200 MHz 64-b Dual-Issue CMOS Microprocessor,\u201d IEEE\n         J. Solid-State Circuits, Vol. 27, No. 11, 1992.\n[Guyo87] Guyot, A., and J.-M. Muller, \u201cA Way to Build Efficient Carry-Skip Adders,\u201d IEEE\n         Trans. Computers, Vol. 36, No. 10, pp. 1144\u20131152, 1987.\n[Jabe09] Jaberipur, G. and B. Parhami, \u201cUnified Approach to the Design of Modulo-(2n \u00b1 1)\n         Adders Based on Signed-LSB Representation of Residues,\u201d Proc. 19th IEEE Int\u2019l\n         Symp. Computer Arithmetic, June 2009, pp. 57\u201364.\n[Kala00] Kalampoukas, L., D. Nikolos, C. Efstathiou, H. T. Vergos, and J. Kalamatianos,\n         \u201cHigh-Speed Parallel-Prefix Modulo 2n \u2212 1 Adders,\u201d IEEE Trans. Computers, Vol.\n         49, No. 7, pp. 673\u2013680, 2000.\n[Kant93] Kantabutra, V., \u201cDesigning Optimum One-Level Carry-Skip Adders,\u201d IEEE Trans.\n         Computers, Vol. 42, No. 6, pp. 759\u2013764, 1993.\n[Lehm61] Lehman, M., and N. Burla, \u201cSkip Techniques for High-Speed Carry Propagation in\n         Binary Arithmetic Units,\u201d IRE Trans. Electronic Computers, Vol. 10, pp. 691\u2013698,\n         1961.\n[Liu03] Liu, J., S. Zhou, H. Zhu, and C.-K. Cheng, \u201cAn Algorithmic Approach for Generic\n         Parallel Adders,\u201d Proc. IEEE/ACM Int\u2019l Conf. Computer-Aided Design, November\n         2003, pp. 734\u2013740.\n[Lync92] Lynch, T., and E. Swartzlander, \u201cA Spanning Tree Carry Lookahead Adder,\u201d IEEE\n         Trans. Computers, Vol. 41, No. 8, pp. 931\u2013939, 1992.\n[Maje67] Majerski, S., \u201cOn Determination of Optimal Distributions of Carry Skip in Adders,\u201d\n         IEEE Trans. Electronic Computers, Vol. 16, pp. 45\u201358, 1967.\n[Niga95] Nigaglioni, R. H., and E. E. Swartzlander, \u201cVariable Spanning Tree Adder,\u201d Proc.\n         Asilomar Conf. Signals, Systems, and Computers, 1995, pp. 586\u2013590, 1995.\n[Oklo96] Oklobdzija, V. G., D. Villeger, and S. S. Liu, \u201cA Method for Speed Optimized Partial\n         Product Reduction and Generation of Fast Parallel Multipliers Using an Algorithmic\n         Approach,\u201d IEEE Trans. Computers, Vol. 45, No. 3, pp. 294\u2013306, 1996.\n[Omon94] Omondi, A. R., Computer Arithmetic Systems: Algorithms, Architecture and\n         Implementation, Prentice-Hall, 1994.\n[Skla60] Sklansky, J., \u201cConditional-Sum Addition Logic,\u201d IRE Trans. Electronic Computers,\n         Vol. 9, No. 2, pp. 226\u2013231, 1960.\n[Turr89] Turrini, S., \u201cOptimal Group Distribution in Carry-Skip Adders,\u201d Proc. 9th Symp.\n         Computer Arithmetic, pp. 96\u2013103, 1989.\n[Yeh00] Yeh, W.-C., and C.-W. Jen, \u201cHigh-Speed Booth-Encoded Parallel Multiplier Design,\u201d\n         IEEE Trans. Computers, Vol. 49, No. 7, pp. 692\u2013701, 2000.\n</code></pre>"},{"location":"Part_02/08/","title":"8. \u591a\u64cd\u4f5c\u6570\u52a0\u6cd5","text":"<p>Multi-operand Addition</p> <p>\u201cIf A equals success, then the formula is A = X + Y + Z. X is work. Y is play. Z is keep your mouth shut.\u201d           \u2014 ALBERT EINSTEIN</p> <p>\u201c\u5982\u679c A \u7b49\u4e8e\u6210\u529f\uff0c\u90a3\u4e48\u516c\u5f0f\u5c31\u662f A = X + Y + Z\u3002X \u5c31\u662f\u5de5\u4f5c\u3002 Y \u662f\u73a9\u800d\u3002 Z\u8bf7\u95ed\u5634\u3002\u201d           \u2014 \u827e\u5c14\u4f2f\u7279.\u7231\u56e0\u65af\u5766</p> <p>In Chapters 6 and 7,we covered several speedup methods for adding two operands. Our primary motivation in dealing with multi-operand addition in this chapter is that both multiplication and inner-product computation reduce to adding a set of numbers, namely, the partial products or the component products. The main idea used is that of deferred carry assimilation made possible by redundant representation of the intermediate results.</p> <p>\u5728\u7b2c 6 \u7ae0\u548c\u7b2c 7 \u7ae0\u4e2d\uff0c\u6211\u4eec\u4ecb\u7ecd\u4e86\u51e0\u79cd\u5c06\u4e24\u4e2a\u64cd\u4f5c\u6570\u76f8\u52a0\u7684\u52a0\u901f\u65b9\u6cd5\u3002 \u6211\u4eec\u5728\u672c\u7ae0\u4e2d\u5904\u7406\u591a\u64cd\u4f5c\u6570\u52a0\u6cd5\u7684\u4e3b\u8981\u52a8\u673a\u662f\u4e58\u6cd5\u548c\u5185\u79ef\u8ba1\u7b97\u90fd\u51cf\u5c11\u4e3a\u6dfb\u52a0\u4e00\u7ec4\u6570\u5b57\uff0c\u5373\u90e8\u5206\u79ef\u6216\u5206\u91cf\u79ef\u3002 \u4f7f\u7528\u7684\u4e3b\u8981\u601d\u60f3\u662f\u901a\u8fc7\u4e2d\u95f4\u7ed3\u679c\u7684\u5197\u4f59\u8868\u793a\u6765\u5b9e\u73b0\u5ef6\u8fdf\u8fdb\u4f4d\u540c\u5316\u3002</p> <ul> <li>8.1 \u57fa\u4e8e\u4e8c\u64cd\u4f5c\u6570\u52a0\u6cd5\u5668 USING TWO OPERAND ADDERS</li> <li>8.2 \u8fdb\u4f4d\u4fdd\u7559\u52a0\u6cd5\u5668 CARRY-SAVE ADDERS</li> <li>8.3 \u534e\u83b1\u571f\u6811\u4e0e\u8fbe\u8fbe\u6811 WALLACE AND DADDA TREES</li> <li>8.4 \u5e76\u884c\u8ba1\u6570\u5668\u4e0e\u5e76\u884c\u538b\u7f29\u5668 PARALLEL COUNTERS AND COMPRESSORS</li> <li>8.5 \u591a\u4e2a\u6709\u7b26\u53f7\u6570\u4e4b\u548c ADDING MULTIPLE SIGNED NUMBERS</li> <li>8.6 \u591a\u64cd\u4f5c\u6570\u6a21\u52a0\u6cd5\u5668 MODULAR MULTIOPERAND ADDERS</li> </ul>"},{"location":"Part_02/08/#81","title":"8.1 \u57fa\u4e8e\u4e8c\u64cd\u4f5c\u6570\u52a0\u6cd5\u5668","text":"<p>Multi-operand addition is implicit in both multiplication and computation of vector inner products (Fig. 8.1). In multiplying a multiplicand  a  by a  k-digit multiplier  x, the  k partial products  xia  must be formed and then added. For inner-product computation, the component product terms  p(j) =  x(j)y(j)  obtained by multiplying the corresponding elements of the two operand vectors  x  and  y, need to be added. Computing averages (e.g., in the design of a mean filter) is another application that requires multioperand addition. </p> <p>\u591a\u64cd\u4f5c\u6570\u52a0\u6cd5\u9690\u542b\u5728\u4e58\u6cd5\u548c\u5411\u91cf\u5185\u79ef\u7684\u8ba1\u7b97\u4e2d\uff08\u56fe 8.1\uff09\u3002\u5728\u5c06\u88ab\u4e58\u6570a\u4e58\u4ee5k\u4f4d\u4e58\u6570x\u65f6\uff0c\u5fc5\u987b\u5f62\u6210k\u4e2a\u90e8\u5206\u79ef\\(x_ia\\)\u7136\u540e\u76f8\u52a0\u3002\u5bf9\u4e8e\u5185\u79ef\u8ba1\u7b97\uff0c\u9700\u8981\u5c06\u4e24\u4e2a\u64cd\u4f5c\u6570\u5411\u91cf x \u548c y \u7684\u76f8\u5e94\u5143\u7d20\u76f8\u4e58\u83b7\u5f97\u7684\u5206\u91cf\u79ef\u9879 \\(p(j) = x(j)y(j)\\) \u76f8\u52a0\u3002\u8ba1\u7b97\u5e73\u5747\u503c\uff08\u4f8b\u5982\uff0c\u5728\u5747\u503c\u6ee4\u6ce2\u5668\u7684\u8bbe\u8ba1\u4e2d\uff09\u662f\u53e6\u4e00\u4e2a\u9700\u8981\u591a\u64cd\u4f5c\u6570\u52a0\u6cd5\u7684\u5e94\u7528\u3002</p> <p></p> <p>We will assume that the  n  operands are unsigned integers of the same width  k  and are aligned at the least-significant end, as in the right side of Fig. 8.1. Extension of the methods to signed operands are discussed in Section 8.5. Application to multiplication is the subject of Part III. </p> <p>\u6211\u4eec\u5047\u8bben\u4e2a\u64cd\u4f5c\u6570\u662f\u5bbd\u5ea6k\u76f8\u540c\u7684\u65e0\u7b26\u53f7\u6574\u6570\uff0c\u5e76\u4e14\u5728\u6700\u4f4e\u6709\u6548\u7aef\u5bf9\u9f50\uff0c\u5982\u56fe8.1\u53f3\u4fa7\u6240\u793a\u3002\u6709\u7b26\u53f7\u64cd\u4f5c\u6570\u7684\u65b9\u6cd5\u5c06\u5728 8.5 \u8282\u4e2d\u8ba8\u8bba\u3002\u4e58\u6cd5\u7684\u5e94\u7528\u662f\u7b2c\u4e09\u90e8\u5206\u7684\u4e3b\u9898\u3002</p> <p>Figure 8.2 depicts a serial solution to the multioperand addition problem using a single two-operand adder. The binary operands  x(i),  i = 0, 1, \u00b7 \u00b7 \u00b7 ,  n \u2212 1, are applied, one per clock cycle, to one input of the adder, with the other input fed back from a partial sum register. Since the final sum can be as large as  n( 2 k \u2212 1 ), the partial sum register must be log  (*2  *n 2 k \u2212  n + 1 ) \u2248  k + log2  n  bits wide. </p> <p>\u56fe 8.2 \u63cf\u8ff0\u4e86\u4f7f\u7528\u5355\u4e2a\u4e8c\u64cd\u4f5c\u6570\u52a0\u6cd5\u5668\u89e3\u51b3\u591a\u64cd\u4f5c\u6570\u52a0\u6cd5\u95ee\u9898\u7684\u4e32\u884c\u89e3\u51b3\u65b9\u6848\u3002\u6bcf\u4e2a\u65f6\u949f\u5468\u671f\u5c06\u4e8c\u8fdb\u5236\u64cd\u4f5c\u6570 \\(x^{(i)}\\)\u3001\\(i = 0\u30011\u3001\u00b7\u00b7\u00b7\u00b7\u3001n \u2212 1\\) \u5e94\u7528\u4e8e\u52a0\u6cd5\u5668\u7684\u4e00\u4e2a\u8f93\u5165\uff0c\u53e6\u4e00\u8f93\u5165\u4ece\u90e8\u5206\u548c\u5bc4\u5b58\u5668\u53cd\u9988\u3002\u7531\u4e8e\u6700\u7ec8\u7684\u548c\u53ef\u4ee5\u4e0e \\(n( 2^k \u2212 1 )\\) \u4e00\u6837\u5927\uff0c\u56e0\u6b64\u90e8\u5206\u548c\u5bc4\u5b58\u5668\u5fc5\u987b\u662f \\(\\log_2 (n 2^k \u2212 n + 1 ) \\approx k + \\log_2 n\\) \u4f4d\u5bbd\u3002</p> <p></p> <p>Assuming the use of a logarithmic-time fast adder, the total latency of the scheme of Fig. 8.2 for adding  n  operands of width  k  is</p> <p>\u5047\u8bbe\u4f7f\u7528\u5bf9\u6570\u65f6\u95f4\u5feb\u901f\u52a0\u6cd5\u5668\uff0c\u56fe 8.2 \u7684\u65b9\u6848\u7528\u4e8e\u6dfb\u52a0 n \u4e2a\u5bbd\u5ea6\u4e3a k \u7684\u64cd\u4f5c\u6570\u7684\u603b\u5ef6\u8fdf\u4e3a</p> <p>\\(T_{serial\u2212multi\u2212add} = O (n \\log (k + \\log n))\\)</p> <p>Since  k + log  n  is no less than max (k, log  n)  and no greater than max ( 2 k, 2 log  n), we have log (k + log  n) = O ( log  k + log log  n)  and </p> <p>\u7531\u4e8e \\(k + \\log n\\) \u4e0d\u5c0f\u4e8e \\(max (k, \\log n)\\) \u4e14\u4e0d\u5927\u4e8e \\(max (2 k, 2 \\log n)\\)\uff0c\u6240\u4ee5\u6211\u4eec\u6709  \\(\\log (k + \\log n) = O ( \\log k + \\log \\log n)\\) \u548c</p> <p>\\(T_{serial\u2212multi\u2212add} = O (n \\log k + n \\log \\log n)\\)</p> <p>Therefore, the addition time grows superlinearly with  n  when  k  is fixed and logarithmically with  k  for a given  n. </p> <p>\u56e0\u6b64\uff0c\u5f53 k \u56fa\u5b9a\u65f6\uff0c\u52a0\u6cd5\u65f6\u95f4\u968f n \u8d85\u7ebf\u6027\u589e\u957f\uff0c\u5e76\u4e14\u5bf9\u4e8e\u7ed9\u5b9a n \u4e0e k \u5448\u5bf9\u6570\u589e\u957f\u3002</p> <p>One can pipeline this serial solution to get somewhat better performance. Figure 8.3 shows that if the adder is implemented as a four-stage pipeline, then three adders can be used to achieve the maximum possible throughput of one operand per clock cycle. Note that the presence of latches is assumed after each of the four adder stages and that a delay block simply represents a null operation followed by latches. The operation of the circuit in Fig. 8.3 is best understood if we trace the partially computed results from left to right. At the clock cycle when the  i th input value  x(i)  arrives from the left and the sum of input values up to  x(i\u221212 )  is output at the right, adder A is supplied with the two values x(i)  and  x(i\u22121 ). The partial results stored at the end of adder A\u2019s four stages correspond to the computations  x(i\u22121 ) +  x(i\u22122 ),  x(i\u22122 ) +  x(i\u22123 ),  x(i\u22123 ) +  x(i\u22124 ), and  x(i\u22124 ) +  x(i\u22125 ), with the latter final result used to label the output of adder A. Other labels attached to the lines in Fig. 8.3 should allow the reader to continue this process, culminating in the determination of partial/final results of adder C. Even though the clock cycle is now shorter because of pipelining, the latency from the first input to the last output remains asymptotically the same with  h-stage pipelining for any fixed  h. </p> <p>\u4eba\u4eec\u53ef\u4ee5\u901a\u8fc7\u6d41\u6c34\u7ebf\u5316\u8fd9\u4e00\u4e32\u884c\u89e3\u51b3\u65b9\u6848\u6765\u83b7\u5f97\u66f4\u597d\u7684\u6027\u80fd\u3002\u56fe8.3\u8868\u660e\u5982\u679c\u52a0\u6cd5\u5668\u5b9e\u73b0\u4e3a\u56db\u7ea7\u6d41\u6c34\u7ebf\uff0c\u5219\u53ef\u4ee5\u4f7f\u7528\u4e09\u4e2a\u52a0\u6cd5\u5668\u6765\u5b9e\u73b0\u6bcf\u4e2a\u65f6\u949f\u5468\u671f\u4e00\u4e2a\u64cd\u4f5c\u6570\u7684\u6700\u5927\u53ef\u80fd\u541e\u5410\u91cf\u3002\u8bf7\u6ce8\u610f\uff0c\u5047\u8bbe\u5728\u56db\u4e2a\u52a0\u6cd5\u5668\u7ea7\u4e2d\u7684\u6bcf\u4e00\u4e2a\u4e4b\u540e\u90fd\u5b58\u5728\u9501\u5b58\u5668\uff0c\u5e76\u4e14\u5ef6\u8fdf\u5757\u4ec5\u8868\u793a\u9501\u5b58\u5668\u540e\u9762\u7684\u7a7a\u64cd\u4f5c\u3002\u5982\u679c\u6211\u4eec\u4ece\u5de6\u5230\u53f3\u8ffd\u8e2a\u90e8\u5206\u8ba1\u7b97\u7ed3\u679c\uff0c\u5c31\u53ef\u4ee5\u6700\u597d\u5730\u7406\u89e3\u56fe 8.3 \u4e2d\u7535\u8def\u7684\u64cd\u4f5c\u3002\u5728\u65f6\u949f\u5468\u671f\uff0c\u5f53\u7b2c \\(i\\) \u4e2a\u8f93\u5165\u503c \\(x^{(i)}\\) \u4ece\u5de6\u4fa7\u5230\u8fbe\u5e76\u4e14\u76f4\u5230 \\(x^{(i\u221212 )}\\) \u7684\u8f93\u5165\u503c\u4e4b\u548c\u5728\u53f3\u4fa7\u8f93\u51fa\u65f6\uff0c\u52a0\u6cd5\u5668 A \u88ab\u63d0\u4f9b\u4e24\u4e2a\u503c \\(x^{(i)}\\) \u548c \\(x^{(i\u22121)}\\)\u3002\u52a0\u6cd5\u5668 A \u56db\u4e2a\u9636\u6bb5\u672b\u5c3e\u5b58\u50a8\u7684\u90e8\u5206\u7ed3\u679c\u5bf9\u5e94\u4e8e\u8ba1\u7b97 \\(x^{(i\u22121)} + x^{(i\u22122)}\\)\u3001\\(x^{(i\u22122)} + x^{(i\u22123)}\\)\u3001\\(x^{(i\u22123)} + x^{(i\u22124)}\\) \u548c \\(x^{(i\u22124)} + x^{(i\u22125)}\\) \uff0c\u540e\u8005\u7684\u6700\u7ec8\u7ed3\u679c\u7528\u4e8e\u6807\u8bb0\u52a0\u6cd5\u5668 A \u7684\u8f93\u51fa\u3002\u5176\u4ed6\u9644\u52a0\u5230\u56fe 8.3 \u4e2d\u884c\u7684\u6807\u7b7e\u5e94\u8be5\u5141\u8bb8\u8bfb\u8005\u7ee7\u7eed\u8fd9\u4e2a\u8fc7\u7a0b\uff0c\u6700\u7ec8\u786e\u5b9a\u52a0\u6cd5\u5668 C \u7684\u90e8\u5206/\u6700\u7ec8\u7ed3\u679c\u3002\u5c3d\u7ba1\u7531\u4e8e\u6d41\u6c34\u7ebf\u64cd\u4f5c\uff0c\u65f6\u949f\u5468\u671f\u73b0\u5728\u66f4\u77ed\uff0c\u4f46\u5bf9\u4e8e\u4efb\u4f55\u56fa\u5b9a\u7684 h\uff0c\u4ece\u7b2c\u4e00\u4e2a\u8f93\u5165\u5230\u6700\u540e\u4e00\u4e2a\u8f93\u51fa\u7684\u5ef6\u8fdf\u4e0e \\(h\\) \u7ea7\u6d41\u6c34\u7ebf\u4fdd\u6301\u6e10\u8fd1\u76f8\u540c\u3002</p> <p></p> <p>Note that the schemes shown in Figs. 8.2 and 8.3 work for any prefix computation involving a binary operator \u2297, provided the adder is replaced by a hardware unit corresponding to the binary operator \u2297. For example, similar designs can be used to find the product of  n  numbers or the largest value among them. </p> <p>\u8bf7\u6ce8\u610f\uff0c\u56fe1\u548c2\u4e2d\u6240\u793a\u7684\u65b9\u6848\u3002 8.2 \u548c 8.3 \u9002\u7528\u4e8e\u6d89\u53ca\u4e8c\u5143\u8fd0\u7b97\u7b26 \u2297 \u7684\u4efb\u4f55\u524d\u7f00\u8ba1\u7b97\uff0c\u524d\u63d0\u662f\u52a0\u6cd5\u5668\u88ab\u66ff\u6362\u4e3a\u4e0e\u4e8c\u5143\u8fd0\u7b97\u7b26 \u2297 \u76f8\u5bf9\u5e94\u7684\u786c\u4ef6\u5355\u5143\u3002\u4f8b\u5982\uff0c\u7c7b\u4f3c\u7684\u8bbe\u8ba1\u53ef\u7528\u4e8e\u6c42n\u4e2a\u6570\u5b57\u7684\u4e58\u79ef\u6216\u5176\u4e2d\u7684\u6700\u5927\u503c\u3002</p> <p>For higher speed, a tree of two-operand adders might be used, as in Fig. 8.4. Such a binary tree of two-operand adders needs  n \u2212 1 adders and is thus quite costly if built of fast adders. Strange as it may seem, the use of simple and slow ripple-carry (or even bit-serial) adders may be the best choice in this design. If we use fast logarithmic-time adders, the latency will be</p> <p>\u4e3a\u4e86\u83b7\u5f97\u66f4\u9ad8\u7684\u901f\u5ea6\uff0c\u53ef\u4ee5\u4f7f\u7528\u4e8c\u64cd\u4f5c\u6570\u52a0\u6cd5\u5668\u6811\uff0c\u5982\u56fe 8.4 \u6240\u793a\u3002\u8fd9\u79cd\u53cc\u64cd\u4f5c\u6570\u52a0\u6cd5\u5668\u7684\u4e8c\u53c9\u6811\u9700\u8981 \\(n \u2212 1\\) \u4e2a\u52a0\u6cd5\u5668\uff0c\u56e0\u6b64\u5982\u679c\u7531\u5feb\u901f\u52a0\u6cd5\u5668\u6784\u5efa\uff0c\u6210\u672c\u76f8\u5f53\u9ad8\u3002\u5c3d\u7ba1\u770b\u8d77\u6765\u5f88\u5947\u602a\uff0c\u4f46\u4f7f\u7528\u7b80\u5355\u4e14\u7f13\u6162\u7684\u7eb9\u6ce2\u8fdb\u4f4d\uff08\u751a\u81f3\u4f4d\u4e32\u884c\uff09\u52a0\u6cd5\u5668\u53ef\u80fd\u662f\u8be5\u8bbe\u8ba1\u4e2d\u7684\u6700\u4f73\u9009\u62e9\u3002\u5982\u679c\u6211\u4eec\u4f7f\u7528\u5feb\u901f\u5bf9\u6570\u65f6\u95f4\u52a0\u6cd5\u5668\uff0c\u5219\u5ef6\u8fdf\u5c06\u4e3a</p> \\[ \\begin{array}{l} T_{tree\u2212fast\u2212multi\u2212add} &amp;= O ( \\log k + \\log (k + 1 ) + \u00b7 \u00b7 \u00b7 + \\log (k + \\left \\lceil \\log_2 n \\right \\rceil \u2212 1 )) \\\\ &amp;= O ( \\log n \\log k + \\log n \\log \\log n) \\end{array} \\] <p></p> <p>The preceding equality can be proven by considering the two cases of log2  n &lt; k  and log2  n &gt; k  and bounding the right-hand side in each case. Supplying the needed details of the proof is left as an exercise. If we use ripple-carry adders in the tree of Fig. 8.4, the delay becomes</p> <p>\u53ef\u4ee5\u901a\u8fc7\u8003\u8651 \\(\\log_2 n &lt; k\\) \u548c \\(\\log_2 n &gt; k\\) \u4e24\u79cd\u60c5\u51b5\u5e76\u5728\u6bcf\u79cd\u60c5\u51b5\u4e0b\u9650\u5236\u53f3\u4fa7\u6765\u8bc1\u660e\u4e0a\u8ff0\u7b49\u5f0f\u3002\u63d0\u4f9b\u8bc1\u660e\u6240\u9700\u7684\u8be6\u7ec6\u4fe1\u606f\u7559\u4f5c\u7ec3\u4e60\u3002\u5982\u679c\u6211\u4eec\u5728\u56fe 8.4 \u7684\u6811\u4e2d\u4f7f\u7528\u7eb9\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\uff0c\u5219\u5ef6\u8fdf\u53d8\u4e3a</p> <p>\\(T_{tree\u2212ripple\u2212multi\u2212add} = O (k + \\log  n)\\)</p> <p>which can be less than the delay with fast adders for large n. Comparing the costs of this and the preceding schemes for different ranges of values for the parameters k and n is left as an exercise.</p> <p>\u5bf9\u4e8e\u5927 \\(n\\)\uff0c\u8fd9\u53ef\u4ee5\u5c0f\u4e8e\u5feb\u901f\u52a0\u6cd5\u5668\u7684\u5ef6\u8fdf\u3002\u5bf9\u4e8e\u53c2\u6570 \\(k\\) \u548c \\(n\\) \u7684\u4e0d\u540c\u503c\u8303\u56f4\uff0c\u6bd4\u8f83\u8be5\u65b9\u6848\u548c\u524d\u9762\u7684\u65b9\u6848\u7684\u6210\u672c\u7559\u4f5c\u7ec3\u4e60\u3002</p> <p>Figure 8.5 shows why the delay with ripple-carry adders is O (k + log n). There are log2 n levels in the tree. An adder in the ( i + 1)th level need not wait for full carry propagation in level i to occur, but rather can start its addition one full-adder (FA) delay after level i. In other words, carry propagation in each level lags 1 time unit behind the preceding level. Thus, we need to allow constant time for all but the last adder level, which needs O (k + log n) time.</p> <p>\u56fe 8.5 \u663e\u793a\u4e86\u4e3a\u4ec0\u4e48\u7eb9\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\u7684\u5ef6\u8fdf\u4e3a \\(O (k + \\log n)\\)\u3002\u6811\u4e2d\u6709 \\(\\left \\lceil \\log_2 n \\right \\rceil\\) \u5c42\u3002\u7b2c \\(( i + 1)\\) \u7ea7\u4e2d\u7684\u52a0\u6cd5\u5668\u4e0d\u9700\u8981\u7b49\u5f85\u7b2c i \u7ea7\u4e2d\u7684\u5168\u8fdb\u4f4d\u4f20\u64ad\u53d1\u751f\uff0c\u800c\u662f\u53ef\u4ee5\u5728\u7b2c \\(i\\) \u7ea7\u4e4b\u540e\u4e00\u4e2a\u5168\u52a0\u5668 (FA) \u5ef6\u8fdf\u540e\u5f00\u59cb\u5176\u52a0\u6cd5\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u6bcf\u4e00\u7ea7\u7684\u8fdb\u4f4d\u4f20\u64ad\u843d\u540e\u4e8e\u524d\u4e00\u7ea71\u4e2a\u65f6\u95f4\u5355\u4f4d\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u9700\u8981\u4e3a\u9664\u6700\u540e\u4e00\u4e2a\u52a0\u6cd5\u5668\u7ea7\u522b\u4e4b\u5916\u7684\u6240\u6709\u7ea7\u522b\u7559\u51fa\u6052\u5b9a\u65f6\u95f4\uff0c\u8fd9\u9700\u8981 \\(O (k + \\log n)\\) \u65f6\u95f4\u3002</p> <p></p> <p>Can we do better than the O (k +log n) delay offered by the tree of ripple-carry adders of Fig. 8.5? The absolute minimum time is O ( log (kn)) = O ( log k + log n), where kn is the total number of input bits to be processed by the multioperand adder, which is ultimately composed of constant\u2013fan-in logic gates. This minimum is achievable with carry-save adders (CSAs).</p> <p>\u6211\u4eec\u80fd\u5426\u505a\u5f97\u6bd4\u56fe 8.5 \u7684\u7eb9\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\u6811\u63d0\u4f9b\u7684 \\(O (k +\\log n)\\) \u5ef6\u8fdf\u66f4\u597d\uff1f\u7edd\u5bf9\u6700\u5c0f\u65f6\u95f4\u4e3a \\(O ( \\log (kn)) = O ( \\log k + \\log n)\\)\uff0c\u5176\u4e2d kn \u662f\u591a\u64cd\u4f5c\u6570\u52a0\u6cd5\u5668\u8981\u5904\u7406\u7684\u8f93\u5165\u4f4d\u6570\u7684\u603b\u6570\uff0c\u8be5\u52a0\u6cd5\u5668\u6700\u7ec8\u7531\u6052\u5b9a\u6247\u5165\u903b\u8f91\u95e8\u7ec4\u6210\u3002\u8fd9\u4e2a\u6700\u5c0f\u503c\u53ef\u4ee5\u901a\u8fc7\u8fdb\u4f4d\u4fdd\u5b58\u52a0\u6cd5\u5668 (CSA) \u6765\u5b9e\u73b0\u30028.2 \u8fdb\u4f4d\u4fdd\u7559\u52a0\u6cd5\u5668</p>"},{"location":"Part_02/08/#82","title":"8.2 \u8fdb\u4f4d\u4fdd\u7559\u52a0\u6cd5\u5668","text":"<p>We can view a row of binary FAs as a mechanism to reduce three numbers to two numbers rather than as one to reduce two numbers to their sum. Figure 8.6 shows the relationship of a ripple-carry adder for the latter reduction and a CSA for the former (see also Fig. 3.5). </p> <p>\u6211\u4eec\u53ef\u4ee5\u5c06\u4e00\u884c\u4e8c\u8fdb\u5236 FA \u89c6\u4e3a\u5c06\u4e09\u4e2a\u6570\u5b57\u51cf\u5c11\u4e3a\u4e24\u4e2a\u6570\u5b57\u7684\u673a\u5236\u800c\u4e0d\u662f\u4f5c\u4e3a\u4e00\u5c06\u4e24\u4e2a\u6570\u5b57\u51cf\u5c11\u5230\u5b83\u4eec\u7684\u603b\u548c\u3002\u56fe 8.6 \u663e\u793a\u4e86\u540e\u8005\u51cf\u5c11\u7684\u7eb9\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\u4e0e\u524d\u8005\u7684 CSA \u7684\u5173\u7cfb\uff08\u53e6\u8bf7\u53c2\u89c1\u56fe 3.5\uff09\u3002</p> <p></p> <p>Figure 8.7 presents, in dot notation, the relationship shown in Fig. 8.6. To specify more precisely how the various dots are related or obtained, we agree to enclose any three dots that form the inputs to a FA in a dashed box and to connect the sum and carry outputs of an FA by a diagonal line (Fig. 8.8). Occasionally, only two dots are combined to form a sum bit and a carry bit. Then the two dots are enclosed in a dashed box and the use of a half-adder (HA) is signified by a cross line on the diagonal line connecting its outputs (Fig. 8.8). </p> <p>\u56fe 8.7 \u4ee5\u70b9\u8868\u793a\u6cd5\u663e\u793a\u4e86\u56fe 8.6 \u4e2d\u6240\u793a\u7684\u5173\u7cfb\u3002\u4e3a\u4e86\u66f4\u7cbe\u786e\u5730\u6307\u5b9a\u5404\u4e2a\u70b9\u662f\u5982\u4f55\u76f8\u5173\u6216\u83b7\u5f97\u7684\uff0c\u6211\u4eec\u540c\u610f\u5c06\u6784\u6210 FA \u8f93\u5165\u7684\u4efb\u610f\u4e09\u4e2a\u70b9\u5305\u542b\u5728\u865a\u7ebf\u6846\u4e2d\uff0c\u5e76\u901a\u8fc7\u5bf9\u89d2\u7ebf\u8fde\u63a5 FA \u7684\u6c42\u548c\u548c\u8fdb\u4f4d\u8f93\u51fa\uff08\u56fe 8.8\uff09\u3002\u6709\u65f6\uff0c\u53ea\u6709\u4e24\u4e2a\u70b9\u7ec4\u5408\u8d77\u6765\u5f62\u6210\u548c\u4f4d\u548c\u8fdb\u4f4d\u4f4d\u3002\u7136\u540e\u5c06\u4e24\u4e2a\u70b9\u62ec\u5728\u865a\u7ebf\u6846\u4e2d\uff0c\u5e76\u901a\u8fc7\u8fde\u63a5\u5176\u8f93\u51fa\u7684\u5bf9\u89d2\u7ebf\u4e0a\u7684\u5341\u5b57\u7ebf\u6765\u8868\u793a\u534a\u52a0\u5668 (HA) \u7684\u4f7f\u7528\uff08\u56fe 8.8\uff09\u3002</p> <p></p> <p>Dot notation suggests another way to view the function of a CSA: as converter of a radix-2 number with the digit set [0, 3] (3 bits in one position) to one with the digit set  [0, 2] (2 bits in one position). </p> <p>\u70b9\u8868\u793a\u6cd5\u63d0\u51fa\u4e86\u53e6\u4e00\u79cd\u67e5\u770b CSA \u529f\u80fd\u7684\u65b9\u6cd5\uff1a\u5c06\u6570\u5b57\u96c6 [0, 3]\uff083 \u6bd4\u7279\u4e00\u4f4d\uff09\u7684\u57fa 2 \u6570\u8f6c\u6362\u4e3a\u6570\u5b57\u96c6\u7684[0, 2]\uff082\u6bd4\u7279\u4e00\u4f4d \uff09\u3002</p> <p>A CSA tree (Fig. 8.9) can reduce  n  binary numbers to two numbers having the same sum in O ( log  n)  levels. If a fast logarithmic-time carry-propagate adder (CPA) is then used to add the two resulting numbers, we have the following results for the cost and</p> <p>CSA \u6811\uff08\u56fe 8.9\uff09\u53ef\u4ee5\u5c06 n \u4e2a\u4e8c\u8fdb\u5236\u6570\u51cf\u5c11\u4e3a \\(O ( \\log n)\\) \u7ea7\u4e2d\u603b\u548c\u76f8\u540c\u7684\u4e24\u4e2a\u6570\u3002\u5982\u679c\u968f\u540e\u4f7f\u7528\u5feb\u901f\u5bf9\u6570\u65f6\u95f4\u8fdb\u4f4d\u4f20\u64ad\u52a0\u6cd5\u5668 (CPA) \u5c06\u4e24\u4e2a\u7ed3\u679c\u6570\u76f8\u52a0\uff0c\u6211\u4eec\u5c06\u5f97\u5230\u4ee5\u4e0b\u6210\u672c\u548c\u7ed3\u679c\uff1a</p> <p></p> <p>delay of n-operand addition:</p> <p>n \u64cd\u4f5c\u6570\u52a0\u6cd5\u7684\u5ef6\u8fdf\uff1a</p> <p>\\(C_{carry\u2212save\u2212multi\u2212add} = (n \u2212 2)C_{CSA} + C_{CPA}\\)</p> <p>$T_{carry\u2212save\u2212multi\u2212add} = O ( \\text{tree height} + T_{CPA} ) = O (\\log n + \\log k) $</p> <p>The needed CSAs are of various widths, but generally the widths are close to k bits; the CPA is of width at most k + log2 n. An example for adding seven 6-bit numbers is shown in Fig. 8.10. A more compact tabular representation of the same process is depicted in Fig. 8.11, where the entries represent the number of dots remaining in the respective columns or bit positions. We begin on the first row with seven dots in each of bit positions 0\u20135; these dots represent the seven 6-bit inputs. Two FAs are used in each 7-dot column, with each FA converting three dots in its column to one dot in that column and one dot in the next higher column. This leads to the distribution of dots shown on the second row of Fig. 8.11. Next, one FA is used in each of the bit positions 0\u20135 containing three dots or more, and so on, until no column contains more than two dots (see below for details). At this point, a CPA is used to reduce the resulting two numbers to the final 9-bit sum represented by a single dot in each of the bit positions 0\u20138. </p> <p>\u6240\u9700\u7684 CSA \u5177\u6709\u5404\u79cd\u5bbd\u5ea6\uff0c\u4f46\u901a\u5e38\u5bbd\u5ea6\u63a5\u8fd1 \\(k\\) \u4f4d\uff1b CPA \u7684\u5bbd\u5ea6\u81f3\u591a\u4e3a \\(k + \\log_2 n\\)\u3002\u4e03\u4e2a 6 \u4f4d\u6570\u5b57\u76f8\u52a0\u7684\u793a\u4f8b\u5982\u56fe 8.10 \u6240\u793a\u3002\u56fe 8.11 \u63cf\u7ed8\u4e86\u540c\u4e00\u8fc7\u7a0b\u7684\u66f4\u7d27\u51d1\u7684\u8868\u683c\u8868\u793a\uff0c\u5176\u4e2d\u6761\u76ee\u8868\u793a\u76f8\u5e94\u5217\u6216\u4f4d\u4f4d\u7f6e\u4e2d\u5269\u4f59\u7684\u70b9\u6570\u3002\u6211\u4eec\u4ece\u7b2c\u4e00\u884c\u5f00\u59cb\uff0c\u6bcf\u4e2a\u4f4d\u4f4d\u7f6e 0-5 \u90fd\u6709\u4e03\u4e2a\u70b9\uff1b\u8fd9\u4e9b\u70b9\u4ee3\u8868\u4e03\u4e2a 6 \u4f4d\u8f93\u5165\u3002\u6bcf\u4e2a 7 \u70b9\u5217\u4e2d\u4f7f\u7528\u4e24\u4e2a FA\uff0c\u6bcf\u4e2a FA \u5c06\u5176\u5217\u4e2d\u7684\u4e09\u4e2a\u70b9\u8f6c\u6362\u4e3a\u8be5\u5217\u4e2d\u7684\u4e00\u4e2a\u70b9\u4ee5\u53ca\u4e0b\u4e00\u8f83\u9ad8\u5217\u4e2d\u7684\u4e00\u4e2a\u70b9\u3002\u8fd9\u5bfc\u81f4\u4e86\u56fe 8.11 \u7b2c\u4e8c\u884c\u6240\u793a\u7684\u70b9\u5206\u5e03\u3002\u63a5\u4e0b\u6765\uff0c\u5728\u5305\u542b\u4e09\u4e2a\u6216\u66f4\u591a\u70b9\u7684\u4f4d\u4f4d\u7f6e 0-5 \u4e2d\u7684\u6bcf\u4e00\u4e2a\u4e2d\u4f7f\u7528\u4e00\u4e2a FA\uff0c\u4f9d\u6b64\u7c7b\u63a8\uff0c\u76f4\u5230\u6ca1\u6709\u5217\u5305\u542b\u8d85\u8fc7\u4e24\u4e2a\u70b9\uff08\u8be6\u7ec6\u4fe1\u606f\u8bf7\u53c2\u89c1\u4e0b\u6587\uff09\u3002\u6b64\u65f6\uff0cCPA\u5c31\u662f\u7528\u4e8e\u5c06\u6240\u5f97\u7684\u4e24\u4e2a\u6570\u5b57\u51cf\u5c11\u4e3a\u6700\u7ec8\u7684 9 \u4f4d\u548c\uff0c\u7531\u6bcf\u4e2a\u4f4d\u4f4d\u7f6e 0-8 \u4e2d\u7684\u4e00\u4e2a\u70b9\u8868\u793a\u3002</p> <p></p> <p></p> <p>In deriving the entries of a row from those of the preceding one, we begin with column 0 and proceed to the leftmost column. In each column, we cast out multiples of 3 and for each group of three that we cast out, we include 1 bit in the same column and 1 bit in the next column to the left. Columns at the right that have already been reduced to 1 need no further reduction. The rightmost column with a 2 can be either reduced using an HA or left intact, postponing its reduction to the final CPA. The former strategy tends to make the width of the final CPA smaller, while the latter strategy minimizes the number of FAs and HAs at the expense of a wider CPA. In the example of Fig. 8.10, and its tabular form in Fig. 8.11, we could have reduced the width of the final CPA from 7 bits to 6 bits by applying an extra HA to the two dots remaining in bit position 1. </p> <p>\u5728\u4ece\u524d\u4e00\u884c\u7684\u6761\u76ee\u4e2d\u6d3e\u751f\u51fa\u4e00\u884c\u7684\u6761\u76ee\u65f6\uff0c\u6211\u4eec\u4ece\u7b2c 0 \u5217\u5f00\u59cb\u5e76\u7ee7\u7eed\u5230\u6700\u5de6\u8fb9\u7684\u5217\u3002\u5728\u6bcf\u4e00\u5217\u4e2d\uff0c\u6211\u4eec\u8f93\u51fa 3 \u7684\u500d\u6570\uff0c\u5bf9\u4e8e\u6211\u4eec\u8f93\u51fa\u7684\u6bcf\u7ec4 3\uff0c\u6211\u4eec\u5728\u540c\u4e00\u5217\u4e2d\u5305\u542b 1 \u4f4d\uff0c\u5728\u5de6\u4fa7\u7684\u4e0b\u4e00\u5217\u4e2d\u5305\u542b 1 \u4f4d\u3002\u53f3\u4fa7\u7684\u5217\u5df2\u51cf\u5c11\u5230 1\uff0c\u65e0\u9700\u8fdb\u4e00\u6b65\u51cf\u5c11\u3002\u6700\u53f3\u8fb9\u5e26\u6709 2 \u7684\u5217\u53ef\u4ee5\u4f7f\u7528 HA \u8fdb\u884c\u7f29\u51cf\uff0c\u4e5f\u53ef\u4ee5\u4fdd\u6301\u539f\u6837\uff0c\u5c06\u5176\u7f29\u51cf\u63a8\u8fdf\u5230\u6700\u7ec8 CPA\u3002\u524d\u4e00\u79cd\u7b56\u7565\u503e\u5411\u4e8e\u4f7f\u6700\u7ec8 CPA \u7684\u5bbd\u5ea6\u66f4\u5c0f\uff0c\u800c\u540e\u4e00\u79cd\u7b56\u7565\u5219\u4ee5\u66f4\u5bbd\u7684 CPA \u4e3a\u4ee3\u4ef7\u6700\u5c0f\u5316 FA \u548c HA \u7684\u6570\u91cf\u3002\u5728\u56fe\u4f8b\u4e2d\u3002\u5982\u56fe 8.10 \u6240\u793a\uff0c\u4ee5\u53ca\u56fe 8.11 \u4e2d\u7684\u8868\u683c\u5f62\u5f0f\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u5bf9\u4f4d\u4f4d\u7f6e 1 \u4e2d\u5269\u4f59\u7684\u4e24\u4e2a\u70b9\u5e94\u7528\u989d\u5916\u7684 HA\uff0c\u5c06\u6700\u7ec8 CPA \u7684\u5bbd\u5ea6\u4ece 7 \u4f4d\u51cf\u5c11\u5230 6 \u4f4d\u3002</p> <p>Figure 8.12 depicts a block diagram for the carry-save addition of seven  k-bit numbers. By tagging each line in the diagram with the bit positions it carries, we see that even though the partial sums do grow in magnitude as more numbers are combined, the widths of the CSAs stay pretty much constant throughout the tree. Note that the lowermost CSA in Fig. 8.12 could have been made only  k \u2212 1 bits wide by letting the two lines in bit position 1 pass through. The CPA would then have become  k + 1 bits wide. </p> <p>\u56fe 8.12 \u63cf\u8ff0\u4e86 7 \u4e2a \\(k\\) \u4f4d\u6570\u5b57\u7684\u8fdb\u4f4d\u4fdd\u5b58\u52a0\u6cd5\u7684\u6846\u56fe\u3002\u901a\u8fc7\u7528\u5b83\u6240\u643a\u5e26\u7684\u4f4d\u4f4d\u7f6e\u6765\u6807\u8bb0\u56fe\u4e2d\u7684\u6bcf\u4e00\u884c\uff0c\u6211\u4eec\u53ef\u4ee5\u770b\u5230\uff0c\u5c3d\u7ba1\u968f\u7740\u66f4\u591a\u6570\u5b57\u7684\u7ec4\u5408\uff0c\u90e8\u5206\u548c\u7684\u5927\u5c0f\u786e\u5b9e\u4f1a\u589e\u957f\uff0c\u4f46 CSA \u7684\u5bbd\u5ea6\u5728\u6574\u4e2a\u6811\u4e2d\u51e0\u4e4e\u4fdd\u6301\u4e0d\u53d8\u3002\u8bf7\u6ce8\u610f\uff0c\u901a\u8fc7\u8ba9\u4f4d\u4f4d\u7f6e 1 \u4e2d\u7684\u4e24\u6761\u7ebf\u901a\u8fc7\uff0c\u53ef\u4ee5\u4f7f\u56fe 8.12 \u4e2d\u6700\u4f4e\u7684 CSA \u4ec5\u5177\u6709 \\(k \u2212 1\\) \u4f4d\u5bbd\u3002\u90a3\u4e48 CPA \u5c06\u53d8\u4e3a \\(k + 1\\) \u4f4d\u5bbd\u3002</p> <p></p> <p>Carry-save addition can be implemented serially using a single CSA, as depicted in Fig. 8.13. This is the preferred method when the operands arrive serially or must be read out from memory one by one. Note, however, that in this case both the CSA and final CPA will have to be wider. </p> <p>\u8fdb\u4f4d\u4fdd\u5b58\u52a0\u6cd5\u53ef\u4ee5\u4f7f\u7528\u5355\u4e2a CSA \u4e32\u884c\u5b9e\u73b0\uff0c\u5982\u56fe 8.13 \u6240\u793a\u3002\u5f53\u64cd\u4f5c\u6570\u8fde\u7eed\u5230\u8fbe\u6216\u5fc5\u987b\u4ece\u5185\u5b58\u4e2d\u9010\u4e00\u8bfb\u51fa\u65f6\uff0c\u8fd9\u662f\u9996\u9009\u65b9\u6cd5\u3002\u4f46\u8bf7\u6ce8\u610f\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0cCSA \u548c\u6700\u7ec8 CPA \u90fd\u5fc5\u987b\u66f4\u5bbd\u3002</p> <p></p>"},{"location":"Part_02/08/#83","title":"8.3 \u534e\u83b1\u571f\u6811\u4e0e\u8fbe\u8fbe\u6811","text":"<p>The CSA tree of Fig. 8.12, which reduces seven  k-bit operands to two ( k +2 )-bit operands having the same sum, is known as a seven-input Wallace tree. More generally, an  n-input Wallace tree reduces its  k-bit inputs to two  (k + log2  n \u2212 1 )-bit outputs. Since each CSA reduces the number of operands by a factor of 1.5, the smallest height  h(n)  of an  n-input Wallace tree satisfies the following recurrence:</p> <p>\u56fe 8.12 \u7684 CSA \u6811\u5c06\u4e03\u4e2a k \u4f4d\u64cd\u4f5c\u6570\u51cf\u5c11\u4e3a\u5177\u6709\u76f8\u540c\u548c\u7684\u4e24\u4e2a \\((k+2)\\) \u4f4d\u64cd\u4f5c\u6570\uff0c\u79f0\u4e3a\u4e03\u8f93\u5165\u534e\u83b1\u58eb\u6811\u3002\u66f4\u4e00\u822c\u5730\uff0cn \u8f93\u5165\u534e\u83b1\u58eb\u6811\u5c06\u5176 k \u4f4d\u8f93\u5165\u51cf\u5c11\u4e3a\u4e24\u4e2a \\((k + \\log_2 n \u2212 1)\\) \u4f4d\u8f93\u51fa\u3002\u7531\u4e8e\u6bcf\u4e2a CSA \u5c06\u64cd\u4f5c\u6570\u6570\u91cf\u51cf\u5c11 1.5 \u500d\uff0c\u56e0\u6b64 n \u8f93\u5165\u534e\u83b1\u58eb\u6811\u7684\u6700\u5c0f\u9ad8\u5ea6 \\(h(n)\\) \u6ee1\u8db3\u4ee5\u4e0b\u9012\u5f52\u5f0f\uff1a</p> \\[ h(n) = 1 + h(\\left \\lceil 2 n/ 3 \\right \\rceil) \\] <p>Applying this recurrence provides an exact value for the height of an  n-input Wallace tree. If we ignore the ceiling operator in the preceding equation and write it as  h(n) = 1 +  h( 2 n/ 3 ), we obtain a lower bound for the height,  h(n) \u2265 log  (*1.5  *n/ 2 ), where equality occurs only for  n = 2, 3. Another way to look at the preceding relationship between the number of inputs and the tree height is to find the maximum number of inputs  n(h)  that can be reduced to two outputs by an  h-level tree. The recurrence for  n( h) is </p> <p>\u5e94\u7528\u6b64\u9012\u63a8\u5f0f\u53ef\u4ee5\u63d0\u4f9b n \u8f93\u5165\u534e\u83b1\u58eb\u6811\u7684\u9ad8\u5ea6\u7684\u7cbe\u786e\u503c\u3002\u5982\u679c\u6211\u4eec\u5ffd\u7565\u4e0a\u5f0f\u4e2d\u7684\u4e0a\u9650\u7b97\u5b50\uff0c\u5c06\u5176\u5199\u4e3a \\(h(n) = 1 + h( 2 n/ 3 )\\)\uff0c\u6211\u4eec\u5f97\u5230\u9ad8\u5ea6\u7684\u4e0b\u754c\uff0c\\(h(n) \u2265 \\log_{1.5}(n/2)\\)\uff0c\u5176\u4e2d\u76f8\u7b49\u4ec5\u5f53 \\(n = 2, 3\\) \u65f6\u53d1\u751f\u3002\u67e5\u770b\u8f93\u5165\u6570\u91cf\u4e0e\u6811\u9ad8\u4e4b\u95f4\u524d\u8ff0\u5173\u7cfb\u7684\u53e6\u4e00\u79cd\u65b9\u6cd5\u662f\u627e\u5230\u53ef\u4ee5\u901a\u8fc7 h \u5c42\u6811\u51cf\u5c11\u4e3a\u4e24\u4e2a\u8f93\u51fa\u7684\u6700\u5927\u8f93\u5165\u6570\u91cf n(h)\u3002 n( h) \u7684\u9012\u63a8\u5f0f\u4e3a </p> \\[ n(h) = \\left \\lfloor 3 n(h \u2212 1 )/ 2 \\right \\rfloor \\] <p>Again ignoring the floor operator, we obtain the upper bound  n(h) \u2264 2 ( 3 / 2 )h. The lower bound  n(h) &gt;  2 ( 3 / 2 )h\u22121 is also easily established. The exact value of  n(h)  for 0 \u2264  h \u2264 20 is given in Table 8.1. </p> <p>\u518d\u6b21\u5ffd\u7565\u4e0b\u53d6\u6574\u8fd0\u7b97\u7b26\uff0c\u6211\u4eec\u5f97\u5230\u4e0a\u9650 \\(n(h) \u2264 2 ( 3 / 2 )^h\\)\u3002\u4e0b\u754c \\(n(h) &gt; 2(3/2)^{h\u22121}\\) \u4e5f\u5f88\u5bb9\u6613\u5efa\u7acb\u3002\u8868 8.1 \u7ed9\u51fa\u4e86 \\(0 \u2264 h \u2264 20\\) \u65f6 \\(n(h)\\) \u7684\u7cbe\u786e\u503c\u3002</p> <p></p> <p>In Wallace trees, we reduce the number of operands at the earliest opportunity (see the example in Fig. 8.10). In other words, if there are  m  dots in a column, we immediately apply  m/ 3 FAs to that column. This tends to minimize the overall delay by making the final CPA as short as possible. </p> <p>\u5728\u534e\u83b1\u58eb\u6811\u4e2d\uff0c\u6211\u4eec\u5c3d\u65e9\u51cf\u5c11\u64cd\u4f5c\u6570\u7684\u6570\u91cf\uff08\u53c2\u89c1\u56fe 8.10 \u4e2d\u7684\u793a\u4f8b\uff09\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u5982\u679c\u4e00\u5217\u4e2d\u6709 m \u4e2a\u70b9\uff0c\u6211\u4eec\u7acb\u5373\u5c06 \\(\\left \\lfloor m/3 \\right \\rfloor\\) \u4e2a FA \u5e94\u7528\u4e8e\u8be5\u5217\u3002\u901a\u8fc7\u4f7f\u6700\u7ec8 CPA \u5c3d\u53ef\u80fd\u77ed\uff0c\u53ef\u4ee5\u6700\u5927\u9650\u5ea6\u5730\u51cf\u5c11\u603b\u4f53\u5ef6\u8fdf\u3002</p> <p>However, the delay of a fast adder is usually not a smoothly increasing function of the word width. A carry-lookahead adder, for example, may have essentially the same delay for word widths of 17\u201332 bits. In Dadda trees, we reduce the number of operands to the next lower value of  n(h)  in Table 8.1 using the fewest FAs and HAs possible. The justification is that seven, eight, or nine operands, say, require four CSA levels; thus there is no point in reducing the number of operands below the next lower  n( h) value in the table, since this would not lead to a faster tree. </p> <p>\u7136\u800c\uff0c\u5feb\u901f\u52a0\u6cd5\u5668\u7684\u5ef6\u8fdf\u901a\u5e38\u4e0d\u662f\u5b57\u5bbd\u7684\u5e73\u6ed1\u589e\u52a0\u51fd\u6570\u3002\u4f8b\u5982\uff0c\u8d85\u524d\u8fdb\u4f4d\u52a0\u6cd5\u5668\u5bf9\u4e8e 17~32 \u4f4d\u5b57\u5bbd\u53ef\u80fd\u5177\u6709\u57fa\u672c\u76f8\u540c\u7684\u5ef6\u8fdf\u3002\u5728 Dadda \u6811\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u5c3d\u53ef\u80fd\u5c11\u7684 FA \u548c HA \u5c06\u64cd\u4f5c\u6570\u7684\u6570\u91cf\u51cf\u5c11\u5230\u8868 8.1 \u4e2d\u7684\u4e0b\u4e00\u4e2a\u8f83\u4f4e\u7684 \\(n(h)\\) \u503c\u3002\u7406\u7531\u662f\u4e03\u4e2a\u3001\u516b\u4e2a\u6216\u4e5d\u4e2a\u64cd\u4f5c\u6570\u9700\u8981\u56db\u4e2a CSA \u7ea7\u522b\uff1b\u56e0\u6b64\uff0c\u51cf\u5c11\u8868\u4e2d\u4e0b\u4e00\u4e2a\u8f83\u4f4e\u7684 n(h) \u503c\u4ee5\u4e0b\u7684\u64cd\u4f5c\u6570\u6570\u91cf\u662f\u6ca1\u6709\u610f\u4e49\u7684\uff0c\u56e0\u4e3a\u8fd9\u4e0d\u4f1a\u5bfc\u81f4\u66f4\u5feb\u7684\u6811\u3002</p> <p>Let us redo the example of Fig. 8.10 by means of Dadda\u2019s strategy. Figure 8.14 shows the result. We start with seven rows of dots, so our first task is to reduce the number of rows to the next lower n(h) value (i.e., 6). This can be done by using 6 FAs; next, we aim for four rows, leading to the use of 11 FAs, and so on. In this particular example, the Wallace and Dadda approaches result in the same number of FAs and HAs and the same width for the CPA. Again, the CPA width could have been reduced to 6 bits by using an extra HA in bit position 1.</p> <p>\u8ba9\u6211\u4eec\u7528Dadda\u7684\u7b56\u7565\u91cd\u505a\u56fe8.10\u7684\u4f8b\u5b50\u3002\u56fe 8.14 \u663e\u793a\u4e86\u7ed3\u679c\u3002\u6211\u4eec\u4ece\u4e03\u884c\u70b9\u5f00\u59cb\uff0c\u6240\u4ee5\u6211\u4eec\u7684\u9996\u8981\u4efb\u52a1\u662f\u51cf\u5c11\u70b9\u7684\u6570\u91cf\u884c\u5230\u4e0b\u4e00\u4e2a\u8f83\u4f4e\u7684 n(h) \u503c\uff08\u5373 6\uff09\u3002\u8fd9\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528 6 \u4e2a FA \u6765\u5b8c\u6210\uff1b\u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u7684\u76ee\u6807\u662f\u56db\u884c\uff0c\u4ece\u800c\u4f7f\u7528 11 \u4e2a FA\uff0c\u4f9d\u6b64\u7c7b\u63a8\u3002\u5728\u6b64\u7279\u5b9a\u793a\u4f8b\u4e2d\uff0cWallace \u548c Dadda \u65b9\u6cd5\u4f1a\u4ea7\u751f\u76f8\u540c\u6570\u91cf\u7684 FA \u548c HA\uff0c\u4ee5\u53ca\u76f8\u540c\u7684 CPA \u5bbd\u5ea6\u3002\u540c\u6837\uff0c\u901a\u8fc7\u5728\u4f4d\u4f4d\u7f6e 1 \u4e2d\u4f7f\u7528\u989d\u5916\u7684 HA\uff0cCPA \u5bbd\u5ea6\u53ef\u4ee5\u51cf\u5c11\u5230 6 \u4f4d\u3002</p> <p></p> <p>Since a CPA has a carry-in signal that can be used to accommodate one of the dots, it is sometimes possible to reduce the complexity of the CSA tree by leaving three dots in the least-significant position of the adder. Figure 8.15 shows the same example as in Figs. 8.10 and 8.14, but with two FAs replaced with HAs, leaving an extra dot in each of the bit positions 1 and 2.</p> <p>\u7531\u4e8e CPA \u5177\u6709\u8fdb\u4f4d\u4fe1\u53f7\uff0c\u53ef\u7528\u4e8e\u5bb9\u7eb3\u5176\u4e2d\u4e00\u4e2a\u70b9\uff0c\u56e0\u6b64\u6709\u65f6\u53ef\u4ee5\u901a\u8fc7\u4fdd\u7559\u4e09\u4e2a\u70b9\u6765\u964d\u4f4e CSA \u6811\u7684\u590d\u6742\u6027\u5728\u52a0\u6cd5\u5668\u7684\u6700\u4f4e\u6709\u6548\u4f4d\u7f6e\u3002\u56fe 8.15 \u663e\u793a\u4e86\u4e0e\u56fe 8.15 \u76f8\u540c\u7684\u793a\u4f8b\u3002 8.10 \u548c 8.14\uff0c\u4f46\u7528 HA \u66ff\u6362\u4e24\u4e2a FA\uff0c\u5728\u4f4d\u4f4d\u7f6e 1 \u548c 2 \u4e2d\u5404\u7559\u4e0b\u4e00\u4e2a\u989d\u5916\u7684\u70b9\u3002</p> <p></p>"},{"location":"Part_02/08/#84","title":"8.4 \u5e76\u884c\u8ba1\u6570\u5668\u4e0e\u5e76\u884c\u538b\u7f29\u5668","text":"<p>A 1-bit FA is sometimes referred to as a \\((3; 2)\\)-counter, meaning that it counts the number of 1s among its 3 input bits and represents the result as a 2-bit number. This can be easily generalized: an \\((n; \\left\\lceil \\log_2(n+1)\\right \\rceil)\\)-counter has n inputs and produces a \\(\\left\\lceil \\log_2(n+1)\\right \\rceil\\)-bit binary output representing the number of 1s among its n inputs. Such a circuit is also known as an n-input parallel counter.</p> <p>1 \u4f4d FA \u6709\u65f6\u79f0\u4e3a \\((3; 2)\\)-\u8ba1\u6570\u5668\uff0c\u8fd9\u610f\u5473\u7740\u5b83\u8ba1\u7b97 3 \u4e2a\u8f93\u5165\u4f4d\u4e2d 1 \u7684\u6570\u91cf\uff0c\u5e76\u5c06\u7ed3\u679c\u8868\u793a\u4e3a 2 \u4f4d\u6570\u5b57\u3002\u8fd9\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u63a8\u5e7f\uff1a \\((n; \\left\\lceil \\log_2(n+1)\\right \\rceil)\\)\u8ba1\u6570\u5668\u6709 n \u4e2a\u8f93\u5165\uff0c\u5e76\u4ea7\u751f\u4e00\u4e2a\\(\\left\\lceil \\log_2(n+1)\\right \\rceil\\)-\u4f4d\u4e8c\u8fdb\u5236\u8f93\u51fa\uff0c\u8868\u793a\u5176 n \u4e2a\u8f93\u5165\u4e2d 1 \u7684\u6570\u91cf\u3002\u8fd9\u79cd\u7535\u8def\u4e5f\u79f0\u4e3a n \u8f93\u5165\u5e76\u884c\u8ba1\u6570\u5668\u3002</p> <p>A 10-input parallel counter, or a (10; 4)-counter, is depicted in Fig. 8.16 in terms of both dot notation and circuit diagram with FAs and HAs. A row of such (10; 4)-counters, one per bit position, can reduce a set of 10 binary numbers to 4 binary numbers. The dot notation representation of this reduction is similar to that of (3; 2)-counters, except that each diagonal line connecting the outputs of a (10; 4)-counter will go through four dots. A (7; 3)-counter can be similarly designed.</p> <p>\u56fe 8.16 \u4e2d\u7528\u70b9\u8868\u793a\u6cd5\u548c\u5e26\u6709 FA \u548c HA \u7684\u7535\u8def\u56fe\u63cf\u8ff0\u4e86 10 \u8f93\u5165\u5e76\u884c\u8ba1\u6570\u5668\u6216 \\((10; 4)\\) \u8ba1\u6570\u5668\u3002\u4e00\u6392\u8fd9\u6837\u7684 \\((10; 4)\\) \u8ba1\u6570\u5668\uff0c\u6bcf\u4e2a\u4f4d\u4f4d\u7f6e\u4e00\u4e2a\uff0c\u53ef\u4ee5\u5c06\u4e00\u7ec4 10 \u4e2a\u4e8c\u8fdb\u5236\u6570\u51cf\u5c11\u5230 4 \u4e2a\u4e8c\u8fdb\u5236\u6570\u3002\u8fd9\u79cd\u5f52\u7ea6\u7684\u70b9\u8868\u793a\u6cd5\u4e0e \\((3; 2)\\) \u8ba1\u6570\u5668\u7684\u70b9\u8868\u793a\u6cd5\u7c7b\u4f3c\uff0c\u53ea\u662f\u8fde\u63a5 (10; 4) \u8ba1\u6570\u5668\u8f93\u51fa\u7684\u6bcf\u6761\u5bf9\u89d2\u7ebf\u5c06\u7ecf\u8fc7\u56db\u4e2a\u70b9\u3002(7;3)\u8ba1\u6570\u5668\u53ef\u4ee5\u7c7b\u4f3c\u5730\u8bbe\u8ba1\u3002</p> <p></p> <p>Even though a circuit that counts the number of 1s among  n  inputs is known as a parallel counter, we note that this does not constitute a true generalization of the notion of a sequential counter. A sequential counter receives 1 bit (the count signal) and adds it to a stored count. A parallel counter, then, could have been defined as a circuit that receives n  count signals and adds them to a stored count, thus in effect incrementing the count by the sum of the input count signals. Such a circuit has been called an \u201caccumulative parallel counter\u201d [Parh95]. An accumulative parallel counter can be built from a parallel incrementer (a combinational circuit receiving a number and producing the sum of the input number and  n  count signals at the output) along with a storage register. </p> <p>\u5c3d\u7ba1\u8ba1\u7b97 n \u4e2a\u8f93\u5165\u4e2d 1 \u7684\u6570\u91cf\u7684\u7535\u8def\u88ab\u79f0\u4e3a\u5e76\u884c\u8ba1\u6570\u5668\uff0c\u4f46\u6211\u4eec\u6ce8\u610f\u5230\u8fd9\u5e76\u4e0d\u6784\u6210\u987a\u5e8f\u8ba1\u6570\u5668\u6982\u5ff5\u7684\u771f\u6b63\u6982\u62ec\u3002\u987a\u5e8f\u8ba1\u6570\u5668\u63a5\u6536 1 \u4f4d\uff08\u8ba1\u6570\u4fe1\u53f7\uff09\u5e76\u5c06\u5176\u6dfb\u52a0\u5230\u5b58\u50a8\u7684\u8ba1\u6570\u4e2d\u3002\u90a3\u4e48\uff0c\u5e76\u884c\u8ba1\u6570\u5668\u53ef\u4ee5\u5b9a\u4e49\u4e3a\u63a5\u6536 n \u4e2a\u8ba1\u6570\u4fe1\u53f7\u5e76\u5c06\u5b83\u4eec\u6dfb\u52a0\u5230\u5b58\u50a8\u7684\u8ba1\u6570\u4e2d\u7684\u7535\u8def\uff0c\u4ece\u800c\u5b9e\u9645\u4e0a\u5c06\u8ba1\u6570\u589e\u52a0\u4e86\u8f93\u5165\u8ba1\u6570\u4fe1\u53f7\u7684\u603b\u548c\u3002\u8fd9\u6837\u7684\u7535\u8def\u88ab\u79f0\u4e3a\u201c\u7d2f\u79ef\u5e76\u884c\u8ba1\u6570\u5668\u201d[Parh95]\u3002\u7d2f\u79ef\u5e76\u884c\u8ba1\u6570\u5668\u53ef\u4ee5\u7531\u5e76\u884c\u589e\u91cf\u5668\uff08\u63a5\u6536\u6570\u5b57\u5e76\u5728\u8f93\u51fa\u5904\u4ea7\u751f\u8f93\u5165\u6570\u5b57\u548c n \u4e2a\u8ba1\u6570\u4fe1\u53f7\u4e4b\u548c\u7684\u7ec4\u5408\u7535\u8def\uff09\u548c\u5b58\u50a8\u5bc4\u5b58\u5668\u6765\u6784\u5efa\u3002</p> <p>Both parallel and accumulative parallel counters can be extended by considering signed count signals. These would constitute generalizations of sequential up/down counters [Parh89]. Accumulative and up/down parallel counters have been applied to the design of efficient Hamming weight comparators, circuits that are used to decide whether the number of 1s in a given bit-vector is greater than or equal to a threshold, or to determine which of two bit-vectors contains more 1s [Parh09]. </p> <p>\u5e76\u884c\u548c\u7d2f\u79ef\u5e76\u884c\u8ba1\u6570\u5668\u90fd\u53ef\u4ee5\u901a\u8fc7\u8003\u8651\u6709\u7b26\u53f7\u8ba1\u6570\u4fe1\u53f7\u6765\u6269\u5c55\u3002\u8fd9\u4e9b\u5c06\u6784\u6210\u987a\u5e8f\u52a0/\u51cf\u8ba1\u6570\u5668\u7684\u6982\u62ec[Parh89]\u3002\u7d2f\u52a0\u548c\u5411\u4e0a/\u5411\u4e0b\u5e76\u884c\u8ba1\u6570\u5668\u5df2\u5e94\u7528\u4e8e\u9ad8\u6548\u6c49\u660e\u6743\u91cd\u6bd4\u8f83\u5668\u7684\u8bbe\u8ba1\uff0c\u8be5\u7535\u8def\u7528\u4e8e\u786e\u5b9a\u7ed9\u5b9a\u4f4d\u5411\u91cf\u4e2d 1 \u7684\u6570\u91cf\u662f\u5426\u5927\u4e8e\u6216\u7b49\u4e8e\u9608\u503c\uff0c\u6216\u786e\u5b9a\u4e24\u4e2a\u4f4d\u5411\u91cf\u4e2d\u54ea\u4e00\u4e2a\u5305\u542b\u66f4\u591a 1 [Parh09]\u3002</p> <p>A parallel counter reduces a number of dots in the same bit position into dots in different positions (one in each). This idea can be easily generalized to circuits that receive \u201cdot patterns\u201d (not necessarily in a single column) and convert them to other dot patterns (not necessarily one in each column). If the output dot pattern has fewer dots than the input dot pattern, compression takes place; repeated use of such circuits can eventually lead to the reduction of  n  numbers to a small set of numbers (ideally two). </p> <p>\u5e76\u884c\u8ba1\u6570\u5668\u5c06\u540c\u4e00\u4f4d\u4f4d\u7f6e\u4e0a\u7684\u591a\u4e2a\u70b9\u51cf\u5c11\u4e3a\u4e0d\u540c\u4f4d\u7f6e\u4e0a\u7684\u70b9\uff08\u6bcf\u4e2a\u70b9\u4e00\u4e2a\uff09\u3002\u8fd9\u4e2a\u60f3\u6cd5\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u63a8\u5e7f\u5230\u63a5\u6536\u201c\u70b9\u56fe\u6848\u201d\uff08\u4e0d\u4e00\u5b9a\u5728\u5355\u5217\u4e2d\uff09\u5e76\u5c06\u5176\u8f6c\u6362\u4e3a\u5176\u4ed6\u70b9\u56fe\u6848\uff08\u4e0d\u4e00\u5b9a\u5728\u6bcf\u4e00\u5217\u4e2d\uff09\u7684\u7535\u8def\u3002\u5982\u679c\u8f93\u51fa\u70b9\u56fe\u6848\u7684\u70b9\u6570\u5c11\u4e8e\u8f93\u5165\u70b9\u56fe\u6848\u7684\u70b9\u6570\uff0c\u5219\u8fdb\u884c\u538b\u7f29\uff1b\u91cd\u590d\u4f7f\u7528\u8fd9\u6837\u7684\u7535\u8def\u6700\u7ec8\u53ef\u4ee5\u5c06n\u4e2a\u6570\u5b57\u51cf\u5c11\u5230\u4e00\u5c0f\u7ec4\u6570\u5b57\uff08\u6700\u597d\u662f\u4e24\u4e2a\uff09\u3002</p> <p>A generalized parallel counter (parallel compressor) is characterized by the number of dots in each input column and in each output column. We do not consider such circuits in their full generality but limit ourselves to those that output a single dot in each column. Thus, the output side of such parallel compressors is again characterized by a single integer representing the number of columns spanned by the output. The input side is characterized by a sequence of integers corresponding to the number of inputs in various columns. </p> <p>\u5e7f\u4e49\u5e76\u884c\u8ba1\u6570\u5668\uff08\u5e76\u884c\u538b\u7f29\u5668\uff09\u7684\u7279\u5f81\u5728\u4e8e\u6bcf\u4e2a\u8f93\u5165\u5217\u548c\u6bcf\u4e2a\u8f93\u51fa\u5217\u4e2d\u7684\u70b9\u6570\u3002\u6211\u4eec\u5e76\u4e0d\u8003\u8651\u6b64\u7c7b\u7535\u8def\u7684\u5168\u90e8\u666e\u904d\u6027\uff0c\u800c\u662f\u5c06\u81ea\u5df1\u9650\u5236\u5728\u6bcf\u5217\u4e2d\u8f93\u51fa\u5355\u4e2a\u70b9\u7684\u7535\u8def\u3002\u56e0\u6b64\uff0c\u8fd9\u79cd\u5e76\u884c\u538b\u7f29\u5668\u7684\u8f93\u51fa\u4fa7\u518d\u6b21\u7531\u8868\u793a\u8f93\u51fa\u8de8\u8d8a\u7684\u5217\u6570\u7684\u5355\u4e2a\u6574\u6570\u6765\u8868\u5f81\u3002\u8f93\u5165\u4fa7\u7684\u7279\u5f81\u662f\u4e0e\u5404\u5217\u4e2d\u7684\u8f93\u5165\u6570\u91cf\u76f8\u5bf9\u5e94\u7684\u6574\u6570\u5e8f\u5217\u3002</p> <p>For example, a (4, 4; 4)-counter receives 4 bits in each of two adjacent columns and produces a 4-bit number representing the sum of the four 2-bit numbers received. Similarly, a (5, 5; 4)-counter, depicted in Fig. 8.17, reduces five 2-bit numbers to a 4-bit number. The numbers of input dots in various columns do not have to be the same. For example, a (4, 6; 4)-counter receives 6 bits of weight 1 and 4 bits of weight 2 and delivers their weighted sum in the form of a 4-bit binary number. For a counter of this type to be feasible, the sum of the output weights must equal or exceed the sum of its input weights. In other words, if there are  \\(n_j\\) dots in each of  h  input columns, \\(0 \u2264  j \u2264  h \u2212 1\\), the associated generalized parallel counter, denoted as \\(( n_{h\u22121}, ..., n_1, n_0; k)\\)-counter, is feasible only if  \\(\\sum(n_j 2^j) \u2264 2^k \u2212 1\\). </p> <p>\u4f8b\u5982\uff0c(4, 4; 4) \u8ba1\u6570\u5668\u63a5\u6536\u4e24\u4e2a\u76f8\u90bb\u5217\u4e2d\u6bcf\u4e00\u5217\u4e2d\u7684 4 \u4f4d\uff0c\u5e76\u751f\u6210\u8868\u793a\u63a5\u6536\u5230\u7684\u56db\u4e2a 2 \u4f4d\u6570\u5b57\u4e4b\u548c\u7684 4 \u4f4d\u6570\u5b57\u3002\u7c7b\u4f3c\u5730\uff0c\u56fe 8.17 \u4e2d\u6240\u793a\u7684 (5, 5; 4) \u8ba1\u6570\u5668\u5c06\u4e94\u4e2a 2 \u4f4d\u6570\u5b57\u51cf\u5c11\u4e3a 4 \u4f4d\u6570\u5b57\u3002\u5404\u5217\u4e2d\u7684\u8f93\u5165\u70b9\u7684\u6570\u91cf\u4e0d\u5fc5\u76f8\u540c\u3002\u4f8b\u5982\uff0c(4, 6; 4) \u8ba1\u6570\u5668\u63a5\u6536 6 \u4f4d\u6743\u91cd 1 \u548c 4 \u4f4d\u6743\u91cd 2\uff0c\u5e76\u4ee5 4 \u4f4d\u4e8c\u8fdb\u5236\u6570\u7684\u5f62\u5f0f\u4f20\u9001\u5b83\u4eec\u7684\u52a0\u6743\u548c\u3002\u4e3a\u4e86\u4f7f\u8fd9\u79cd\u7c7b\u578b\u7684\u8ba1\u6570\u5668\u53ef\u884c\uff0c\u8f93\u51fa\u6743\u91cd\u7684\u603b\u548c\u5fc5\u987b\u7b49\u4e8e\u6216\u8d85\u8fc7\u5176\u8f93\u5165\u6743\u91cd\u7684\u603b\u548c\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u5982\u679c h \u4e2a\u8f93\u5165\u5217\u4e2d\u7684\u6bcf\u4e00\u5217\u4e2d\u6709 \\(n_j\\) \u4e2a\u70b9\uff0c\\(0 \u2264 j \u2264 h \u2212 1\\)\uff0c\u5219\u5173\u8054\u7684\u5e7f\u4e49\u5e76\u884c\u8ba1\u6570\u5668\uff0c\u8868\u793a\u4e3a \\(( n_{h\u22121}, ..., n_1, n_0; k)\\) \u8ba1\u6570\u5668\uff0c\u4ec5\u5f53\\(\\sum(n_j 2^j) \u2264 2^k \u2212 1\\)\u65f6\u624d\u53ef\u884c\u3002</p> <p></p> <p>Generalized parallel counters are quite powerful. For example, a 4-bit binary FA is really a (2, 2, 2, 3; 5)-counter. </p> <p>\u5e7f\u4e49\u5e76\u884c\u8ba1\u6570\u5668\u975e\u5e38\u5f3a\u5927\u3002\u4f8b\u5982\uff0c4 \u4f4d\u4e8c\u8fdb\u5236 FA \u5b9e\u9645\u4e0a\u662f\u4e00\u4e2a (2, 2, 2, 3; 5) \u8ba1\u6570\u5668\u3002</p> <p>Since our goal in multioperand carry-save addition is to reduce  n  numbers to two numbers, we sometimes talk of ( n; 2)-counters, even though, with our preceding definition, this does not make sense for  n &gt;  3. By an ( n; 2)-counter,  n &gt;  3, we usually mean a slice of a circuit that helps us reduce  n  numbers to two numbers when suitably replicated.  Slice  i  of the circuit receives  n  input bits in position  i, plus transfer or \u201ccarry\u201d bits from one or more positions to the right ( i \u2212 1,  i \u2212 2, etc.), and produces output bits in the two positions  i  and  i + 1 plus transfer bits into one or more higher positions ( i + 1,  i + 2, etc.). </p> <p>\u7531\u4e8e\u6211\u4eec\u5728\u591a\u64cd\u4f5c\u6570\u8fdb\u4f4d\u4fdd\u5b58\u52a0\u6cd5\u4e2d\u7684\u76ee\u6807\u662f\u5c06 n \u4e2a\u6570\u5b57\u51cf\u5c11\u5230\u4e24\u4e2a\u6570\u5b57\uff0c\u56e0\u6b64\u6211\u4eec\u6709\u65f6\u4f1a\u8c08\u8bba \\((n; 2)\\) \u8ba1\u6570\u5668\uff0c\u5c3d\u7ba1\u6839\u636e\u6211\u4eec\u524d\u9762\u7684\u5b9a\u4e49\uff0c\u8fd9\u5bf9\u4e8e n &gt; 3 \u6765\u8bf4\u6ca1\u6709\u610f\u4e49\u3002\u901a\u8fc7 \\(( n; 2)\\) \u8ba1\u6570\u5668\uff0cn &gt; 3\uff0c\u6211\u4eec\u901a\u5e38\u6307\u7684\u662f\u7535\u8def\u7684\u4e00\u4e2a\u5207\u7247\uff0c\u5728\u9002\u5f53\u590d\u5236\u65f6\u53ef\u4ee5\u5e2e\u52a9\u6211\u4eec\u5c06 n \u4e2a\u6570\u5b57\u51cf\u5c11\u5230\u4e24\u4e2a\u6570\u5b57\u3002\u7535\u8def\u7684\u5207\u7247 \\(i\\) \u5728\u4f4d\u7f6e \\(i\\) \u63a5\u6536 \\(n\\) \u4e2a\u8f93\u5165\u4f4d\uff0c\u52a0\u4e0a\u4ece\u4e00\u4e2a\u6216\u591a\u4e2a\u4f4d\u7f6e\u5411\u53f3\u4f20\u8f93\u6216\u201c\u8fdb\u4f4d\u201d\u4f4d\uff08\\(i \u2212 1\\)\u3001\\(i \u2212 2\\) \u7b49\uff09\uff0c\u5e76\u5728\u4e24\u4e2a\u4f4d\u7f6e \\(i\\) \u548c \\(i + 1\\) \u4e2d\u4ea7\u751f\u8f93\u51fa\u4f4d\uff0c\u52a0\u4e0a\u5c06\u4f4d\u4f20\u8f93\u5230\u4e00\u4e2a\u6216\u591a\u4e2a\u66f4\u9ad8\u4f4d\u7f6e\uff08\\(i + 1\\)\u3001\\(i + 2\\) \u7b49\uff09\u3002</p> <p>Figure 8.18 shows the block diagram of an ( n; 2)-counter, composed of  k  identical circuit slices with horizontal interconnections among them. Each slice combines  n  input bits with a number of carries coming from slices to its right, producing 2 output bits along with carries that are sent to its left. If  \u03c8j  denotes the number of transfer bits from slice  i  to slice  i +  j, the fundamental inequality to be satisfied for this scheme to work is </p> <p>\u56fe8.18\u663e\u793a\u4e86(n;2)\u8ba1\u6570\u5668\u7684\u6846\u56fe\uff0c\u8be5\u8ba1\u6570\u5668\u7531k\u4e2a\u76f8\u540c\u7684\u7535\u8def\u7247\u7ec4\u6210\uff0c\u5e76\u4e14\u5b83\u4eec\u4e4b\u95f4\u5177\u6709\u6c34\u5e73\u4e92\u8fde\u3002\u6bcf\u4e2a\u7247\u5c06 n \u4e2a\u8f93\u5165\u4f4d\u4e0e\u6765\u81ea\u5176\u53f3\u4fa7\u7247\u7684\u591a\u4e2a\u8fdb\u4f4d\u7ec4\u5408\u8d77\u6765\uff0c\u4ea7\u751f 2 \u4e2a\u8f93\u51fa\u4f4d\u4ee5\u53ca\u53d1\u9001\u5230\u5176\u5de6\u4fa7\u7684\u8fdb\u4f4d\u3002\u5982\u679c \\(\u03c8j\\) \u8868\u793a\u4f20\u8f93\u4f4d\u6570\u5c06 i \u5207\u7247\u5230 i + j \u5207\u7247\uff0c\u8be5\u65b9\u6848\u5de5\u4f5c\u9700\u8981\u6ee1\u8db3\u7684\u57fa\u672c\u4e0d\u7b49\u5f0f\u4e3a</p> <p></p> <p>\\(n + \u03c8 1 + \u03c8 2 + \u03c8 3 + \u00b7 \u00b7 \u00b7 \u2264 3 + 2 \u03c8 1 + 4 \u03c8 2 + 8 \u03c8 3 + \u00b7 \u00b7 \u00b7\\)</p> <p>where 3 represents the maximum value of the 2 output bits. For example, a (7; 2)-counter can be built by allowing  \u03c8 1 = 1 transfer bit from position  i  to position  i + 1 and  \u03c8 2 = 1 transfer bit into position  i + 2. For maximum speed, the circuit slice must be designed in such a way that transfer signals are introduced as close to the circuit\u2019s outputs as possible, to prevent the transfers from rippling through many stages. Design of a (7; 2)-counter using these principles is left as an exercise. </p> <p>\u5176\u4e2d 3 \u8868\u793a 2 \u4e2a\u8f93\u51fa\u4f4d\u7684\u6700\u5927\u503c\u3002\u4f8b\u5982\uff0c\u53ef\u4ee5\u901a\u8fc7\u5141\u8bb8 \\(\u03c8 1 = 1\\) \u5c06\u4f4d\u4ece\u4f4d\u7f6e \\(i\\) \u4f20\u8f93\u5230\u4f4d\u7f6e \\(i + 1\\) \u4e14 \\(\u03c8 2 = 1\\) \u6765\u6784\u5efa (7; 2) \u8ba1\u6570\u5668\u5c06\u4f4d\u4f20\u8f93\u5230\u4f4d\u7f6e \\(i + 2\\)\u3002\u4e3a\u4e86\u83b7\u5f97\u6700\u5927\u901f\u5ea6\uff0c\u7535\u8def\u5207\u7247\u7684\u8bbe\u8ba1\u65b9\u5f0f\u5fc5\u987b\u4f7f\u4f20\u8f93\u4fe1\u53f7\u5c3d\u53ef\u80fd\u9760\u8fd1\u7535\u8def\u7684\u8f93\u51fa\u5f15\u5165\uff0c\u4ee5\u9632\u6b62\u4f20\u8f93\u5728\u591a\u4e2a\u7ea7\u4e2d\u4ea7\u751f\u7eb9\u6ce2\u3002\u4f7f\u7528\u8fd9\u4e9b\u539f\u7406\u8bbe\u8ba1 (7; 2) \u8ba1\u6570\u5668\u7559\u4f5c\u7ec3\u4e60\u3002</p> <p>For  n = 4, a (4; 2)-counter can be synthesized with  \u03c8 1 = 1, that is, with 1 carry bit between adjacent slices. An efficient circuit realization for such a counter will be presented in Section 11.2, in connection with reduction circuits for parallel multipliers organized as binary trees (see Fig. 11.5). </p> <p>\u5bf9\u4e8e \\(n = 4\\)\uff0c\u53ef\u4ee5\u7528 \\(\u03c8 1 = 1\\) \u5408\u6210 (4; 2) \u8ba1\u6570\u5668\uff0c\u5373\u76f8\u90bb\u7247\u4e4b\u95f4\u6709 1 \u4e2a\u8fdb\u4f4d\u4f4d\u3002\u8fd9\u79cd\u8ba1\u6570\u5668\u7684\u6709\u6548\u7535\u8def\u5b9e\u73b0\u5c06\u5728\u7b2c 11.2 \u8282\u4e2d\u4ecb\u7ecd\uff0c\u5e76\u7ed3\u5408\u4ee5\u4e8c\u53c9\u6811\u5f62\u5f0f\u7ec4\u7ec7\u7684\u5e76\u884c\u4e58\u6cd5\u5668\u7684\u7b80\u5316\u7535\u8def\uff08\u89c1\u56fe 11.5\uff09\u3002</p>"},{"location":"Part_02/08/#85","title":"8.5 \u591a\u4e2a\u6709\u7b26\u53f7\u6570\u4e4b\u548c","text":"<p>When the operands to be added are 2\u2019s-complement numbers, they must be sign-extended to the width of the final result if multiple-operand addition is to yield their correct sum. The example in Fig. 8.19 shows extension of the sign bits  xk\u22121,  yk\u22121, and  zk\u22121 across five extra positions. </p> <p>\u5f53\u8981\u76f8\u52a0\u7684\u64cd\u4f5c\u6570\u662f 2 \u7684\u8865\u7801\u6570\u5b57\u65f6\uff0c\u5982\u679c\u591a\u64cd\u4f5c\u6570\u76f8\u52a0\u8981\u4ea7\u751f\u6b63\u786e\u7684\u548c\uff0c\u5219\u5fc5\u987b\u5bf9\u5b83\u4eec\u8fdb\u884c\u7b26\u53f7\u6269\u5c55\u81f3\u6700\u7ec8\u7ed3\u679c\u7684\u5bbd\u5ea6\u3002\u56fe 8.19 \u4e2d\u7684\u793a\u4f8b\u663e\u793a\u4e86\u7b26\u53f7\u4f4d \\(x_{k\u22121}\\)\u3001\\(y_{k\u22121}\\) \u548c \\(z_{k\u22121}\\) \u8de8\u4e94\u4e2a\u989d\u5916\u4f4d\u7f6e\u7684\u6269\u5c55\u3002</p> <p>It appears, therefore, that sign extension may dramatically increase the complexity of the CSA tree used for  n-operand addition when  n  is large. However, since the sign extension bits are identical, a single FA can do the job of several FAs that would be receiving identical inputs if used. With this hardware-sharing scheme, the CSA widths are only marginally increased. For the three operands in Fig. 8.19a, a single (3; 2)-counter can be used in lieu of six that would be receiving the same input bits  xk\u22121,  yk\u22121, and  zk\u22121. </p> <p>\u56e0\u6b64\uff0c\u5f53 n \u5f88\u5927\u65f6\uff0c\u7b26\u53f7\u6269\u5c55\u53ef\u80fd\u4f1a\u663e\u7740\u589e\u52a0\u7528\u4e8e n \u64cd\u4f5c\u6570\u52a0\u6cd5\u7684 CSA \u6811\u7684\u590d\u6742\u6027\u3002\u7136\u800c\uff0c\u7531\u4e8e\u7b26\u53f7\u6269\u5c55\u4f4d\u662f\u76f8\u540c\u7684\uff0c\u56e0\u6b64\u5355\u4e2a FA \u53ef\u4ee5\u5b8c\u6210\u591a\u4e2a FA \u7684\u5de5\u4f5c\uff0c\u8fd9\u4e9b FA \u5728\u4f7f\u7528\u65f6\u5c06\u63a5\u6536\u76f8\u540c\u7684\u8f93\u5165\u3002\u901a\u8fc7\u8fd9\u79cd\u786c\u4ef6\u5171\u4eab\u65b9\u6848\uff0cCSA \u5bbd\u5ea6\u4ec5\u7565\u6709\u589e\u52a0\u3002\u5bf9\u4e8e\u56fe 8.19a \u4e2d\u7684\u4e09\u4e2a\u64cd\u4f5c\u6570\uff0c\u5355\u4e2a (3; 2)-\u8ba1\u6570\u5668\u53ef\u4ee5\u7528\u6765\u4ee3\u66ff\u63a5\u6536\u76f8\u540c\u8f93\u5165\u4f4d xk\u22121\u3001yk\u22121 \u548c zk\u22121 \u7684 6 \u4e2a\u8ba1\u6570\u5668\u3002</p> <p></p> <p>It is possible to avoid sign extension by taking advantage of the negative-weight interpretation of the sign bit in 2\u2019s-complement representation. A negative sign bit \u2212 xk\u22121 can be replaced by 1 \u2212 xk\u22121 = \u00af xk\u22121 (the complement of xk\u22121), with the extra 1 canceled by inserting a \u22121 in that same column. Multiple \u22121s in a given column can be paired, with each pair replaced by a \u22121 in the next higher column. Finally, a solitary \u22121 in a given column is replaced by 1 in that column and \u22121 in the next higher column. Eventually, all the \u22121s disappear off the left end and at most a single extra 1 is left in some of the columns.</p> <p>\u901a\u8fc7\u5229\u7528 2 \u8865\u7801\u8868\u793a\u4e2d\u7b26\u53f7\u4f4d\u7684\u8d1f\u6743\u91cd\u89e3\u91ca\uff0c\u53ef\u4ee5\u907f\u514d\u7b26\u53f7\u6269\u5c55\u3002\u8d1f\u53f7\u4f4d \\(\u2212x_{k\u22121}\\)\u53ef\u4ee5\u66ff\u6362\u4e3a \\(1 \u2212 x_{k\u22121} = \\bar{x}_{k\u22121}\\)  \uff08\\(x_{k\u22121}\\) \u7684\u8865\u7801\uff09\uff0c\u901a\u8fc7\u5728\u540c\u4e00\u5217\u4e2d\u63d2\u5165 \u22121 \u6765\u53d6\u6d88\u989d\u5916\u7684 1\u3002\u7ed9\u5b9a\u5217\u4e2d\u7684\u591a\u4e2a -1 \u53ef\u4ee5\u914d\u5bf9\uff0c\u6bcf\u5bf9\u90fd\u88ab\u4e0b\u4e00\u4e2a\u8f83\u9ad8\u5217\u4e2d\u7684 -1 \u66ff\u6362\u3002\u6700\u540e\uff0c\u7ed9\u5b9a\u5217\u4e2d\u7684\u5355\u4e2a -1 \u88ab\u8be5\u5217\u4e2d\u7684 1 \u4ee5\u53ca\u4e0b\u4e00\u4e2a\u8f83\u9ad8\u5217\u4e2d\u7684 -1 \u66ff\u6362\u3002\u6700\u7ec8\uff0c\u6240\u6709 -1 \u4ece\u5de6\u7aef\u6d88\u5931\uff0c\u5e76\u4e14\u5728\u67d0\u4e9b\u5217\u4e2d\u6700\u591a\u7559\u4e0b\u4e00\u4e2a\u989d\u5916\u7684 1\u3002</p> <p>Figure 8.19b shows how this method is applied when adding three 2\u2019s-complement numbers. The three sign bits are complemented and three \u22121s are inserted in the sign position. These three \u22121s are then replaced by a 1 in the sign position and two \u22121s in the next higher position ( k). These two \u22121s are then removed and, instead, a single \u22121 is inserted in position k + 1. The latter \u22121 is in turn replaced by a 1 in position k + 1 and a \u22121 in position k + 2, and so on. The \u22121 that moves out from the leftmost position is immaterial in view of ( k + 5)-bit 2\u2019s-complement arithmetic being performed modulo 2 k+5.</p> <p>\u56fe 8.19b \u663e\u793a\u4e86\u5728\u4e09\u4e2a 2 \u7684\u8865\u7801\u76f8\u52a0\u65f6\u5982\u4f55\u5e94\u7528\u6b64\u65b9\u6cd5\u3002\u4e09\u4e2a\u7b26\u53f7\u4f4d\u88ab\u8865\u7801\u5e76\u5728\u7b26\u53f7\u4f4d\u7f6e\u63d2\u5165\u4e09\u4e2a-1\u3002\u7136\u540e\uff0c\u8fd9\u4e09\u4e2a -1 \u5728\u7b26\u53f7\u4f4d\u7f6e\u88ab\u66ff\u6362\u4e3a 1\uff0c\u5e76\u5728\u4e0b\u4e00\u4e2a\u66f4\u9ad8\u4f4d\u7f6e (k) \u88ab\u66ff\u6362\u4e3a\u4e24\u4e2a -1\u3002\u7136\u540e\uff0c\u8fd9\u4e24\u4e2a -1 \u88ab\u79fb\u9664\uff0c\u53d6\u800c\u4ee3\u4e4b\u7684\u662f\u4e00\u4e2a -1 \u88ab\u63d2\u5165\u5230\u4f4d\u7f6e k + 1 \u4e2d\u3002\u540e\u8005\u7684 -1 \u4f9d\u6b21\u88ab\u4f4d\u7f6e k + 1 \u4e2d\u7684 1 \u548c\u4f4d\u7f6e k + 2 \u4e2d\u7684 -1 \u66ff\u6362\uff0c\u4f9d\u6b64\u7c7b\u63a8\u3002\u9274\u4e8e\u4ee5 \\(2^{k+5}\\) \u4e3a\u6a21\u6267\u884c ( k + 5) \u4f4d 2 \u7684\u8865\u7801\u7b97\u672f\uff0c\u4ece\u6700\u5de6\u8fb9\u4f4d\u7f6e\u79fb\u51fa\u7684 -1 \u5e76\u4e0d\u91cd\u8981\u3002</p>"},{"location":"Part_02/08/#86","title":"8.6 \u591a\u64cd\u4f5c\u6570\u6a21\u52a0\u6cd5\u5668","text":"<p>For the same reasons offered for modular two-operand addition in Section 7.6, on occasion we need to add n numbers modulo a given constant m. An obvious approach would be to perform the required computation in two stages: (1) Forming the proper sum of the input operands, using any of the multioperand adder designs described thus far, and (2) reducing the sum modulo m. In many cases, however, we can obtain more efficient designs by merging (interlacing) the addition and modular reduction operations.</p> <p>\u51fa\u4e8e\u4e0e\u7b2c 7.6 \u8282\u4e2d\u6a21\u4e8c\u64cd\u4f5c\u6570\u52a0\u6cd5\u76f8\u540c\u7684\u539f\u56e0\uff0c\u6709\u65f6\u6211\u4eec\u9700\u8981\u5bf9\u7ed9\u5b9a\u5e38\u91cf m \u8fdb\u884c\u6a21\u52a0 n \u4e2a\u6570\u5b57\u3002\u4e00\u79cd\u660e\u663e\u7684\u65b9\u6cd5\u662f\u5206\u4e24\u4e2a\u9636\u6bb5\u6267\u884c\u6240\u9700\u7684\u8ba1\u7b97\uff1a\uff081\uff09\u4f7f\u7528\u8fc4\u4eca\u4e3a\u6b62\u63cf\u8ff0\u7684\u4efb\u4f55\u591a\u64cd\u4f5c\u6570\u52a0\u6cd5\u5668\u8bbe\u8ba1\u5f62\u6210\u8f93\u5165\u64cd\u4f5c\u6570\u7684\u6b63\u786e\u603b\u548c\uff0c\u4ee5\u53ca\uff082\uff09\u4ee5 m \u4e3a\u6a21\u51cf\u5c11\u603b\u548c\u3002\u7136\u800c\uff0c\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u5408\u5e76\uff08\u4ea4\u9519\uff09\u52a0\u6cd5\u548c\u6a21\u7ea6\u7b80\u64cd\u4f5c\u6765\u83b7\u5f97\u66f4\u6709\u6548\u7684\u8bbe\u8ba1\u3002</p> <p>As in the case of two-operand addition, the three special moduli 2 k , 2 k \u2212 1, and 2 k + 1 are easier to deal with. For m = 2 k , we simply drop any bit that is produced in column k. This simplification is depicted in Fig. 8.20a. Thus, for example, no CSA in Fig. 8.12 needs to extend past position k \u2212 1 in this case. For m = 2 k \u2212 1, a bit generated in position k is reinserted into position 0, as shown in Fig. 8.20b. Given the empty slot available in position 0, this \u201cend-around carry\u201d does not lead to an increase in latency. In the case of m = 2 k + 1, assuming nonzero operands with diminished-1 encoding, the arguments presented in Example 7.3 suggest that an inverted end-around carry (Fig. 8.20c) allows the conversion of three diminished-1 inputs to two diminished-1 outputs.</p> <p>\u4e0e\u53cc\u64cd\u4f5c\u6570\u52a0\u6cd5\u7684\u60c5\u51b5\u4e00\u6837\uff0c\u4e09\u4e2a\u7279\u6b8a\u6a21 \\(2^k\\) \u3001\\(2^k \u2212 1\\) \u548c \\(2^k + 1\\) \u66f4\u5bb9\u6613\u5904\u7406\u3002\u5bf9\u4e8e \\(m = 2^k\\) \uff0c\u6211\u4eec\u53ea\u9700\u5220\u9664 k \u5217\u4e2d\u751f\u6210\u7684\u4efb\u4f55\u4f4d\u5373\u53ef\u3002\u8fd9\u79cd\u7b80\u5316\u5982\u56fe 8.20 a \u6240\u793a\u3002\u56e0\u6b64\uff0c\u4f8b\u5982\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u56fe 8.12 \u4e2d\u7684 CSA \u4e0d\u9700\u8981\u5ef6\u4f38\u8d85\u8fc7\u4f4d\u7f6e k - 1\u3002\u5bf9\u4e8e \\(m = 2^k \u2212 1\\)\uff0c\u5728\u4f4d\u7f6e k \u751f\u6210\u7684\u4f4d\u88ab\u91cd\u65b0\u63d2\u5165\u5230\u4f4d\u7f6e 0\uff0c\u5982\u56fe 8.20 b \u6240\u793a\u3002\u8003\u8651\u5230\u4f4d\u7f6e 0 \u5904\u6709\u53ef\u7528\u7684\u7a7a\u69fd\uff0c\u8fd9\u79cd\u201c\u672b\u7aef\u5faa\u73af\u8fdb\u4f4d\u201d\u4e0d\u4f1a\u5bfc\u81f4\u5ef6\u8fdf\u589e\u52a0\u3002\u5728 \\(m = 2^k + 1\\) \u7684\u60c5\u51b5\u4e0b\uff0c\u5047\u8bbe\u975e\u96f6\u64cd\u4f5c\u6570\u51cf 1\u7f16\u7801\uff0c\u4f8b 7.3 \u4e2d\u63d0\u51fa\u7684\u8bba\u70b9\u8868\u660e\uff0c\u53cd\u8f6c\u7684\u672b\u7aef\u5faa\u73af\u8fdb\u4f4d\uff08\u56fe 8.20 c\uff09\u5141\u8bb8\u5c06\u4e09\u4e2a\u51cf 1 \u8f93\u5165\u8f6c\u6362\u4e3a\u4e24\u4e2a\u51cf 1\u8f93\u51fa\u3002</p> <p></p> <p>For a general modulus m, we need multioperand addition schemes that are more elaborate than (inverted) end-around carry. Many techniques have been developed for specific values of m. For example, if m is such that 2 h = 1 mod m for a fairly small value of h, one can perform tree reduction with h-bit pseudoresidues (see Section 4.5) and end-around carry [Pies94]. To apply this method to mod-21 addition of a set of n input integers in the range [0, 20], we can use any tree reduction scheme, while keeping all intermediate values in the range [0, 63]. Bits generated in column 6 are then fed back to column 0 in the same manner as the end-around carry used for modulo-63 reduction, given that 64 = 1 mod 21. Once all operands have been combined into two 6-bit values, the latter are added with end-around carry and the final 6-bit sum is reduced modulo 21. Figure 8.21 depicts an example with n = 6.</p> <p>\u5bf9\u4e8e\u4e00\u822c\u6a21\u6570 m\uff0c\u6211\u4eec\u9700\u8981\u6bd4\uff08\u53cd\u5411\uff09\u7aef\u5faa\u73af\u8fdb\u4f4d\u66f4\u590d\u6742\u7684\u591a\u64cd\u4f5c\u6570\u52a0\u6cd5\u65b9\u6848\u3002\u9488\u5bf9\u7279\u5b9a\u7684 m \u503c\uff0c\u5df2\u7ecf\u5f00\u53d1\u4e86\u8bb8\u591a\u6280\u672f\u3002\u4f8b\u5982\uff0c\u5982\u679c m \u4f7f\u5f97 \\(2^h = 1 \\mod m\\) \u5bf9\u4e8e\u76f8\u5f53\u5c0f\u7684 h \u503c\uff0c\u5219\u53ef\u4ee5\u4f7f\u7528 h \u4f4d\u4f2a\u4f59\u6570\uff08\u53c2\u89c1\u7b2c 4.5 \u8282\uff09\u548c\u7ed3\u675f\u8fdb\u4f4d\u6267\u884c\u6811\u7f29\u51cf [Pies94]\u3002\u8981\u5c06\u6b64\u65b9\u6cd5\u5e94\u7528\u4e8e [0, 20] \u8303\u56f4\u5185\u7684\u4e00\u7ec4 n \u4e2a\u8f93\u5165\u6574\u6570\u7684 mod-21 \u52a0\u6cd5\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u4efb\u4f55\u6811\u7f29\u51cf\u65b9\u6848\uff0c\u540c\u65f6\u5c06\u6240\u6709\u4e2d\u95f4\u503c\u4fdd\u6301\u5728 [0, 63] \u8303\u56f4\u5185\u3002\u7136\u540e\uff0c\u7b2c 6 \u5217\u4e2d\u751f\u6210\u7684\u4f4d\u5c06\u53cd\u9988\u5230\u7b2c 0 \u5217\uff0c\u5176\u65b9\u5f0f\u4e0e\u7528\u4e8e\u6a21 63 \u5f52\u7ea6\u7684\u7ed3\u675f\u8fdb\u4f4d\u76f8\u540c\uff0c\u5047\u8bbe \\(64 = 1 \\mod 21\\)\u3002\u4e00\u65e6\u6240\u6709\u64cd\u4f5c\u6570\u7ec4\u5408\u6210\u4e24\u4e2a 6 \u4f4d\u503c\uff0c\u540e\u8005\u5c31\u4f1a\u4e0e\u7ed3\u675f\u8fdb\u4f4d\u76f8\u52a0\uff0c\u6700\u540e\u7684 6 \u4f4d\u548c\u4f1a\u51cf\u5c11\u6a21 21\u3002\u56fe 8.21 \u63cf\u8ff0\u4e86 \\(n = 6\\) \u7684\u793a\u4f8b\u3002</p> <p></p>"},{"location":"Part_02/08/#_1","title":"\u95ee\u9898\uff08\u7565\uff09","text":""},{"location":"Part_02/08/#_2","title":"\u53c2\u8003\u6587\u732e\u548c\u8fdb\u4e00\u6b65\u9605\u8bfb","text":"<pre><code>[Dadd65] Dadda, L., \u201cSome Schemes for Parallel Multipliers,\u201d Alta Frequenza, Vol. 34,\n         pp. 349\u2013356, 1965.\n[Dadd76] Dadda, L., \u201cOn Parallel Digital Multipliers,\u201d Alta Frequenza, Vol. 45, pp. 574\u2013580,\n         1976.\n[De94]   De, M., and B. P. Sinha, \u201cFast Parallel Algorithm for Ternary Multiplication Using\n         Multivalued I2L Technology,\u201d IEEE Trans. Computers, Vol. 43, No. 5, pp. 603\u2013607,\n         1994.\n[Didi04] Didier, L. S., and P.-Y. H. Rivaille, \u201cA Comparative Study of Modular Adders,\u201d\n         Advanced Signal Processing Algorithms, Architectures, and Implementations XIV\n         (Proc. SPIE Conf.), 2004, pp. 13\u201320.\n[Fior99] Fiore, P. D., \u201cParallel Multiplication Using Fast Sorting Networks,\u201d IEEE Trans.\n         Computers, Vol. 48, No. 6, pp. 640\u2013645, 1999.\n[Fost71] Foster, C. C., and F. D. Stockton, \u201cCounting Responders in an Associative Memory,\u201d\n         IEEE Trans. Computers, Vol. 20, pp. 1580\u20131583, 1971.\n[Kore03] Koren, I., Y. Koren, and B. G. Oomman, \u201cSaturating Counters: Application and Design\n         Alternatives,\u201d Proc. 16th IEEE Symp. Computer Arithmetic, pp. 228\u2013235, 2003.\n[Parh89] Parhami, B., \u201cParallel Counters for Signed Binary Signals,\u201d Proc. 23rd Asilomar\n         Conf. Signals, Systems, and Computers, pp. 513\u2013516, 1989.\n[Parh95] Parhami, B., and C.-H. Yeh, \u201cAccumulative Parallel Counters,\u201d Proc. 29th Asilomar\n         Conf. Signals, Systems, and Computers, pp. 966\u2013970, 1995.\n[Parh99] Parhami, B., Introduction to Parallel Processing: Algorithms and Architectures,\n         Plenum, 1999.\n[Parh09] Parhami, B., \u201cEfficient Hamming Weight Comparators for Binary Vectors Based on\n         Accumulative and Up/Down Parallel Counters,\u201d IEEE Trans. Circuits and Systems II,\n         Vol. 56, No. 2, pp. 167\u2013171, 2009.\n[Pies94] Piestrak, S. J., \u201cDesign of Residue Generators and Multioperand Modular Adders\n         Using Carry-Save Adders,\u201d IEEE Trans. Computers, Vol. 43, No. 1, pp. 68\u201377, 1994.\n[Shim97] Shim, D., and W. Kim, \u201cThe Design of 16 \u00d7 16 Wave Pipelined Multiplier Using\n         Fan-In Equalization Technique,\u201d Proc. Midwest Symp. Circuits &amp; Systems, Vol. 1, pp.\n         336\u2013339, 1997.\n[Swar73] Swartzlander, E. E., \u201cParallel Counters,\u201d IEEE Trans. Computers, Vol. 22, No. 11,\n         pp. 1021\u20131024, 1973.\n[Wall64] Wallace, C. S., \u201cA Suggestion for a Fast Multiplier,\u201d IEEE Trans. Electronic\n         Computers, Vol. 13, pp. 14\u201317, 1964.\n[Wang96] Wang, Z., G. A. Jullien, and W. C. Carter, \u201cAn Efficient Tree Architecture for Modulo\n         2n + 1 Multiplication,\u201d J. VLSI Signal Processing, Vol. 14, No. 3, pp. 241\u2013248, 1996.\n</code></pre>"},{"location":"Part_03/","title":"\u4e58\u6cd5","text":"<p>MULTIPLICATION</p> <p>\u201cAt least one good reason for studying multiplication and division is that there is an infinite number of ways of performing these operations and hence there is an infinite number of PhDs (or expenses-paid visits to conferences in the USA) to be won from inventing new forms of multiplier.\u201d               \u2014 ALAN CLEMENTS , THE PRINCIPLES OF COMPUTER  HARDWARE , 1986</p> <p>\u201cCivilization is a limitless multiplication of unnecessary necessaries.\u201d               \u2014 MARK TWAIN</p> <p>\u201c\u7814\u7a76\u4e58\u6cd5\u548c\u9664\u6cd5\u7684\u81f3\u5c11\u4e00\u4e2a\u5145\u5206\u7406\u7531\u662f\uff0c\u6267\u884c\u8fd9\u4e9b\u8fd0\u7b97\u7684\u65b9\u6cd5\u6709\u65e0\u6570\u79cd\uff0c\u56e0\u6b64\u53ef\u4ee5\u901a\u8fc7\u53d1\u660e\u65b0\u5f62\u5f0f\u7684\u4e58\u6cd5\u8d62\u5f97\u65e0\u6570\u7684\u535a\u58eb\u5b66\u4f4d\uff08\u6216\u514d\u8d39\u8bbf\u95ee\u7f8e\u56fd\u7684\u4f1a\u8bae\uff09\u7684\u673a\u4f1a\u3002 \u201d               \u2014 \u827e\u4f26\u00b7\u514b\u83b1\u95e8\u8328\uff0c\u300a\u8ba1\u7b97\u673a\u786c\u4ef6\u539f\u7406\u300b\uff0c1986 \u5e74</p> <p>\u201c\u6587\u660e\u662f\u4e0d\u5fc5\u8981\u7684\u5fc5\u9700\u54c1\u7684\u65e0\u9650\u589e\u6b96\u3002\u201d               \u2014 \u9a6c\u514b\u00b7\u5410\u6e29</p> <p>MULTIPLICATION, OFTEN REALIZED BY k CYCLES OF SHIFTING AND ADDING , IS a heavily used arithmetic operation that figures prominently in signal processing and scientific applications. In this part, after examining shift/add multiplication schemes and their various implementations, we note that there are but two ways to speed up the underlying multioperand addition: reducing the number of operands to be added leads to high-radix multipliers, and devising hardware multioperand adders that minimize the latency and/or maximize the throughput leads to tree and array multipliers. Of course, speed is not the only criterion of interest. Cost, chip area, and pin limitations favor bit-serial designs, while the desire to use available building blocks leads to designs based on additive multiply modules. Finally, the special case of squaring is of interest as it leads to considerable simplification. This part consists of the following four chapters:</p> <p>**\u4e58\u6cd5\u901a\u5e38\u901a\u8fc7 k \u4e2a\u79fb\u4f4d\u548c\u52a0\u6cd5\u5faa\u73af\u6765\u5b9e\u73b0\uff0c\u662f**\u4e00\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684\u7b97\u672f\u8fd0\u7b97\uff0c\u5728\u4fe1\u53f7\u5904\u7406\u548c\u79d1\u5b66\u5e94\u7528\u4e2d\u5360\u6709\u91cd\u8981\u5730\u4f4d\u3002 \u5728\u8fd9\u4e00\u90e8\u5206\u4e2d\uff0c\u5728\u68c0\u67e5\u4e86\u79fb\u4f4d/\u52a0\u6cd5\u4e58\u6cd5\u65b9\u6848\u53ca\u5176\u5404\u79cd\u5b9e\u73b0\u4e4b\u540e\uff0c\u6211\u4eec\u6ce8\u610f\u5230\u53ea\u6709\u4e24\u79cd\u65b9\u6cd5\u53ef\u4ee5\u52a0\u901f\u5e95\u5c42\u591a\u64cd\u4f5c\u6570\u52a0\u6cd5\uff1a\u51cf\u5c11\u8981\u6dfb\u52a0\u7684\u64cd\u4f5c\u6570\u6570\u91cf\u5bfc\u81f4\u9ad8\u57fa\u6570\u4e58\u6cd5\u5668\uff0c\u4ee5\u53ca\u8bbe\u8ba1\u6700\u5c0f\u5316\u5ef6\u8fdf\u548c/\u6216\u6700\u5927\u5316\u541e\u5410\u91cf\u7684\u786c\u4ef6\u591a\u64cd\u4f5c\u6570\u52a0\u6cd5\u5668\u5bfc\u81f4\u6811\u548c\u6570\u7ec4\u4e58\u6cd5\u5668\u3002 \u5f53\u7136\uff0c\u901f\u5ea6\u5e76\u4e0d\u662f\u5174\u8da3\u7684\u552f\u4e00\u6807\u51c6\u3002 \u6210\u672c\u3001\u82af\u7247\u9762\u79ef\u548c\u5f15\u811a\u9650\u5236\u6709\u5229\u4e8e\u4f4d\u4e32\u884c\u8bbe\u8ba1\uff0c\u800c\u4f7f\u7528\u53ef\u7528\u6784\u5efa\u5757\u7684\u613f\u671b\u5bfc\u81f4\u57fa\u4e8e\u52a0\u6cd5\u4e58\u6cd5\u6a21\u5757\u7684\u8bbe\u8ba1\u3002 \u6700\u540e\uff0c\u5e73\u65b9\u7684\u7279\u6b8a\u60c5\u51b5\u5f88\u6709\u8da3\uff0c\u56e0\u4e3a\u5b83\u53ef\u4ee5\u5e26\u6765\u76f8\u5f53\u5927\u7684\u7b80\u5316\u3002 \u672c\u90e8\u5206\u7531\u4ee5\u4e0b\u56db\u7ae0\u7ec4\u6210\uff1a</p> <ul> <li>\u7b2c\u4e5d\u7ae0 \u57fa\u7840\u7684\u4e58\u6cd5\u65b9\u6848 Basic Mutiplication Schemes</li> <li>\u7b2c\u5341\u7ae0 \u9ad8\u57fa\u4e58\u6cd5\u5668 High-Radix Mutipliers</li> <li>\u7b2c\u5341\u4e00\u7ae0 \u6811\u578b\u4e58\u6cd5\u5668\u4e0e\u9635\u5217\u4e58\u6cd5\u5668 Tree and Array Multipliers</li> <li>\u7b2c\u5341\u4e8c\u7ae0 \u5176\u5b83\u4e58\u6cd5\u5668 Variations in Multipliers</li> </ul>"},{"location":"Part_03/09/","title":"9. \u57fa\u7840\u7684\u4e58\u6cd5\u65b9\u6848","text":"<p>Basic Mutiplication Schemes</p> <p>\u201cScience: That false secondary power by which we multiply distinctions.\u201d WILLIAM WORDSWORTH</p> <p>\u201c\u79d1\u5b66\uff1a\u4e00\u79cd\u865a\u5047\u7684\u6b21\u8981\u529b\u91cf\uff0c\u901a\u8fc7\u5b83\u6211\u4eec\u53ef\u4ee5\u500d\u589e\u5dee\u5f02\u3002\u201d \u5a01\u5ec9\u00b7\u534e\u5179\u534e\u65af</p> <p>The multi-operand addition process needed for multiplying two k-bit operands can be realized in k cycles of shifting and adding, with hardware, firmware, or software control of the loop. In this chapter,we review such economical,but slow,bit-at-a-time designs and set the stage for speedup methods and variations to be presented in Chapters 10\u201312. We also consider the special case of multiplication by a constant. Chapter topics include:</p> <p>\u4e24\u4e2ak\u4f4d\u64cd\u4f5c\u6570\u76f8\u4e58\u6240\u9700\u7684\u591a\u64cd\u4f5c\u6570\u52a0\u6cd5\u8fc7\u7a0b\u53ef\u4ee5\u901a\u8fc7\u5faa\u73af\u7684\u786c\u4ef6\u3001\u56fa\u4ef6\u6216\u8f6f\u4ef6\u63a7\u5236\u5728k\u4e2a\u79fb\u4f4d\u548c\u52a0\u6cd5\u5468\u671f\u4e2d\u5b9e\u73b0\u3002 \u5728\u672c\u7ae0\u4e2d\uff0c\u6211\u4eec\u56de\u987e\u4e86\u8fd9\u79cd\u7ecf\u6d4e\u4f46\u7f13\u6162\u7684\u4e00\u6b21\u8bbe\u8ba1\uff0c\u5e76\u4e3a\u7b2c 10 \u7ae0\u81f3\u7b2c 12 \u7ae0\u4e2d\u4ecb\u7ecd\u7684\u52a0\u901f\u65b9\u6cd5\u548c\u53d8\u4f53\u5960\u5b9a\u4e86\u57fa\u7840\u3002 \u6211\u4eec\u8fd8\u8003\u8651\u4e58\u4ee5\u5e38\u6570\u7684\u7279\u6b8a\u60c5\u51b5\u3002 \u7ae0\u8282\u4e3b\u9898\u5305\u62ec\uff1a</p> <ul> <li>9.1 \u79fb\u4f4d\u76f8\u52a0\u4e58\u6cd5\u7b97\u6cd5 SHIFT-ADD MULTIPLICATION ALGORITHMS</li> <li>9.2 \u7a0b\u5e8f\u5b9e\u73b0\u7684\u4e58\u6cd5 PROGRAMMED MULTIPLICATION</li> <li>9.3 \u57fa\u7840\u786c\u4ef6\u4e58\u6cd5\u5668 BASIC HARDWARE MULTIPLIERS</li> <li>9.4 \u6709\u7b26\u53f7\u6570\u4e58\u6cd5 MULTIPLICATION OF SIGNED NUMBERS</li> <li>9.5 \u4e58\u4ee5\u4e00\u4e2a\u5e38\u6570 MULTIPLICATION BY CONSTANTS</li> <li>9.6 \u9ad8\u901f\u4e58\u6cd5\u5668\u7684\u9884\u89c8 PREVIEW OF FAST MULTIPLIERS</li> </ul>"},{"location":"Part_03/09/#91","title":"9.1 \u79fb\u4f4d\u76f8\u52a0\u4e58\u6cd5\u7b97\u6cd5","text":"<p>\u6211\u4eec\u540e\u9762\u7684\u8ba8\u8bba\u4f7f\u7528\u5982\u4e0b\u7684\u8bb0\u6cd5:</p> \\[ \\begin{array}{l} a &amp;\\text{Multiplicand} &amp;a_{k\u22121}a_{k\u22122} \u00b7 \u00b7 \u00b7 a_1a_0 \\\\ x &amp;\\text{Multiplier}   &amp;x_{k\u22121}x_{k\u22122} \u00b7 \u00b7 \u00b7 x_1x_0 \\\\ p &amp;\\text{Product}      &amp;p_{2k\u22121}p_{2k\u22122} \u00b7 \u00b7 \u00b7 p_1p_0 \\end{array} \\] <p>Figure 9.1 shows the multiplication of two 4-bit unsigned binary numbers in dot notation. The two numbers a and x are shown at the top. Each of the following four rows of dots corresponds to the product of the multiplicand  a  and 1 bit of the multiplier  x, with each dot representing the product (logical AND) of two bits. Since  xj  is in {0, 1}, each term xja  is either 0 or  a. Thus, the problem of binary multiplication reduces to adding a set of numbers, each of which is 0 or a shifted version of the multiplicand  a. </p> <p>\u56fe 9.1 \u4ee5\u70b9\u8868\u793a\u6cd5\u663e\u793a\u4e86\u4e24\u4e2a 4 \u4f4d\u65e0\u7b26\u53f7\u4e8c\u8fdb\u5236\u6570\u7684\u4e58\u6cd5\u3002 \u4e24\u4e2a\u6570\u5b57 a \u548c x \u663e\u793a\u5728\u9876\u90e8\u3002 \u63a5\u4e0b\u6765\u7684\u56db\u884c\u70b9\u5206\u522b\u5bf9\u5e94\u88ab\u4e58\u6570 a \u548c\u4e58\u6570 x*\u4e2d1\u6bd4\u7279\u4f4d\u7684\u4e58\u79ef\uff0c\u6bcf\u4e2a\u70b9\u4ee3\u8868\u4e58\u79ef\uff08\u903b\u8f91\u4e0e\uff09\u3002 \u7531\u4e8e \\(x_j\\) \u4f4d\u4e8e {0, 1} \u4e2d\uff0c\u56e0\u6b64\u6bcf\u4e00\u9879 \\(x_ja\\) \u8981\u4e48\u662f 0\uff0c\u8981\u4e48\u662f *a\u3002 \u56e0\u6b64\uff0c\u4e8c\u8fdb\u5236\u4e58\u6cd5\u7684\u95ee\u9898\u7b80\u5316\u4e3a\u6dfb\u52a0\u4e00\u7ec4\u6570\u5b57\uff0c\u6bcf\u4e2a\u6570\u5b57\u90fd\u662f 0 \u6216\u88ab\u4e58\u6570 \\(a\\) \u7684\u79fb\u4f4d\u7248\u672c\u3002</p> <p>Figure 9.1 also applies to nonbinary multiplication, except that with  r &gt;  2, computing the terms  xja  becomes more difficult and the resulting numbers will be one digit wider than  a. The rest of the process (multioperand addition), however, remains substantially the same. </p> <p>\u56fe 9.1 \u4e5f\u9002\u7528\u4e8e\u975e\u4e8c\u8fdb\u5236\u4e58\u6cd5\uff0c\u53ea\u4e0d\u8fc7\u5f53 \\(r &gt; 2\\) \u65f6\uff0c\u8ba1\u7b97\u9879 \\(x_ja\\) \u53d8\u5f97\u66f4\u52a0\u56f0\u96be\uff0c\u5e76\u4e14\u6240\u5f97\u6570\u5b57\u5c06\u6bd4 a \u5bbd\u4e00\u4f4d\u6570\u3002\u7136\u800c\uff0c\u8be5\u8fc7\u7a0b\u7684\u5176\u4f59\u90e8\u5206\uff08\u591a\u64cd\u4f5c\u6570\u52a0\u6cd5\uff09\u57fa\u672c\u4fdd\u6301\u4e0d\u53d8\u3002</p> <p></p> <p>Sequential or bit-at-a-time multiplication can be done by keeping a cumulative partial product (initialized to 0) and successively adding to it the properly shifted terms  \\(x_ja\\).  Since each successive number to be added to the cumulative partial product is shifted by 1 bit with respect to the preceding one, a simpler approach is to shift the cumulative partial product by 1 bit in order to align its bits with those of the next partial product.  Two versions of this algorithm can be devised, depending on whether the partial product terms  \\(x_ja\\)  in Fig. 9.1 are processed from top to bottom or from bottom to top. </p> <p>\u987a\u5e8f\u6216\u4e00\u6b21\u4e00\u4f4d\u4e58\u6cd5\u53ef\u4ee5\u901a\u8fc7\u4fdd\u6301\u7d2f\u79ef\u90e8\u5206\u79ef\uff08\u521d\u59cb\u5316\u4e3a 0\uff09\u5e76\u8fde\u7eed\u6dfb\u52a0\u6b63\u786e\u79fb\u4f4d\u7684\u9879 \\(x_ja\\) \u6765\u5b8c\u6210\u3002\u7531\u4e8e\u8981\u6dfb\u52a0\u5230\u7d2f\u79ef\u90e8\u5206\u79ef\u7684\u6bcf\u4e2a\u8fde\u7eed\u6570\u5b57\u76f8\u5bf9\u4e8e\u524d\u4e00\u4e2a\u6570\u5b57\u79fb\u4f4d 1 \u4f4d\uff0c\u56e0\u6b64\u4e00\u79cd\u66f4\u7b80\u5355\u7684\u65b9\u6cd5\u662f\u5c06\u7d2f\u79ef\u90e8\u5206\u79ef\u79fb\u4f4d 1 \u4f4d\uff0c\u4ee5\u4fbf\u5c06\u5176\u4f4d\u4e0e\u4e0b\u4e00\u4e2a\u90e8\u5206\u79ef\u7684\u4f4d\u5bf9\u9f50\u3002\u53ef\u4ee5\u8bbe\u8ba1\u8be5\u7b97\u6cd5\u7684\u4e24\u4e2a\u7248\u672c\uff0c\u5177\u4f53\u53d6\u51b3\u4e8e\u56fe 9.1 \u4e2d\u7684\u90e8\u5206\u79ef\u9879 xja \u662f\u4ece\u4e0a\u5230\u4e0b\u8fd8\u662f\u4ece\u4e0b\u5230\u4e0a\u5904\u7406\u3002</p> <p>In multiplication with right shifts, the partial product terms  xja  are accumulated from top to bottom:</p> <p>\u5728\u53f3\u79fb\u4e58\u6cd5\u4e2d\uff0c\u90e8\u5206\u79ef\u9879 xja \u4ece\u4e0a\u5230\u4e0b\u7d2f\u52a0\uff1a</p> <p></p> <p>Because the right shifts will cause the first partial product to be multiplied by 2\u2212 k by the time we are done, we premultiply a by 2 k to offset the effect of the right shifts. This premultiplication is done simply by aligning a with the upper half of the 2 k-bit cumulative partial product in the addition steps (i.e., storing a in the left half of a double-width register).</p> <p>\u56e0\u4e3a\u5728\u5b8c\u6210\u65f6\u53f3\u79fb\u5c06\u5bfc\u81f4\u7b2c\u4e00\u4e2a\u90e8\u5206\u79ef\u4e58\u4ee5 \\(2^{\u2212k}\\)\uff0c\u6240\u4ee5\u6211\u4eec\u5c06 a \u9884\u4e58\u4ee5 \\(2^k\\) \u4ee5\u62b5\u6d88\u53f3\u79fb\u7684\u5f71\u54cd\u3002\u8fd9\u79cd\u9884\u4e58\u6cd5\u53ea\u9700\u5728\u52a0\u6cd5\u6b65\u9aa4\u4e2d\u5c06 a \u4e0e 2k \u4f4d\u7d2f\u79ef\u90e8\u5206\u79ef\u7684\u4e0a\u534a\u90e8\u5206\u5bf9\u9f50\u5373\u53ef\u5b8c\u6210\uff08\u5373\uff0c\u5c06 a \u5b58\u50a8\u5728\u53cc\u5bbd\u5ea6\u5bc4\u5b58\u5668\u7684\u5de6\u534a\u90e8\u5206\uff09\u3002</p> <p>After k iterations, the preceding recurrence leads to</p> <p>\u7ecf\u8fc7 k \u6b21\u8fed\u4ee3\u540e\uff0c\u524d\u9762\u7684\u9012\u5f52\u5bfc\u81f4</p> <p>\\(p^{(k)} = ax + p^{(0)}2^{\u2212k}\\)</p> <p>Thus if instead of 0, p( 0 ) is initialized to y 2 k , the expression ax + y will be evaluated. This multiply-add operation is quite useful for many applications and is performed at essentially no extra cost compared with plain shift/add multiplication.</p> <p>\u56e0\u6b64\uff0c\u5982\u679c \\(p^{(0)}\\) \u521d\u59cb\u5316\u4e3a \\(y 2^k\\) \u800c\u4e0d\u662f 0\uff0c\u5219\u5c06\u8ba1\u7b97\u8868\u8fbe\u5f0f \\(ax + y\\)\u3002\u8fd9\u79cd\u4e58\u52a0\u8fd0\u7b97\u5bf9\u4e8e\u8bb8\u591a\u5e94\u7528\u6765\u8bf4\u975e\u5e38\u6709\u7528\uff0c\u5e76\u4e14\u4e0e\u666e\u901a\u7684\u79fb\u4f4d/\u52a0\u6cd5\u4e58\u6cd5\u76f8\u6bd4\uff0c\u57fa\u672c\u4e0a\u4e0d\u9700\u8981\u989d\u5916\u7684\u6210\u672c\u5373\u53ef\u6267\u884c\u3002</p> <p>In multiplication with left shifts, the terms  xja  are added up from bottom to top: </p> <p>\u5728\u5de6\u79fb\u4e58\u6cd5\u4e2d\uff0c\u9879 \\(x_ja\\) \u4ece\u4e0b\u5230\u4e0a\u76f8\u52a0\uff1a</p> <p></p> <p>After k iterations, the preceding recurrence leads to</p> <p>\u7ecf\u8fc7 k \u6b21\u8fed\u4ee3\u540e\uff0c\u524d\u9762\u7684\u9012\u5f52\u5bfc\u81f4</p> <p>\\(p^{(k)} = ax + p^{(0)} 2^k\\)</p> <p>In this case, the expression  ax +  y  will be evaluated if we initialize  p( 0 )  to  y 2\u2212 k . </p> <p>\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u5982\u679c\u6211\u4eec\u5c06 p( 0 ) \u521d\u59cb\u5316\u4e3a y 2\u2212 k \uff0c\u5219\u8868\u8fbe\u5f0f ax + y \u5c06\u88ab\u6c42\u503c\u3002</p> <p>Figure 9.2 shows the multiplication of  a =  ( 10 ) ten =  ( 1010 ) two and  x =  ( 11 ) ten = ( 1011 ) two, to obtain their product  p =  ( 110 ) ten =  ( 0110 1110 ) two, using both the right-and left-shift algorithms. </p> <p>\u56fe 9.2 \u663e\u793a\u4e86 \\(a = ( 10 )_{10} = ( 1010 )_2\\) \u548c \\(x = ( 11 ) _{10} = ( 1011 )_2\\)\u7684\u4e58\u6cd5\uff0c\u4f7f\u7528\u53f3\u79fb\u548c\u5de6\u79fb\u7b97\u6cd5\u83b7\u5f97\u5b83\u4eec\u7684\u4e58\u79ef \\(p = ( 110 )_{10} = ( 0110 1110 )_2\\)\u3002</p> <p>From the examples in Fig. 9.2, we see that the two algorithms are quite similar. Each algorithm entails  k  additions and  k  shifts; however, additions in the left-shift algorithm are 2 k  bits wide (the carry produced from the lower  k  bits may affect the upper  k  bits), whereas the right-shift algorithm requires  k-bit additions. For this reason, multiplication with right shifts is preferable. </p> <p>\u4ece\u56fe 9.2 \u7684\u4f8b\u5b50\u4e2d\uff0c\u6211\u4eec\u770b\u5230\u8fd9\u4e24\u79cd\u7b97\u6cd5\u975e\u5e38\u76f8\u4f3c\u3002\u6bcf\u4e2a\u7b97\u6cd5\u90fd\u9700\u8981 k \u4e2a\u52a0\u6cd5\u548c k \u4e2a\u79fb\u4f4d\uff1b\u7136\u800c\uff0c\u5de6\u79fb\u7b97\u6cd5\u4e2d\u7684\u52a0\u6cd5\u662f 2 k \u4f4d\u5bbd\uff08\u4f4e k \u4f4d\u4ea7\u751f\u7684\u8fdb\u4f4d\u53ef\u80fd\u5f71\u54cd\u9ad8 k \u4f4d\uff09\uff0c\u800c\u53f3\u79fb\u7b97\u6cd5\u9700\u8981 k \u4f4d\u52a0\u6cd5\u3002\u56e0\u6b64\uff0c\u4f18\u9009\u53f3\u79fb\u4e58\u6cd5\u3002</p> <p></p>"},{"location":"Part_03/09/#92","title":"9.2 \u7a0b\u5e8f\u5b9e\u73b0\u7684\u4e58\u6cd5","text":"<p>On a processor that does not have a multiply instruction, one can use shift and add instructions to perform integer multiplication. Figure 9.3 shows the structure of the needed program for the right-shift algorithm. The instructions used in this program fragment are typical of instructions available on many processors. </p> <p>\u5728\u6ca1\u6709\u4e58\u6cd5\u6307\u4ee4\u7684\u5904\u7406\u5668\u4e0a\uff0c\u53ef\u4ee5\u4f7f\u7528\u79fb\u4f4d\u548c\u52a0\u6cd5\u6307\u4ee4\u6765\u6267\u884c\u6574\u6570\u4e58\u6cd5\u3002\u56fe 9.3 \u663e\u793a\u4e86\u53f3\u79fb\u7b97\u6cd5\u6240\u9700\u7684\u7a0b\u5e8f\u7ed3\u6784\u3002\u8be5\u7a0b\u5e8f\u7247\u6bb5\u4e2d\u4f7f\u7528\u7684\u6307\u4ee4\u662f\u8bb8\u591a\u5904\u7406\u5668\u4e0a\u53ef\u7528\u7684\u5178\u578b\u6307\u4ee4\u3002</p> <p></p> <p>Ignoring operand load and result store instructions (which would be needed in any case), the function of a multiply instruction is accomplished by executing between 6 k +3 and 7 k+3 machine instructions, depending on the multiplier. More precisely, if the binary representation of the multiplier  x  is of weight  w (i.e., its number of 1 bits equals  w), then 6 k +  w + 3 instructions will be executed by the program of Fig. 9.3. The dependence of program execution time on w arises from the fact that the add instruction is skipped when the bit of  x  being processed in a particular iteration is 0. For 32-bit operands, this means 200+ instructions for each multiplication on the average. The situation improves somewhat if a special instruction that does some or all of the required functions within the multiplication loop is available. However, even then, no fewer than 32 instructions are executed in the multiplication loop. We thus see the importance of hardware multipliers for applications that involve many numerical computations. </p> <p>\u5ffd\u7565\u64cd\u4f5c\u6570\u52a0\u8f7d\u548c\u7ed3\u679c\u5b58\u50a8\u6307\u4ee4\uff08\u5728\u4efb\u4f55\u60c5\u51b5\u4e0b\u90fd\u9700\u8981\uff09\uff0c\u4e58\u6cd5\u6307\u4ee4\u7684\u529f\u80fd\u662f\u901a\u8fc7\u6267\u884c \\(6 k +3\\) \u548c \\(7 k+3\\) \u6761\u673a\u5668\u6307\u4ee4\u4e4b\u95f4\u6765\u5b8c\u6210\u7684\uff0c\u5177\u4f53\u53d6\u51b3\u4e8e\u4e58\u6570\u3002\u66f4\u51c6\u786e\u5730\u8bf4\uff0c\u5982\u679c\u4e58\u6570 x \u7684\u4e8c\u8fdb\u5236\u8868\u793a\u7684\u6743\u91cd\u4e3a w\uff08\u5373\uff0c\u5176 1 \u4f4d\u6570\u7b49\u4e8e w\uff09\uff0c\u5219\u56fe 9.3 \u7684\u7a0b\u5e8f\u5c06\u6267\u884c \\(6 k + w + 3\\) \u6761\u6307\u4ee4\u3002\u7a0b\u5e8f\u6267\u884c\u65f6\u95f4\u5bf9 w \u7684\u4f9d\u8d56\u662f\u7531\u4e8e\u5f53\u7279\u5b9a\u8fed\u4ee3\u4e2d\u6b63\u5728\u5904\u7406\u7684 x \u7684\u4f4d\u4e3a 0 \u65f6\uff0c\u52a0\u6cd5\u6307\u4ee4\u4f1a\u88ab\u8df3\u8fc7\u3002\u5bf9\u4e8e 32 \u4f4d\u64cd\u4f5c\u6570\uff0c\u8fd9\u610f\u5473\u7740\u6bcf\u6b21\u4e58\u6cd5\u5e73\u5747\u9700\u8981 200 \u591a\u4e2a\u6307\u4ee4\u3002\u5982\u679c\u53ef\u4ee5\u4f7f\u7528\u5728\u4e58\u6cd5\u5faa\u73af\u5185\u6267\u884c\u90e8\u5206\u6216\u5168\u90e8\u6240\u9700\u529f\u80fd\u7684\u7279\u6b8a\u6307\u4ee4\uff0c\u5219\u60c5\u51b5\u4f1a\u6709\u6240\u6539\u5584\u3002\u7136\u800c\uff0c\u5373\u4fbf\u5982\u6b64\uff0c\u4e58\u6cd5\u5faa\u73af\u4e2d\u6267\u884c\u7684\u6307\u4ee4\u4e5f\u4e0d\u5c11\u4e8e 32 \u6761\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u770b\u5230\u4e86\u786c\u4ef6\u4e58\u6cd5\u5668\u5bf9\u4e8e\u6d89\u53ca\u8bb8\u591a\u6570\u503c\u8ba1\u7b97\u7684\u5e94\u7528\u7684\u91cd\u8981\u6027\u3002</p> <p>Processors with microprogrammed control and no hardware multiplier essentially</p> <p>\u5177\u6709\u5fae\u7a0b\u5e8f\u63a7\u5236\u4e14\u672c\u8d28\u4e0a\u6ca1\u6709\u786c\u4ef6\u4e58\u6cd5\u5668\u7684\u5904\u7406\u5668</p> <p>use a microroutine very similar to the program in Fig. 9.3 to effect multiplication. Since microinstructions typically contain some parallelism and built-in conditional branching,  the number of microinstructions in the main loop is likely to be smaller than 6. This reduction, along with the savings in machine instruction fetching and decoding times, makes multiplication microroutines significantly faster than their machine-language counterparts, though still slower than the hardwired implementations we examine next. </p> <p>\u4f7f\u7528\u4e0e\u56fe 9.3 \u4e2d\u7684\u7a0b\u5e8f\u975e\u5e38\u76f8\u4f3c\u7684\u5fae\u7a0b\u5e8f\u6765\u5b9e\u73b0\u4e58\u6cd5\u3002\u7531\u4e8e\u5fae\u6307\u4ee4\u901a\u5e38\u5305\u542b\u4e00\u4e9b\u5e76\u884c\u6027\u548c\u5185\u7f6e\u6761\u4ef6\u5206\u652f\uff0c\u4e3b\u5faa\u73af\u4e2d\u7684\u5fae\u6307\u4ee4\u6570\u91cf\u53ef\u80fd\u5c0f\u4e8e 6\u3002\u8fd9\u79cd\u51cf\u5c11\uff0c\u52a0\u4e0a\u673a\u5668\u6307\u4ee4\u83b7\u53d6\u548c\u89e3\u7801\u65f6\u95f4\u7684\u8282\u7701\uff0c\u4f7f\u5f97\u4e58\u6cd5\u5fae\u4f8b\u7a0b\u6bd4\u673a\u5668\u8bed\u8a00\u5bf9\u5e94\u7684\u5fae\u4f8b\u7a0b\u5feb\u5f97\u591a\uff0c\u5c3d\u7ba1\u4ecd\u7136\u6bd4\u6211\u4eec\u63a5\u4e0b\u6765\u68c0\u67e5\u7684\u786c\u8fde\u7ebf\u5b9e\u73b0\u6162\u3002</p>"},{"location":"Part_03/09/#93","title":"9.3 \u57fa\u7840\u786c\u4ef6\u4e58\u6cd5\u5668","text":"<p>Hardware realization of the multiplication algorithm with right shifts is depicted in Fig. 9.4a. The multiplier  x  and the cumulative partial product  p  are stored in shift registers. The next bit of the multiplier to be considered is always available at the right end of the  x  register and is used to select 0 or  a  for the addition. Addition and shifting can be performed in 2 separate cycles or in 2 subcycles within the same clock cycle. In either case, temporary storage for the adder\u2019s carry-out signal is needed. Alternatively, shifting can be performed by connecting the  i th sum output of the adder to the ( k +  i \u2212 1)th bit of the partial product register and the adder\u2019s carry-out to bit 2 k \u2212 1, thus doing the addition and shifting as a single operation. </p> <p>\u53f3\u79fb\u4e58\u6cd5\u7b97\u6cd5\u7684\u786c\u4ef6\u5b9e\u73b0\u5982\u56fe 9.4a \u6240\u793a\u3002\u4e58\u6570 \\(x\\) \u548c\u7d2f\u79ef\u90e8\u5206\u79ef \\(p\\) \u5b58\u50a8\u5728\u79fb\u4f4d\u5bc4\u5b58\u5668\u4e2d\u3002\u8981\u8003\u8651\u7684\u4e58\u6cd5\u5668\u7684\u4e0b\u4e00\u4f4d\u59cb\u7ec8\u4f4d\u4e8e \\(x\\) \u5bc4\u5b58\u5668\u7684\u53f3\u7aef\uff0c\u7528\u4e8e\u9009\u62e9 0 \u6216 a \u8fdb\u884c\u52a0\u6cd5\u3002\u52a0\u6cd5\u548c\u79fb\u4f4d\u53ef\u4ee5\u5728 2 \u4e2a\u5355\u72ec\u7684\u5468\u671f\u6216\u540c\u4e00\u65f6\u949f\u5468\u671f\u5185\u7684 2 \u4e2a\u5b50\u5468\u671f\u4e2d\u6267\u884c\u3002\u65e0\u8bba\u54ea\u79cd\u60c5\u51b5\uff0c\u90fd\u9700\u8981\u4e34\u65f6\u5b58\u50a8\u52a0\u6cd5\u5668\u7684\u8fdb\u4f4d\u4fe1\u53f7\u3002\u6216\u8005\uff0c\u53ef\u4ee5\u901a\u8fc7\u5c06\u52a0\u6cd5\u5668\u7684\u7b2c \\(i\\) \u4e2a\u548c\u8f93\u51fa\u8fde\u63a5\u5230\u90e8\u5206\u79ef\u5bc4\u5b58\u5668\u7684\u7b2c \\((k + i \u2212 1)\\) \u4f4d\u5e76\u5c06\u52a0\u6cd5\u5668\u7684\u8fdb\u4f4d\u8f93\u51fa\u8fde\u63a5\u5230\u4f4d \\(2 k \u2212 1\\) \u6765\u6267\u884c\u79fb\u4f4d\uff0c\u4ece\u800c\u5c06\u52a0\u6cd5\u548c\u79fb\u4f4d\u4f5c\u4e3a\u5355\u4e2a\u64cd\u4f5c\u8fdb\u884c\u3002</p> <p>The control portion of the multiplier, which is not shown in Fig. 9.4a, consists of a counter to keep track of the number of iterations and a simple circuit to effect initialization and detect termination. Note that the multiplier and the lower half of the cumulative partial product can share the same register, since as  p  expands into this register, bits of  x are relaxed, keeping the total number of bits at 2 k. This gradual expansion of  p  into the lower half of the double-width partial product register (at the rate of 1 bit per cycle) is readily observable in Fig. 9.2a. </p> <p>\u4e58\u6cd5\u5668\u7684\u63a7\u5236\u90e8\u5206\uff08\u56fe 9.4a \u4e2d\u672a\u663e\u793a\uff09\u7531\u4e00\u4e2a\u7528\u4e8e\u8ddf\u8e2a\u8fed\u4ee3\u6b21\u6570\u7684\u8ba1\u6570\u5668\u548c\u4e00\u4e2a\u7528\u4e8e\u5b9e\u73b0\u521d\u59cb\u5316\u548c\u68c0\u6d4b\u7ec8\u6b62\u7684\u7b80\u5355\u7535\u8def\u7ec4\u6210\u3002\u8bf7\u6ce8\u610f\uff0c\u4e58\u6cd5\u5668\u548c\u7d2f\u79ef\u90e8\u5206\u4e58\u79ef\u7684\u4e0b\u534a\u90e8\u5206\u53ef\u4ee5\u5171\u4eab\u76f8\u540c\u7684\u5bc4\u5b58\u5668\uff0c\u56e0\u4e3a\u5f53 \\(p\\) \u6269\u5c55\u5230\u8be5\u5bc4\u5b58\u5668\u65f6\uff0c\\(x\\) \u7684\u4f4d\u88ab\u653e\u5bbd\uff0c\u4ece\u800c\u4f7f\u603b\u4f4d\u6570\u4fdd\u6301\u5728 \\(2 k\\)\u3002 \\(p\\) \u9010\u6e10\u6269\u5c55\u5230\u53cc\u5bbd\u90e8\u5206\u79ef\u5bc4\u5b58\u5668\u7684\u4e0b\u534a\u90e8\u5206\uff08\u4ee5\u6bcf\u5468\u671f 1 \u4f4d\u7684\u901f\u7387\uff09\u5728\u56fe 9.2a \u4e2d\u5f88\u5bb9\u6613\u89c2\u5bdf\u5230\u3002</p> <p></p> <p>Figure 9.5 shows the double-width register shared by the cumulative partial product and the unused part of the multiplier, along with connections needed to effect simultaneous loading and shifting. Since the register is loaded at the very end of each cycle, the change in its least-significant bit, which is controlling the current cycle, will not cause any problem. </p> <p>\u56fe 9.5 \u663e\u793a\u4e86\u7531\u7d2f\u79ef\u90e8\u5206\u79ef\u548c\u4e58\u6cd5\u5668\u672a\u4f7f\u7528\u90e8\u5206\u5171\u4eab\u7684\u53cc\u5bbd\u5ea6\u5bc4\u5b58\u5668\uff0c\u4ee5\u53ca\u5b9e\u73b0\u540c\u65f6\u52a0\u8f7d\u548c\u79fb\u4f4d\u6240\u9700\u7684\u8fde\u63a5\u3002\u7531\u4e8e\u5bc4\u5b58\u5668\u5728\u6bcf\u4e2a\u5468\u671f\u7684\u6700\u540e\u52a0\u8f7d\uff0c\u56e0\u6b64\u63a7\u5236\u5f53\u524d\u5468\u671f\u7684\u6700\u4f4e\u6709\u6548\u4f4d\u7684\u53d8\u5316\u4e0d\u4f1a\u5f15\u8d77\u4efb\u4f55\u95ee\u9898\u3002</p> <p></p> <p>Hardware realization of the algorithm with left shifts is depicted in Fig. 9.4b. Here too the multiplier  x  and the cumulative partial product  p  are stored in shift registers, but the registers shift to the left rather than to the right. The next bit of the multiplier to be considered is always available at the left end of the  x  register and is used to select 0 or  a  for the addition. Note that a 2 k-bit adder (actually, a  k-bit adder in the lower part, augmented with a  k-bit incrementer at the upper end) is needed in the hardware realization of multiplication with left shifts. Because the hardware in Fig. 9.4b is more complex than that in Fig. 9.4a, multiplication with right shifts is the preferred method. </p> <p>\u5de6\u79fb\u7b97\u6cd5\u7684\u786c\u4ef6\u5b9e\u73b0\u5982\u56fe 9.4b \u6240\u793a\u3002\u8fd9\u91cc\uff0c\u4e58\u6570 x \u548c\u7d2f\u79ef\u90e8\u5206\u79ef p \u4e5f\u5b58\u50a8\u5728\u79fb\u4f4d\u5bc4\u5b58\u5668\u4e2d\uff0c\u4f46\u5bc4\u5b58\u5668\u5411\u5de6\u79fb\u4f4d\u800c\u4e0d\u662f\u5411\u53f3\u79fb\u4f4d\u3002\u8981\u8003\u8651\u7684\u4e58\u6cd5\u5668\u7684\u4e0b\u4e00\u4f4d\u59cb\u7ec8\u4f4d\u4e8e x \u5bc4\u5b58\u5668\u7684\u5de6\u7aef\uff0c\u7528\u4e8e\u9009\u62e9 0 \u6216 a \u8fdb\u884c\u52a0\u6cd5\u3002\u6ce8\u610f\uff0c\u5de6\u79fb\u4e58\u6cd5\u7684\u786c\u4ef6\u5b9e\u73b0\u9700\u8981\u4e00\u4e2a2k\u4f4d\u52a0\u6cd5\u5668\uff08\u5b9e\u9645\u4e0a\u662f\u4e0b\u534a\u90e8\u5206\u7684k\u4f4d\u52a0\u6cd5\u5668\uff0c\u4e0a\u7aef\u589e\u52a0\u4e86k\u4f4d\u589e\u91cf\u5668\uff09\u3002\u7531\u4e8e\u56fe 9.4b \u4e2d\u7684\u786c\u4ef6\u6bd4\u56fe 9.4a \u4e2d\u7684\u786c\u4ef6\u66f4\u590d\u6742\uff0c\u56e0\u6b64\u53f3\u79fb\u4e58\u6cd5\u662f\u9996\u9009\u65b9\u6cd5\u3002</p> <p>The control portion of the multiplier, which is not shown in Fig. 9.4b, is similar to that for multiplication with right shifts. Here, register sharing is possible for the multiplier and the upper half of the cumulative partial product, since with each 1-bit expansion in  p, 1 bit of  x  is relaxed. This gradual expansion of  p  into the upper half of the double-width partial product register (at the rate of 1 bit per cycle) is readily observable in Fig. 9.2b. One difference with the right-shift scheme is that because the double-width register is shifted at the beginning of each cycle, temporary storage is required for keeping the multiplier bit that controls the rest of the cycle. </p> <p>\u4e58\u6cd5\u5668\u7684\u63a7\u5236\u90e8\u5206\uff08\u56fe 9.4b \u4e2d\u672a\u793a\u51fa\uff09\u4e0e\u53f3\u79fb\u4e58\u6cd5\u7684\u63a7\u5236\u90e8\u5206\u7c7b\u4f3c\u3002\u8fd9\u91cc\uff0c\u5bc4\u5b58\u5668\u5171\u4eab\u5bf9\u4e8e\u4e58\u6cd5\u5668\u548c\u7d2f\u79ef\u90e8\u5206\u4e58\u79ef\u7684\u4e0a\u534a\u90e8\u5206\u662f\u53ef\u80fd\u7684\uff0c\u56e0\u4e3a\u968f\u7740p\u4e2d\u7684\u6bcf1\u4f4d\u6269\u5c55\uff0cx\u76841\u4f4d\u88ab\u653e\u677e\u3002 p \u9010\u6e10\u6269\u5c55\u5230\u53cc\u5bbd\u90e8\u5206\u79ef\u5bc4\u5b58\u5668\u7684\u4e0a\u534a\u90e8\u5206\uff08\u4ee5\u6bcf\u5468\u671f 1 \u4f4d\u7684\u901f\u7387\uff09\u5728\u56fe 9.2b \u4e2d\u5f88\u5bb9\u6613\u89c2\u5bdf\u5230\u3002\u4e0e\u53f3\u79fb\u65b9\u6848\u7684\u4e00\u4e2a\u533a\u522b\u662f\uff0c\u7531\u4e8e\u53cc\u5bbd\u5ea6\u5bc4\u5b58\u5668\u5728\u6bcf\u4e2a\u5468\u671f\u5f00\u59cb\u65f6\u79fb\u4f4d\uff0c\u56e0\u6b64\u9700\u8981\u4e34\u65f6\u5b58\u50a8\u6765\u4fdd\u5b58\u63a7\u5236\u5468\u671f\u5176\u4f59\u90e8\u5206\u7684\u4e58\u6cd5\u5668\u4f4d\u3002</p> <p>Note that for both Figs. 9.4a and 9.4b, the multiplexer (mux) can be replaced by a set of  k  AND gates, with one input of each tied to  xi. We will see later that, for signed multiplication, one of three possible values must be fed to the left input of the adder in Fig. 9.4:  a,  a compl, or 0. In the latter case, we can use a 2-way multiplexer with its enable signal tied to  xi. When  xi = 0, the value 0 will be sent to the adder; otherwise,  a  or  a compl is sent, depending on the setting of a selection signal supplied by the control unit. </p> <p>\u8bf7\u6ce8\u610f\uff0c\u5bf9\u4e8e\u4e24\u4e2a\u56fe\u3002 9.4a \u548c 9.4b \u4e2d\uff0c\u591a\u8def\u590d\u7528\u5668 (mux) \u53ef\u4ee5\u7531\u4e00\u7ec4 k \u4e2a\u4e0e\u95e8\u4ee3\u66ff\uff0c\u6bcf\u4e2a\u4e0e\u95e8\u7684\u4e00\u4e2a\u8f93\u5165\u8fde\u63a5\u5230 \\(x_i\\)\u3002\u7a0d\u540e\u6211\u4eec\u5c06\u770b\u5230\uff0c\u5bf9\u4e8e\u6709\u7b26\u53f7\u4e58\u6cd5\uff0c\u5fc5\u987b\u5c06\u4e09\u4e2a\u53ef\u80fd\u503c\u4e4b\u4e00\u9988\u9001\u5230\u56fe 9.4 \u4e2d\u7684\u52a0\u6cd5\u5668\u7684\u5de6\u4fa7\u8f93\u5165\uff1a\\(a\\)\u3001\\(a^{compl}\\) \u6216 0\u3002\u5728\u540e\u4e00\u79cd\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 2 \u8def\u591a\u8def\u590d\u7528\u5668\uff0c\u5176\u4f7f\u80fd\u4fe1\u53f7\u4e0e \\(x_i\\) \u76f8\u8fde\u3002\u5f53\\(x_i = 0\\)\u65f6\uff0c\u503c0\u5c06\u88ab\u53d1\u9001\u5230\u52a0\u6cd5\u5668\uff1b\u5426\u5219\uff0c\u6839\u636e\u63a7\u5236\u5355\u5143\u63d0\u4f9b\u7684\u9009\u62e9\u4fe1\u53f7\u7684\u8bbe\u7f6e\uff0c\u53d1\u9001\\(a\\)\u6216\\(a^{compl}\\)\u3002</p>"},{"location":"Part_03/09/#94","title":"9.4 \u6709\u7b26\u53f7\u6570\u4e58\u6cd5","text":"<p>The preceding discussions of multiplication algorithms and hardware realizations assume unsigned operands and result. Multiplication of signed-magnitude numbers needs little more, since the product\u2019s sign can be computed separately by XORing the operand signs. One way to multiply signed values with complement representations is to complement the negative operand(s), multiply unsigned values, and then complement the result if only one operand was complemented at the outset. Such an indirect multiplication scheme is quite efficient for 1\u2019s-complement numbers but involves too much overhead for 2\u2019s-complement representation. It is preferable to use a direct multiplication algorithm for such numbers, as discussed in the remainder of this section.</p> <p>\u524d\u9762\u5bf9\u4e58\u6cd5\u7b97\u6cd5\u548c\u786c\u4ef6\u5b9e\u73b0\u7684\u8ba8\u8bba\u5047\u8bbe\u64cd\u4f5c\u6570\u548c\u7ed3\u679c\u662f\u65e0\u7b26\u53f7\u6570\u3002 \u6709\u7b26\u53f7\u6570\u503c\u7684\u4e58\u6cd5\u51e0\u4e4e\u4e0d\u9700\u8981\u66f4\u591a\u6539\u53d8\uff0c\u56e0\u4e3a\u53ef\u4ee5\u901a\u8fc7\u5bf9\u64cd\u4f5c\u6570\u7b26\u53f7\u8fdb\u884c\u5f02\u6216\u6765\u5355\u72ec\u8ba1\u7b97\u4e58\u79ef\u7684\u7b26\u53f7\u3002 \u5c06\u6709\u7b26\u53f7\u503c\u4e0e\u8865\u7801\u8868\u793a\u76f8\u4e58\u7684\u4e00\u79cd\u65b9\u6cd5\u662f\u5bf9\u8d1f\u64cd\u4f5c\u6570\u6c42\u8865\uff0c\u5c06\u65e0\u7b26\u53f7\u503c\u76f8\u4e58\uff0c\u5982\u679c\u4e00\u5f00\u59cb\u53ea\u5bf9\u4e00\u4e2a\u64cd\u4f5c\u6570\u6c42\u8865\uff0c\u5219\u5bf9\u7ed3\u679c\u6c42\u8865\u3002 \u8fd9\u79cd\u95f4\u63a5\u4e58\u6cd5\u65b9\u6848\u5bf9\u4e8e 1 \u8865\u6570\u8868\u793a\u975e\u5e38\u6709\u6548\uff0c\u4f46\u5bf9\u4e8e 2 \u8865\u6570\u8868\u793a\u6d89\u53ca\u592a\u591a\u5f00\u9500\u3002 \u6700\u597d\u5bf9\u8fd9\u4e9b\u6570\u5b57\u4f7f\u7528\u76f4\u63a5\u4e58\u6cd5\u7b97\u6cd5\uff0c\u5982\u672c\u8282\u5176\u4f59\u90e8\u5206\u6240\u8ff0\u3002</p> <p>We first note that the preceding bit-at-a-time algorithms can work directly with a negative 2\u2019s-complement multiplicand and a positive multiplier. In this case, each xja term will be a 2\u2019s-complement number and the sum will be correctly accumulated if we use sign-extended values during the addition process. Figure 9.6 shows the multiplication of a negative multiplicand a = (\u221210 ) ten = ( 10110 ) 2s\u2212compl by a positive multiplier x = ( 11 ) ten = ( 01011 ) 2s\u2212compl using the right-shift algorithm. Note that the leftmost digit of the sum p(i) + xia is obtained assuming sign-extended operands.</p> <p>\u6211\u4eec\u9996\u5148\u6ce8\u610f\u5230\uff0c\u524d\u9762\u7684\u4e00\u6b21\u6bd4\u7279\u7b97\u6cd5\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528\u8d1f 2 \u8865\u7801\u88ab\u4e58\u6570\u548c**\u6b63\u4e58\u6570**\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6bcf\u4e2a \\(x_ja\\) \u9879\u5c06\u662f\u4e00\u4e2a 2 \u7684\u8865\u6570\uff0c\u5982\u679c\u6211\u4eec\u5728\u52a0\u6cd5\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u7b26\u53f7\u6269\u5c55\u503c\uff0c\u5219\u603b\u548c\u5c06\u6b63\u786e\u7d2f\u52a0\u3002\u56fe 9.6 \u663e\u793a\u4e86\u4f7f\u7528\u53f3\u79fb\u7b97\u6cd5\u5c06\u8d1f\u88ab\u4e58\u6570 \\(a = (\u221210 ) _{ten} = ( 10110 ) _{2s\u2212compl}\\) \u4e0e\u6b63\u4e58\u6570 \\(x = ( 11 )_{ten} = ( 01011 ) _{2s\u2212compl}\\) \u76f8\u4e58\u3002\u8bf7\u6ce8\u610f\uff0c\\(p^{(i)} + x_ia\\) \u4e4b\u548c\u7684\u6700\u5de6\u8fb9\u6570\u5b57\u662f\u5728\u5047\u8bbe\u7b26\u53f7\u6269\u5c55\u64cd\u4f5c\u6570\u7684\u60c5\u51b5\u4e0b\u83b7\u5f97\u7684\u3002</p> <p></p> <p>In view of the negative-weight interpretation of the sign bit in 2\u2019s-complement numbers, a negative 2\u2019s-complement multiplier can be handled correctly if xk\u22121 a is subtracted, rather than added, in the last cycle. In practice, the required subtraction is performed by adding the 2\u2019s-complement of the multiplicand or, actually, adding the 1\u2019s-complement of the multiplicand and inserting a carry-in of 1 into the adder (see Fig. 2.7). The required control logic becomes only slightly more complex. Figure 9.7 shows the multiplication of negative values a = (\u221210 ) ten = ( 10110 ) 2s\u2212compl and x = (\u221211 ) ten = ( 10101 ) two by means of the right-shift algorithm.</p> <p>\u9274\u4e8e 2 \u8865\u7801\u6570\u4e2d\u7b26\u53f7\u4f4d\u7684\u8d1f\u6743\u91cd\u89e3\u91ca\uff0c\u5982\u679c\u5728\u6700\u540e\u4e00\u4e2a\u5468\u671f\u4e2d\u51cf\u53bb\u800c\u4e0d\u662f\u52a0 \\(x_{k\u22121} a\\) \uff0c\u5219\u53ef\u4ee5\u6b63\u786e\u5904\u7406\u8d1f 2 \u8865\u7801\u4e58\u6570\u3002\u5b9e\u9645\u4e0a\uff0c\u6240\u9700\u7684\u51cf\u6cd5\u662f\u901a\u8fc7\u6dfb\u52a0\u88ab\u4e58\u6570\u7684 2 \u8865\u7801\u6765\u6267\u884c\u7684\uff0c\u6216\u8005\u5b9e\u9645\u4e0a\u662f\u6dfb\u52a0\u88ab\u4e58\u6570\u7684 1 \u8865\u7801\u5e76\u5c06\u8fdb\u4f4d 1 \u63d2\u5165\u52a0\u6cd5\u5668\uff08\u89c1\u56fe 2.7\uff09\u3002\u6240\u9700\u7684\u63a7\u5236\u903b\u8f91\u4ec5\u53d8\u5f97\u7a0d\u5fae\u590d\u6742\u4e00\u4e9b\u3002\u56fe9.7\u663e\u793a\u901a\u8fc7\u53f3\u79fb\u7b97\u6cd5\u5c06\u8d1f\u503c \\(a = (\u221210 ) _{ten} = ( 10110 ) _{2's\u2212compl}\\) \u548c \\(x = (\u221211 ) _{ten} = ( 10101 ) _{two}\\) \u76f8\u4e58\u3002</p> <p></p> <p>Figure 9.8 shows a hardware 2\u2019s-complement multiplier whose structure is substantially the same as that of Fig. 9.4a. The control unit, not shown in Fig. 9.8, causes the multiplicand to be added to the partial product in all but the final cycle, when a subtraction is performed by choosing the complement of the multiplicand and inserting a carry-in of 1.</p> <p>\u56fe9.8\u663e\u793a\u4e86\u4e00\u4e2a\u786c\u4ef62\u7684\u8865\u7801\u4e58\u6cd5\u5668\uff0c\u5176\u7ed3\u6784\u4e0e\u56fe9.4a\u57fa\u672c\u76f8\u540c\u3002\u5f53\u901a\u8fc7\u9009\u62e9\u88ab\u4e58\u6570\u7684\u8865\u6570\u5e76\u63d2\u5165\u8fdb\u4f4d 1 \u6765\u6267\u884c\u51cf\u6cd5\u65f6\uff0c\u63a7\u5236\u5355\u5143\uff08\u56fe 9.8 \u4e2d\u672a\u663e\u793a\uff09\u4f1a\u5bfc\u81f4\u9664\u6700\u540e\u4e00\u4e2a\u5faa\u73af\u4e4b\u5916\u7684\u6240\u6709\u5faa\u73af\u4e2d\u7684\u88ab\u4e58\u6570\u4e0e\u90e8\u5206\u79ef\u76f8\u52a0\u3002</p> <p>Multiplication with left shifts becomes even less competitive when we are dealing with 2\u2019s-complement numbers directly. Referring to Fig. 9.4b, we note that the</p> <p>multiplicand must be sign-extended by k bits. We thus have a more complex adder as well as slower additions. With right shifts, on the other hand, sign extension occurs incrementally; thus the adder needs to be only 1 bit wider. Alternatively, a k-bit adder can be augmented with special logic to handle the extra bit at the left. </p> <p>An alternate way of dealing with 2\u2019s-complement numbers is to use Booth\u2019s recoding to represent the multiplier  x  in signed-digit format. </p> <p>\u5f53\u6211\u4eec\u76f4\u63a5\u7528 2 \u7684\u8865\u7801\u8fdb\u884c\u4e58\u6cd5\u8fd0\u7b97\uff0c\u5de6\u79fb\u4e58\u6cd5\u53d8\u5f97\u66f4\u52a0\u6ca1\u6709\u7ade\u4e89\u529b\u3002\u53c2\u8003\u56fe9.4b\uff0c\u6211\u4eec\u6ce8\u610f\u5230\u88ab\u4e58\u6570\u5fc5\u987b\u7b26\u53f7\u6269\u5c55 k \u4f4d\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u6709\u4e00\u4e2a\u66f4\u590d\u6742\u7684\u52a0\u6cd5\u5668\u4ee5\u53ca\u66f4\u6162\u7684\u52a0\u6cd5\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u5bf9\u4e8e\u53f3\u79fb\uff0c\u7b26\u53f7\u6269\u5c55\u662f\u9010\u6e10\u53d1\u751f\u7684\u3002\u56e0\u6b64\u52a0\u6cd5\u5668\u53ea\u9700\u52a0\u5bbd 1 \u4f4d\u3002\u6216\u8005\uff0c\u53ef\u4ee5\u4f7f\u7528\u7279\u6b8a\u903b\u8f91\u6765\u589e\u5f3a k \u4f4d\u52a0\u6cd5\u5668\uff0c\u4ee5\u5904\u7406\u5de6\u4fa7\u7684\u989d\u5916\u4f4d\u3002</p> <p>\u5904\u7406 2 \u8865\u7801\u7684\u53e6\u4e00\u79cd\u65b9\u6cd5\u662f\u4f7f\u7528 Booth \u91cd\u65b0\u7f16\u7801\u4ee5\u6709\u7b26\u53f7\u6570\u5b57\u683c\u5f0f\u8868\u793a\u4e58\u6570 x\u3002</p> <p>Booth\u2019s recoding (also known as Booth\u2019s encoding) was first proposed for speeding up radix-2 multiplication in early digital computers. Recall that radix-2 multiplication consists of a sequence of shifts and adds. When 0 is added to the cumulative partial product in a step, the addition operation can be skipped altogether. This does not make sense in the designs of Fig. 9.4, since the data paths go through the adder. But in an asynchronous implementation, or in developing a (micro)program for multiplication, shifting alone is faster than addition followed by shifting, and one may take advantage of this fact to reduce the multiplication time on the average. The resulting algorithm or its associated hardware implementation will have variable delay depending on the multiplier value: the more 1s there are in the binary representation of  x, the slower the multiplication. Booth observed that whenever there are a large number of consecutive 1s in  x, multiplication can be speeded up by replacing the corresponding sequence of additions with a subtraction at the least-significant end and an addition in the position immediately to the left of its most-significant end. In other words</p> <p>\u5e03\u65af\u91cd\u65b0\u7f16\u7801\uff08\u4e5f\u79f0\u4e3a\u5e03\u65af\u7f16\u7801\uff09\u6700\u521d\u662f\u4e3a\u4e86\u52a0\u901f\u65e9\u671f\u6570\u5b57\u8ba1\u7b97\u673a\u4e2d\u7684\u57fa 2 \u4e58\u6cd5\u800c\u63d0\u51fa\u7684\u3002\u56de\u60f3\u4e00\u4e0b\uff0c\u57fa 2 \u4e58\u6cd5\u7531\u4e00\u7cfb\u5217\u79fb\u4f4d\u548c\u52a0\u6cd5\u7ec4\u6210\u3002\u5f53\u4e00\u6b65\u4e2d\u5c060\u6dfb\u52a0\u5230\u7d2f\u79ef\u90e8\u5206\u79ef\u65f6\uff0c\u53ef\u4ee5\u5b8c\u5168\u8df3\u8fc7\u52a0\u6cd5\u64cd\u4f5c\u3002\u8fd9\u5728\u56fe 9.4 \u7684\u8bbe\u8ba1\u4e2d\u6ca1\u6709\u610f\u4e49\uff0c\u56e0\u4e3a\u6570\u636e\u8def\u5f84\u7ecf\u8fc7\u52a0\u6cd5\u5668\u3002\u4f46\u5728\u5f02\u6b65\u5b9e\u73b0\u4e2d\uff0c\u6216\u5728\u5f00\u53d1\u4e58\u6cd5\uff08\u5fae\uff09\u7a0b\u5e8f\u65f6\uff0c\u5355\u72ec\u79fb\u4f4d\u6bd4\u5148\u52a0\u540e\u79fb\u4f4d\u8981\u5feb\uff0c\u5e76\u4e14\u53ef\u4ee5\u5229\u7528\u8fd9\u4e00\u4e8b\u5b9e\u6765\u5e73\u5747\u51cf\u5c11\u4e58\u6cd5\u65f6\u95f4\u3002\u751f\u6210\u7684\u7b97\u6cd5\u6216\u5176\u76f8\u5173\u786c\u4ef6\u5b9e\u73b0\u5c06\u5177\u6709\u53ef\u53d8\u5ef6\u8fdf\uff0c\u5177\u4f53\u53d6\u51b3\u4e8e\u4e58\u6570\u503c\uff1ax \u7684\u4e8c\u8fdb\u5236\u8868\u793a\u4e2d\u7684 1 \u8d8a\u591a\uff0c\u4e58\u6cd5\u5c31\u8d8a\u6162\u3002 Booth \u89c2\u5bdf\u5230\uff0c\u6bcf\u5f53 x \u4e2d\u5b58\u5728\u5927\u91cf\u8fde\u7eed 1 \u65f6\uff0c\u901a\u8fc7\u5c06\u76f8\u5e94\u7684\u52a0\u6cd5\u5e8f\u5217\u66ff\u6362\u4e3a\u6700\u4f4e\u6709\u6548\u7aef\u7684\u51cf\u6cd5\u548c\u7d27\u90bb\u6700\u9ad8\u6709\u6548\u7aef\u5de6\u4fa7\u4f4d\u7f6e\u7684\u52a0\u6cd5\uff0c\u53ef\u4ee5\u52a0\u5feb\u4e58\u6cd5\u901f\u5ea6\u3002\u6362\u53e5\u8bdd\u8bf4</p> <p>\\(2^j + 2^{j\u22121} + \u00b7 \u00b7 \u00b7 + 2^{i+1} + 2^i = 2^{j+1} \u2212 2^i\\)</p> <p>The longer the sequence of 1s, the larger the savings achieved. The effect of this transformation is to change the binary number  x  with digit set [0, 1] to the binary signed-digit number  y  using the digit set [\u22121, 1]. Hence, Booth\u2019s recoding can be viewed as a kind of digit-set conversion. Table 9.1 shows how the digit  yi  of the recoded number  y can be obtained from the two digits  xi  and  xi\u22121 of  x. Thus, as  x  is scanned from right to left, the digits  yi  can be determined on the fly and used to choose add, subtract, or no-operation in each cycle. </p> <p>\u7684\u5e8f\u5217\u8d8a\u957f\uff0c\u8282\u7701\u7684\u6210\u672c\u5c31\u8d8a\u5927\u3002\u6b64\u8f6c\u6362\u7684\u6548\u679c\u662f\u5c06\u5177\u6709\u6570\u5b57\u96c6 [0, 1] \u7684\u4e8c\u8fdb\u5236\u6570 \\(x\\) \u66f4\u6539\u4e3a\u4f7f\u7528\u6570\u5b57\u96c6 [\u22121, 1] \u7684\u4e8c\u8fdb\u5236\u6709\u7b26\u53f7\u6570\u5b57 \\(y\\)\u3002\u56e0\u6b64\uff0c\u5e03\u65af\u7684\u91cd\u65b0\u7f16\u7801\u53ef\u4ee5\u88ab\u89c6\u4e3a\u4e00\u79cd\u6570\u5b57\u96c6\u8f6c\u6362\u3002\u88689.1\u663e\u793a\u4e86\u5982\u4f55\u4ece\\(x\\)\u7684\u4e24\u4f4d\u6570\u5b57\\(x_i\\)\u548c\\(x_{i\u22121}\\)\u83b7\u5f97\u91cd\u65b0\u7f16\u7801\u7684\u6570\u5b57\\(y\\)\u7684\u6570\u5b57\\(y_i\\)\u3002\u56e0\u6b64\uff0c\u5f53\u4ece\u53f3\u5411\u5de6\u626b\u63cf \\(x\\) \u65f6\uff0c\u53ef\u4ee5\u52a8\u6001\u786e\u5b9a\u6570\u5b57 \\(y_i\\) \u5e76\u7528\u4e8e\u5728\u6bcf\u4e2a\u5468\u671f\u4e2d\u9009\u62e9\u52a0\u6cd5\u3001\u51cf\u6cd5\u6216\u65e0\u64cd\u4f5c\u3002</p> <p></p> <p>For example, consider the following 16-bit binary number and its recoded version: 1 0 0 1</p> <p>\u4f8b\u5982\uff0c\u8003\u8651\u4ee5\u4e0b 16 \u4f4d\u4e8c\u8fdb\u5236\u6570\u53ca\u5176\u91cd\u65b0\u7f16\u7801\u7248\u672c\uff1a</p> <pre><code>     1 0 0 1   1  1 0 1    1 0  1 0   1 1  1 0    Operand x\n(1) -1 0 1 0   0 -1 1 0   -1 1 -1 1   0 0 -1 0    Recoded version y\n</code></pre> <p>In this particular example, the recoding does not reduce the number of additions. However, the example serves to illustrate two points. First, the recoded number may have to be extended by 1 bit if the value of x as an unsigned number is to be preserved. Second, if x is a 2\u2019s-complement number, then not extending the width (ignoring the leftmost 1 in the recoded version above) leads to the proper handling of negative numbers. Note how in the example, the sign bit of the 2\u2019s-complement number has assumed a negative weight in the recoded version, as it should. A complete multiplication example is given in Fig. 9.9. </p> <p>\u5728\u8be5\u7279\u5b9a\u793a\u4f8b\u4e2d\uff0c\u91cd\u65b0\u7f16\u7801\u5e76\u6ca1\u6709\u51cf\u5c11\u6dfb\u52a0\u7684\u6570\u91cf\u3002 \u7136\u800c\uff0c\u8fd9\u4e2a\u4f8b\u5b50\u53ef\u4ee5\u8bf4\u660e\u4e24\u70b9\u3002 \u9996\u5148\uff0c\u5982\u679c\u8981\u4fdd\u7559 x \u7684\u503c\u4f5c\u4e3a\u65e0\u7b26\u53f7\u6570\uff0c\u5219\u91cd\u65b0\u7f16\u7801\u7684\u6570\u53ef\u80fd\u5fc5\u987b\u6269\u5c55 1 \u4f4d\u3002 \u5176\u6b21\uff0c\u5982\u679c x \u662f 2 \u7684\u8865\u7801\u6570\uff0c\u5219\u4e0d\u6269\u5c55\u5bbd\u5ea6\uff08\u5ffd\u7565\u4e0a\u9762\u91cd\u65b0\u7f16\u7801\u7248\u672c\u4e2d\u6700\u5de6\u8fb9\u7684 1\uff09\u4f1a\u5bfc\u81f4\u6b63\u786e\u5904\u7406\u8d1f\u6570\u3002 \u8bf7\u6ce8\u610f\uff0c\u5728\u793a\u4f8b\u4e2d\uff0c2 \u7684\u8865\u7801\u6570\u7684\u7b26\u53f7\u4f4d\u5728\u91cd\u65b0\u7f16\u7801\u7684\u7248\u672c\u4e2d\u91c7\u7528\u4e86\u8d1f\u6743\u91cd\uff0c\u6b63\u5982\u5b83\u5e94\u8be5\u7684\u90a3\u6837\u3002 \u56fe 9.9 \u7ed9\u51fa\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u4e58\u6cd5\u793a\u4f8b\u3002</p> <p></p> <p>The multiplier of Fig. 9.8 can be easily converted to a Booth multiplier. All that is required is to provide a flip-flop on the right side of the multiplier register to hold xi\u22121 as it is shifted out, and a two-input, two-output combinational circuit to derive a representation of  yi  based on  xi  and  xi\u22121 (see Table 9.1). A convenient representation of yi  consists of the 2 bits \u201cnonzero\u201d (tied to the multiplexer\u2019s enable input) and \u201cnegative\u201d (feeding the multiplexer\u2019s select input and the adder\u2019s carry-in). </p> <p>Radix-2 Booth recoding is not directly applied in modern arithmetic circuits, but it serves as a tool in understanding the radix-4 version of this recoding, to be discussed in Section 10.2. </p> <p>\u56fe 9.8 \u7684\u4e58\u6570\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u8f6c\u6362\u4e3a\u5e03\u65af\u4e58\u6570\u3002\u6240\u9700\u8981\u7684\u53ea\u662f\u5728\u4e58\u6cd5\u5668\u5bc4\u5b58\u5668\u7684\u53f3\u4fa7\u63d0\u4f9b\u4e00\u4e2a\u89e6\u53d1\u5668\uff0c\u4ee5\u5728\u79fb\u51fa\u65f6\u4fdd\u5b58 \\(x_{i\u22121}\\)\uff0c\u4ee5\u53ca\u4e00\u4e2a\u4e24\u8f93\u5165\u3001\u4e24\u8f93\u51fa\u7ec4\u5408\u7535\u8def\uff0c\u4ee5\u6839\u636e \\(x_i\\) \u548c \\(x_{i\u22121}\\) \u5bfc\u51fa \\(y_i\\) \u7684\u8868\u793a\u5f62\u5f0f\uff08\u53c2\u89c1\u8868 9.1\uff09\u3002 \\(y_i\\) \u7684\u65b9\u4fbf\u8868\u793a\u7531 2 \u4f4d\u201c\u975e\u96f6\u201d\uff08\u4e0e\u591a\u8def\u590d\u7528\u5668\u7684\u4f7f\u80fd\u8f93\u5165\u76f8\u5173\uff09\u548c\u201c\u8d1f\u201d\u7ec4\u6210\uff08\u9988\u9001\u591a\u8def\u590d\u7528\u5668\u7684\u9009\u62e9\u8f93\u5165\u548c\u52a0\u6cd5\u5668\u7684\u8fdb\u4f4d\u8f93\u5165\uff09\u3002</p> <p>Radix-2 Booth \u91cd\u65b0\u7f16\u7801\u5e76\u4e0d\u76f4\u63a5\u5e94\u7528\u4e8e\u73b0\u4ee3\u7b97\u672f\u7535\u8def\uff0c\u4f46\u5b83\u53ef\u4ee5\u4f5c\u4e3a\u7406\u89e3\u8be5\u91cd\u65b0\u7f16\u7801\u7684 radix-4 \u7248\u672c\u7684\u5de5\u5177\uff0c\u5c06\u5728 10.2 \u8282\u4e2d\u8ba8\u8bba\u3002</p>"},{"location":"Part_03/09/#95","title":"9.5 \u4e58\u4ee5\u4e00\u4e2a\u5e38\u6570","text":"<p>When a hardware multiplier, or a corresponding firmware routine, is unavailable, multiplication must be performed by a software routine similar to that in Fig. 9.3. In applications that are not arithmetic-intensive, loss of speed due to the use of such routines is tolerable. However, many applications involve frequent use of multiplication; in these applications, indiscriminate use of such slow routines may be unacceptable.</p> <p>\u5f53\u786c\u4ef6\u4e58\u6cd5\u5668\u6216\u76f8\u5e94\u7684\u56fa\u4ef6\u4f8b\u7a0b\u4e0d\u53ef\u7528\u65f6\uff0c\u4e58\u6cd5\u5fc5\u987b\u7531\u7c7b\u4f3c\u4e8e\u56fe9.3\u4e2d\u7684\u8f6f\u4ef6\u4f8b\u7a0b\u6765\u6267\u884c\u3002\u5728\u975e\u7b97\u672f\u5bc6\u96c6\u578b\u7684\u5e94\u7528\u7a0b\u5e8f\u4e2d\uff0c\u7531\u4e8e\u4f7f\u7528\u6b64\u7c7b\u4f8b\u7a0b\u800c\u9020\u6210\u7684\u901f\u5ea6\u635f\u5931\u662f\u53ef\u4ee5\u5bb9\u5fcd\u7684\u3002\u7136\u800c\uff0c\u8bb8\u591a\u5e94\u7528\u90fd\u6d89\u53ca\u9891\u7e41\u4f7f\u7528\u4e58\u6cd5\uff1b\u5728\u8fd9\u4e9b\u5e94\u7528\u4e2d\uff0c\u4e0d\u52a0\u533a\u522b\u5730\u4f7f\u7528\u8fd9\u79cd\u7f13\u6162\u7684\u4f8b\u7a0b\u53ef\u80fd\u662f\u4e0d\u53ef\u63a5\u53d7\u7684\u3002</p> <p>Even for applications involving many multiplications, it is true that in a large fraction of cases, one of the operands is a constant that is known at circuit-design or program-compilation time. We know that multiplication and division by powers of 2 can be done through shifting. It is less obvious that multiplication by many other constants can be performed by short sequences of simple operations without a need to use a hardware multiplier or to invoke a complicated general multiplication routine or instruction.</p> <p>\u5373\u4f7f\u5bf9\u4e8e\u6d89\u53ca\u8bb8\u591a\u4e58\u6cd5\u7684\u5e94\u7528\uff0c\u5728\u5f88\u5927\u4e00\u90e8\u5206\u60c5\u51b5\u4e0b\uff0c\u64cd\u4f5c\u6570\u4e4b\u4e00\u786e\u5b9e\u662f\u5728\u7535\u8def\u8bbe\u8ba1\u6216\u7a0b\u5e8f\u7f16\u8bd1\u65f6\u5df2\u77e5\u7684\u5e38\u6570\u3002\u6211\u4eec\u77e5\u90532\u7684\u4e58\u6cd5\u548c\u9664\u6cd5\u53ef\u4ee5\u901a\u8fc7\u79fb\u4f4d\u6765\u5b8c\u6210\u3002\u4e0d\u592a\u660e\u663e\u7684\u662f\uff0c\u4e58\u4ee5\u8bb8\u591a\u5176\u4ed6\u5e38\u6570\u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u64cd\u4f5c\u7684\u77ed\u5e8f\u5217\u6765\u6267\u884c\uff0c\u65e0\u9700\u4f7f\u7528\u786c\u4ef6\u4e58\u6cd5\u5668\u6216\u8c03\u7528\u590d\u6742\u7684\u901a\u7528\u4e58\u6cd5\u4f8b\u7a0b\u6216\u6307\u4ee4\u3002</p> <p>Besides explicit multiplications appearing in arithmetic expressions within programs, there are many implicit multiplications to compute offsets into arrays. For example, if an m \u00d7 n array A is stored in row-major order, the offset of the element Ai, j (assuming 0-origin indexing) is obtained from the expression ni+ j. In such implicit multiplications, as well as in a significant fraction of explicit ones, one of the operands is a constant. A multiply instruction takes much longer to execute than a shift or an add instruction even if a hardware multiplier is available. Thus, one might want to avoid the use of a multiply instruction even when it is supported by the hardware.</p> <p>\u9664\u4e86\u7a0b\u5e8f\u4e2d\u7b97\u672f\u8868\u8fbe\u5f0f\u4e2d\u51fa\u73b0\u7684\u663e\u5f0f\u4e58\u6cd5\u4e4b\u5916\uff0c\u8fd8\u6709\u8bb8\u591a\u9690\u5f0f\u4e58\u6cd5\u6765\u8ba1\u7b97\u6570\u7ec4\u7684\u504f\u79fb\u91cf\u3002\u4f8b\u5982\uff0c\u5982\u679c \\(m \u00d7 n\\) \u6570\u7ec4 A \u6309\u884c\u4f18\u5148\u987a\u5e8f\u5b58\u50a8\uff0c\u5219\u5143\u7d20 \\(A_{i, j}\\)\uff08\u5047\u8bbe\u4ece 0 \u5f00\u59cb\u7d22\u5f15\uff09\u7684\u504f\u79fb\u91cf\u53ef\u4ece\u8868\u8fbe\u5f0f \\(ni+ j\\) \u83b7\u5f97\u3002\u5728\u6b64\u7c7b\u9690\u5f0f\u4e58\u6cd5\u4ee5\u53ca\u663e\u5f0f\u4e58\u6cd5\u7684\u5f88\u5927\u4e00\u90e8\u5206\u4e2d\uff0c\u5176\u4e2d\u4e00\u4e2a\u64cd\u4f5c\u6570\u662f\u5e38\u91cf\u3002\u5373\u4f7f\u786c\u4ef6\u4e58\u6cd5\u5668\u53ef\u7528\uff0c\u4e58\u6cd5\u6307\u4ee4\u7684\u6267\u884c\u65f6\u95f4\u4e5f\u6bd4\u79fb\u4f4d\u6216\u52a0\u6cd5\u6307\u4ee4\u8981\u957f\u5f97\u591a\u3002\u56e0\u6b64\uff0c\u5373\u4f7f\u786c\u4ef6\u652f\u6301\u4e58\u6cd5\u6307\u4ee4\uff0c\u4eba\u4eec\u4e5f\u53ef\u80fd\u5e0c\u671b\u907f\u514d\u4f7f\u7528\u5b83\u3002</p> <p>In the remainder of this section, we describe algorithms for multiplication by integer constants in terms of shift and add/subtract operations performed on register contents.</p> <p>The algorithms can thus be readily translated to sequences of instructions for any specific processor. The algorithms described can also be viewed as hardware structures to be built into application-specific designs. For example, a digital filter may be characterized by the equation y[ t] = ax[ t] + bx[ t \u2212 1] + cx[ t \u2212 2] + dy[ t \u2212 1] + ey[ t \u2212 2], in which a- e are constants, x[ i] is the input at time step i, and y[ j] is the output at time step j. Depending on the constants involved, the circuit computing y[ t] may not need multipliers at all. In fact, the circuit could be less complex, faster, and lower-powered if implemented by means of adders only. With the latter interpretation, the registers would represent intermediate bundles of wire that interconnect adder modules. Multiple additions can be performed via conventional two-operand adders or by means of carry-save adder trees, followed by a final carry-propagate adder. In both the hardware and software interpretations, the goal is to produce an optimal arrangement that requires a minimal number of operations and intermediate values. In the case of compiler-initiated optimizations, the complexity of the algorithm used for deriving the optimal sequence of operations is also of interest, as it affects the compiler\u2019s running time.</p> <p>\u5728\u672c\u8282\u7684\u5176\u4f59\u90e8\u5206\u4e2d\uff0c\u6211\u4eec\u5c06\u6839\u636e\u5bf9\u5bc4\u5b58\u5668\u5185\u5bb9\u6267\u884c\u7684\u79fb\u4f4d\u548c\u52a0/\u51cf\u8fd0\u7b97\u6765\u63cf\u8ff0\u4e58\u4ee5\u6574\u6570\u5e38\u91cf\u7684\u7b97\u6cd5\u3002\u56e0\u6b64\uff0c\u7b97\u6cd5\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u8f6c\u6362\u4e3a\u4efb\u4f55\u7279\u5b9a\u5904\u7406\u5668\u7684\u6307\u4ee4\u5e8f\u5217\u3002\u6240\u63cf\u8ff0\u7684\u7b97\u6cd5\u4e5f\u53ef\u4ee5\u88ab\u89c6\u4e3a\u6784\u5efa\u5230\u7279\u5b9a\u5e94\u7528\u8bbe\u8ba1\u4e2d\u7684\u786c\u4ef6\u7ed3\u6784\u3002\u4f8b\u5982\uff0c\u6570\u5b57\u6ee4\u6ce2\u5668\u53ef\u4ee5\u7528\u65b9\u7a0b \\(y[ t] = ax[ t] + bx[ t \u2212 1] + cx[ t \u2212 2] + dy[ t \u2212 1] + ey[ t \u2212 2]\\) \u6765\u8868\u5f81\uff0c\u5176\u4e2d \\(a-e\\) \u662f\u5e38\u6570\uff0c\\(x[ i]\\) \u662f\u65f6\u95f4\u6b65 i \u7684\u8f93\u5165\uff0c\\(y[ j]\\) \u662f\u65f6\u95f4\u6b65 j \u7684\u8f93\u51fa\u3002\u6839\u636e\u6240\u6d89\u53ca\u7684\u5e38\u6570\uff0c\u8ba1\u7b97 \\(y[t]\\) \u7684\u7535\u8def\u53ef\u80fd\u6839\u672c\u4e0d\u9700\u8981\u4e58\u6cd5\u5668\u3002\u4e8b\u5b9e\u4e0a\uff0c\u5982\u679c\u4ec5\u901a\u8fc7\u52a0\u6cd5\u5668\u5b9e\u73b0\uff0c\u7535\u8def\u53ef\u80fd\u4f1a\u66f4\u7b80\u5355\u3001\u66f4\u5feb\u4e14\u529f\u8017\u66f4\u4f4e\u3002\u5bf9\u4e8e\u540e\u4e00\u79cd\u89e3\u91ca\uff0c\u5bc4\u5b58\u5668\u5c06\u4ee3\u8868\u4e92\u8fde\u52a0\u6cd5\u5668\u6a21\u5757\u7684\u4e2d\u95f4\u7ebf\u675f\u3002\u591a\u91cd\u52a0\u6cd5\u53ef\u4ee5\u901a\u8fc7\u4f20\u7edf\u7684\u53cc\u64cd\u4f5c\u6570\u52a0\u6cd5\u5668\u6216\u901a\u8fc7\u8fdb\u4f4d\u4fdd\u5b58\u52a0\u6cd5\u5668\u6811\u4ee5\u53ca\u6700\u540e\u7684\u8fdb\u4f4d\u4f20\u64ad\u52a0\u6cd5\u5668\u6765\u6267\u884c\u3002\u5728\u786c\u4ef6\u548c\u8f6f\u4ef6\u89e3\u91ca\u4e2d\uff0c\u76ee\u6807\u662f\u4ea7\u751f\u9700\u8981\u6700\u5c11\u6570\u91cf\u7684\u64cd\u4f5c\u548c\u4e2d\u95f4\u503c\u7684\u6700\u4f73\u5b89\u6392\u3002\u5728\u7f16\u8bd1\u5668\u542f\u52a8\u7684\u4f18\u5316\u7684\u60c5\u51b5\u4e0b\uff0c\u7528\u4e8e\u5bfc\u51fa\u6700\u4f73\u64cd\u4f5c\u5e8f\u5217\u7684\u7b97\u6cd5\u7684\u590d\u6742\u6027\u4e5f\u4ee4\u4eba\u611f\u5174\u8da3\uff0c\u56e0\u4e3a\u5b83\u4f1a\u5f71\u54cd\u7f16\u8bd1\u5668\u7684\u8fd0\u884c\u65f6\u95f4\u3002</p> <p>In the examples that follow, R1 denotes the register holding the multiplicand and R i will denote an intermediate result that is i times the multiplicand (e.g., R65 denotes the result of multiplying the multiplicand a by 65). Note that a new value R j can be saved in the same physical register that holds R i, provided the old value in R i is not needed for subsequent computation steps.</p> <p>\u5728\u4e0b\u9762\u7684\u793a\u4f8b\u4e2d\uff0c\\(R_1\\) \u8868\u793a\u4fdd\u5b58\u88ab\u4e58\u6570\u7684\u5bc4\u5b58\u5668\uff0c\\(R_i\\) \u8868\u793a \\(i\\) \u500d\u88ab\u4e58\u6570\u7684\u4e2d\u95f4\u7ed3\u679c\uff08\u4f8b\u5982\uff0c\\(R_{65}\\) \u8868\u793a\u88ab\u4e58\u6570 \\(a\\) \u4e58\u4ee5 65 \u7684\u7ed3\u679c\uff09\u3002\u8bf7\u6ce8\u610f\uff0c\u5982\u679c\u540e\u7eed\u8ba1\u7b97\u6b65\u9aa4\u4e0d\u9700\u8981 \\(R_i\\) \u4e2d\u7684\u65e7\u503c\uff0c\u5219\u65b0\u503c R j \u53ef\u4ee5\u4fdd\u5b58\u5728\u4fdd\u5b58 R i \u7684\u540c\u4e00\u7269\u7406\u5bc4\u5b58\u5668\u4e2d\u3002</p> <p>A simple way to multiply the contents of a register by an integer constant multiplier is to write the multiplier in binary format and to use shifts and adds according to the 1s in the binary representation. For example to multiply R1 by 113 = ( 1110001 ) two, one might use</p> <p>\u5c06\u5bc4\u5b58\u5668\u7684\u5185\u5bb9\u4e58\u4ee5\u6574\u6570\u5e38\u91cf\u4e58\u6570\u7684\u4e00\u79cd\u7b80\u5355\u65b9\u6cd5\u662f\u4ee5\u4e8c\u8fdb\u5236\u683c\u5f0f\u7f16\u5199\u4e58\u6570\uff0c\u5e76\u6839\u636e\u4e8c\u8fdb\u5236\u8868\u793a\u5f62\u5f0f\u4e2d\u7684 1 \u4f7f\u7528\u79fb\u4f4d\u548c\u52a0\u6cd5\u3002\u4f8b\u5982\uff0c\u8981\u5c06 R1 \u4e58\u4ee5 113 = ( 1110001 ) \u4e8c\uff0c\u53ef\u4ee5\u4f7f\u7528</p> <pre><code>R2   \u2190 R1 shift-left 1\nR3   \u2190 R2 + R1\nR6   \u2190 R3 shift-left 1\nR7   \u2190 R6 + R1\nR112 \u2190 R7 shift-left 4\nR113 \u2190 R112 + R1\n</code></pre> <p>Only two registers are required; one to store the multiplicand a and one to hold the latest partial result.</p> <p>\u53ea\u9700\u8981\u4e24\u4e2a\u5bc4\u5b58\u5668\uff1b \u4e00\u4e2a\u5b58\u50a8\u88ab\u4e58\u6570 a\uff0c\u4e00\u4e2a\u4fdd\u5b58\u6700\u65b0\u7684\u90e8\u5206\u7ed3\u679c\u3002</p> <p>If a shift-and-add instruction is available, the sequence above becomes</p> <p>\u5982\u679c\u79fb\u4f4d\u52a0\u6cd5\u6307\u4ee4\u53ef\u7528\uff0c\u5219\u4e0a\u9762\u7684\u5e8f\u5217\u53d8\u4e3a</p> <pre><code>R3   \u2190 R1 shift-left 1 + R1\nR7   \u2190 R3 shift-left 1 + R1\nR113 \u2190 R7 shift-left 4 + R1\n</code></pre> <p>If only 1-bit shifts are allowed, the last instruction in the preceding sequence must be replaced by three shifts followed by a shift-and-add. Note that the pattern of shift-andadds and shifts (s&amp;a, s&amp;a, shift, shift, shift, s&amp;a) in this latter version matches the bit pattern of the multiplier if its most-significant bit is ignored (110001). </p> <p>\u5982\u679c\u53ea\u5141\u8bb8 1 \u4f4d\u79fb\u4f4d\uff0c\u5219\u524d\u9762\u5e8f\u5217\u4e2d\u7684\u6700\u540e\u4e00\u6761\u6307\u4ee4\u5fc5\u987b\u66ff\u6362\u4e3a\u4e09\u4e2a\u79fb\u4f4d\uff0c\u7136\u540e\u662f\u79fb\u4f4d\u52a0\u6cd5\u3002\u8bf7\u6ce8\u610f\uff0c\u5982\u679c\u5ffd\u7565\u6700\u9ad8\u6709\u6548\u4f4d (110001)\uff0c\u5219\u540e\u4e00\u4e2a\u7248\u672c\u4e2d\u7684\u79fb\u4f4d\u4e0e\u52a0\u6cd5\u548c\u79fb\u4f4d (s&amp;a, s&amp;a, shift, shift, shift, s&amp;a) \u7684\u6a21\u5f0f\u4e0e\u4e58\u6cd5\u5668\u7684\u4f4d\u6a21\u5f0f\u5339\u914d\u3002</p> <p>Many other instruction sequences are possible. For example, one could proceed by computing R16, R32, R64, R65, R97 ( R65 + R32 ), and R113 ( R97 + R16). However, this would use up more registers. If subtraction is allowed in the sequence, the number of instructions can be reduced in some cases. For example, by taking advantage of the equality 113 = 128 \u2212 16 + 1 = 16 ( 8 \u2212 1 ) + 1, one can derive the following sequence of instructions for multiplication by 113:</p> <p>\u8bb8\u591a\u5176\u4ed6\u6307\u4ee4\u5e8f\u5217\u662f\u53ef\u80fd\u7684\u3002\u4f8b\u5982\uff0c\u53ef\u4ee5\u901a\u8fc7\u8ba1\u7b97 R16\u3001R32\u3001R64\u3001R65\u3001R97 (R65 + R32) \u548c R113 (R97 + R16)\u3002\u7136\u800c\uff0c\u8fd9\u4f1a\u5360\u7528\u66f4\u591a\u7684\u5bc4\u5b58\u5668\u3002\u5982\u679c\u5e8f\u5217\u4e2d\u5141\u8bb8\u51cf\u6cd5\uff0c\u5219\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53ef\u4ee5\u51cf\u5c11\u6307\u4ee4\u6570\u91cf\u3002\u4f8b\u5982\uff0c\u5229\u7528\u7b49\u5f0f 113 = 128 \u2212 16 + 1 = 16 ( 8 \u2212 1 ) + 1\uff0c\u53ef\u4ee5\u5bfc\u51fa\u4ee5\u4e0b\u4e58\u4ee5 113 \u7684\u6307\u4ee4\u5e8f\u5217\uff1a</p> <pre><code>R8   \u2190 R1 shift-left 3\nR7   \u2190 R8 \u2212 R1\nR112 \u2190 R7 shift-left 4\nR113 \u2190 R112 + R1\n</code></pre> <p>In general, the use of subtraction helps if the binary representation of the integer has several consecutive 1s, since a sequence of j consecutive 1s can be replaced by 1 0 0 0 \u00b7 \u00b7 \u00b7 0 0 -1, where there are j \u2212 1 zeros (Booth\u2019s recoding).</p> <p>\u4e00\u822c\u6765\u8bf4\uff0c\u5982\u679c\u6574\u6570\u7684\u4e8c\u8fdb\u5236\u8868\u793a\u6709\u51e0\u4e2a\u8fde\u7eed\u7684 1\uff0c\u5219\u4f7f\u7528\u51cf\u6cd5\u4f1a\u6709\u6240\u5e2e\u52a9\uff0c\u56e0\u4e3a j \u4e2a\u8fde\u7eed 1 \u7684\u5e8f\u5217\u53ef\u4ee5\u7528 1 0 0 0 \u00b7 \u00b7 \u00b7 0 0 -1\u66ff\u6362\uff0c\u5176\u4e2d\u6709 j \u2212 1 \u4e2a\u96f6\uff08\u5e03\u65af\u91cd\u65b0\u7f16\u7801\uff09\u3002</p> <p>Factoring a number sometimes helps in obtaining efficient code. For example, to multiply R1 by 119, one can use the fact that 119 = 7 \u00d7 17 = ( 8 \u2212 1 ) \u00d7 ( 16 + 1 ) to obtain the sequence</p> <p>\u5bf9\u6570\u5b57\u8fdb\u884c\u56e0\u5f0f\u5206\u89e3\u6709\u65f6\u6709\u52a9\u4e8e\u83b7\u5f97\u9ad8\u6548\u7684\u4ee3\u7801\u3002\u4f8b\u5982\uff0c\u8981\u5c06 R1 \u4e58\u4ee5 119\uff0c\u53ef\u4ee5\u4f7f\u7528 119 = 7 \u00d7 17 = ( 8 \u2212 1 ) \u00d7 ( 16 + 1 ) \u6765\u83b7\u5f97\u5e8f\u5217</p> <pre><code>R8   \u2190 R1 shift-left 3\nR7   \u2190 R8 \u2212 R1\nR112 \u2190 R7 shift-left 4\nR119 \u2190 R112 + R7\n</code></pre> <p>With shift-and-add/subtract instructions, the preceding sequence reduces to only two instructions:</p> <p>\u4f7f\u7528\u79fb\u4f4d\u548c\u52a0/\u51cf\u6307\u4ee4\uff0c\u524d\u9762\u7684\u5e8f\u5217\u51cf\u5c11\u5230\u53ea\u6709\u4e24\u6761\u6307\u4ee4\uff1a</p> <pre><code>R7   \u2190 R1 shift-left 3 \u2212 R1\nR119 \u2190 R7 shift-left 4 + R7\n</code></pre> <p>In general, factors of the form 2 b \u00b1 1 translate directly into a shift followed by an add or subtract and lead to a simplification of the computation sequence. </p> <p>\u4e00\u822c\u6765\u8bf4\uff0c2 b \u00b1 1 \u5f62\u5f0f\u7684\u56e0\u5b50\u76f4\u63a5\u8f6c\u6362\u4e3a\u79fb\u4f4d\uff0c\u7136\u540e\u8fdb\u884c\u52a0\u6cd5\u6216\u51cf\u6cd5\uff0c\u4ece\u800c\u7b80\u5316\u8ba1\u7b97\u5e8f\u5217\u3002</p> <p>In a compiler that removes common subexpressions, moves invariant code out of loops, and performs a reduction of strength on multiplications inside loops (in particular changes multiplications to additions where possible), the effect of multiplication by constants is quite noticeable. It is not uncommon to obtain a 20% improvement in the resulting code, and some programs exhibit 60% improved performance [Bern86]. </p> <p>\u5728\u5220\u9664\u516c\u5171\u5b50\u8868\u8fbe\u5f0f\u7684\u7f16\u8bd1\u5668\u4e2d\uff0c\u5c06\u4e0d\u53d8\u4ee3\u7801\u79fb\u51fa\u5faa\u73af\uff0c\u5e76\u964d\u4f4e\u5faa\u73af\u5185\u4e58\u6cd5\u7684\u5f3a\u5ea6\uff08\u7279\u522b\u662f\u5728\u53ef\u80fd\u7684\u60c5\u51b5\u4e0b\u5c06\u4e58\u6cd5\u66f4\u6539\u4e3a\u52a0\u6cd5\uff09\uff0c\u4e58\u4ee5\u5e38\u6570\u7684\u6548\u679c\u975e\u5e38\u660e\u663e\u3002\u751f\u6210\u7684\u4ee3\u7801\u83b7\u5f97 20% \u7684\u6539\u8fdb\u5e76\u4e0d\u7f55\u89c1\uff0c\u6709\u4e9b\u7a0b\u5e8f\u7684\u6027\u80fd\u63d0\u9ad8\u4e86 60% [Bern86]\u3002</p> <p>For many small constants of practical interest, one can obtain reasonably efficient sequences of shift and add/subtract operations by trial and error, although the optimal synthesis problem for constant multiplication is known to be NP-complete in general [Capp84]. Optimal implementations have been derived by means of exhaustive search for constants of up to 19 bits [Gust02]. Additionally, automated design tools can assist us with finding suitable designs under various implementation technologies and constraints [Xili99]. </p> <p>\u5bf9\u4e8e\u8bb8\u591a\u5177\u6709\u5b9e\u9645\u610f\u4e49\u7684\u5c0f\u5e38\u6570\uff0c\u4eba\u4eec\u53ef\u4ee5\u901a\u8fc7\u53cd\u590d\u8bd5\u9a8c\u83b7\u5f97\u76f8\u5f53\u6709\u6548\u7684\u79fb\u4f4d\u548c\u52a0/\u51cf\u8fd0\u7b97\u5e8f\u5217\uff0c\u5c3d\u7ba1\u5e38\u6570\u4e58\u6cd5\u7684\u6700\u4f73\u7efc\u5408\u95ee\u9898\u901a\u5e38\u5df2\u77e5\u662f NP \u5b8c\u5168\u95ee\u9898 [Capp84]\u3002\u901a\u8fc7\u5bf9\u6700\u591a 19 \u4f4d\u5e38\u91cf\u7684\u7a77\u4e3e\u641c\u7d22\u5f97\u51fa\u4e86\u6700\u4f73\u5b9e\u73b0 [Gust02]\u3002\u6b64\u5916\uff0c\u81ea\u52a8\u5316\u8bbe\u8ba1\u5de5\u5177\u53ef\u4ee5\u5e2e\u52a9\u6211\u4eec\u5728\u5404\u79cd\u5b9e\u65bd\u6280\u672f\u548c\u7ea6\u675f\u4e0b\u627e\u5230\u5408\u9002\u7684\u8bbe\u8ba1 [Xili99]. </p>"},{"location":"Part_03/09/#96","title":"9.6 \u9ad8\u901f\u4e58\u6cd5\u5668\u7684\u9884\u89c8","text":"<p>If one views multiplication as a multioperand addition problem, there are but two ways to speed it up:</p> <ul> <li> <p>Reducing the number of operands to be added.</p> </li> <li> <p>Adding the operands faster.</p> </li> </ul> <p>\u5982\u679c\u4eba\u4eec\u5c06\u4e58\u6cd5\u89c6\u4e3a\u591a\u64cd\u4f5c\u6570\u52a0\u6cd5\u95ee\u9898\uff0c\u90a3\u4e48\u53ea\u6709\u4e24\u79cd\u65b9\u6cd5\u53ef\u4ee5\u52a0\u901f\u5b83\uff1a</p> <ul> <li>\u51cf\u5c11\u8981\u6dfb\u52a0\u7684\u64cd\u4f5c\u6570\u7684\u6570\u91cf\u3002</li> <li>\u66f4\u5feb\u5730\u5bf9\u64cd\u4f5c\u6570\u505a\u52a0\u6cd5\u3002</li> </ul> <p>Reducing the number of operands to be added leads to high-radix multipliers in which several bits of the multiplier are multiplied by the multiplicand in 1 cycle. Speedup is achieved for radix 2 j as long as multiplying j bits of the multiplier by the multiplicand and adding the result to the cumulative partial product takes less than j times as long as multiplying 1 bit and adding the result. High-radix multipliers are covered in Chapter 10.</p> <p>\u51cf\u5c11\u8981\u76f8\u52a0\u7684\u64cd\u4f5c\u6570\u6570\u91cf\u4f1a\u5bfc\u81f4\u9ad8\u57fa\u6570\u4e58\u6cd5\u5668\uff0c\u5176\u4e2d\u4e58\u6cd5\u5668\u7684\u51e0\u4e2a\u4f4d\u5728 1 \u4e2a\u5468\u671f\u5185\u4e0e\u88ab\u4e58\u6570\u76f8\u4e58\u3002\u5bf9\u4e8e\u57fa\u6570 \\(2^j\\)\uff0c\u53ea\u8981\u5c06\u4e58\u6cd5\u5668\u7684 \\(j\\) \u4f4d\u4e58\u4ee5\u88ab\u4e58\u6570\u5e76\u5c06\u7ed3\u679c\u4e0e\u7d2f\u79ef\u90e8\u5206\u79ef\u76f8\u52a0\uff0c\u6240\u9700\u65f6\u95f4\u5c11\u4e8e\u4e58\u4ee5 1 \u4f4d\u5e76\u5c06\u7ed3\u679c\u76f8\u52a0\u7684 \\(j\\) \u500d\uff0c\u5373\u53ef\u5b9e\u73b0\u52a0\u901f\u3002\u7b2c 10 \u7ae0\u4ecb\u7ecd\u4e86\u9ad8\u57fa\u6570\u4e58\u6cd5\u5668\u3002</p> <p>To add the partial products faster, one can design hardware multioperand adders that minimize the latency and/or maximize the throughput by using some of the ideas discussed in Chapter 8. These multioperand addition techniques lead to tree and array multipliers, which form the subjects of Chapter 11.</p> <p>\u4e3a\u4e86\u66f4\u5feb\u5730\u6dfb\u52a0\u90e8\u5206\u4e58\u79ef\uff0c\u53ef\u4ee5\u4f7f\u7528\u7b2c 8 \u7ae0\u4e2d\u8ba8\u8bba\u7684\u4e00\u4e9b\u60f3\u6cd5\u6765\u8bbe\u8ba1\u786c\u4ef6\u591a\u64cd\u4f5c\u6570\u52a0\u6cd5\u5668\uff0c\u4ee5\u6700\u5c0f\u5316\u5ef6\u8fdf\u548c/\u6216\u6700\u5927\u5316\u541e\u5410\u91cf\u3002\u8fd9\u4e9b\u591a\u64cd\u4f5c\u6570\u52a0\u6cd5\u6280\u672f\u5bfc\u81f4\u4e86\u6811\u548c\u6570\u7ec4\u4e58\u6cd5\u5668\uff0c\u5b83\u4eec\u6784\u6210\u4e86\u7b2c 11 \u7ae0\u7684\u4e3b\u9898\u3002</p>"},{"location":"Part_03/09/#_1","title":"\u95ee\u9898\uff08\u7565\uff09","text":""},{"location":"Part_03/09/#_2","title":"\u53c2\u8003\u6587\u732e\u548c\u8fdb\u4e00\u6b65\u9605\u8bfb","text":"<pre><code>[Bern86] Bernstein, R., \u201cMultiplication by Integer Constants,\u201d Software\u2014Practice and\n         Experience, Vol. 16, No. 7, pp. 641\u2013652, 1986.\n[Boot51] Booth, A. D., \u201cA Signed Binary Multiplication Technique,\u201d Quarterly J. Mechanics\n         and Applied Mathematics, Vol. 4, Pt. 2, pp. 236\u2013240, 1951.\n[Boul03] Boullis, N., and A. Tisserand, \u201cSome Optimizations of Hardware Multiplication by\n         Constant Matrices,\u201d Proc. 16th IEEE Symp. Computer Arithmetic, June 2003, pp.\n         20\u201327.\n[Bris08] Brisebarre, N., and J.-M. Muller, \u201cCorrectly Rounded Multiplication by Arbitrary\n         Precision Constants,\u201d IEEE Trans. Computers, Vol. 57, No. 2, pp. 165\u2013174, 2008.\n[Capp84] Cappelo, P. R., and K. Steiglitz, \u201cSome Complexity Issues in Digital Signal\n         Processing,\u201d IEEE Trans. Acoustics, Speech and Signal Processing, Vol. 32, No. 5,\n         pp. 1037\u20131041, 1984.\n[Gust02] Gustafsson, O., A. G. Dempster, and L. Wanhammar, \u201cExtended Results for\n         Minimum-Adder Constant Integer Multipliers,\u201d Proc. IEEE Int\u2019l Symp. Circuits and\n         Systems, Vol. 1, pp. 73\u201376, 2002.\n[Kore93] Koren, I., Computer Arithmetic Algorithms, Prentice-Hall, 1993.\n[Omon94] Omondi, A. R., Computer Arithmetic Systems: Algorithms, Architecture and\n         Implementations, Prentice-Hall, 1994.\n[Robe55] Robertson, J. E., \u201cTwo\u2019s Complement Multiplication in Binary Parallel Computers,\u201d\n         IRE Trans. Electronic Computers, Vol. 4, No. 3, pp. 118\u2013119, 1955.\n[Shaw50] Shaw, R. F., \u201cArithmetic Operations in a Binary Computer,\u201d Rev. Scientific\n         Instruments, Vol. 21, pp. 687\u2013693, 1950.\n[Voro07] Voroneko, Y., and M. Puschel, \u201cMultiplierless Multiple Constant Multiplication,\u201d\n         ACM Trans. Algorithms, Vol. 3, No. 2, Article 11, 38 pp., 2007.\n[Xili99] Xilinx Corporation, \u201cConstant (K) Coefficient Multiplier Generator for Virtex,\u201d\n         Application note, March 1999.\n</code></pre>"},{"location":"Part_03/10/","title":"10. \u9ad8\u57fa\u4e58\u6cd5\u5668","text":"<p>High-Radix Multipliers</p> <p>\u201cWe go on multiplying our conveniences only to multiply our cares.We increase our possessions only to the enlargement of our anxieties.\u201d ANNA C . BRACKETT</p> <p>\u201c\u6211\u4eec\u4e0d\u65ad\u589e\u52a0\u6211\u4eec\u7684\u4fbf\u5229\uff0c\u53ea\u4f1a\u589e\u52a0\u6211\u4eec\u7684\u5fe7\u8651\u3002\u6211\u4eec\u589e\u52a0\u6211\u4eec\u7684\u8d22\u4ea7\uff0c\u53ea\u4f1a\u52a0\u5267\u6211\u4eec\u7684\u7126\u8651\u3002\u201d \u5b89\u5a1c\u00b7C. \u5e03\u83b1\u514b\u7279</p> <p>In this chapter, we review multiplication schemes that handle more than 1 bit of the multiplier in each cycle (2 bits per cycle in radix 4, 3 bits in radix 8, etc.). The reduction in the number of cycles, along with the use of recoding and carry-save addition to simplify the required computations in each cycle, leads to significant gains in speed over the basic multipliers of Chapter 9. Chapter topics include:</p> <p>\u5728\u672c\u7ae0\u4e2d\uff0c\u6211\u4eec\u56de\u987e\u5728\u6bcf\u4e2a\u5468\u671f\u4e2d\u5904\u7406\u8d85\u8fc7 1 \u4f4d\u4e58\u6cd5\u5668\u7684\u4e58\u6cd5\u65b9\u6848\uff08\u57fa 4 \u4e2d\u6bcf\u4e2a\u5468\u671f 2 \u4f4d\uff0c\u57fa 8 \u4e2d\u6bcf\u4e2a\u5468\u671f 3 \u4f4d\uff0c\u7b49\u7b49\uff09\u3002 \u5faa\u73af\u6570\u91cf\u7684\u51cf\u5c11\uff0c\u4ee5\u53ca\u4f7f\u7528\u91cd\u65b0\u7f16\u7801\u548c\u8fdb\u4f4d\u4fdd\u5b58\u52a0\u6cd5\u6765\u7b80\u5316\u6bcf\u4e2a\u5faa\u73af\u4e2d\u6240\u9700\u7684\u8ba1\u7b97\uff0c\u4e0e\u7b2c 9 \u7ae0\u7684\u57fa\u672c\u4e58\u6cd5\u5668\u76f8\u6bd4\uff0c\u901f\u5ea6\u663e\u7740\u63d0\u9ad8\u3002\u672c\u7ae0\u4e3b\u9898\u5305\u62ec\uff1a</p> <ul> <li>10.1 \u57fa 4 \u4e58\u6cd5 RADIX 4 MULTIPLICATION</li> <li>10.2 \u6539\u8fdb\u7684\u5e03\u65af\u7f16\u7801 MODIFIED BOOTH'S RECODING</li> <li>10.3 \u5e94\u7528\u8fdb\u4f4d\u4fdd\u7559\u52a0\u6cd5\u5668 USING CARRY SAVE ADDERS</li> <li>10.4 \u57fa 8 \u4e0e\u57fa 16 \u4e58\u6cd5\u5668 RADIX 8 AND RADIX-16 MULTIPLIERS</li> <li>10.5 \u591a\u8282\u62cd\u4e58\u6cd5\u5668 MULTIBEAT MULTIPLIERS</li> <li>10.6 VLSI\u590d\u6742\u6027\u5206\u6790\u4e3b\u9898 VLSI COMPLEXITY ISSUES</li> </ul>"},{"location":"Part_03/10/#101-4","title":"10.1 \u57fa 4 \u4e58\u6cd5","text":"<p>For a given range of numbers to be represented, a higher representation radix leads to fewer digits. Thus, a digit-at-a-time multiplication algorithm requires fewer cycles as we move to higher radices. This motivates us to study high-radix multiplication algorithms and associated hardware implementations. Since a k-bit binary number can be interpreted as a k/ 2-digit radix-4 number, a k/ 3-digit radix-8 number, and so on, the use of high-radix multiplication essentially entails dealing with more than 1 bit of the multiplier in each cycle.</p> <p>\u5bf9\u4e8e\u7ed9\u5b9a\u7684\u8981\u8868\u793a\u7684\u6570\u5b57\u8303\u56f4\uff0c\u8f83\u9ad8\u7684\u8868\u793a\u57fa\u6570\u4f1a\u5bfc\u81f4\u8f83\u5c11\u7684\u6570\u5b57\u3002\u56e0\u6b64\uff0c\u5f53\u6211\u4eec\u8f6c\u5411\u66f4\u9ad8\u7684\u57fa\u6570\u65f6\uff0c\u4e00\u6b21\u6570\u5b57\u4e58\u6cd5\u7b97\u6cd5\u9700\u8981\u66f4\u5c11\u7684\u5468\u671f\u3002\u8fd9\u6fc0\u52b1\u6211\u4eec\u7814\u7a76\u9ad8\u57fa\u6570\u4e58\u6cd5\u7b97\u6cd5\u548c\u76f8\u5173\u7684\u786c\u4ef6\u5b9e\u73b0\u3002\u7531\u4e8e k \u4f4d\u4e8c\u8fdb\u5236\u6570\u53ef\u4ee5\u89e3\u91ca\u4e3a \\(\\left \\lceil k/ 2 \\right \\rceil\\) \u4f4d\u57fa\u6570 4 \u6570\u3001\\(\\left \\lceil k/ 3 \\right \\rceil\\) \u4f4d\u57fa\u6570 8 \u6570\u7b49\uff0c\u56e0\u6b64\u4f7f\u7528\u9ad8\u57fa\u6570\u4e58\u6cd5\u672c\u8d28\u4e0a\u9700\u8981\u5728\u6bcf\u4e2a\u5468\u671f\u4e2d\u5904\u7406\u591a\u4e8e 1 \u4f4d\u7684\u4e58\u6cd5\u5668\u3002</p> <p>We begin by presenting the general radix- r versions of the multiplication recurrences given in Section 9.1:</p> <p>\u6211\u4eec\u9996\u5148\u4ecb\u7ecd\u7b2c 9.1 \u8282\u4e2d\u7ed9\u51fa\u7684\u4e58\u6cd5\u9012\u5f52\u7684\u4e00\u822c\u57fa\u6570-r \u7248\u672c\uff1a</p> <p></p> <p>Since multiplication by r\u22121 or r still entails right or left shifting by one digit, the only difference between high-radix and radix-2 multiplication is in forming the terms xia, which now require more computation.</p> <p>\u7531\u4e8e\u4e58\u4ee5 \\(r\u22121\\) \u6216 \\(r\\) \u4ecd\u7136\u9700\u8981\u53f3\u79fb\u6216\u5de6\u79fb\u4e00\u4f4d\u6570\uff0c\u56e0\u6b64\u9ad8\u57fa\u6570\u4e58\u6cd5\u548c\u57fa 2 \u4e58\u6cd5\u4e4b\u95f4\u7684\u552f\u4e00\u533a\u522b\u5728\u4e8e\u5f62\u6210\u9879 \\(x_ia\\)\uff0c\u73b0\u5728\u9700\u8981\u66f4\u591a\u8ba1\u7b97\u3002</p> <p>For example, if multiplication is done in radix 4, in each step, the partial product term (xi+1 xi) two a needs to be formed and added to the cumulative partial product. Figure 10.1 shows the multiplication process in dot notation. Straightforward application of this method leads to the following problem. Whereas in radix-2 multiplication, each row of dots in the partial products matrix represents 0 or a shifted version of a, here we need the multiples 0 a, 1 a, 2 a, and 3 a. The first three of these present no problem (2 a is simply the shifted version of a). But computing 3 a needs at least an addition operation (3 a = 2 a + a).</p> <p>\u4f8b\u5982\uff0c\u5982\u679c\u4ee5\u57fa\u65704\u8fdb\u884c\u4e58\u6cd5\uff0c\u5219\u5728\u6bcf\u4e00\u6b65\u4e2d\uff0c\u9700\u8981\u5f62\u6210\u90e8\u5206\u79ef\u9879\\((x_{i+1}x_i)_2\\)\u548ca\uff0c\u5e76\u5c06\u5176\u4e0e\u7d2f\u79ef\u90e8\u5206\u79ef\u76f8\u52a0\u3002\u56fe 10.1 \u4ee5\u70b9\u8868\u793a\u6cd5\u663e\u793a\u4e86\u4e58\u6cd5\u8fc7\u7a0b\u3002\u76f4\u63a5\u5e94\u7528\u8be5\u65b9\u6cd5\u4f1a\u5bfc\u81f4\u4ee5\u4e0b\u95ee\u9898\u3002\u800c\u5728\u57fa 2 \u4e58\u6cd5\u4e2d\uff0c\u90e8\u5206\u79ef\u77e9\u9635\u4e2d\u7684\u6bcf\u4e00\u884c\u70b9\u4ee3\u8868 0 \u6216 \\(a\\) \u7684\u79fb\u4f4d\u7248\u672c\uff0c\u8fd9\u91cc\u6211\u4eec\u9700\u8981\u500d\u6570 \\(0 a\u30011 a\u30012 a\\) \u548c \\(3 a\\)\u3002\u5176\u4e2d\u524d\u4e09\u4e2a\u6ca1\u6709\u95ee\u9898\uff082 a \u53ea\u662f a \u7684\u79fb\u4f4d\u7248\u672c\uff09\u3002\u4f46\u8ba1\u7b97\\(3a\\)\u81f3\u5c11\u9700\u8981\u4e00\u6b21\u52a0\u6cd5\u8fd0\u7b97\uff08\\(3a=2a+a\\)\uff09\u3002</p> <p></p> <p>In the remainder of this section, and in Section 10.2, we review several solutions for the preceding problem in radix-4 multiplication.</p> <p>\u5728\u672c\u8282\u7684\u5269\u4f59\u90e8\u5206\u548c\u7b2c 10.2 \u8282\u4e2d\uff0c\u6211\u4eec\u56de\u987e\u4e86\u57fa 4 \u4e58\u6cd5\u4e2d\u4e0a\u8ff0\u95ee\u9898\u7684\u51e0\u79cd\u89e3\u51b3\u65b9\u6848\u3002</p> <p>The first option is to compute 3 a once at the outset and store it in a register for future use. Then, the rest of the multiplier hardware will be very similar to that depicted in Fig. 9.4a, except that the two-way multiplexer (mux) is replaced by a four-way multiplexer as shown in Fig. 10.2. An example multiplication is given in Fig. 10.3.</p> <p>\u7b2c\u4e00\u4e2a\u9009\u9879\u662f\u4ece\u4e00\u5f00\u59cb\u5c31\u8ba1\u7b97 \\(3 a\\) \u4e00\u6b21\u5e76\u5c06\u5176\u5b58\u50a8\u5728\u5bc4\u5b58\u5668\u4e2d\u4ee5\u4f9b\u5c06\u6765\u4f7f\u7528\u3002\u7136\u540e\uff0c\u4e58\u6cd5\u5668\u786c\u4ef6\u7684\u5176\u4f59\u90e8\u5206\u5c06\u4e0e\u56fe 9.4a \u4e2d\u6240\u793a\u7684\u975e\u5e38\u76f8\u4f3c\uff0c\u9664\u4e86\u4e24\u8def\u591a\u8def\u590d\u7528\u5668\uff08mux\uff09\u88ab\u56db\u8def\u591a\u8def\u590d\u7528\u5668\u53d6\u4ee3\uff0c\u5982\u56fe10.2\u6240\u793a\u3002\u56fe 10.3 \u7ed9\u51fa\u4e86\u4e00\u4e2a\u4e58\u6cd5\u793a\u4f8b\u3002</p> <p></p> <p></p> <p>Another possible solution exists when 3 a needs to be added: we add \u2212 a and send a carry of 1 into the next radix-4 digit of the multiplier (Fig. 10.4). Including the incoming carry, the needed multiple in each cycle is in [0, 4]. The multiples 0, 1, and 2 are handled directly, while the multiples 3 and 4 are converted to \u22121 and 0, respectively, plus an outgoing carry of 1, which is stored in a flip-flop (FF) for addition to the next radix-4 multiplier digit. An extra cycle may be needed at the end because of the carry.</p> <p>\u5b58\u5728\u53e6\u4e00\u79cd\u53ef\u80fd\u7684\u52a0 \\(3 a\\) \u89e3\u51b3\u65b9\u6848\uff1a\u6211\u4eec\u52a0 \\(\u2212 a\\) \u5e76\u5c06\u8fdb\u4f4d 1 \u53d1\u9001\u5230\u4e58\u6cd5\u5668\u7684\u4e0b\u4e00\u4e2a\u57fa 4 \u6570\u5b57\u4e2d\uff08\u56fe 10.4\uff09\u3002\u5305\u62ec\u4f20\u5165\u7684\u8fdb\u4f4d\u5728\u5185\uff0c\u6bcf\u4e2a\u5468\u671f\u6240\u9700\u7684\u500d\u6570\u5728[0, 4]\u4e2d\u3002\u500d\u6570 0\u30011 \u548c 2 \u76f4\u63a5\u5904\u7406\uff0c\u800c\u500d\u6570 3 \u548c 4 \u5206\u522b\u8f6c\u6362\u4e3a -1 \u548c 0\uff0c\u52a0\u4e0a\u4f20\u51fa\u8fdb\u4f4d 1\uff0c\u5c06\u5176\u5b58\u50a8\u5728\u89e6\u53d1\u5668 (FF) \u4e2d\u4ee5\u6dfb\u52a0\u5230\u4e0b\u4e00\u4e2a\u57fa\u6570 4 \u4e58\u6570\u4f4d\u6570\u3002\u7531\u4e8e\u8fdb\u4f4d\uff0c\u6700\u540e\u53ef\u80fd\u9700\u8981\u4e00\u4e2a\u989d\u5916\u7684\u5468\u671f\u3002</p> <p></p> <p>The multiplication schemes depicted in Figs. 10.2 and 10.4 can be extended to radices 8, 16, etc., but the multiple generation hardware becomes more complex for higher radices, nullifying most, if not all, of the gain in speed due to fewer cycles. For example, in radix 8, one needs to precompute the multiples 3 a, 5 a, and 7 a, or else precompute only 3 a  and use a carry scheme similar to that in Fig. 10.4 to convert the multiples 5 a, 6 a, and 7 a  to \u22123 a, \u22122 a, and \u2212 a, respectively, plus a carry of 1. Supplying the details is left as an exercise. </p> <p>\u56fe 1 \u548c 2 \u4e2d\u63cf\u7ed8\u7684\u4e58\u6cd5\u65b9\u6848\u3002 10.2\u548c10.4\u53ef\u4ee5\u6269\u5c55\u5230\u57fa\u6570 8\u300116 \u7b49\uff0c\u4f46\u5bf9\u4e8e\u66f4\u9ad8\u7684\u57fa\u6570\uff0c\u591a\u4ee3\u786c\u4ef6\u53d8\u5f97\u66f4\u52a0\u590d\u6742\uff0c\u62b5\u6d88\u4e86\u5927\u90e8\u5206\uff08\u5982\u679c\u4e0d\u662f\u5168\u90e8\uff09\u7531\u4e8e\u5468\u671f\u6570\u8f83\u5c11\u800c\u5e26\u6765\u7684\u901f\u5ea6\u589e\u76ca\u3002\u4f8b\u5982\uff0c\u5728\u57fa\u6570 8 \u4e2d\uff0c\u9700\u8981\u9884\u5148\u8ba1\u7b97\u500d\u6570 \\(3a\\)\u3001\\(5a\\) \u548c \\(7a\\)\uff0c\u6216\u8005\u4ec5\u9884\u5148\u8ba1\u7b97 \\(3a\\)\uff0c\u5e76\u4f7f\u7528\u7c7b\u4f3c\u4e8e\u56fe 10.4 \u4e2d\u7684\u8fdb\u4f4d\u65b9\u6848\u5c06\u500d\u6570 \\(5a\\)\u3001\\(6a\\) \u548c \\(7a\\) \u5206\u522b\u8f6c\u6362\u4e3a \\(-3a\\)\u3001\\(-2a\\) \u548c \\(-a\\)\uff0c\u518d\u52a0\u4e0a\u8fdb\u4f4d 1\u3002\u63d0\u4f9b\u8be6\u7ec6\u4fe1\u606f\u7559\u4f5c\u7ec3\u4e60\u3002</p> <p>We will see later in this chapter that with certain other hardware implementations, even higher radices become practical. </p> <p>\u6211\u4eec\u5c06\u5728\u672c\u7ae0\u540e\u9762\u770b\u5230\uff0c\u901a\u8fc7\u67d0\u4e9b\u5176\u4ed6\u786c\u4ef6\u5b9e\u73b0\uff0c\u751a\u81f3\u66f4\u9ad8\u7684\u57fa\u6570\u4e5f\u53d8\u5f97\u5b9e\u7528\u3002</p>"},{"location":"Part_03/10/#102","title":"10.2 \u6539\u8fdb\u7684\u5e03\u65af\u7f16\u7801","text":"<p>As stated near the end of Section 9.4, radix-2 Booth recoding is not directly applied in modern arithmetic circuits; however, it does serve as a tool in understanding the higher-radix versions of Booth\u2019s recoding. It is easy to see that when a binary number is recoded using Table 9.1, the result will not have consecutive 1s or -1s. Thus, if radix-4 multiplication is performed with the recoded multiplier, only the multiples \u00b1 a and \u00b12 a of the multiplicand will be required, all of which are easily obtained by shifting and/or complementation.</p> <p>\u6b63\u5982\u7b2c 9.4 \u8282\u672b\u5c3e\u6240\u8ff0\uff0cradix-2 Booth \u91cd\u65b0\u7f16\u7801\u5e76\u4e0d\u76f4\u63a5\u5e94\u7528\u4e8e\u73b0\u4ee3\u7b97\u672f\u7535\u8def\u4e2d\uff1b \u7136\u800c\uff0c\u5b83\u786e\u5b9e\u53ef\u4ee5\u4f5c\u4e3a\u7406\u89e3\u5e03\u65af\u91cd\u65b0\u7f16\u7801\u7684\u9ad8\u57fa\u6570\u7248\u672c\u7684\u5de5\u5177\u3002 \u5f88\u5bb9\u6613\u770b\u51fa\uff0c\u5f53\u4f7f\u7528\u88689.1\u91cd\u65b0\u7f16\u7801\u4e00\u4e2a\u4e8c\u8fdb\u5236\u6570\u65f6\uff0c\u7ed3\u679c\u4e0d\u4f1a\u6709\u8fde\u7eed\u7684\\(1\\)\u6216\\(-1\\)\u3002 \u56e0\u6b64\uff0c\u5982\u679c\u7528\u91cd\u65b0\u7f16\u7801\u7684\u4e58\u6cd5\u5668\u6267\u884c\u57fa4\u4e58\u6cd5\uff0c\u5219\u4ec5\u9700\u8981\u88ab\u4e58\u6570\u7684\u500d\u6570\u00b1a*\u548c\u00b12*a\uff0c\u6240\u6709\u8fd9\u4e9b\u90fd\u53ef\u4ee5\u901a\u8fc7\u79fb\u4f4d\u548c/\u6216\u6c42\u8865\u6765\u5bb9\u6613\u5730\u83b7\u5f97\u3002</p> <p>Now since yi+1 depends on xi+1 and xi, and yi depends on xi and xi\u22121, the radix-4 digit zi/ 2 = (yi+1 yi) two, i even, can be obtained directly from xi+1, xi, and xi\u22121 without a need for first forming the radix-2 recoded number y (Table 10.1).</p> <p>\u73b0\u5728\uff0c\u7531\u4e8e \\(y_{i+1}\\) \u53d6\u51b3\u4e8e \\(x_{i+1}\\) \u548c \\(x_i\\)\uff0c\u5e76\u4e14 \\(y_i\\) \u53d6\u51b3\u4e8e \\(x_i\\) \u548c \\(x_i\u22121\\)\uff0c\u56e0\u6b64\u57fa-4\u6570\u5b57 $z_{i/2} = (y_{i+1} y_{i})_2 $\uff0c\u5176\u4e2d \\(i\\)\u662f\u5076\u6570\uff0c\u53ef\u4ee5\u76f4\u63a5\u4ece \\(x_{i+1}\u3001x_i\\) \u548c \\(x_{i\u22121}\\) \u83b7\u5f97\uff0c\u800c\u4e0d\u9700\u8981\u9996\u5148\u5f62\u6210\u57fa 2 \u91cd\u65b0\u7f16\u7801\u7684\u6570\u5b57 \\(y\\)\uff08\u8868 10.1\uff09\u3002</p> <p></p> <p>Like the radix-2 version, radix-4 Booth\u2019s recoding can be viewed as digit-set conversion: the recoding takes a radix-4 number with digits in [0, 3] and converts it to the digit set [\u22122, 2]. As an example, Table 10.1 can be used to perform the following conversion of an unsigned number into a signed-digit number:</p> <p>\u4e0e radix-2 \u7248\u672c\u4e00\u6837\uff0cradix-4 Booth \u7684\u91cd\u65b0\u7f16\u7801\u53ef\u4ee5\u89c6\u4e3a\u6570\u5b57\u96c6\u8f6c\u6362\uff1a\u91cd\u65b0\u7f16\u7801\u628a\u6570\u5b57\u4e3a [0, 3] \u7684 radix-4 \u6570\u5b57\u8f6c\u6362\u4e3a\u6570\u5b57\u96c6 [\u22122, 2]\u7684\u6570\u5b57\u3002\u4f8b\u5982\uff0c\u8868 10.1 \u53ef\u7528\u4e8e\u6267\u884c\u4ee5\u4e0b\u65e0\u7b26\u53f7\u6570\u5230\u6709\u7b26\u53f7\u6570\u7684\u8f6c\u6362\uff1a</p> <p>$$ \\begin{array}{lr} ( 21 31 22 32 )_4 &amp;= &amp; &amp;(10 &amp;01 &amp; 11 &amp; 01 &amp;10 &amp;10 &amp;11 &amp;10)_2 \\                      &amp;= &amp;( 1 &amp;^-2 &amp;2  &amp;^-1 &amp;2 &amp;^-1 &amp;^-1 &amp;0 &amp;^-2 )_4 \\end{array} $$ Note that the 16-bit unsigned number turns into a 9-digit radix-4 number. Generally, the radix-4 signed-digit representation of a k-bit unsigned binary number will need k/ 2 + 1 = (k + 1 )/ 2 digits when its most-significant bit is 1. Note also that x\u22121 = xk = xk+1 = 0 is assumed. If the binary number in the preceding example is interpreted as being in 2\u2019s-complement format, then simply ignoring the extra radix-4 digit produced leads to correct encoding of the represented value:</p> <p>\u8bf7\u6ce8\u610f\uff0c16 \u4f4d\u65e0\u7b26\u53f7\u6570\u4f1a\u53d8\u6210 9 \u4f4d\u57fa\u6570 4 \u6570\u3002\u4e00\u822c\u6765\u8bf4\uff0c\u5f53\u6700\u9ad8\u6709\u6548\u4f4d\u4e3a 1 \u65f6\uff0c\\(k\\)-\u4f4d\u65e0\u7b26\u53f7\u4e8c\u8fdb\u5236\u6570\u7684\u57fa 4 \u6709\u7b26\u53f7\u6570\u5b57\u8868\u793a\u5c06\u9700\u8981 \\(\\left \\lfloor k/ 2 \\right \\rfloor + 1 = \\left \\lceil (k + 1 )/ 2 \\right \\rceil\\) \u4f4d\u3002\u53e6\u8bf7\u6ce8\u610f \\(x_{\u22121} = x_k = x_{k+1} = 0\\)\u3002\u5982\u679c\u4e0a\u4f8b\u4e2d\u7684\u4e8c\u8fdb\u5236\u6570\u88ab\u89e3\u91ca\u4e3a 2 \u7684\u8865\u7801\u683c\u5f0f\uff0c\u7136\u540e\u7b80\u5355\u5730\u5ffd\u7565\u751f\u6210\u7684\u989d\u5916\u57fa\u6570 4 \u6570\u5b57\u5373\u53ef\u5f97\u5230\u6240\u8868\u793a\u503c\u7684\u6b63\u786e\u7f16\u7801\uff1a </p> <p>\\(( 10\\ 01\\ 11\\ 01\\ 10\\ 10\\ 11\\ 10 )_{2\u2019s-compl} = (^-2\\ 2\\ ^-1\\ 2\\ ^-1\\ ^-1\\ 0\\ ^-2 )_4\\)</p> <p>Thus, for k-bit binary numbers in 2\u2019s-complement format, the Booth-encoded radix-4 version will have k/ 2 digits. When k is odd, xk = xk\u22121 is assumed for proper recoding. In any case, x\u22121 = 0.</p> <p>\u56e0\u6b64\uff0c\u5bf9\u4e8e 2 \u8865\u7801\u683c\u5f0f\u7684 k \u4f4d\u4e8c\u8fdb\u5236\u6570\uff0c\u5e03\u65af\u7f16\u7801\u7684 radix-4\u7248\u672c\u5c06\u6709 k/ 2 \u4f4d\u6570\u5b57\u3002\u5f53 k \u4e3a\u5947\u6570\u65f6\uff0c\u5047\u8bbe \\(x_k = x_{k\u22121}\\) \u4ee5\u4fbf\u6b63\u786e\u91cd\u65b0\u7f16\u7801\u3002\u65e0\u8bba\u5982\u4f55\uff0c\\(x_{\u22121} = 0\\)\u3002</p> <p>The digit-set conversion process defined by radix-4 Booth\u2019s recoding entails no carry propagation. Each radix-4 digit in [\u22122, 2] is obtained, independently from all others, by examining 3 bits of the multiplier, with consecutive 3-bit segments overlapping in 1 bit. For this reason, radix-4 Booth\u2019s recoding is said to be based on overlapped 3-bit scanning of the multiplier. This can be extended to overlapped multiple-bit scanning schemes for higher radices (see Section 10.4).</p> <p>radix-4 Booth \u91cd\u65b0\u7f16\u7801\u5b9a\u4e49\u7684\u6570\u5b57\u96c6\u8f6c\u6362\u8fc7\u7a0b\u4e0d\u9700\u8981\u8fdb\u4f4d\u4f20\u64ad\u3002 \\([\u22122, 2]\\) \u4e2d\u7684\u6bcf\u4e2a\u57fa\u6570 4 \u6570\u5b57\u90fd\u662f\u901a\u8fc7\u68c0\u67e5\u4e58\u6cd5\u5668\u7684 3 \u4f4d\uff08\u5176\u4e2d\u8fde\u7eed 3 \u4f4d\u6bb5\u5728 1 \u4f4d\u4e2d\u91cd\u53e0\uff09\u72ec\u7acb\u4e8e\u6240\u6709\u5176\u4ed6\u6570\u5b57\u800c\u83b7\u5f97\u7684\u3002\u56e0\u6b64\uff0cradix-4 Booth \u7684\u91cd\u7f16\u7801\u88ab\u79f0\u4e3a\u662f\u57fa\u4e8e\u91cd\u53e0 3 \u4f4d\u626b\u63cf\u7684\u4e58\u6cd5\u5668\u3002\u8fd9\u53ef\u4ee5\u6269\u5c55\u5230\u66f4\u9ad8\u57fa\u6570\u7684\u91cd\u53e0\u591a\u4f4d\u626b\u63cf\u65b9\u6848\uff08\u53c2\u89c1\u7b2c 10.4 \u8282\uff09\u3002</p> <p>An example radix-4 multiplication using Booth\u2019s recoding is shown in Fig. 10.5. The 4-bit 2\u2019s-complement multiplier x = ( 1010 ) two is recoded as a 2-digit radix-4 number z = (-1-2 ) four, which then dictates the multiples z 0 a = \u22122 a and z 1 a = \u2212 a to be added to the cumulative partial product in the 2 cycles. Note that in all intermediate steps, the upper half of the cumulative partial product is extended from 4 bits to 6 bits to accommodate the sign extension needed for proper handling of the negative values. Also, note the sign extension during the right shift to obtain p( 1 ) from 4 p( 1 ).</p> <p>\u4f7f\u7528 Booth \u91cd\u65b0\u7f16\u7801\u7684\u57fa 4 \u4e58\u6cd5\u793a\u4f8b\u5982\u56fe 10.5 \u6240\u793a\u3002 4 \u4f4d 2 \u7684\u8865\u7801\u4e58\u6cd5\u5668 \\(x = ( 1010 )_2\\) \u88ab\u91cd\u65b0\u7f16\u7801\u4e3a 2 \u4f4d\u57fa\u6570 4 \u6570 \\(z = (-1\\ -2 )_4\\)\uff0c\u7136\u540e\u6307\u793a\u8981\u6dfb\u52a0\u5230 2 \u4e2a\u5468\u671f\u4e2d\u7684\u7d2f\u79ef\u90e8\u5206\u79ef\u7684\u500d\u6570 \\(z_0 a = \u22122 a\\) \u548c \\(z_1 a = \u2212 a\\)\u3002\u8bf7\u6ce8\u610f\uff0c\u5728\u6240\u6709\u4e2d\u95f4\u6b65\u9aa4\u4e2d\uff0c\u7d2f\u79ef\u90e8\u5206\u79ef\u7684\u4e0a\u534a\u90e8\u5206\u4ece 4 \u4f4d\u6269\u5c55\u5230 6 \u4f4d\uff0c\u4ee5\u9002\u5e94\u6b63\u786e\u5904\u7406\u8d1f\u503c\u6240\u9700\u7684\u7b26\u53f7\u6269\u5c55\u3002\u53e6\u5916\uff0c\u8bf7\u6ce8\u610f\u53f3\u79fb\u671f\u95f4\u7684\u7b26\u53f7\u6269\u5c55\uff0c\u4ee5\u4fbf\u4ece \\(4p^{( 1 )}\\) \u83b7\u5f97 \\(p^{( 1 )}\\) \u3002</p> <p></p> <p>Figure 10.6 depicts a possible circuit implementation for multiple generation based on radix-4 Booth\u2019s recoding. Since five possible multiples of a or digits (0, \u00b11, \u00b12) are</p> <p>involved, we need at least 3 bits to encode a desired multiple. A simple and efficient encoding is to devote 1 bit to distinguish 0 from nonzero digits, 1 bit to the sign of a nonzero digit, and 1 bit to the magnitude of a nonzero digit (2 encoded as 1 and 1 as 0). The recoding circuit thus has three inputs ( xi+1, xi, xi\u22121) and produces three outputs: \u201cneg\u201d indicates whether the multiple should be added (0) or subtracted (1), \u201cnon0\u201d indicates if the multiple is nonzero, and \u201ctwo\u201d indicates that a nonzero multiple is 2.</p> <p>\u56fe 10.6 \u63cf\u8ff0\u4e86\u57fa\u4e8e radix-4 Booth \u91cd\u65b0\u7f16\u7801\u7684\u591a\u91cd\u751f\u6210\u7684\u53ef\u80fd\u7535\u8def\u5b9e\u73b0\u3002\u7531\u4e8e\u53ef\u80fd\u6d89\u53ca\u5230\\(a\\)\u7684\u4e94\u4e2a\u7684\u500d\u6570\u6216\u6570\u5b57\uff080\u3001\u00b11\u3001\u00b12\uff09\uff0c\u6211\u4eec\u81f3\u5c11\u9700\u8981 3 \u4f4d\u6765\u7f16\u7801\u6240\u9700\u7684\u500d\u6570\u3002\u4e00\u79cd\u7b80\u5355\u800c\u9ad8\u6548\u7684\u7f16\u7801\u662f\u7528 1 \u4f4d\u6765\u533a\u5206 0 \u548c\u975e\u96f6\u6570\u5b57\uff0c\u7528 1 \u4f4d\u6765\u533a\u5206\u975e\u96f6\u6570\u5b57\u7684\u7b26\u53f7\uff0c\u7528 1 \u4f4d\u6765\u533a\u5206\u975e\u96f6\u6570\u5b57\u7684\u5927\u5c0f\uff082 \u7f16\u7801\u4e3a 1\uff0c1 \u7f16\u7801\u4e3a 0\uff09\u3002\u56e0\u6b64\uff0c\u91cd\u65b0\u7f16\u7801\u7535\u8def\u5177\u6709\u4e09\u4e2a\u8f93\u5165\uff08\\(x_{i+1}\u3001x_i\u3001x_{i\u22121}\\)\uff09\u5e76\u4ea7\u751f\u4e09\u4e2a\u8f93\u51fa\uff1a</p> <ul> <li>\u201cneg\u201d\u8868\u793a\u500d\u6570\u662f\u52a0\uff080\uff09\u8fd8\u662f\u51cf\uff081\uff09\uff0c</li> <li>\u201cnon0\u201d \u8868\u793a\u500d\u6570\u662f\u5426\u975e\u96f6\uff0c</li> <li>\u201ctwo\u201d\u8868\u793a\u975e\u96f6\u500d\u6570\u4e3a 2\u3002</li> </ul> <p></p> <p>It is instructive to compare the recoding scheme implicit in the design of Fig. 10.4 with Booth\u2019s recoding of Fig. 10.6 in terms of cost and delay. This is left as an exercise. Note, in particular, that while the recoding produced in Fig. 10.4 is serial and must thus be done from right to left, Booth\u2019s recoding is fully parallel and carry-free. This latter property is of no avail in designing digit-at-a-time multipliers, since the recoded digits are used serially anyway. But we will see later that Booth\u2019s recoding can be applied to the design of tree and array multipliers, where all the multiples are needed at once.</p> <p>\u6bd4\u8f83\u56fe 10.4 \u8bbe\u8ba1\u4e2d\u9690\u542b\u7684\u91cd\u7f16\u7801\u4e0e\u56fe 10.6 Booth\u91cd\u7f16\u7801\u7684\u65b9\u6848\u7684\u6210\u672c\u548c\u5ef6\u8fdf\u662f\u6709\u542f\u53d1\u6027\u7684\u3002\u8fd9\u7559\u4f5c\u7ec3\u4e60\u3002\u8bf7\u7279\u522b\u6ce8\u610f\uff0c\u867d\u7136\u56fe 10.4 \u4e2d\u4ea7\u751f\u7684\u91cd\u65b0\u7f16\u7801\u662f\u4e32\u884c\u7684\uff0c\u56e0\u6b64\u5fc5\u987b\u4ece\u53f3\u5230\u5de6\u5b8c\u6210\uff0c\u4f46\u5e03\u65af\u7684\u91cd\u65b0\u7f16\u7801\u662f\u5b8c\u5168\u5e76\u884c\u4e14\u65e0\u8fdb\u4f4d\u7684\u3002\u540e\u4e00\u4e2a\u5728\u8bbe\u8ba1\u4e00\u6b21\u6570\u5b57\u4e58\u6cd5\u5668\u65f6\u6ca1\u6709\u4efb\u4f55\u7528\u5904\uff0c\u56e0\u4e3a\u65e0\u8bba\u5982\u4f55\u91cd\u65b0\u7f16\u7801\u7684\u6570\u5b57\u90fd\u662f\u4e32\u884c\u4f7f\u7528\u7684\u3002\u4f46\u7a0d\u540e\u6211\u4eec\u4f1a\u770b\u5230\uff0c\u5e03\u65af\u7684\u91cd\u65b0\u7f16\u7801\u53ef\u4ee5\u5e94\u7528\u4e8e\u6811\u548c\u6570\u7ec4\u4e58\u6cd5\u5668\u7684\u8bbe\u8ba1\uff0c\u5176\u4e2d\u6240\u6709\u500d\u6570\u90fd\u540c\u65f6\u9700\u8981\u3002</p>"},{"location":"Part_03/10/#103","title":"10.3 \u5e94\u7528\u8fdb\u4f4d\u4fdd\u7559\u52a0\u6cd5\u5668","text":"<p>Carry-save adders (CSAs) can be used to reduce the number of addition cycles as well as to make each cycle faster. For example, radix-4 multiplication without Booth\u2019s recoding can be implemented by using a CSA to handle the 3 a multiple, as shown in Fig. 10.7. Here, the CSAhelps us in doing radix-4 multiplication (generating the required multiples) without reducing the add time. In fact, one can say that the add time is slightly increased, since the CSA overhead is paid in every cycle, regardless of whether we actually need 3 a.</p> <p>\u8fdb\u4f4d\u4fdd\u5b58\u52a0\u6cd5\u5668 (CSA) \u53ef\u7528\u4e8e\u51cf\u5c11\u52a0\u6cd5\u5468\u671f\u6570\u5e76\u4f7f\u6bcf\u4e2a\u5468\u671f\u66f4\u5feb\u3002\u4f8b\u5982\uff0c\u65e0\u9700\u5e03\u65af\u91cd\u65b0\u7f16\u7801\u7684\u57fa 4 \u4e58\u6cd5\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528 CSA \u6765\u5904\u7406 \\(3a\\) \u7684\u500d\u6570\u6765\u5b9e\u73b0\uff0c\u5982\u56fe 10.7 \u6240\u793a\u3002\u5728\u8fd9\u91cc\uff0cCSA \u5e2e\u52a9\u6211\u4eec\u8fdb\u884c\u57fa 4 \u4e58\u6cd5\uff08\u751f\u6210\u6240\u9700\u7684\u500d\u6570\uff09\uff0c\u800c\u65e0\u9700\u51cf\u5c11\u52a0\u6cd5\u65f6\u95f4\u3002\u4e8b\u5b9e\u4e0a\uff0c\u53ef\u4ee5\u8bf4\u52a0\u6cd5\u65f6\u95f4\u7565\u6709\u589e\u52a0\uff0c\u56e0\u4e3a CSA \u5f00\u9500\u662f\u5728\u6bcf\u4e2a\u5468\u671f\u4e2d\u652f\u4ed8\u7684\uff0c\u65e0\u8bba\u6211\u4eec\u662f\u5426\u5b9e\u9645\u4e0a\u9700\u8981 \\(3a\\) \u3002</p> <p></p> <p>The CSA and multiplexers in the radix-4 multiplier of Fig. 10.7 can be put to better use for reducing the addition time in radix-2 multiplication by keeping the cumulative partial product in stored-carry form. In fact, only the upper half of the cumulative partial product needs to be kept in redundant form, since as we add the three values that form the next cumulative partial product, 1 bit of the final product is obtained in standard binary form and is shifted into the lower half of the double-width partial product register (Fig. 10.8b). This eliminates the need for carry propagation in all but the final addition.</p> <p>\u56fe 10.7 \u7684 radix-4 \u4e58\u6cd5\u5668\u4e2d\u7684 CSA \u548c\u591a\u8def\u590d\u7528\u5668\u53ef\u4ee5\u901a\u8fc7\u5c06\u7d2f\u79ef\u90e8\u5206\u79ef\u4fdd\u6301\u4e3a\u5b58\u50a8\u8fdb\u4f4d\u5f62\u5f0f\u6765\u66f4\u597d\u5730\u7528\u4e8e\u51cf\u5c11 radix-2 \u4e58\u6cd5\u4e2d\u7684\u52a0\u6cd5\u65f6\u95f4\u3002\u4e8b\u5b9e\u4e0a\uff0c\u53ea\u6709\u7d2f\u79ef\u90e8\u5206\u79ef\u7684\u4e0a\u534a\u90e8\u5206\u9700\u8981\u4ee5\u5197\u4f59\u5f62\u5f0f\u4fdd\u7559\uff0c\u56e0\u4e3a\u5f53\u6211\u4eec\u5c06\u5f62\u6210\u4e0b\u4e00\u4e2a\u7d2f\u79ef\u90e8\u5206\u79ef\u7684\u4e09\u4e2a\u503c\u76f8\u52a0\u65f6\uff0c\u6700\u7ec8\u79ef\u7684 1 \u4f4d\u5c06\u4ee5\u6807\u51c6\u4e8c\u8fdb\u5236\u5f62\u5f0f\u83b7\u5f97\uff0c\u5e76\u79fb\u5165\u4e24\u500d\u5bbd\u5ea6\u90e8\u5206\u79ef\u5bc4\u5b58\u5668\uff08\u56fe10.8b\uff09\u7684\u4e0b\u534a\u90e8\u5206\u3002 \u8fd9\u6d88\u9664\u4e86\u9664\u6700\u540e\u52a0\u6cd5\u4e4b\u5916\u7684\u6240\u6709\u8fc7\u7a0b\u4e2d\u8fdb\u4f4d\u4f20\u64ad\u7684\u9700\u8981\u3002</p> <p></p> <p>Each of the first k \u22121 cycles can now be made much shorter, since in these cycles, signals pass through only a few gate levels corresponding to the multiplexers and the CSA. In particular, the delay in these cycles is independent of the word width k. Compared with a simple sequential multiplier (Fig. 9.4a), the additional components needed to implement the CSA-based binary multiplier of Fig. 10.8a are a k-bit register, a k-bit CSA, and a k-bit multiplexer; only the extra k-bit register is missing in the design of Fig. 10.7.</p> <p>\u73b0\u5728\u53ef\u4ee5\u4f7f\u524d k -1 \u4e2a\u5468\u671f\u4e2d\u7684\u6bcf\u4e2a\u5468\u671f\u53d8\u5f97\u66f4\u77ed\uff0c\u56e0\u4e3a\u5728\u8fd9\u4e9b\u5468\u671f\u4e2d\uff0c\u4fe1\u53f7\u4ec5\u901a\u8fc7\u4e0e\u591a\u8def\u590d\u7528\u5668\u548c CSA \u76f8\u5bf9\u5e94\u7684\u51e0\u4e2a\u95e8\u7ea7\u3002\u7279\u522b\u5730\uff0c\u8fd9\u4e9b\u5468\u671f\u4e2d\u7684\u5ef6\u8fdf\u4e0e\u5b57\u5bbdk\u65e0\u5173\u3002\u4e0e\u7b80\u5355\u7684\u987a\u5e8f\u4e58\u6cd5\u5668\uff08\u56fe9.4a\uff09\u76f8\u6bd4\uff0c\u5b9e\u73b0\u56fe10.8a\u7684\u57fa\u4e8eCSA\u7684\u4e8c\u8fdb\u5236\u4e58\u6cd5\u5668\u6240\u9700\u7684\u9644\u52a0\u7ec4\u4ef6\u662fk\u4f4d\u5bc4\u5b58\u5668\u3001k\u4f4dCSA\u548ck\u4f4d\u591a\u8def\u590d\u7528\u5668\uff1b\u56fe 10.7 \u7684\u8bbe\u8ba1\u4e2d\u4ec5\u7f3a\u5c11\u989d\u5916\u7684 k \u4f4d\u5bc4\u5b58\u5668\u3002</p> <p>The CSA-based design of Fig. 10.8 can be combined with radix-4 Booth\u2019s recoding to reduce the number of cycles by 50%, while also making each cycle considerably shorter. The changes needed in the design of Fig. 10.8 to accomplish this are depicted in Fig. 10.9, where the small 2-bit adder is needed to combine 2 bits of the sum, 1 bit of the carry, and a carry from a preceding cycle into 2 bits that are shifted into the lower half of the cumulative partial product (PP) register and a carry that is kept for the next cycle. In other words, whereas a 1-bit right shift of the stored-carry partial product at the bottom of Fig. 10.8b moves 1 bit from the upper half to the lower half of the double-width partial product, as indicated by the dashed arrow, a 2-bit right shift in radix-4 multiplication would move 3 bits: one from column k and two from column k + 1. The 2-bit adder converts these bits from redundant to nonredundant format, which is the format used in the lower half of the partial product register. The use of the carry-in input of the 2-bit adder is explained shortly.</p> <p>\u56fe 10.8 \u4e2d\u57fa\u4e8e CSA \u7684\u8bbe\u8ba1\u53ef\u4ee5\u4e0e radix-4 Booth \u7684\u91cd\u65b0\u7f16\u7801\u76f8\u7ed3\u5408\uff0c\u5c06\u5468\u671f\u6570\u51cf\u5c11 50%\uff0c\u540c\u65f6\u4e5f\u4f7f\u6bcf\u4e2a\u5468\u671f\u5927\u5927\u7f29\u77ed\u3002\u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e00\u70b9\uff0c\u56fe 10.8 \u7684\u8bbe\u8ba1\u4e2d\u9700\u8981\u8fdb\u884c\u7684\u66f4\u6539\u5982\u56fe 10.9 \u6240\u793a\uff0c\u5176\u4e2d\u9700\u8981\u5c0f\u578b 2 \u4f4d\u52a0\u6cd5\u5668\uff0c\u5c06 2 \u4f4d\u548c\u30011 \u4f4d\u8fdb\u4f4d\u4ee5\u53ca\u6765\u81ea\u524d\u4e00\u5468\u671f\u7684\u8fdb\u4f4d\u5408\u5e76\u4e3a 2 \u4f4d\uff0c\u8fd9\u4e9b\u4f4d\u88ab\u79fb\u5165\u7d2f\u79ef\u90e8\u5206\u79ef (PP) \u5bc4\u5b58\u5668\u7684\u4e0b\u534a\u90e8\u5206\u4ee5\u53ca\u4e3a\u4e0b\u4e00\u4e2a\u5468\u671f\u4fdd\u7559\u7684\u8fdb\u4f4d\u3002\u6362\u53e5\u8bdd\u8bf4\uff0c\u5982\u56fe 10.8b \u5e95\u90e8\u7684\u5b58\u50a8\u8fdb\u4f4d\u90e8\u5206\u79ef\u7684 1 \u4f4d\u53f3\u79fb\u5c06 1 \u4f4d\u4ece\u4e24\u500d\u5bbd\u90e8\u5206\u79ef\u7684\u4e0a\u534a\u90e8\u5206\u79fb\u52a8\u5230\u4e0b\u534a\u90e8\u5206\uff0c\u5982\u865a\u7ebf\u7bad\u5934\u6240\u793a\uff0c\u800c\u57fa 4 \u4e58\u6cd5\u4e2d\u7684 2 \u4f4d\u53f3\u79fb\u5c06\u79fb\u52a8 3 \u4f4d\uff1a\u4e00\u4f4d\u6765\u81ea k \u5217\uff0c\u4e24\u4f4d\u6765\u81ea k + 1 \u5217\u30022 \u4f4d\u52a0\u6cd5\u5668\u5c06\u8fd9\u4e9b\u4f4d\u4ece\u5197\u4f59\u683c\u5f0f\u8f6c\u6362\u4e3a\u975e\u5197\u4f59\u683c\u5f0f\uff0c\u8fd9\u662f\u4e0b\u5c42\u4e2d\u4f7f\u7528\u7684\u683c\u5f0f\u3002\u90e8\u5206\u4ea7\u54c1\u767b\u8bb0\u518c\u7684\u4e00\u534a\u3002\u7b80\u77ed\u5730\u89e3\u91ca\u4e86 2 \u4f4d\u52a0\u6cd5\u5668\u7684\u8fdb\u4f4d\u8f93\u5165\u7684\u4f7f\u7528\u3002</p> <p></p> <p>The Booth recoding and multiple selection logic of Fig. 10.9 is different from the arrangement in Fig. 10.6, since the sign of each multiple must be incorporated in the multiple itself, rather than as a signal that controls addition/subtraction. Figure 10.10 depicts Booth recoding and multiple selection circuits that can be used for stored-carry and parallel multipliers.</p> <p>\u56fe10.9\u7684\u5e03\u65af\u91cd\u65b0\u7f16\u7801\u548c\u500d\u6570\u9009\u62e9\u903b\u8f91\u4e0e\u56fe10.6\u4e2d\u7684\u5e03\u7f6e\u4e0d\u540c\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u500d\u6570\u7684\u7b26\u53f7\u5fc5\u987b\u5408\u5e76\u5728\u500d\u6570\u672c\u8eab\u4e2d\uff0c\u800c\u4e0d\u662f\u4f5c\u4e3a\u63a7\u5236\u52a0\u6cd5/\u51cf\u6cd5\u7684\u4fe1\u53f7\u3002\u56fe10.10\u63cf\u8ff0\u4e86\u53ef\u7528\u4e8e\u5b58\u50a8\u8fdb\u4f4d\u548c\u5e76\u884c\u4e58\u6cd5\u5668\u7684\u5e03\u65af\u91cd\u65b0\u7f16\u7801\u548c\u591a\u91cd\u9009\u62e9\u7535\u8def\u3002</p> <p></p> <p>Note that in the circuit of Fig. 10.10, the negative multiples \u2212 a and \u22122 a are produced in 2\u2019s-complement format. As usual, this is done by bitwise complementation of a or 2 a and the addition of 1 in the least-significant bit position. The multiple a or 2 a produced from xi and xi+1 is aligned at the right with bit position i and thus must be padded with i zeros at its right end when viewed as a 2 k-bit number. Bitwise complementation of these 0s, followed by the addition of 1 in the least-significant bit position, converts them back to 0s and causes a carry to enter bit position i. For this reason, we can continue to ignore positions 0 through i \u2212 1 in the negative multiples and insert the extra \u201cdot\u201d directly in bit position i (Fig. 10.9).</p> <p>\u8bf7\u6ce8\u610f\uff0c\u5728\u56fe 10.10 \u7684\u7535\u8def\u4e2d\uff0c\u8d1f\u500d\u6570 \u2212 a \u548c \u22122 a \u4ee5 2 \u8865\u7801\u683c\u5f0f\u751f\u6210\u3002\u4e0e\u5f80\u5e38\u4e00\u6837\uff0c\u8fd9\u662f\u901a\u8fc7\u5bf9 a \u6216 2 a \u6309\u4f4d\u8865\u7801\u5e76\u5728\u6700\u4f4e\u6709\u6548\u4f4d\u4f4d\u7f6e\u52a0 1 \u6765\u5b8c\u6210\u7684\u3002\u7531 xi \u548c xi+1 \u751f\u6210\u7684\u500d\u6570 a \u6216 2 a \u4e0e\u4f4d\u4f4d\u7f6e i \u53f3\u4fa7\u5bf9\u9f50\uff0c\u56e0\u6b64\u5f53\u5c06\u5176\u89c6\u4e3a 2 k \u4f4d\u6570\u5b57\u65f6\uff0c\u5fc5\u987b\u5728\u5176\u53f3\u7aef\u586b\u5145 i \u4e2a\u96f6\u3002\u5bf9\u8fd9\u4e9b 0 \u6309\u4f4d\u8865\u7801\uff0c\u7136\u540e\u5728\u6700\u4f4e\u6709\u6548\u4f4d\u4f4d\u7f6e\u52a0 1\uff0c\u5c06\u5b83\u4eec\u8f6c\u6362\u56de 0\uff0c\u5e76\u5bfc\u81f4\u8fdb\u4f4d\u8fdb\u5165\u4f4d\u4f4d\u7f6e i\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u7ee7\u7eed\u5ffd\u7565\u8d1f\u500d\u6570\u4e2d\u7684\u4f4d\u7f6e 0 \u5230 i-1\uff0c\u5e76\u5c06\u989d\u5916\u7684\u201c\u70b9\u201d\u76f4\u63a5\u63d2\u5165\u4f4d\u4f4d\u7f6e i\uff08\u56fe 10.9\uff09\u3002</p> <p>Alternatively, one can do away with Booth\u2019s recoding and use the scheme depicted in Fig. 10.7 to accommodate the required 3 a multiple. Now, four numbers (the sum and carry components of the cumulative partial product, xia, and 2 xi+1 a) need to be combined, thus necessitating a two-level CSA tree (Fig. 10.11).</p> <p>\u6216\u8005\uff0c\u53ef\u4ee5\u53d6\u6d88 Booth \u7684\u91cd\u65b0\u7f16\u7801\uff0c\u5e76\u4f7f\u7528\u56fe 10.7 \u4e2d\u63cf\u8ff0\u7684\u65b9\u6848\u6765\u9002\u5e94\u6240\u9700\u7684 3 \u4e2a\u500d\u6570\u3002\u73b0\u5728\uff0c\u56db\u4e2a\u6570\u5b57\uff08\u603b\u548c\u7d2f\u79ef\u90e8\u5206\u79ef \\(x_ia\\) \u548c \\(2 x_{i+1} a\\)) \u7684\u8fdb\u4f4d\u5206\u91cf\u9700\u8981\u7ec4\u5408\uff0c\u56e0\u6b64\u9700\u8981\u4e24\u5c42 CSA \u6811\uff08\u56fe 10.11\uff09\u3002</p> <p></p>"},{"location":"Part_03/10/#104-8-16","title":"10.4 \u57fa 8 \u4e0e\u57fa 16 \u4e58\u6cd5\u5668","text":"<p>From the radix-4 multiplier in Fig. 10.11, it is an easy step to visualize higher-radix multipliers. A radix-8 multiplier, for example, might have a three-level CSA tree to combine the carry-save cumulative partial product with the three multiples xia, 2 xi+1 a, and 4 xi+2 a into a new cumulative partial product in carry-save form. However, once we have gone to three levels of CSA, we might as well invest in one more CSA to implement a radix-16, or 4-bits-at-a-time, multiplier. The resulting design is depicted in Fig. 10.12.</p> <p>\u4ece\u56fe 10.11 \u4e2d\u7684\u57fa\u6570 4 \u4e58\u6cd5\u5668\u4e2d\uff0c\u53ef\u4ee5\u8f7b\u677e\u5730\u53ef\u89c6\u5316\u66f4\u9ad8\u57fa\u6570\u4e58\u6cd5\u5668\u3002\u4f8b\u5982\uff0c\u57fa 8 \u4e58\u6cd5\u5668\u53ef\u80fd\u5177\u6709\u4e09\u7ea7 CSA \u6811\uff0c\u7528\u4e8e\u5c06\u8fdb\u4f4d\u4fdd\u5b58\u7d2f\u79ef\u90e8\u5206\u79ef\u4e0e\u4e09\u4e2a\u500d\u6570 \\(x_ia\\)\u3001\\(2 x_{i+1} a\\) \u548c \\(4 x_{i+2} a\\) \u7ec4\u5408\u6210\u8fdb\u4f4d\u4fdd\u5b58\u5f62\u5f0f\u7684\u65b0\u7d2f\u79ef\u90e8\u5206\u79ef\u3002\u7136\u800c\uff0c\u4e00\u65e6\u6211\u4eec\u8fbe\u5230\u4e86\u4e09\u4e2a\u7ea7\u522b\u7684 CSA\uff0c\u6211\u4eec\u4e0d\u59a8\u518d\u6295\u8d44\u4e00\u4e2a CSA \u6765\u5b9e\u73b0\u57fa\u6570 16 \u6216\u4e00\u6b21 4 \u4f4d\u4e58\u6cd5\u5668\u3002\u6700\u7ec8\u7684\u8bbe\u8ba1\u5982\u56fe 10.12 \u6240\u793a\u3002</p> <p></p> <p>An alternative radix-16 multiplier can be derived from Fig. 10.11 if we replace each of the multiplexers with Booth recoding and multiple selection circuits. Supplying the details of the multiplier design, including proper alignment and sign extension for the inputs to the CSA tree, is left as an exercise.</p> <p>\u5982\u679c\u6211\u4eec\u7528 Booth \u91cd\u65b0\u7f16\u7801\u548c\u591a\u91cd\u9009\u62e9\u7535\u8def\u66ff\u6362\u6bcf\u4e2a\u591a\u8def\u590d\u7528\u5668\uff0c\u5219\u53ef\u4ee5\u4ece\u56fe 10.11 \u4e2d\u5f97\u51fa\u66ff\u4ee3\u7684 radix-16 \u4e58\u6cd5\u5668\u3002\u63d0\u4f9b\u4e58\u6cd5\u5668\u8bbe\u8ba1\u7684\u7ec6\u8282\uff0c\u5305\u62ec CSA \u6811\u8f93\u5165\u7684\u6b63\u786e\u5bf9\u9f50\u548c\u7b26\u53f7\u6269\u5c55\uff0c\u7559\u4f5c\u7ec3\u4e60\u3002</p> <p>Which of the preceding radix-16 multipliers (Fig. 10.12 or Fig. 10.11 modified to include Booth\u2019s recoding) is faster or more cost-effective depends on the detailed circuit-level designs as well as technological parameters.</p> <p>\u524d\u9762\u7684\u57fa 16 \u4e58\u6cd5\u5668\uff08\u4fee\u6539\u56fe 10.12 \u6216\u56fe 10.11\u5305\u62ec\u5e03\u65af\u7684\u91cd\u65b0\u7f16\u7801\uff09\u4e2d\u54ea\u4e00\u4e2a\u66f4\u5feb\u6216\u66f4\u5177\u6210\u672c\u6548\u76ca\u53d6\u51b3\u4e8e\u8be6\u7ec6\u7684\u7535\u8def\u7ea7\u8bbe\u8ba1\u4ee5\u53ca\u6280\u672f\u53c2\u6570\u3002</p> <p>Note that in radix-2 b multiplication with Booth\u2019s recoding, we have to reduce b/*2 multiples to 2 using a ( *b/ 2 + 2)-input CSA tree whose other two inputs are taken by the carry-save partial product. Without Booth\u2019s recoding, a ( b + 2)-input CSA tree would be needed. Whether to use Booth\u2019s recoding is a fairly close call, since Booth recoding circuit and multiple selection logic is somewhat slower than a CSA but also has a larger reduction factor in the number of operands (2 vs. 1.5).</p> <p>\u8bf7\u6ce8\u610f\uff0c\u5728 radix-\\(2^b\\) \u4e0e Booth \u91cd\u65b0\u7f16\u7801\u7684\u4e58\u6cd5\u4e2d\uff0c\u6211\u4eec\u5fc5\u987b \\(b/ 2\\)\u4e2a\u4e58\u79ef\u5f52\u5e76\u52302\u4e2a \uff0c\u4f7f\u7528 \\(( b/ 2 + 2)\\) \u8f93\u5165 CSA \u6811\uff0c\u8be5\u6811\u7684\u5176\u4ed6\u4e24\u4e2a\u8f93\u5165\u7531\u8fdb\u4f4d\u4fdd\u5b58\u90e8\u5206\u79ef\u5360\u7528\u3002\u5982\u679c\u6ca1\u6709 Booth \u7684\u91cd\u65b0\u7f16\u7801\uff0c\u5c06\u9700\u8981 (b + 2) \u8f93\u5165 CSA \u6811\u3002\u662f\u5426\u4f7f\u7528 Booth \u91cd\u65b0\u7f16\u7801\u662f\u4e00\u4e2a\u76f8\u5f53\u63a5\u8fd1\u7684\u51b3\u5b9a\uff0c\u56e0\u4e3a Booth \u91cd\u65b0\u7f16\u7801\u7535\u8def\u548c\u591a\u91cd\u9009\u62e9\u903b\u8f91\u6bd4 CSA \u7a0d\u6162\uff0c\u4f46\u64cd\u4f5c\u6570\u6570\u91cf\u4e5f\u6709\u66f4\u5927\u7684\u51cf\u5c11\u56e0\u5b50\uff082 vs. 1.5\uff09\u3002</p> <p>Varied as the preceding choices are, they do not exhaust the design space. Other alternatives include radix-8 and radix-16 Booth\u2019s recoding, which represent the multiplier using the digit sets [\u22124, 4] and [\u22128, 8], respectively. We will explore the recoding process and the associated multiplier design options in the end-of-chapter problems. Note, for example, that with radix-8 recoding, we have the \u00b13 a  multiples to deal with. As before, we can precompute 3 a  or represent it as the pair of numbers 2 a  and  a, leading to the requirement for an extra input into the CSA tree. </p> <p>\u5c3d\u7ba1\u524d\u9762\u7684\u9009\u62e9\u591a\u79cd\u591a\u6837\uff0c\u4f46\u5b83\u4eec\u5e76\u4e0d\u662f\u6240\u6709\u8bbe\u8ba1\u7a7a\u95f4\u3002\u5176\u4ed6\u66ff\u4ee3\u65b9\u6848\u5305\u62ec radix-8 \u548c radix-16 Booth \u7684\u91cd\u65b0\u7f16\u7801\uff0c\u5b83\u4eec\u4ee3\u8868\u4e58\u6570\u5206\u522b\u4f7f\u7528\u6570\u5b57\u96c6 [\u22124, 4] \u548c [\u22128, 8]\u3002\u6211\u4eec\u5c06\u5728\u7ae0\u672b\u95ee\u9898\u4e2d\u63a2\u8ba8\u91cd\u65b0\u7f16\u7801\u8fc7\u7a0b\u548c\u76f8\u5173\u7684\u4e58\u6cd5\u5668\u8bbe\u8ba1\u9009\u9879\u3002\u8bf7\u6ce8\u610f\uff0c\u4f8b\u5982\uff0c\u4f7f\u7528 radix-8 \u91cd\u65b0\u7f16\u7801\u65f6\uff0c\u6211\u4eec\u9700\u8981\u5904\u7406 \\(\u00b13 a\\) \u500d\u6570\u3002\u548c\u4ee5\u524d\u4e00\u6837\uff0c\u6211\u4eec\u53ef\u4ee5\u9884\u5148\u8ba1\u7b97 \\(3 a\\) \u6216\u5c06\u5176\u8868\u793a\u4e3a\u4e00\u5bf9\u6570\u5b57 \\(2 a\\) \u548c \\(a\\)\uff0c\u4ece\u800c\u9700\u8981\u5411 CSA \u6811\u63d0\u4f9b\u989d\u5916\u7684\u8f93\u5165\u3002</p> <p>There is, no compelling reason to stop at radix 16. A design similar to that in Fig. </p> <p>10.12 can be used for radix-256 (8-bits-at-a-time) multiplication if Booth\u2019s recoding is applied first. This would require that the four multiplexers in Fig. 10.12 be replaced by the Booth recoding and selection logic. Again, whether this new arrangement will lead to a cost-effective design (compared, for example, with taking 7 bits of the multiplier and adding nine numbers in a four-level CSA tree) depends on the technology and cannot be discerned in general. </p> <p>\u6ca1\u6709\u7406\u7531\u4e00\u5b9a\u8981\u505c\u6b62\u5728\u57fa16 \u5904\u3002 \u5982\u679c\u5148\u7528 Booth \u91cd\u65b0\u7f16\u7801\uff0c\u5219\u7c7b\u4f3c\u4e8e\u56fe 10.12 \u53ef\u7528\u4e8e radix-256\uff08\u4e00\u6b21 8 \u4f4d\uff09\u4e58\u6cd5\u7684\u8bbe\u8ba1\u3002\u8fd9\u9700\u8981\u5c06\u56fe 10.12 \u4e2d\u7684\u56db\u4e2a\u591a\u8def\u590d\u7528\u5668\u66ff\u6362\u4e3aBooth \u91cd\u65b0\u7f16\u7801\u548c\u9009\u62e9\u903b\u8f91\u3002\u540c\u6837\uff0c\u8fd9\u79cd\u65b0\u7684\u5b89\u6392\u662f\u5426\u4f1a\u5e26\u6765\u5177\u6709\u6210\u672c\u6548\u76ca\u7684\u8bbe\u8ba1\uff08\u4f8b\u5982\uff0c\u4e0e\u91c7\u7528\u4e58\u6cd5\u5668\u7684 7 \u4f4d\u5e76\u5728\u56db\u7ea7 CSA \u6811\u4e2d\u52a0 9 \u4e2a\u6570\u5b57\u76f8\u6bd4\uff09\u53d6\u51b3\u4e8e\u5de5\u827a\uff0c\u4e00\u822c\u65e0\u6cd5\u8fa8\u522b\u3002</p> <p>Designs such as the ones depicted in Figs. 10.11 and 10.12 can be viewed as intermediate between basic sequential (1-bit-at-a-time) multiplication and fully parallel tree multipliers to be discussed in Chapter 11. Thus, high-radix or partial-tree multipliers can be viewed as designs that offer speedup over sequential multiplication or economy over fully parallel tree multipliers (Fig. 10.13). </p> <p>\u5982\u56fe\u6240\u793a\u7684\u8bbe\u8ba1\u3002 10.11 \u548c 10.12 \u53ef\u4ee5\u88ab\u89c6\u4e3a\u57fa\u672c\u987a\u5e8f\uff08\u4e00\u6b21 1 \u4f4d\uff09\u4e58\u6cd5\u548c\u5b8c\u5168\u5e76\u884c\u6811\u4e58\u6cd5\u5668\u4e4b\u95f4\u7684\u4e2d\u95f4\u4f53\uff0c\u5c06\u5728\u7b2c 11 \u7ae0\u4e2d\u8ba8\u8bba\u3002\u56e0\u6b64\uff0c\u9ad8\u57fa\u6570\u6216\u90e8\u5206\u6811\u4e58\u6cd5\u5668\u53ef\u4ee5\u88ab\u89c6\u4e3a\u6bd4\u987a\u5e8f\u4e58\u6cd5\u63d0\u4f9b\u52a0\u901f\u6216\u6bd4\u5b8c\u5168\u5e76\u884c\u6811\u4e58\u6cd5\u5668\u66f4\u7ecf\u6d4e\u7684\u8bbe\u8ba1\uff08\u56fe 10.13\uff09\u3002</p> <p></p>"},{"location":"Part_03/10/#105","title":"10.5 \u591a\u8282\u62cd\u4e58\u6cd5\u5668","text":"<p>In the CSA-based binary multiplier shown in Fig. 10.8a, CSA outputs are loaded into the same registers that supply its inputs. A common implementation method is to use master-slave flip-flops for the registers. In this method, each register has two sides: the master side accepts new data being written into the register while the slave side, which supplies the register\u2019s outputs, keeps the old data for the entire half-cycle when the clock is high. When the clock goes low, the new data in the master side is transferred to the slave side in preparation for the next cycle. In this case, one might be able to insert an extra CSA between the master and slave registers, with little or no effect on the clock\u2019s cycle time. This virtually doubles the speed of partial-product accumulation.</p> <p>\u5728\u56fe 10.8a \u6240\u793a\u7684\u57fa\u4e8e CSA \u7684\u4e8c\u8fdb\u5236\u4e58\u6cd5\u5668\u4e2d\uff0cCSA \u8f93\u51fa\u52a0\u8f7d\u5230\u63d0\u4f9b\u5176\u8f93\u5165\u7684\u76f8\u540c\u5bc4\u5b58\u5668\u4e2d\u3002\u5e38\u89c1\u7684\u5b9e\u73b0\u65b9\u6cd5\u662f\u5bf9\u5bc4\u5b58\u5668\u4f7f\u7528\u4e3b\u4ece\u89e6\u53d1\u5668\u3002\u5728\u8fd9\u79cd\u65b9\u6cd5\u4e2d\uff0c\u6bcf\u4e2a\u5bc4\u5b58\u5668\u90fd\u6709\u4e24\u4fa7\uff1a\u4e3b\u4fa7\u63a5\u53d7\u5199\u5165\u5bc4\u5b58\u5668\u7684\u65b0\u6570\u636e\uff0c\u800c\u4ece\u4fa7\u63d0\u4f9b\u5bc4\u5b58\u5668\u7684\u8f93\u51fa\uff0c\u5728\u65f6\u949f\u4e3a\u9ad8\u7535\u5e73\u65f6\u5728\u6574\u4e2a\u534a\u5468\u671f\u5185\u4fdd\u7559\u65e7\u6570\u636e\u3002\u5f53\u65f6\u949f\u53d8\u4f4e\u65f6\uff0c\u4e3b\u673a\u4fa7\u7684\u65b0\u6570\u636e\u88ab\u4f20\u8f93\u5230\u4ece\u673a\u4fa7\uff0c\u4e3a\u4e0b\u4e00\u4e2a\u5468\u671f\u505a\u51c6\u5907\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u4eba\u4eec\u53ef\u4ee5\u5728\u4e3b\u5bc4\u5b58\u5668\u548c\u4ece\u5bc4\u5b58\u5668\u4e4b\u95f4\u63d2\u5165\u4e00\u4e2a\u989d\u5916\u7684 CSA\uff0c\u8fd9\u5bf9\u65f6\u949f\u5468\u671f\u65f6\u95f4\u5f71\u54cd\u5f88\u5c0f\u6216\u6ca1\u6709\u5f71\u54cd\u3002\u8fd9\u5b9e\u9645\u4e0a\u4f7f\u90e8\u5206\u4ea7\u54c1\u79ef\u7d2f\u7684\u901f\u5ea6\u52a0\u500d\u3002</p> <p>Figure 10.14 shows a schematic representation of a 3-bit-at-a-time twin-beat multiplier that effectively retires 6 bits of the multiplier in each clock cycle. This multiplier, which uses radix-8 Booth\u2019s recoding, is similar to the twin-beat design used in Manchester University\u2019s MU5 computer [Gosl71].</p> <p>\u56fe 10.14 \u663e\u793a\u4e86\u4e00\u6b21 3 \u4f4d\u53cc\u8282\u62cd\u4e58\u6cd5\u5668\u7684\u793a\u610f\u56fe\uff0c\u8be5\u4e58\u6cd5\u5668\u5728\u6bcf\u4e2a\u65f6\u949f\u5468\u671f\u6709\u6548\u5730\u9000\u51fa\u4e86\u4e58\u6cd5\u5668\u7684 6 \u4f4d\u3002\u8be5\u4e58\u6cd5\u5668\u4f7f\u7528 radix-8 Booth \u7684\u91cd\u65b0\u7f16\u7801\uff0c\u7c7b\u4f3c\u4e8e\u66fc\u5f7b\u65af\u7279\u5927\u5b66 MU5 \u8ba1\u7b97\u673a [Gosl71] \u4e2d\u4f7f\u7528\u7684\u53cc\u8282\u62cd\u8bbe\u8ba1\u3002</p> <p></p> <p>Each clock cycle is divided into two phases or beats. In the first beat, the left multiplier register is used to determine the next multiple to be added, while in the second beat, the right multiplier register is used. After each cycle (two beats), the small adder at the lower right of Fig. 10.14 determines 6 bits of the product, which are shifted into the lower half of the cumulative partial product register. This adder is in all likelihood slower than the CSAs; hence, to make each cycle as short as possible, the adder must be pipelined. Since the product bits, once produced, do not change, the latency in deriving these bits has no effect on the rest of the computation in the carry-save portion of the circuit.</p> <p>\u6bcf\u4e2a\u65f6\u949f\u5468\u671f\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\u6216\u8282\u62cd\u3002\u5728\u7b2c\u4e00\u4e2a\u8282\u62cd\u4e2d\uff0c\u5de6\u4e58\u6cd5\u5668\u5bc4\u5b58\u5668\u7528\u4e8e\u786e\u5b9a\u4e0b\u4e00\u4e2a\u8981\u76f8\u52a0\u7684\u500d\u6570\uff0c\u800c\u5728\u7b2c\u4e8c\u4e2a\u8282\u62cd\u4e2d\uff0c\u4f7f\u7528\u53f3\u4e58\u6cd5\u5668\u5bc4\u5b58\u5668\u3002\u6bcf\u4e2a\u5468\u671f\uff08\u4e24\u4e2a\u8282\u62cd\uff09\u540e\uff0c\u56fe 10.14 \u53f3\u4e0b\u89d2\u7684\u5c0f\u52a0\u6cd5\u5668\u786e\u5b9a\u4e58\u79ef\u7684 6 \u4f4d\uff0c\u8fd9\u4e9b\u4f4d\u88ab\u79fb\u5165\u7d2f\u79ef\u90e8\u5206\u4e58\u79ef\u5bc4\u5b58\u5668\u7684\u4e0b\u534a\u90e8\u5206\u3002\u8be5\u52a0\u6cd5\u5668\u5f88\u53ef\u80fd\u6bd4 CSA \u6162\uff1b\u56e0\u6b64\uff0c\u4e3a\u4e86\u4f7f\u6bcf\u4e2a\u5468\u671f\u5c3d\u53ef\u80fd\u77ed\uff0c\u52a0\u6cd5\u5668\u5fc5\u987b\u91c7\u7528\u6d41\u6c34\u7ebf\u65b9\u5f0f\u3002\u7531\u4e8e\u4e58\u79ef\u4f4d\u4e00\u65e6\u4ea7\u751f\u5c31\u4e0d\u4f1a\u6539\u53d8\uff0c\u56e0\u6b64\u5bfc\u51fa\u8fd9\u4e9b\u4f4d\u7684\u5ef6\u8fdf\u5bf9\u7535\u8def\u8fdb\u4f4d\u4fdd\u5b58\u90e8\u5206\u4e2d\u7684\u5176\u4f59\u8ba1\u7b97\u6ca1\u6709\u5f71\u54cd\u3002</p> <p>Figure 10.15 helps us understand the workings of the twin-beat multiplier and allows us to extend the application of this method to other designs. Consider an arbitrary sequential circuit realized as in Fig. 10.15a and running at a clock frequency f . We can convert this design to the one depicted in Fig. 10.15b, where PH1 and PH2 are nonoverlapping clocks with the same frequency f . When the PH1 clock is low and PH2 is high, the upper latches provide stable outputs, which lead to stable inputs for the lower latches. The situation reverses when PH1 is high and PH2 is low. Essentially, the circuit performs useful computation during both clock half-cycles, rather than only during one of them.</p> <p>\u56fe 10.15 \u5e2e\u52a9\u6211\u4eec\u7406\u89e3\u53cc\u8282\u62cd\u4e58\u6cd5\u5668\u7684\u5de5\u4f5c\u539f\u7406\uff0c\u5e76\u5141\u8bb8\u6211\u4eec\u5c06\u6b64\u65b9\u6cd5\u7684\u5e94\u7528\u6269\u5c55\u5230\u5176\u4ed6\u8bbe\u8ba1\u3002\u8003\u8651\u5982\u56fe 10.15a \u6240\u793a\u5b9e\u73b0\u5e76\u4ee5\u65f6\u949f\u9891\u7387 f \u8fd0\u884c\u7684\u4efb\u610f\u65f6\u5e8f\u7535\u8def\u3002\u6211\u4eec\u53ef\u4ee5\u5c06\u6b64\u8bbe\u8ba1\u8f6c\u6362\u4e3a\u56fe 10.15b \u6240\u793a\u7684\u8bbe\u8ba1\uff0c\u5176\u4e2d PH1 \u548c PH2 \u662f\u5177\u6709\u76f8\u540c\u9891\u7387 f \u7684\u975e\u91cd\u53e0\u65f6\u949f\u3002\u5f53 PH1 \u65f6\u949f\u4e3a\u4f4e\u7535\u5e73\u4e14 PH2 \u65f6\u949f\u4e3a\u9ad8\u7535\u5e73\u65f6\uff0c\u4e0a\u90e8\u9501\u5b58\u5668\u63d0\u4f9b\u7a33\u5b9a\u7684\u8f93\u51fa\uff0c\u4ece\u800c\u4e3a\u4e0b\u90e8\u9501\u5b58\u5668\u63d0\u4f9b\u7a33\u5b9a\u7684\u8f93\u5165\u3002\u5f53 PH1 \u4e3a\u9ad8\u4e14 PH2 \u4e3a\u4f4e\u65f6\uff0c\u60c5\u51b5\u76f8\u53cd\u3002\u672c\u8d28\u4e0a\uff0c\u7535\u8def\u5728\u4e24\u4e2a\u65f6\u949f\u534a\u5468\u671f\u671f\u95f4\u6267\u884c\u6709\u7528\u7684\u8ba1\u7b97\uff0c\u800c\u4e0d\u662f\u4ec5\u5728\u5176\u4e2d\u4e00\u4e2a\u65f6\u949f\u534a\u5468\u671f\u671f\u95f4\u3002</p> <p></p> <p>The twin-beat concept can be easily extended to obtain a three-beat multiplier. Such a design can be visualized by putting the three CSAs and associated latches into a ring (Fig. 10.16), whose nodes are driven by a three-phase clock [deAn95]. Each node requires two beats before making its results available to the next node, thus leading to separate accumulation of odd- and even-indexed partial products. At the end, the four operands are reduced to two operands, which are then added to obtain the final product.</p> <p>\u53cc\u8282\u62cd\u6982\u5ff5\u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u6269\u5c55\u4ee5\u83b7\u5f97\u4e09\u8282\u62cd\u4e58\u6cd5\u5668\u3002\u8fd9\u79cd\u8bbe\u8ba1\u53ef\u4ee5\u901a\u8fc7\u5c06\u4e09\u4e2a CSA \u548c\u76f8\u5173\u9501\u5b58\u5668\u653e\u5165\u4e00\u4e2a\u73af\u4e2d\u6765\u53ef\u89c6\u5316\uff08\u56fe 10.16\uff09\uff0c\u5176\u8282\u70b9\u7531\u4e09\u76f8\u65f6\u949f\u9a71\u52a8 [deAn95]\u3002\u6bcf\u4e2a\u8282\u70b9\u5728\u5c06\u5176\u7ed3\u679c\u63d0\u4f9b\u7ed9\u4e0b\u4e00\u4e2a\u8282\u70b9\u4e4b\u524d\u9700\u8981\u4e24\u6b21\u8282\u62cd\uff0c\u4ece\u800c\u5bfc\u81f4\u5947\u6570\u548c\u5076\u6570\u7d22\u5f15\u90e8\u5206\u79ef\u7684\u5355\u72ec\u7d2f\u79ef\u3002\u6700\u540e\uff0c\u5c06\u56db\u4e2a\u64cd\u4f5c\u6570\u51cf\u5c11\u4e3a\u4e24\u4e2a\u64cd\u4f5c\u6570\uff0c\u7136\u540e\u5c06\u5176\u76f8\u52a0\u4ee5\u83b7\u5f97\u6700\u7ec8\u7ed3\u679c\u3002</p> <p></p>"},{"location":"Part_03/10/#106-vlsi","title":"10.6 VLSI\u590d\u6742\u6027\u5206\u6790\u4e3b\u9898","text":"<p>Implementation of sequential radix-2 and high-radix multipliers described thus far in Chapters 9 and 10 is straightforward. The components used are CSAs, registers, multiplexers, and a final fast carry-propagate adder, for which numerous designs are available. A small amount of random control logic is also required. Note that each 2-to-1 multiplexer with one of the inputs tied to 0 can be simplified to a set of AND gates. Similarly, a multiplexer with complementary inputs, a and a compl, may be replaceable with a set of XOR gates, with one input of every gate tied to the original multiplexer selection signal.</p> <p>\u7b2c 9 \u7ae0\u548c\u7b2c 10 \u7ae0\u4e2d\u63cf\u8ff0\u7684\u987a\u5e8f\u57fa 2 \u548c\u9ad8\u57fa\u4e58\u6cd5\u5668\u7684\u5b9e\u73b0\u975e\u5e38\u7b80\u5355\u3002\u6240\u4f7f\u7528\u7684\u7ec4\u4ef6\u5305\u62ec CSA\u3001\u5bc4\u5b58\u5668\u3001\u591a\u8def\u590d\u7528\u5668\u548c\u6700\u7ec8\u7684\u5feb\u901f\u8fdb\u4f4d\u4f20\u64ad\u52a0\u6cd5\u5668\uff0c\u9488\u5bf9\u8fd9\u4e9b\u7ec4\u4ef6\u6709\u591a\u79cd\u8bbe\u8ba1\u53ef\u4f9b\u9009\u62e9\u3002\u8fd8\u9700\u8981\u5c11\u91cf\u7684\u968f\u673a\u63a7\u5236\u903b\u8f91\u3002\u6ce8\u610f\u8f93\u5165\u4e4b\u4e00\u8fde\u63a5\u5230 0 \u7684 2 \u9009 1 \u591a\u8def\u590d\u7528\u5668\u53ef\u4ee5\u7b80\u5316\u4e3a\u4e00\u7ec4 AND \u95e8\u3002\u7c7b\u4f3c\u5730\uff0c\u5177\u6709\u4e92\u8865\u8f93\u5165\\(a\\)\u548c\\(a^{compl}\\)\u7684\u591a\u8def\u590d\u7528\u5668\u53ef\u4ee5\u7528\u4e00\u7ec4\u5f02\u6216\u95e8\u4ee3\u66ff\uff0c\u6bcf\u4e2a\u95e8\u7684\u4e00\u4e2a\u8f93\u5165\u4e0e\u539f\u59cb\u591a\u8def\u590d\u7528\u5668\u9009\u62e9\u4fe1\u53f7\u76f8\u5173\u3002</p> <p>For the CSA tree of a radix-2 b multiplier, typically a bit slice is designed and then replicated. Since without Booth\u2019s recoding, the CSA tree receives b + 2 inputs, the required slice is a ( b + 2; 2)-counter; see Section 8.5. For example, a set of (7; 2)-counter slices can be used to implement the CSA tree of a radix-32 multiplier without Booth\u2019s recoding. When radix-2 h Booth\u2019s recoding is applied first, then the number of multiples per cycle is reduced by a factor of h and a ( b/h + 2; 2)-counter slice will be needed.</p> <p>\u5bf9\u4e8e\u57fa \\(2^b\\) \u4e58\u6cd5\u5668\u7684 CSA \u6811\uff0c\u901a\u5e38\u4f1a\u8bbe\u8ba1\u4e00\u4e2a\u4f4d\u7247\uff0c\u7136\u540e\u8fdb\u884c\u590d\u5236\u3002\u7531\u4e8e\u6ca1\u6709 Booth \u91cd\u65b0\u7f16\u7801\uff0cCSA \u6811\u63a5\u6536 \\(b + 2\\) \u4e2a\u8f93\u5165\uff0c\u56e0\u6b64\u6240\u9700\u7684\u5207\u7247\u662f \\(( b + 2; 2)\\)-\u8ba1\u6570\u5668\uff1b\u53c2\u89c1\u7b2c 8.5 \u8282\u3002\u4f8b\u5982\uff0c\u4e00\u7ec4 \\((7; 2)\\)-\u8ba1\u6570\u5668\u5207\u7247\u53ef\u7528\u4e8e\u5b9e\u73b0 radix-32 \u4e58\u6cd5\u5668\u7684 CSA \u6811\uff0c\u800c\u65e0\u9700 Booth \u91cd\u65b0\u7f16\u7801\u3002\u5f53\u9996\u5148\u5e94\u7528radix-\\(2^h\\) Booth\u91cd\u7f16\u7801\u65f6\uff0c\u5219\u6bcf\u4e2a\u5468\u671f\u7684\u500d\u6570\u6570\u91cf\u51cf\u5c11h\u500d\uff0c\u5e76\u4e14\u5c06\u9700\u8981\\((b/h + 2; 2)\\)\u8ba1\u6570\u5668\u7247\u3002</p> <p>In performing radix-2 b multiplication, bk two-input AND gates are required to form the b multiples for each cycle in parallel. The area complexity of the CSA tree that reduces these b multiples to 2 is O( bk). Since these complexities dominate that of the final fast adder, the overall area requirement is seen to be</p> <p>\u5728\u6267\u884c\u57fa \\(2^b\\) \u4e58\u6cd5\u65f6\uff0c\u9700\u8981 \\(bk\\) \u4e2a\u4e8c\u8f93\u5165\u4e0e\u95e8\u6765\u5e76\u884c\u5f62\u6210\u6bcf\u4e2a\u5468\u671f\u7684 \\(b\\) \u500d\u6570\u3002\u5c06\u8fd9\u4e9b\\(b\\)\u500d\u6570\u51cf\u5c11\u52302\u7684CSA\u6811\u7684\u9762\u79ef\u590d\u6742\u5ea6\u662f\\(O(bk)\\)\u3002\u7531\u4e8e\u8fd9\u4e9b\u590d\u6742\u6027\u4e3b\u5bfc\u4e86\u6700\u7ec8\u5feb\u901f\u52a0\u6cd5\u5668\u7684\u590d\u6742\u6027\uff0c\u56e0\u6b64\u603b\u4f53\u9762\u79ef\u8981\u6c42\u4e3a</p> <p>\\(A = O (bk)\\)</p> <p>In view of the logarithmic height of the CSA tree, as discussed in Section 8.3, multiplication is performed in k/b cycles of duration O ( log b), plus a final addition requiring O ( log k) time. The overall time complexity thus becomes</p> <p>\u9274\u4e8e CSA \u6811\u7684\u5bf9\u6570\u9ad8\u5ea6\uff0c\u5982\u7b2c 8.3 \u8282\u4e2d\u6240\u8ba8\u8bba\u7684\uff0c\u4e58\u6cd5\u4ee5\u6301\u7eed\u65f6\u95f4\u4e3a \\(O ( \\log b)\\) \u7684 \\(k/b\\) \u5468\u671f\u6267\u884c\uff0c\u52a0\u4e0a\u9700\u8981 O ( log k) \u65f6\u95f4\u7684\u6700\u7ec8\u52a0\u6cd5\u3002\u6574\u4f53\u65f6\u95f4\u590d\u6742\u5ea6\u56e0\u6b64\u53d8\u4e3a</p> <p>\\(T = O ((k/b) \\log b + \\log k)\\)</p> <p>It is well known that any circuit computing the product of two k-bit integers must satisfy the following constraints involving its on-chip layout area A and computational latency T : AT is at least proportional to k\u221ak and AT 2 grows at least as fast as k 2 [Bren81]. For the preceding implementations, we have</p> <p>\u4f17\u6240\u5468\u77e5\uff0c\u4efb\u4f55\u8ba1\u7b97\u4e24\u4e2a k \u4f4d\u6574\u6570\u4e58\u79ef\u7684\u7535\u8def\u90fd\u5fc5\u987b\u6ee1\u8db3\u4ee5\u4e0b\u7ea6\u675f\uff0c\u6d89\u53ca\u5176\u7247\u4e0a\u5e03\u5c40\u9762\u79ef A \u548c\u8ba1\u7b97\u5ef6\u8fdf T \uff1aAT \u81f3\u5c11\u4e0e \\(k\\sqrt{k}\\)  \u6210\u6b63\u6bd4\uff0c\u4e14 \\(AT^2\\)\u7684\u589e\u957f\u901f\u5ea6\u81f3\u5c11\u4e0e \\(k^2\\) \u4e00\u6837\u5feb [Bren81]\u3002\u5bf9\u4e8e\u524d\u9762\u7684\u5b9e\u73b0\uff0c\u6211\u4eec\u6709</p> <p>\\(AT = O (k^2 \\log b + bk \\log k)\\)</p> <p>\\(AT^2 = O ((k^3/b) \\log^2 b)\\)</p> <p>At the lower end of the complexity scale, where b is a constant, the AT and AT 2 measures for our multipliers become O( k 2) and O( k 3), respectively. At the other extreme corresponding to b = k, where all the multiplier bits are considered at once, we have AT = O (k 2 log k) and AT 2 = O (k 2 log2 k). Intermediate designs do not yield better values for AT and AT 2; thus, the multipliers remain asymptotically suboptimal for the entire range of the parameter b.</p> <p>\u5728\u590d\u6742\u6027\u8303\u56f4\u7684\u4e0b\u7aef\uff0c\u5176\u4e2d b \u662f\u5e38\u6570\uff0c\u4e58\u6cd5\u5668\u7684 AT \u548c AT 2 \u5ea6\u91cf\u5206\u522b\u53d8\u4e3a \\(O(k^2)\\) \u548c \\(O(k^3)\\)\u3002\u5728\u5bf9\u5e94\u4e8e \\(b = k\\) \u7684\u53e6\u4e00\u4e2a\u6781\u7aef\uff0c\u5176\u4e2d\u6240\u6709\u4e58\u6570\u4f4d\u90fd\u88ab\u540c\u65f6\u8003\u8651\uff0c\u6211\u4eec\u6709\\(AT = O (k^2 \\log k)\\) \u4e14 \\(AT^2 = O (k^2 \\log^2 k)\\)\u3002\u4e2d\u95f4\u8bbe\u8ba1\u4e0d\u4f1a\u4e3a \\(AT\\) \u548c \\(AT^2\\) \u4ea7\u751f\u66f4\u597d\u7684\u503c\uff1b\u56e0\u6b64\uff0c\u5bf9\u4e8e\u53c2\u6570 b \u7684\u6574\u4e2a\u8303\u56f4\uff0c\u4e58\u6cd5\u5668\u4ecd\u7136\u662f\u6e10\u8fd1\u6b21\u4f18\u7684\u3002</p> <p>By the AT measure, which is often taken as an indicator of cost-effectiveness, the slower radix-2 multipliers are better than high-radix or tree multipliers. Therefore, in applications calling for a large number of independent multiplications, it may be appropriate to use the available chip area for a large number of slow multipliers as opposed to a small number of faster units.</p> <p>\u6839\u636e\u901a\u5e38\u88ab\u89c6\u4e3a\u6210\u672c\u6548\u76ca\u6307\u6807\u7684 AT \u8861\u91cf\u6807\u51c6\uff0c\u8f83\u6162\u7684\u57fa 2 \u4e58\u6cd5\u5668\u4f18\u4e8e\u9ad8\u57fa\u6570\u6216\u6811\u4e58\u6cd5\u5668\u3002\u56e0\u6b64\uff0c\u5728\u9700\u8981\u5927\u91cf\u72ec\u7acb\u4e58\u6cd5\u7684\u5e94\u7528\u4e2d\uff0c\u5c06\u53ef\u7528\u82af\u7247\u9762\u79ef\u7528\u4e8e\u5927\u91cf\u6162\u901f\u4e58\u6cd5\u5668\u800c\u4e0d\u662f\u5c11\u91cf\u66f4\u5feb\u7684\u5355\u5143\u53ef\u80fd\u662f\u5408\u9002\u7684\u3002</p> <p>We will see, in Chapter 11, that the time complexity of high-radix multipliers can actually be reduced from O ((k/b) log b + log k) to O (k/b + log k) through a more effective pipelining scheme. Even though the resulting designs lead to somewhat better AT and AT 2 measures, the preceding conclusions do not change.</p> <p>\u5728\u7b2c 11 \u7ae0\u4e2d\uff0c\u6211\u4eec\u5c06\u770b\u5230\uff0c\u901a\u8fc7\u66f4\u6709\u6548\u7684\u6d41\u6c34\u7ebf\u65b9\u6848\uff0c\u9ad8\u57fa\u4e58\u6cd5\u5668\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u5b9e\u9645\u4e0a\u53ef\u4ee5\u4ece \\(O((k/b) \\log b + \\log k)\\) \u964d\u4f4e\u5230 \\(O(k/b + \\log k)\\)\u3002\u5c3d\u7ba1\u6700\u7ec8\u7684\u8bbe\u8ba1\u5bfc\u81f4\u4e86\u66f4\u597d\u7684 \\(AT\\) \u548c \\(AT^2\\) \u6d4b\u91cf\uff0c\u4f46\u524d\u9762\u7684\u7ed3\u8bba\u5e76\u6ca1\u6709\u6539\u53d8\u3002</p> <p>Despite these negative results pointing to the asymptotic suboptimality of high-radix and tree multipliers, such designs are quite practical for a wide range of the parameter b, given that the word width k is quite modest in practice. Multiplication with very wide words (large values of k) does find applications, such as in cryptography. However, in nearly all such applications, multiprecision arithmetic, using multipliers with short-to-moderate word widths, is the preferred method, [Scot07].</p> <p>\u5c3d\u7ba1\u8fd9\u4e9b\u8d1f\u9762\u7ed3\u679c\u8868\u660e\u9ad8\u57fa\u6570\u548c\u6811\u4e58\u6cd5\u5668\u7684\u6e10\u8fd1\u6b21\u4f18\u6027\uff0c\u4f46\u8003\u8651\u5230\u5b57\u5bbd k \u5728\u5b9e\u8df5\u4e2d\u76f8\u5f53\u9002\u4e2d\uff0c\u8fd9\u79cd\u8bbe\u8ba1\u5bf9\u4e8e\u5927\u8303\u56f4\u7684\u53c2\u6570 b \u6765\u8bf4\u975e\u5e38\u5b9e\u7528\u3002\u4e0e\u975e\u5e38\u5bbd\u7684\u5b57\uff08\u8f83\u5927\u7684 k \u503c\uff09\u76f8\u4e58\u786e\u5b9e\u6709\u5e94\u7528\uff0c\u4f8b\u5982\u5728\u5bc6\u7801\u5b66\u4e2d\u3002\u7136\u800c\uff0c\u5728\u51e0\u4e4e\u6240\u6709\u6b64\u7c7b\u5e94\u7528\u4e2d\uff0c\u4f7f\u7528\u77ed\u5230\u4e2d\u7b49\u5b57\u5bbd\u7684\u4e58\u6cd5\u5668\u7684\u591a\u7cbe\u5ea6\u7b97\u672f\u662f\u9996\u9009\u65b9\u6cd5\uff0c[Scot07]\u3002</p>"},{"location":"Part_03/10/#_1","title":"\u95ee\u9898\uff08\u7565\uff09","text":""},{"location":"Part_03/10/#_2","title":"\u53c2\u8003\u6587\u732e\u548c\u8fdb\u4e00\u6b65\u9605\u8bfb","text":"<pre><code>[Boot51] Booth, A. D., \u201cA Signed Binary Multiplication Technique,\u201d Quarterly J. Mechanics\n         and Applied Mathematics, Vol. 4, Pt. 2, pp. 236\u2013240, June 1951.\n[Bren81] Brent, R. P., and H. T. Kung, \u201cThe Area-Time Complexity of Binary Multiplication,\u201d\n         J. ACM, Vol. 28, No. 3, pp. 521-534, 1981.\n[deAn95] de Angel, E., A. Chowdhury, and E. E. Swartzlander, \u201cThe Star Multiplier,\u201d Proc.\n         29th Asilomar Conf. Signals, Systems, and Computers, pp. 604\u2013607, 1995.\n[Gosl71] Gosling, J. B., \u201cDesign of Large High-Speed Binary Multiplier Units,\u201d Proc. IEE,\n         Vol. 118, Nos. 3/4, pp. 499\u2013505, 1971.\n[MacS61] MacSorley, O. L., \u201cHigh-Speed Arithmetic in Binary Computers,\u201d Proc. IRE, Vol. 49,\n         pp. 67\u201391, 1961.\n[Rubi75] Rubinfield, L. P., \u201cA Proof of the Modified Booth\u2019s Algorithm for Multiplication,\u201d\n         IEEE Trans. Computers, Vol. 25, No. 10, pp. 1014\u20131015, 1975.\n[Sam90] Sam, H., and A. Gupta, \u201cA Generalized Multibit Recoding of the Two\u2019s Complement\n         Binary Numbers and Its Proof with Application in Multiplier Implementations,\u201d IEEE\n         Trans. Computers, Vol. 39, No. 8, pp. 1006\u20131015, 1990.\n[Scot07] Scott, M., and P. Szczechowiak, \u201cOptimizing Multiprecision Multiplication for Public\n         Key Cryptography,\u201d Cryptology ePrint Archive: http://eprint.iacr.org/2007/299.pdf.\n[Seid05] Seidel, P.-M., L. D. McFearin, and D. W. Matula, \u201cSecondary Radix Recodings for\n         Higher Radix Multipliers,\u201d IEEE Trans. Computers, Vol. 54, No. 2, pp. 111\u2013123,\n         2005.\n[Vass89] Vassiliadis, S., E. M. Schwartz, and D. J. Hanrahan, \u201cA General Proof for Overlapped\n         Multiple-Bit Scanning Multiplications,\u201d IEEE Trans. Computers, Vol. 38, No. 2,\n         pp. 172\u2013183, 1989.\n[Wase82] Waser, S., and M. J. Flynn, Introduction to Arithmetic for Digital Systems Designers,\n         Holt, Rinehart, &amp; Winston, 1982.\n[Zura87] Zurawski, J. H. P., and J. B. Gosling, \u201cDesign of a High-Speed Square-Root,\n         Multiply, and Divide Unit,\u201d IEEE Trans. Computers, Vol. 36, No. 1, pp. 13\u201323, 1987.\n</code></pre>"},{"location":"Part_03/11/","title":"11. \u6811\u578b\u4e58\u6cd5\u5668\u4e0e\u9635\u5217\u4e58\u6cd5\u5668","text":"<p>Tree and Array Multipliers</p> <p>\u201cAll my discoveries were simply improvements in notation\u201d GOTTFRIED WILHELM VON LEIBNIZ</p> <p>\u201c\u6211\u6240\u6709\u7684\u53d1\u73b0\u90fd\u53ea\u662f\u7b26\u53f7\u7684\u6539\u8fdb\u201d \u6208\u7279\u5f17\u91cc\u5fb7\u00b7\u5a01\u5ec9\u00b7\u51af\u00b7\u83b1\u5e03\u5c3c\u8328</p> <p>Tree,or fully parallel,multipliers constitute limiting cases of high-radix multipliers (radix-2^k).With a high-performance carry-save adder (CSA) tree followed by a fast adder, logarithmic time multiplication becomes possible. The resulting multipliers are expensive but justifiable for applications in which multiplication speed is critical. One-sided CSA trees lead to much slower, but highly regular, structures known as array multipliers that offer higher pipelined throughput than tree multipliers and significantly lower chip area at the same time.Chapter topics include:</p> <p>\u6811\u578b\u6216\u5b8c\u5168\u5e76\u884c\u4e58\u6cd5\u5668\u6784\u6210\u4e86\u9ad8\u57fa\u6570\u4e58\u6cd5\u5668 (radix-\\(2^k\\)) \u7684\u6781\u9650\u60c5\u51b5\u3002\u901a\u8fc7\u9ad8\u6027\u80fd\u8fdb\u4f4d\u4fdd\u5b58\u52a0\u6cd5\u5668 (CSA) \u6811\u548c\u540e\u63a5\u7684\u5feb\u901f\u52a0\u6cd5\u5668\uff0c\u5bf9\u6570\u65f6\u95f4\u4e58\u6cd5\u6210\u4e3a\u53ef\u80fd\u3002 \u7531\u6b64\u4ea7\u751f\u7684\u4e58\u6cd5\u5668\u4ef7\u683c\u6602\u8d35\uff0c\u4f46\u5bf9\u4e8e\u4e58\u6cd5\u901f\u5ea6\u81f3\u5173\u91cd\u8981\u7684\u5e94\u7528\u6765\u8bf4\u662f\u5408\u7406\u7684\u3002 \u5355\u8fb9 CSA \u6811\u5bfc\u81f4\u901f\u5ea6\u6162\u5f97\u591a\uff0c\u4f46\u9ad8\u5ea6\u89c4\u5219\u7684\u7ed3\u6784\uff0c\u79f0\u4e3a\u9635\u5217\u4e58\u6cd5\u5668\uff0c\u5b83\u63d0\u4f9b\u6bd4\u6811\u4e58\u6cd5\u5668\u66f4\u9ad8\u7684\u6d41\u6c34\u7ebf\u541e\u5410\u91cf\uff0c\u540c\u65f6\u663e\u7740\u964d\u4f4e\u82af\u7247\u9762\u79ef\u3002\u7ae0\u8282\u4e3b\u9898\u5305\u62ec\uff1a</p> <ul> <li>11.1 \u6ee1\u6811\u4e58\u6cd5\u5668 FULL-TREE MULTIPLIERS</li> <li>11.2 \u66ff\u4ee3\u7ea6\u7b80\u6811\u6811 ALTERNATIVE REDUCTION TREES</li> <li>11.3 \u6709\u7b26\u53f7\u6570\u7684\u6811\u578b\u4e58\u6cd5\u5668 TREE MULTIPLIERS FOR SIGNED NUMBERS</li> <li>11.4 \u622a\u65ad\u4e58\u6cd5\u5668\u4e0e\u6811\u578b\u4e58\u6cd5\u5668 PARTIAL-TREE AND TRUNCATED MULTIPLIER</li> <li>11.5 \u9635\u5217\u4e58\u6cd5\u5668 ARRAY MULTIPLIERS</li> <li>11.6 \u6d41\u6c34\u5316\u4e58\u6cd5\u5668\u4e0e\u9635\u5217\u4e58\u6cd5\u5668 PIPELINED TREE AND ARRAY MULTIPLIERS</li> </ul>"},{"location":"Part_03/11/#111","title":"11.1 \u6ee1\u6811\u4e58\u6cd5\u5668","text":"<p>In their simplest forms, parallel or full-tree multipliers can be viewed as extreme cases of the design in Fig. 10.12, where all the k multiples of the multiplicand are produced at once and a k-input carry-save adder (CSA) tree is used to reduce them to two operands for the final addition. Because all the multiples are combined in one pass, the tree does not require feedback links, making pipelining quite feasible.</p> <p>\u5728\u6700\u7b80\u5355\u7684\u5f62\u5f0f\u4e2d\uff0c\u5e76\u884c\u6216\u5168\u6811\u4e58\u6cd5\u5668\u53ef\u4ee5\u88ab\u89c6\u4e3a\u56fe 10.12 \u4e2d\u8bbe\u8ba1\u7684\u6781\u7aef\u60c5\u51b5\uff0c\u5176\u4e2d\u88ab\u4e58\u6570\u7684\u6240\u6709 k \u4e2a\u500d\u6570\u90fd\u662f\u4e00\u6b21\u6027\u751f\u6210\u7684\uff0c\u5e76\u4e14\u4f7f\u7528 k \u8f93\u5165\u8fdb\u4f4d\u4fdd\u5b58\u52a0\u6cd5\u5668 (CSA) \u6811\u5c06\u5b83\u4eec\u51cf\u5c11\u4e3a\u4e24\u4e2a\u64cd\u4f5c\u6570\u4ee5\u8fdb\u884c\u6700\u7ec8\u52a0\u6cd5\u3002\u7531\u4e8e\u6240\u6709\u500d\u6570\u90fd\u5728\u4e00\u6b21\u4f20\u9012\u4e2d\u7ec4\u5408\uff0c\u56e0\u6b64\u6811\u4e0d\u9700\u8981\u53cd\u9988\u94fe\u63a5\uff0c\u53ef\u4ee5\u505a\u6d41\u6c34\u7ebf\u3002</p> <p>Figure 11.1 shows the general structure of a full-tree multiplier. Various multiples of the multiplicand a, corresponding to binary or high-radix digits of the multiplier x or its recoded version, are formed at the top. The multiple-forming circuits may be a collection ofAND gates (binary multiplier), radix-4 Booth\u2019s multiple generators (recoded multiplier), and so on. These multiples are added in a combinational partial products reduction tree, which produces their sum in redundant form. Finally, the redundant result is converted to standard binary output at the bottom.</p> <p>\u56fe 11.1 \u663e\u793a\u4e86\u5168\u6811\u4e58\u6cd5\u5668\u7684\u4e00\u822c\u7ed3\u6784\u3002\u88ab\u4e58\u6570 \\(a\\) \u7684\u5404\u79cd\u500d\u6570\uff0c\u5bf9\u5e94\u4e8e\u4e58\u6570 \\(x\\) \u6216\u5176\u8bb0\u5f55\u7248\u672c\u7684\u4e8c\u8fdb\u5236\u6216\u9ad8\u57fa\u6570\u6570\u5b57\uff0c\u5728\u9876\u90e8\u5f62\u6210\u3002\u591a\u91cd\u5f62\u6210\u7535\u8def\u53ef\u4ee5\u662fAND\u95e8\uff08\u4e8c\u8fdb\u5236\u4e58\u6cd5\u5668\uff09\u3001radix-4 Booth\u591a\u91cd\u751f\u6210\u5668\uff08\u91cd\u65b0\u7f16\u7801\u4e58\u6cd5\u5668\uff09\u7b49\u7684\u96c6\u5408\u3002\u8fd9\u4e9b\u500d\u6570\u88ab\u6dfb\u52a0\u5230\u7ec4\u5408\u90e8\u5206\u79ef\u5f52\u7ea6\u6811\u4e2d\uff0c\u4ece\u800c\u4ee5\u5197\u4f59\u5f62\u5f0f\u751f\u6210\u5b83\u4eec\u7684\u603b\u548c\u3002\u6700\u540e\uff0c\u5728\u5e95\u5c42\u5c06\u5197\u4f59\u7ed3\u679c\u8f6c\u6362\u4e3a\u6807\u51c6\u4e8c\u8fdb\u5236\u8f93\u51fa\u3002</p> <p></p> <p>Many types of tree multipliers have been built or proposed. These are distinguished by the designs of the following three elements in Fig. 11.1:</p> <ul> <li>Multiple-forming circuits</li> <li>Partial-products reduction tree</li> <li>Redundant-to-binary converter</li> </ul> <p>\u5df2\u7ecf\u5efa\u9020\u6216\u63d0\u51fa\u4e86\u8bb8\u591a\u7c7b\u578b\u7684\u6811\u4e58\u6cd5\u5668\u3002\u5b83\u4eec\u7684\u533a\u522b\u5728\u4e8e\u56fe 11.1 \u4e2d\u4ee5\u4e0b\u4e09\u4e2a\u5143\u7d20\u7684\u8bbe\u8ba1\uff1a</p> <ul> <li>\u4e58\u79ef\u6210\u5f62\u7535\u8def</li> <li>\u90e8\u5206\u79ef\u7ea6\u7b80\u6811</li> <li>\u5197\u4f59\u4e8c\u8fdb\u5236\u8f6c\u6362\u5668</li> </ul> <p>In the remainder of this section, we focus on tree multiplier variations involving unsigned binary multiples and CSA reduction trees. With the redundant result in carry-save form, the final converter is simply a fast adder. Deviations from the foregoing multiple generation and reduction schemes are discussed in Section 11.2. Signed tree multipliers are covered in Section 11.3.</p> <p>\u5728\u672c\u8282\u7684\u5176\u4f59\u90e8\u5206\u4e2d\uff0c\u6211\u4eec\u5c06\u91cd\u70b9\u5173\u6ce8\u6d89\u53ca\u65e0\u7b26\u53f7\u4e8c\u8fdb\u5236\u500d\u6570\u548c CSA \u7ea6\u7b80\u6811\u7684\u6811\u4e58\u6cd5\u5668\u53d8\u4f53\u3002\u7531\u4e8e\u5197\u4f59\u7ed3\u679c\u91c7\u7528\u8fdb\u4f4d\u4fdd\u5b58\u5f62\u5f0f\uff0c\u6700\u7ec8\u8f6c\u6362\u5668\u53ea\u662f\u4e00\u4e2a\u5feb\u901f\u52a0\u6cd5\u5668\u3002\u4e0e\u524d\u8ff0\u4e58\u79ef\u751f\u6210\u548c\u7f29\u51cf\u65b9\u6848\u7684\u504f\u5dee\u5c06\u5728\u7b2c 11.2 \u8282\u4e2d\u8ba8\u8bba\u3002\u7b2c 11.3 \u8282\u4ecb\u7ecd\u4e86\u6709\u7b26\u53f7\u6811\u4e58\u6cd5\u5668\u3002</p> <p>From our discussion of sequential multiplication in Chapters 9 and 10, we know how the partial-products can be formed and how, through the use of high-radix methods, the number of partial products can be reduced. The trade-offs mentioned for high-radix multipliers exist here as well: more complex multiple-forming circuits can lead to simplification in the reduction tree. Again, we cannot say in general which combination will lead to greater cost-effectiveness because the exact nature of the trade-off is design- and technology-dependent. </p> <p>\u4ece\u7b2c 9 \u7ae0\u548c\u7b2c 10 \u7ae0\u5bf9\u987a\u5e8f\u4e58\u6cd5\u7684\u8ba8\u8bba\u4e2d\uff0c\u6211\u4eec\u77e5\u9053\u5982\u4f55\u5f62\u6210\u90e8\u5206\u4e58\u79ef\u4ee5\u53ca\u5982\u4f55\u901a\u8fc7\u4f7f\u7528\u9ad8\u57fa\u6570\u65b9\u6cd5\u6765\u51cf\u5c11\u90e8\u5206\u4e58\u79ef\u7684\u6570\u91cf\u3002\u63d0\u5230\u7684\u9ad8\u57fa\u6570\u4e58\u6cd5\u5668\u7684\u6743\u8861\u8fd9\u91cc\u4e5f\u5b58\u5728\uff1a\u66f4\u590d\u6742\u7684\u4e58\u79ef\u5f62\u6210\u7535\u8def\u53ef\u4ee5\u5bfc\u81f4\u6811\u7684\u7b80\u5316\u3002\u540c\u6837\uff0c\u6211\u4eec\u4e0d\u80fd\u7b3c\u7edf\u5730\u8bf4\u54ea\u79cd\u7ec4\u5408\u4f1a\u5e26\u6765\u66f4\u5927\u7684\u6210\u672c\u6548\u76ca\uff0c\u56e0\u4e3a\u6743\u8861\u7684\u786e\u5207\u6027\u8d28\u53d6\u51b3\u4e8e\u8bbe\u8ba1\u548c\u5de5\u827a\u3002</p> <p>Recall Wallace\u2019s and Dadda\u2019s strategies for constructing CSA trees discussed in Section 8.3. These give rise to Wallace and Dadda tree multipliers, respectively. Essentially, Wallace\u2019s strategy for building CSA trees is to combine the partial-product bits at the earliest opportunity. With Dadda\u2019s method, combining takes place as late as possible, while keeping the critical path length of the CSA tree at a minimum. Wallace\u2019s method leads to the fastest possible design, and Dadda\u2019s strategy usually leads to a simpler CSA tree and a wider carry-propagate adder (CPA).</p> <p>\u56de\u60f3\u4e00\u4e0b\u7b2c 8.3 \u8282\u4e2d\u8ba8\u8bba\u7684 Wallace \u548c Dadda \u6784\u5efa CSA \u6811\u7684\u7b56\u7565\u3002\u8fd9\u4e9b\u5206\u522b\u4ea7\u751f\u534e\u83b1\u58eb\u6811\u4e58\u6570\u548c\u8fbe\u8fbe\u6811\u4e58\u6570\u3002\u672c\u8d28\u4e0a\uff0c\u534e\u83b1\u58eb\u6784\u5efa CSA \u6811\u7684\u7b56\u7565\u662f\u5c3d\u65e9\u7ec4\u5408\u90e8\u5206\u4e58\u79ef\u4f4d\u3002\u4f7f\u7528 Dada \u7684\u65b9\u6cd5\uff0c\u5408\u5e76\u5c3d\u53ef\u80fd\u665a\u5730\u53d1\u751f\uff0c\u540c\u65f6\u4fdd\u6301 CSA \u6811\u7684\u5173\u952e\u8def\u5f84\u957f\u5ea6\u6700\u77ed\u3002 Wallace \u7684\u65b9\u6cd5\u4f1a\u5e26\u6765\u5c3d\u53ef\u80fd\u6700\u5feb\u7684\u8bbe\u8ba1\uff0c\u800c Dadda \u7684\u7b56\u7565\u901a\u5e38\u4f1a\u5e26\u6765\u66f4\u7b80\u5355\u7684 CSA \u6811\u548c\u66f4\u5bbd\u7684\u8fdb\u4f4d\u4f20\u64ad\u52a0\u6cd5\u5668 (CPA)\u3002</p> <p>As a simple example, we derive Wallace and Dadda tree multipliers for 4 \u00d7 4 multiplication. Figure 11.2 shows the design process and results in tabular form, where the integers indicate the number of dots remaining in the various columns. Each design begins with 16 AND gates forming the xiaj terms or dots, 0 \u2264 i, j \u2264 3. The resulting 16 dots are spread across seven columns in the pattern 1, 2, 3, 4, 3, 2, 1. The Wallace tree design requires 3 full adders (FAs) and 1 half-adder (HA) in the first level, then 2 FAs and 2 HAs in the second level, and a 4-bit CPA at the end. With the Dadda tree design, our first goal is to reduce the height of the partial products dot matrix from 4 to 3, thus necessitating 2 FAs in the first level. These are followed by 2 FAs and 2 HAs in the second level (reducing the height from 3 to 2) and a 6-bit CPA at the end.</p> <p>\u4f5c\u4e3a\u4e00\u4e2a\u7b80\u5355\u7684\u4f8b\u5b50\uff0c\u6211\u4eec\u63a8\u5bfc\u51fa\u7528\u4e8e 4 \u00d7 4 \u4e58\u6cd5\u7684 Wallace \u548c Dadda \u6811\u4e58\u5b50\u3002\u56fe 11.2 \u4ee5\u8868\u683c\u5f62\u5f0f\u663e\u793a\u4e86\u8bbe\u8ba1\u8fc7\u7a0b\u548c\u7ed3\u679c\uff0c\u5176\u4e2d\u6574\u6570\u8868\u793a\u5404\u5217\u4e2d\u5269\u4f59\u7684\u70b9\u6570\u3002\u6bcf\u4e2a\u8bbe\u8ba1\u90fd\u4ee5 16 \u4e2a\u4e0e\u95e8\u5f00\u59cb\uff0c\u5f62\u6210 \\(x_ia_j\\) \u9879\u6216\u70b9\uff0c\\(0 \u2264 i\uff0cj \u2264 3\\)\u3002\u751f\u6210\u7684 16 \u4e2a\u70b9\u4ee5\u6a21\u5f0f 1\u30012\u30013\u30014\u30013\u30012\u30011 \u5206\u5e03\u5728\u4e03\u5217\u4e2d\u3002\u534e\u83b1\u58eb\u6811\u8bbe\u8ba1\u5728\u7b2c\u4e00\u7ea7\u9700\u8981 3 \u4e2a\u5168\u52a0\u5668 (FA) \u548c 1 \u4e2a\u534a\u52a0\u5668 (HA)\uff0c\u7136\u540e\u7b2c\u4e8c\u7ea7\u6709 2 \u4e2aFA \u548c 2 \u4e2a HA\uff0c\u6700\u540e\u6709 4 \u4f4d CPA\u3002\u901a\u8fc7 Dada \u6811\u8bbe\u8ba1\uff0c\u6211\u4eec\u7684\u7b2c\u4e00\u4e2a\u76ee\u6807\u662f\u5c06\u90e8\u5206\u79ef\u70b9\u9635\u7684\u9ad8\u5ea6\u4ece 4 \u51cf\u5c11\u5230 3\uff0c\u56e0\u6b64\u5728\u7b2c\u4e00\u5c42\u9700\u8981 2 \u4e2a FA\u3002\u63a5\u4e0b\u6765\u662f\u7b2c\u4e8c\u7ea7\u4e2d\u7684 2 \u4e2a FA \u548c 2 \u4e2a HA\uff08\u5c06\u9ad8\u5ea6\u4ece 3 \u964d\u4f4e\u5230 2\uff09\uff0c\u6700\u540e\u662f 6 \u4f4d CPA\u3002</p> <p></p> <p>Intermediate approaches between those of Wallace and Dadda yield various designs that offer speed-cost trade-offs. For example, it may be that neither the Wallace tree nor the Dadda tree leads to a convenient width for the fast adder. In such cases, a hybrid approach may yield the best results. </p> <p>Note that the results introduced for carry-save multioperand addition in Chapter 8 apply to the design of partial products reduction trees with virtually no change. The only modifications required stem from the relative shifting of the operands to be added. For example, in Fig. 8.12, we see that in adding seven right-aligned k-bit operands, the CSAs are all k bits wide. In a seven-operand CSA tree of a 7 \u00d7 7 tree multiplier, the input operands appear with shifts of 0 to 6 bits, leading to the input configuration shown at the top of Fig. 11.3. We see that the shifted inputs necessitate somewhat wider blocks at the bottom of the tree. It is instructive for the reader to compare Fig. 11.3 and Fig. 8.12, noting all the differences.</p> <p>\u534e\u83b1\u58eb\u548c\u8fbe\u8fbe\u4e4b\u95f4\u7684\u4e2d\u95f4\u65b9\u6cd5\u4ea7\u751f\u4e86\u5404\u79cd\u63d0\u4f9b\u901f\u5ea6\u4e0e\u6210\u672c\u6743\u8861\u7684\u8bbe\u8ba1\u3002\u4f8b\u5982\uff0c\u534e\u83b1\u58eb\u6811\u548c\u8fbe\u8fbe\u6811\u90fd\u53ef\u80fd\u65e0\u6cd5\u4e3a\u5feb\u901f\u52a0\u6cd5\u5668\u5e26\u6765\u65b9\u4fbf\u7684\u5bbd\u5ea6\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6df7\u5408\u65b9\u6cd5\u53ef\u80fd\u4f1a\u4ea7\u751f\u6700\u4f73\u7ed3\u679c\u3002</p> <p>\u6ce8\u610f\u7b2c 8 \u7ae0\u4e2d\u4ecb\u7ecd\u7684\u8fdb\u4f4d\u4fdd\u5b58\u591a\u64cd\u4f5c\u6570\u52a0\u6cd5\u7684\u7ed3\u679c\u9002\u7528\u4e8e\u90e8\u5206\u4e58\u79ef\u5f52\u7ea6\u6811\u7684\u8bbe\u8ba1\uff0c\u51e0\u4e4e\u6ca1\u6709\u4efb\u4f55\u53d8\u5316\u3002\u552f\u4e00\u9700\u8981\u7684\u4fee\u6539\u6e90\u4e8e\u8981\u6dfb\u52a0\u7684\u64cd\u4f5c\u6570\u7684\u76f8\u5bf9\u79fb\u4f4d\u3002\u4f8b\u5982\uff0c\u5728\u56fe8.12\u4e2d\uff0c\u6211\u4eec\u770b\u5230\u5728\u6dfb\u52a0\u4e03\u4e2a\u53f3\u5bf9\u9f50\u7684k\u4f4d\u64cd\u4f5c\u6570\u65f6\uff0cCSA\u90fd\u662f\\(k\\)\u4f4d\u5bbd\u3002\u5728 \\(7 \u00d7 7\\) \u6811\u4e58\u6cd5\u5668\u7684\u4e03\u64cd\u4f5c\u6570 CSA \u6811\u4e2d\uff0c\u8f93\u5165\u64cd\u4f5c\u6570\u51fa\u73b0 0 \u5230 6 \u4f4d\u7684\u79fb\u4f4d\uff0c\u5bfc\u81f4\u8f93\u5165\u914d\u7f6e\u5982\u56fe 11.3 \u9876\u90e8\u6240\u793a\u3002\u6211\u4eec\u770b\u5230\uff0c\u79fb\u4f4d\u7684\u8f93\u5165\u9700\u8981\u5728\u6811\u7684\u5e95\u90e8\u8bbe\u7f6e\u66f4\u5bbd\u7684\u5757\u3002 \u6bd4\u8f83\u56fe 11.3 \u548c\u56fe 8.12\uff0c\u5bf9\u8bfb\u8005\u6765\u8bf4\u662f\u6709\u542f\u53d1\u6027\u7684\uff0c\u6ce8\u610f\u6240\u6709\u7684\u5dee\u5f02\u3002</p> <p></p> <p>There is no compelling reason to keep all the bits of the input or intermediate operands together and feed them to multibit CSAs, thus necessitating the use of many HAs that simply rearrange the dots without contributing to their reduction. Doing the reduction with 1-bit FAs and HAs, as in Fig. 11.2, leads to lower complexity and perhaps even greater speed. Deriving the Wallace and Dadda tree multipliers to perform the same function as the circuit of Fig. 11.3 is left as an exercise.</p> <p>\u6ca1\u6709\u4ee4\u4eba\u4fe1\u670d\u7684\u7406\u7531\u5c06\u8f93\u5165\u6216\u4e2d\u95f4\u64cd\u4f5c\u6570\u7684\u6240\u6709\u4f4d\u4fdd\u6301\u5728\u4e00\u8d77\u5e76\u5c06\u5b83\u4eec\u9988\u9001\u5230\u591a\u4f4dCSA\uff0c\u56e0\u6b64\u9700\u8981\u4f7f\u7528\u8bb8\u591aHA\uff0c\u8fd9\u4e9bHA\u53ea\u662f\u7b80\u5355\u5730\u91cd\u65b0\u6392\u5217\u70b9\u800c\u65e0\u52a9\u4e8e\u51cf\u5c11\u5b83\u4eec\u3002\u5982\u56fe 11.2 \u6240\u793a\uff0c\u4f7f\u7528 1 \u4f4d FA \u548c HA \u8fdb\u884c\u7f29\u51cf\u53ef\u4ee5\u964d\u4f4e\u590d\u6742\u6027\uff0c\u751a\u81f3\u53ef\u80fd\u63d0\u9ad8\u901f\u5ea6\u3002\u63a8\u5bfc Wallace \u548c Dadda \u6811\u4e58\u6cd5\u5668\u4ee5\u6267\u884c\u4e0e\u56fe 11.3 \u7535\u8def\u76f8\u540c\u7684\u529f\u80fd\u7559\u4f5c\u7ec3\u4e60\u3002</p> <p>One point is quite clear from Fig. 11.3 or its Wallace tree and Dadda tree equivalents: a logarithmic depth reduction tree based on CSAs has an irregular structure that makes its design and layout quite difficult. Additionally, connections and signal paths of varying lengths lead to logic hazards and signal skew that have implications for both performance and power consumption. In very large-scale integration (VLSI) design, we strive to build circuits from iterated or recursive structures that lend themselves to efficient automatic synthesis and layout. Alternative reduction trees that are more suitable for VLSI implementation are discussed next.</p> <p>\u4ece\u56fe 11.3 \u6216\u5176\u534e\u83b1\u58eb\u6811\u548c\u8fbe\u8fbe\u6811\u7b49\u4ef7\u7269\u4e2d\u53ef\u4ee5\u6e05\u695a\u5730\u770b\u51fa\u4e00\u70b9\uff1a\u57fa\u4e8e CSA \u7684\u5bf9\u6570\u6df1\u5ea6\u7f29\u51cf\u6811\u5177\u6709\u4e0d\u89c4\u5219\u7684\u7ed3\u6784\uff0c\u8fd9\u4f7f\u5f97\u5176\u8bbe\u8ba1\u548c\u5e03\u5c40\u76f8\u5f53\u56f0\u96be\u3002\u6b64\u5916\uff0c\u4e0d\u540c\u957f\u5ea6\u7684\u8fde\u63a5\u548c\u4fe1\u53f7\u8def\u5f84\u4f1a\u5bfc\u81f4\u903b\u8f91\u5371\u9669\u548c\u4fe1\u53f7\u504f\u5dee\uff0c\u4ece\u800c\u5f71\u54cd\u6027\u80fd\u548c\u529f\u8017\u3002\u5728\u8d85\u5927\u89c4\u6a21\u96c6\u6210\uff08VLSI\uff09\u8bbe\u8ba1\u4e2d\uff0c\u6211\u4eec\u52aa\u529b\u4ece\u8fed\u4ee3\u6216\u9012\u5f52\u7ed3\u6784\u6784\u5efa\u7535\u8def\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u6548\u7684\u81ea\u52a8\u7efc\u5408\u548c\u5e03\u5c40\u3002\u63a5\u4e0b\u6765\u8ba8\u8bba\u66f4\u9002\u5408 VLSI \u5b9e\u73b0\u7684\u66ff\u4ee3\u7ea6\u7b80\u6811\u3002</p>"},{"location":"Part_03/11/#112","title":"11.2 \u66ff\u4ee3\u7ea6\u7b80\u6811","text":"<p>Recall from our discussion in Section 8.4 that a (7; 2)-counter slice can be designed that takes 7 bits in the same column i as inputs and produces 1 bit in each of the columns i and i + 1 as outputs. Such a slice, when suitably replicated, can perform the function of the reduction tree part of Fig. 11.3. Of course, not all columns in Fig. 11.3 have seven inputs. The preceding iterative circuit can then be left intact and supplied with dummy 0 inputs in the interest of regularity, or it can be pruned by removing the redundant parts in each slice. Such optimizations are well within the capabilities of automated design tools.</p> <p>\u56de\u60f3\u4e00\u4e0b\u6211\u4eec\u5728\u7b2c 8.4 \u8282\u4e2d\u7684\u8ba8\u8bba\uff0c\u53ef\u4ee5\u8bbe\u8ba1\u4e00\u4e2a \\((7; 2)\\) \u8ba1\u6570\u5668\u7247\uff0c\u5c06\u540c\u4e00\u5217 \\(i\\) \u4e2d\u7684 7 \u4f4d\u4f5c\u4e3a\u8f93\u5165\uff0c\u5e76\u5728 \\(i\\) \u5217\u548c \\(i + 1\\) \u5217\u4e2d\u7684\u6bcf\u4e00\u5217\u4e2d\u4ea7\u751f 1 \u4f4d\u4f5c\u4e3a\u8f93\u51fa\u3002\u5f53\u9002\u5f53\u590d\u5236\u65f6\uff0c\u8fd9\u6837\u7684\u5207\u7247\u53ef\u4ee5\u6267\u884c\u56fe 11.3 \u7684\u5f52\u7ea6\u6811\u90e8\u5206\u529f\u80fd\u3002\u5f53\u7136\uff0c\u5e76\u975e\u56fe 11.3 \u4e2d\u7684\u6240\u6709\u5217\u90fd\u6709\u4e03\u4e2a\u8f93\u5165\u3002\u7136\u540e\uff0c\u524d\u9762\u7684\u8fed\u4ee3\u7535\u8def\u53ef\u4ee5\u4fdd\u6301\u5b8c\u6574\u5e76\u4e3a\u4e86\u89c4\u5f8b\u6027\u800c\u63d0\u4f9b\u865a\u62df0\u8f93\u5165\uff0c\u6216\u8005\u53ef\u4ee5\u901a\u8fc7\u5220\u9664\u6bcf\u4e2a\u5207\u7247\u4e2d\u7684\u5197\u4f59\u90e8\u5206\u6765\u4fee\u526a\u5b83\u3002\u8fd9\u79cd\u4f18\u5316\u5b8c\u5168\u5728\u81ea\u52a8\u5316\u8bbe\u8ba1\u5de5\u5177\u7684\u80fd\u529b\u8303\u56f4\u5185\u3002</p> <p>Based on Table 8.1, an (11; 2)-counter has at least five FA levels. Figure 11.4 shows a particular five-level arrangement of FAs for performing 11-to-2 reduction with the property that all outputs are produced after the same number of FA delays. Observe how all carries produced in level i enter FAs in level i + 1. The FAs of Fig. 11.4 can be laid out to occupy a narrow vertical slice that can then be replicated to form an 11-input reduction tree of desired width. Such balanced-delay trees are quite suitable for VLSI implementation of parallel multipliers.</p> <p>\u6839\u636e\u8868 8.1\uff0c\\((11; 2)\\) \u8ba1\u6570\u5668\u81f3\u5c11\u6709\u4e94\u4e2a FA \u7ea7\u522b\u3002\u56fe 11.4 \u663e\u793a\u4e86\u7528\u4e8e\u6267\u884c 11-2 \u7f29\u51cf\u7684 FA \u7684\u7279\u5b9a\u4e94\u7ea7\u6392\u5217\uff0c\u5176\u7279\u6027\u662f\u6240\u6709\u8f93\u51fa\u90fd\u662f\u5728\u76f8\u540c\u6570\u91cf\u7684 FA \u5ef6\u8fdf\u540e\u4ea7\u751f\u7684\u3002\u89c2\u5bdf\u7b2c i \u7ea7\u4e2d\u4ea7\u751f\u7684\u6240\u6709\u8fdb\u4f4d\u5982\u4f55\u8fdb\u5165\u7b2c i+1 \u7ea7\u4e2d\u7684 FA\u3002\u56fe 11.4 \u4e2d\u7684 FA \u53ef\u4ee5\u5e03\u5c40\u4e3a\u5360\u636e\u4e00\u4e2a\u72ed\u7a84\u7684\u5782\u76f4\u5207\u7247\uff0c\u7136\u540e\u53ef\u4ee5\u590d\u5236\u8be5\u5207\u7247\u4ee5\u5f62\u6210\u6240\u9700\u5bbd\u5ea6\u7684 11 \u8f93\u5165\u7f29\u51cf\u6811\u3002\u8fd9\u79cd\u5e73\u8861\u5ef6\u8fdf\u6811\u975e\u5e38\u9002\u5408\u5e76\u884c\u4e58\u6cd5\u5668\u7684VLSI\u5b9e\u73b0\u3002</p> <p>The circuit of Fig. 11.4 is composed of three columns containing one, three, and five FAs, going from left to right. It is now easy to see that the number of inputs can be expanded from 11 to 18 by simply appending to the right of the circuit an additional column of seven FAs. The top FA in the added column will accommodate three new inputs, while each of the others, except for the lowermost two, can accept one new input; these latter FAs must also accommodate a sum coming from above and a carry coming from the right. Note that the FAs in the various columns are more or less independent in that adjacent columns are linked by just one wire. This property makes it possible to lay out the circuit in a narrow slice without having to devote a lot of space to the interconnections.</p> <p>\u56fe 11.4 \u7684\u7535\u8def\u7531\u4e09\u5217\u7ec4\u6210\uff0c\u4ece\u5de6\u5230\u53f3\u5206\u522b\u5305\u542b 1\u30013 \u548c 5 \u4e2a FA\u3002\u73b0\u5728\u5f88\u5bb9\u6613\u770b\u51fa\uff0c\u53ea\u9700\u5728\u7535\u8def\u53f3\u4fa7\u9644\u52a0\u4e00\u5217\u7531\u4e03\u4e2a FA \u7ec4\u6210\u7684\u9644\u52a0\u5217\uff0c\u5373\u53ef\u5c06\u8f93\u5165\u6570\u91cf\u4ece 11 \u4e2a\u6269\u5c55\u5230 18 \u4e2a\u3002\u6dfb\u52a0\u5217\u4e2d\u7684\u9876\u90e8 FA \u5c06\u5bb9\u7eb3\u4e09\u4e2a\u65b0\u7684\u8f93\u5165\uff0c\u800c\u9664\u4e86\u6700\u4e0b\u9762\u7684\u4e24\u4e2a\u4e4b\u5916\uff0c\u5176\u4ed6\u6bcf\u4e2a\u90fd\u53ef\u4ee5\u63a5\u53d7\u4e00\u4e2a\u65b0\u8f93\u5165\uff1b\u540e\u9762\u7684 FA \u8fd8\u5fc5\u987b\u5bb9\u7eb3\u6765\u81ea\u4e0a\u65b9\u7684\u603b\u548c\u4ee5\u53ca\u6765\u81ea\u53f3\u4fa7\u7684\u8fdb\u4f4d\u3002\u8bf7\u6ce8\u610f\uff0c\u5404\u4e2a\u5217\u4e2d\u7684 FA \u6216\u591a\u6216\u5c11\u662f\u72ec\u7acb\u7684\uff0c\u56e0\u4e3a\u76f8\u90bb\u5217\u4ec5\u901a\u8fc7\u4e00\u6839\u7535\u7ebf\u8fde\u63a5\u3002\u8fd9\u4e00\u7279\u6027\u4f7f\u5f97\u53ef\u4ee5\u5728\u72ed\u7a84\u7684\u5207\u7247\u4e2d\u5e03\u5c40\u7535\u8def\uff0c\u800c\u65e0\u9700\u4e3a\u4e92\u8fde\u6295\u5165\u5927\u91cf\u7a7a\u95f4\u3002</p> <p></p> <p>Instead of building partial products reduction trees from CSAs, or (3; 2)-counters, one can use a module that reduces four numbers to two as the basic building block. Then, partial products reduction trees can be structured as binary trees that possess a recursive structure making them more regular and easier to lay out (Fig. 11.5a). Figure 11.6 shows a possible way of laying out the seven-module tree of Fig. 11.5a. Note that adding a level to the tree of Fig. 11.6 involves duplicating the tree and inserting a 4-to-2 reduction module between them.</p> <p>\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u5c06\u56db\u4e2a\u6570\u5b57\u51cf\u5c11\u5230\u4e24\u4e2a\u7684\u6a21\u5757\u4f5c\u4e3a\u57fa\u672c\u6784\u5efa\u5757\uff0c\u800c\u4e0d\u662f\u4ece CSA \u6216 (3; 2) \u8ba1\u6570\u5668\u6784\u5efa\u90e8\u5206\u4e58\u79ef\u5f52\u7ea6\u6811\u3002\u8fd9\u6837\u7684\u90e8\u5206\u79ef\u5f52\u7ea6\u6811\u53ef\u4ee5\u6784\u9020\u4e3a\u5177\u6709\u9012\u5f52\u7ed3\u6784\u7684\u4e8c\u53c9\u6811\uff0c\u4f7f\u5b83\u4eec\u66f4\u52a0\u89c4\u5219\u4e14\u66f4\u6613\u4e8e\u5e03\u5c40\uff08\u56fe 11.5a\uff09\u3002\u56fe 11.6 \u663e\u793a\u4e86\u5e03\u7f6e\u56fe 11.5a \u7684\u4e03\u4e2a\u6a21\u5757\u6811\u7684\u4e00\u79cd\u53ef\u80fd\u65b9\u6cd5\u3002\u8bf7\u6ce8\u610f\uff0c\u5411\u56fe 11.6 \u7684\u6811\u6dfb\u52a0\u4e00\u4e2a\u7ea7\u522b\u6d89\u53ca\u590d\u5236\u8be5\u6811\u5e76\u5728\u5b83\u4eec\u4e4b\u95f4\u63d2\u5165\u4e00\u4e2a 4 \u5230 2 \u7684\u7f29\u51cf\u6a21\u5757\u3002</p> <p></p> <p>In Fig. 11.6, the first, third, fifth, and seventh rectangular boxes correspond to top-level blocks of Fig. 11.5a. These blocks receive four multiples of the multiplicand (two from above and two from below) and reduce them to a pair of numbers for the second and sixth blocks. Each of the latter blocks in turn supplies two numbers to the fourth block, which feeds the redundant-to-binary converter.</p> <p>\u5728\u56fe11.6\u4e2d\uff0c\u7b2c\u4e00\u3001\u7b2c\u4e09\u3001\u7b2c\u4e94\u548c\u7b2c\u4e03\u77e9\u5f62\u6846\u5bf9\u5e94\u4e8e\u56fe11.5a\u7684\u9876\u7ea7\u5757\u3002\u8fd9\u4e9b\u5757\u63a5\u6536\u88ab\u4e58\u6570\u7684\u56db\u4e2a\u500d\u6570\uff08\u4e24\u4e2a\u4e0a\u9762\u7684\u4e24\u4e2a\u548c\u4e0b\u9762\u7684\u4e24\u4e2a\uff09\u5e76\u5c06\u5b83\u4eec\u51cf\u5c11\u4e3a\u7b2c\u4e8c\u4e2a\u548c\u7b2c\u516d\u4e2a\u5757\u7684\u4e00\u5bf9\u6570\u5b57\u3002\u540e\u9762\u7684\u6bcf\u4e2a\u5757\u4f9d\u6b21\u5411\u7b2c\u56db\u4e2a\u5757\u63d0\u4f9b\u4e24\u4e2a\u6570\u5b57\uff0c\u7b2c\u56db\u4e2a\u5757\u4e3a\u5197\u4f59\u5230\u4e8c\u8fdb\u5236\u8f6c\u6362\u5668\u63d0\u4f9b\u6570\u636e\u3002</p> <p></p> <p>If the 4-to-2 reduction modules are internally composed of two CSA levels, as suggested in Fig. 11.5b, then there may be more CSA levels in the binary tree structure than in Wallace or Dadda trees. However, regularity of interconnections, and the resulting efficient layout, can more than compensate for the added logic delays due to the greater circuit depth. Direct realization of 4-to-2 reduction modules from their input/output specifications can lead to more compact and/or faster circuits. The realization depicted in Fig. 11.5c, for example, has a latency of three XOR gate levels, compared with four XOR gate levels that would result from the design of Fig. 11.5b.</p> <p>\u5982\u679c 4-to-2 \u5f52\u7ea6\u6a21\u5757\u5185\u90e8\u7531\u4e24\u4e2a CSA \u7ea7\u522b\u7ec4\u6210\uff0c\u5982\u56fe 11.5b \u6240\u793a\uff0c\u90a3\u4e48\u4e8c\u53c9\u6811\u7ed3\u6784\u4e2d\u53ef\u80fd\u6bd4 Wallace \u6216 Dadda \u6811\u4e2d\u6709\u66f4\u591a\u7684 CSA \u7ea7\u522b\u3002\u7136\u800c\uff0c\u4e92\u8fde\u7684\u89c4\u5f8b\u6027\u4ee5\u53ca\u7531\u6b64\u4ea7\u751f\u7684\u9ad8\u6548\u5e03\u5c40\u53ef\u4ee5\u5145\u5206\u8865\u507f\u7531\u4e8e\u66f4\u5927\u7684\u7535\u8def\u6df1\u5ea6\u800c\u589e\u52a0\u7684\u903b\u8f91\u5ef6\u8fdf\u3002\u6839\u636e\u5176\u8f93\u5165/\u8f93\u51fa\u89c4\u683c\u76f4\u63a5\u5b9e\u73b0 4 \u6bd4 2 \u7f29\u51cf\u6a21\u5757\u53ef\u4ee5\u5bfc\u81f4\u66f4\u7d27\u51d1\u548c/\u6216\u66f4\u5feb\u7684\u7535\u8def\u3002\u4f8b\u5982\uff0c\u56fe 11.5c \u6240\u793a\u7684\u5b9e\u73b0\u5177\u6709\u4e09\u4e2a\u5f02\u6216\u95e8\u7ea7\u522b\u7684\u5ef6\u8fdf\uff0c\u800c\u56fe 11.5b \u7684\u8bbe\u8ba1\u5219\u5177\u6709\u56db\u4e2a\u5f02\u6216\u95e8\u7ea7\u522b\u7684\u5ef6\u8fdf\u3002</p> <p>Note that a 4-to-2 reduction circuit for binary operands can be viewed as a generalized signed-digit adder for radix-2 numbers with the digit set [0, 2], where the digits are encoded in the following 2-bit code:</p> <p>\u8bf7\u6ce8\u610f\uff0c\u4e8c\u8fdb\u5236\u64cd\u4f5c\u6570\u7684 4-to-2 \u7ea6\u7b80\u7535\u8def\u53ef\u4ee5\u88ab\u89c6\u4e3a\u5177\u6709\u6570\u5b57\u96c6 [0, 2] \u7684\u57fa 2 \u6570\u5b57\u7684\u901a\u7528\u7b26\u53f7\u6570\u5b57\u52a0\u6cd5\u5668\uff0c\u5176\u4e2d\u6570\u5b57\u4ee5\u4ee5\u4e0b 2 \u4f4d\u4ee3\u7801\u8fdb\u884c\u7f16\u7801\uff1a</p> <ul> <li> <p>Zero: ( 0, 0 )</p> </li> <li> <p>One:( 0, 1 ) \u6216 ( 1, 0 )</p> </li> <li> <p>Two: ( 1, 1 )</p> </li> </ul> <p>A variant of this binary tree reduction scheme is based on binary signed-digit (BSD), rather than carry-save, representation of the partial products [Taka85]. These partial products are combined by a tree of BSD adders to obtain the final product in BSD form. The standard binary result is then obtained via a BSD-to-binary converter, which is essentially a fast subtractor for subtracting the negative component of the BSD number from its positive part. One benefit of BSD partial products is that negative multiples resulting from the sign bit in 2\u2019s-complement numbers can be easily accommodated (see Section 11.3). Some inefficiency results from the extra bit used to accommodate the digit signs going to waste for most of the multiples that are positive.</p> <p>\u8fd9\u79cd\u4e8c\u53c9\u6811\u7f29\u51cf\u65b9\u6848\u7684\u4e00\u4e2a\u53d8\u4f53\u57fa\u4e8e\u4e8c\u8fdb\u5236\u6709\u7b26\u53f7\u6570\u5b57\uff08BSD\uff09\uff0c\u800c\u4e0d\u662f\u8fdb\u4f4d\u4fdd\u5b58\uff0c\u8868\u793a\u90e8\u5206\u79ef[Taka85]\u3002\u8fd9\u4e9b\u90e8\u5206\u4e58\u79ef\u7531 BSD \u52a0\u6cd5\u5668\u6811\u7ec4\u5408\u4ee5\u83b7\u5f97 BSD \u5f62\u5f0f\u7684\u6700\u7ec8\u4e58\u79ef\u3002\u7136\u540e\u901a\u8fc7 BSD \u5230\u4e8c\u8fdb\u5236\u8f6c\u6362\u5668\u83b7\u5f97\u6807\u51c6\u4e8c\u8fdb\u5236\u7ed3\u679c\uff0c\u8be5\u8f6c\u6362\u5668\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u5feb\u901f\u51cf\u6cd5\u5668\uff0c\u7528\u4e8e\u4ece BSD \u6570\u7684\u6b63\u6570\u90e8\u5206\u4e2d\u51cf\u53bb BSD \u6570\u7684\u8d1f\u6570\u90e8\u5206\u3002 BSD \u90e8\u5206\u79ef\u7684\u597d\u5904\u4e4b\u4e00\u662f\u53ef\u4ee5\u8f7b\u677e\u5bb9\u7eb3\u7531 2 \u8865\u7801\u6570\u4e2d\u7684\u7b26\u53f7\u4f4d\u4ea7\u751f\u7684\u8d1f\u500d\u6570\uff08\u8bf7\u53c2\u89c1\u7b2c 11.3 \u8282\uff09\u3002\u7531\u4e8e\u7528\u4e8e\u5bb9\u7eb3\u6570\u5b57\u7b26\u53f7\u7684\u989d\u5916\u4f4d\u4f1a\u6d6a\u8d39\u5927\u591a\u6570\u6b63\u500d\u6570\uff0c\u56e0\u6b64\u4f1a\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u3002</p> <p>Carry-save and BSD numbers are not the only ones that allow fast reduction via limited-carry addition. Several other digit sets are possible that offer certain advantages depending on technological capabilities and constraints [Parh96]. For example, radix-2 partial products using the digit set [0, 3] lend themselves to an efficient parallel-carries addition process (Fig. 3.11c), while also accommodating three, rather than one or two, multiples of a binary multiplicand. Interestingly, the final conversion from the redundant digit set [0, 3] to [0, 1] is not any harder than conversion from [0, 2] to [0, 1].</p> <p>\u8fdb\u4f4d\u4fdd\u5b58\u548c BSD \u6570\u5b57\u5e76\u4e0d\u662f\u552f\u4e00\u5141\u8bb8\u901a\u8fc7\u6709\u9650\u8fdb\u4f4d\u52a0\u6cd5\u5feb\u901f\u7ea6\u51cf\u7684\u6570\u5b57\u3002\u6839\u636e\u5de5\u827a\u80fd\u529b\u548c\u9650\u5236\uff0c\u5176\u4ed6\u51e0\u79cd\u6570\u5b57\u96c6\u4e5f\u53ef\u80fd\u5177\u6709\u4e00\u5b9a\u7684\u4f18\u52bf[Parh96]\u3002\u4f8b\u5982\uff0c\u4f7f\u7528\u6570\u5b57\u96c6 [0, 3] \u7684\u57fa 2 \u90e8\u5206\u79ef\u6709\u52a9\u4e8e\u9ad8\u6548\u7684\u5e76\u884c\u8fdb\u4f4d\u52a0\u6cd5\u8fc7\u7a0b\uff08\u56fe 3.11c\uff09\uff0c\u540c\u65f6\u8fd8\u53ef\u4ee5\u5bb9\u7eb3\u4e09\u4e2a\u800c\u4e0d\u662f\u4e00\u4e2a\u6216\u4e24\u4e2a\u4e8c\u8fdb\u5236\u88ab\u4e58\u6570\u7684\u500d\u6570 \u3002 \u6709\u8da3\u7684\u662f\uff0c\u4ece\u5197\u4f59\u6570\u5b57\u96c6 [0, 3] \u5230 [0, 1] \u7684\u6700\u7ec8\u8f6c\u6362\u5e76\u4e0d\u6bd4\u4ece [0, 2] \u5230 [0, 1] \u7684\u8f6c\u6362\u56f0\u96be\u3002</p> <p>Clearly, any method used for building the CSA tree can be combined with radix-2 b Booth\u2019s recoding to reduce the tree size. However, for modern VLSI technology, the use of Booth recoding in tree multipliers has been questioned [Vill93]; it seems that the additional CSAs needed for reducing k, rather than k/ b, numbers could be less complex than the Booth recoding logic when wiring and the overhead due to irregularity and nonuniformity are taken into account.</p> <p>\u663e\u7136\uff0c\u4efb\u4f55\u7528\u4e8e\u6784\u5efa CSA \u6811\u7684\u65b9\u6cd5\u90fd\u53ef\u4ee5\u4e0e radix-\\(2^b\\) Booth \u7684\u91cd\u65b0\u7f16\u7801\u76f8\u7ed3\u5408\uff0c\u4ee5\u51cf\u5c0f\u6811\u7684\u5927\u5c0f\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u73b0\u4ee3VLSI\u6280\u672f\uff0c\u5728\u6811\u4e58\u6cd5\u5668\u4e2d\u4f7f\u7528Booth\u91cd\u65b0\u7f16\u7801\u53d7\u5230\u4e86\u8d28\u7591[Vill93]\uff1b\u5f53\u8003\u8651\u5230\u5e03\u7ebf\u4ee5\u53ca\u7531\u4e8e\u4e0d\u89c4\u5219\u548c\u4e0d\u5747\u5300\u6027\u5bfc\u81f4\u7684\u5f00\u9500\u65f6\uff0c\u4f3c\u4e4e\u51cf\u5c11 \\(k\\)\uff08\u800c\u4e0d\u662f \\(k/ b\\)\uff09\u6570\u5b57\u6240\u9700\u7684\u989d\u5916 CSA \u53ef\u80fd\u6bd4 Booth \u91cd\u65b0\u7f16\u7801\u903b\u8f91\u66f4\u7b80\u5355\u3002</p>"},{"location":"Part_03/11/#113","title":"11.3 \u6709\u7b26\u53f7\u6570\u7684\u6811\u578b\u4e58\u6cd5\u5668","text":"<p>When one is multiplying 2\u2019s-complement numbers directly, each of the partial products to be added is a signed number. Thus, for the CSA tree to yield the correct sum of its inputs, each partial product must be sign-extended to the width of the final product. Recall our discussion of signed multioperand addition in Section 8.5, where the 2\u2019s-complement operands were assumed to be aligned at their least-significant bits. In particular, refer to Fig. 8.19 for two possible methods based on sign extension (with hardware sharing) and transforming negative bits into positive bits.</p> <p>\u5f53\u76f4\u63a5\u4e58\u4ee5 2 \u7684\u8865\u7801\u65f6\uff0c\u8981\u76f8\u52a0\u7684\u6bcf\u4e2a\u90e8\u5206\u79ef\u90fd\u662f\u4e00\u4e2a\u6709\u7b26\u53f7\u6570\u3002\u56e0\u6b64\uff0c\u4e3a\u4e86\u4f7f CSA \u6811\u4ea7\u751f\u6b63\u786e\u7684\u8f93\u5165\u603b\u548c\uff0c\u6bcf\u4e2a\u90e8\u5206\u4e58\u79ef\u5fc5\u987b\u7b26\u53f7\u6269\u5c55\u81f3\u6700\u7ec8\u4e58\u79ef\u7684\u5bbd\u5ea6\u3002\u56de\u60f3\u4e00\u4e0b\u6211\u4eec\u7b2c 8.5 \u8282\u4e2d\u5bf9\u6709\u7b26\u53f7\u591a\u64cd\u4f5c\u6570\u52a0\u6cd5\u7684\u8ba8\u8bba\uff0c\u5176\u4e2d\u5047\u5b9a 2 \u7684\u8865\u7801\u64cd\u4f5c\u6570\u5728\u5176\u6700\u4f4e\u6709\u6548\u4f4d\u5904\u5bf9\u9f50\u3002\u7279\u522b\u662f\uff0c\u8bf7\u53c2\u8003\u56fe 8.19\uff0c\u4e86\u89e3\u57fa\u4e8e\u7b26\u53f7\u6269\u5c55\uff08\u5177\u6709\u786c\u4ef6\u5171\u4eab\uff09\u548c\u5c06\u8d1f\u4f4d\u8f6c\u6362\u4e3a\u6b63\u4f4d\u7684\u4e24\u79cd\u53ef\u80fd\u7684\u65b9\u6cd5\u3002</p> <p>Considerations for adding 2\u2019s-complement partial products are similar, the only difference being the shifts. Figure 11.7 depicts an example with three sign-extended partial products. We see that here too a single FA can produce the results needed in several different columns. If this procedure is applied to all rows in the partial products bit matrix, the resulting structure will be somewhat more complex than the one assuming unsigned operands. Note that because of the shifts, there are fewer repetitions in Fig. 11.7 than in Fig. 8.19, thus making the expansion in width to accommodate the signs slightly larger.</p> <p>\u6dfb\u52a0 2 \u7684\u8865\u7801\u90e8\u5206\u79ef\u7684\u6ce8\u610f\u4e8b\u9879\u7c7b\u4f3c\uff0c\u552f\u4e00\u7684\u533a\u522b\u662f\u79fb\u4f4d\u3002 \u56fe 11.7 \u63cf\u8ff0\u4e86\u5177\u6709\u4e09\u4e2a\u7b26\u53f7\u6269\u5c55\u90e8\u5206\u79ef\u7684\u793a\u4f8b\u3002 \u6211\u4eec\u5728\u8fd9\u91cc\u770b\u5230\uff0c\u5355\u4e2a FA \u4e5f\u53ef\u4ee5\u4ea7\u751f\u591a\u4e2a\u4e0d\u540c\u5217\u6240\u9700\u7684\u7ed3\u679c\u3002 \u5982\u679c\u5c06\u6b64\u8fc7\u7a0b\u5e94\u7528\u4e8e\u90e8\u5206\u4e58\u79ef\u4f4d\u77e9\u9635\u4e2d\u7684\u6240\u6709\u884c\uff0c\u5219\u6240\u5f97\u7ed3\u6784\u5c06\u6bd4\u5047\u8bbe\u65e0\u7b26\u53f7\u64cd\u4f5c\u6570\u7684\u7ed3\u6784\u7a0d\u5fae\u590d\u6742\u4e00\u4e9b\u3002 \u8bf7\u6ce8\u610f\uff0c\u7531\u4e8e\u8fd9\u4e9b\u53d8\u5316\uff0c\u56fe 11.7 \u4e2d\u7684\u91cd\u590d\u6b21\u6570\u6bd4\u56fe 8.19 \u4e2d\u7684\u8981\u5c11\uff0c\u56e0\u6b64\uff0c\u4e3a\u4e86\u5bb9\u7eb3\u7b26\u53f7\u800c\u6269\u5927\u7684\u5bbd\u5ea6\u7a0d\u5927\u4e00\u4e9b\u3002</p> <p></p> <p>Another approach, due to Baugh and Wooley [Baug73], is even more efficient and is thus often preferred, in its original or modified form, for 2\u2019s-complement multiplication. To understand this method, we begin with unsigned multiplication in Fig. 11.8a and note that the negative weight of the sign bit in 2\u2019s-complement representation must be taken into account to obtain the correct product (Fig. 11.8b). To avoid having to deal with negatively weighted bits in the partial products matrix, Baugh and Wooley suggest that we modify the bits in the way shown in Fig. 11.8c, adding five entries to the bit matrix in the process.</p> <p>Baugh \u548c Wooley [Baug73] \u63d0\u51fa\u7684\u53e6\u4e00\u79cd\u65b9\u6cd5\u751a\u81f3\u66f4\u6709\u6548\uff0c\u56e0\u6b64\u5728 2 \u8865\u7801\u4e58\u6cd5\u4e2d\uff0c\u4ee5\u5176\u539f\u59cb\u5f62\u5f0f\u6216\u4fee\u6539\u5f62\u5f0f\u901a\u5e38\u662f\u9996\u9009\u65b9\u6cd5\u3002\u4e3a\u4e86\u7406\u89e3\u8fd9\u79cd\u65b9\u6cd5\uff0c\u6211\u4eec\u4ece\u56fe 11.8a \u4e2d\u7684\u65e0\u7b26\u53f7\u4e58\u6cd5\u5f00\u59cb\uff0c\u5e76\u6ce8\u610f\u5fc5\u987b\u8003\u8651 2 \u8865\u7801\u8868\u793a\u4e2d\u7b26\u53f7\u4f4d\u7684\u8d1f\u6743\u91cd\u624d\u80fd\u83b7\u5f97\u6b63\u786e\u7684\u4e58\u79ef\uff08\u56fe 11.8b\uff09\u3002\u4e3a\u4e86\u907f\u514d\u5904\u7406\u90e8\u5206\u4e58\u79ef\u77e9\u9635\u4e2d\u7684\u8d1f\u6743\u91cd\u4f4d\uff0cBaugh \u548c Wooley \u5efa\u8bae\u6211\u4eec\u6309\u7167\u56fe 11.8c \u6240\u793a\u7684\u65b9\u5f0f\u4fee\u6539\u4f4d\uff0c\u5728\u6b64\u8fc7\u7a0b\u4e2d\u5411\u4f4d\u77e9\u9635\u6dfb\u52a0\u4e94\u4e2a\u6761\u76ee\u3002</p> <p></p> <p>Baugh and Wooley\u2019s strategy increases the maximum column height by 2, thus potentially leading to greater delay through the CSA tree. For example, in the 5 \u00d7 5 multiplication depicted in Fig. 11.8c, maximum column height is increased from 5 to 7, leading to an extra CSA level. In this particular example, however, the extra delay can be avoided by removing the x 4 entry from column 4 and placing two x 4 entries in column 3, which has only four entries. This reduces the maximum height to 6, which can still be handled by a three-level CSA tree.</p> <p>Baugh \u548c Wooley \u7684\u7b56\u7565\u5c06\u6700\u5927\u5217\u9ad8\u589e\u52a0\u4e86 2\uff0c\u56e0\u6b64\u53ef\u80fd\u4f1a\u5bfc\u81f4 CSA \u6811\u51fa\u73b0\u66f4\u5927\u7684\u5ef6\u8fdf\u3002 \u4f8b\u5982\uff0c\u5728\u56fe 11.8c \u6240\u793a\u7684 5 \u00d7 5 \u4e58\u6cd5\u4e2d\uff0c\u6700\u5927\u5217\u9ad8\u4ece 5 \u589e\u52a0\u5230 7\uff0c\u5bfc\u81f4\u989d\u5916\u7684 CSA \u7ea7\u522b\u3002 \u7136\u800c\uff0c\u5728\u6b64\u7279\u5b9a\u793a\u4f8b\u4e2d\uff0c\u53ef\u4ee5\u901a\u8fc7\u4ece\u7b2c 4 \u5217\u4e2d\u5220\u9664 \\(x_4\\) \u6761\u76ee\u5e76\u5c06\u4e24\u4e2a \\(x_4\\) \u6761\u76ee\u653e\u7f6e\u5728\u53ea\u6709\u56db\u4e2a\u6761\u76ee\u7684\u7b2c 3 \u5217\u4e2d\u6765\u907f\u514d\u989d\u5916\u7684\u5ef6\u8fdf\u3002 \u8fd9\u5c06\u6700\u5927\u9ad8\u5ea6\u51cf\u5c11\u5230 6\uff0c\u4f46\u4ecd\u53ef\u4ee5\u7531\u4e09\u5c42 CSA \u6811\u5904\u7406\u3002</p> <p>To prove the correctness of the Baugh\u2013Wooley scheme, let us focus on the entry a 4 x 0 in Fig. 11.8c. Given that the sign bit in 2\u2019s-complement numbers has a negative weight, this entry should have been \u2212 a 4 x 0. We note that</p> <p>\u4e3a\u4e86\u8bc1\u660e Baugh-Wooley \u65b9\u6848\u7684\u6b63\u786e\u6027\uff0c\u8ba9\u6211\u4eec\u5173\u6ce8\u56fe 11.8c \u4e2d\\(a_4\\bar{x}_0\\) \u9879\u3002\u9274\u4e8e 2 \u8865\u7801\u4e2d\u7684\u7b26\u53f7\u4f4d\u5177\u6709\u8d1f\u6743\u91cd\uff0c\u8be5\u6761\u76ee\u5e94\u8be5\u662f \\(\u2212 a_4 x_0\\)\u3002\u6211\u4eec\u6ce8\u610f\u5230</p> <p>\\(\u2212 a_4 x_0 = a_4 ( 1 \u2212 x_0 ) \u2212 a_4 = a_4 \\bar{x}_0 \u2212 a_4\\)</p> <p>Hence, we can replace \u2212 a 4 x 0 with the two entries a 4 x 0 and \u2212 a 4. If instead of \u2212 a 4 we use an entry a 4, the column sum increases by 2 a 4. To compensate for this, we must insert \u2212 a 4 in the next higher column. The same argument can be repeated for a 4 x 1, a 4 x 2, and a 4 x 3. Each column, other than the first, gets an a 4 and a \u2212 a 4, which cancel each other out. The p 8 column gets a \u2212 a 4 entry, which can be replaced with a 4 \u2212 1. The same argument can be repeated for the aix 4 entries, leading to the insertion of x 4 in the p 4 column and x 4 \u2212 1 in the p 8 column. The two \u22121s thus produced in the eighth column are equivalent to a \u22121 entry in the p 9 column, which can in turn be replaced with a 1 and a borrow into the nonexistent (and inconsequential) tenth column.</p> <p>\u56e0\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06 \\(\u2212 a_4 x_0\\) \u66ff\u6362\u4e3a\u4e24\u4e2a\u6761\u76ee \\(a_4 \\bar{x}_0\\) \u548c \\(\u2212 a_4\\)\u3002\u5982\u679c\u6211\u4eec\u4f7f\u7528\u6761\u76ee \\(a_4\\) \u4ee3\u66ff \\(\u2212 a_4\\)\uff0c\u5219\u5217\u603b\u548c\u4f1a\u589e\u52a0 \\(2 a_4\\)\u3002\u4e3a\u4e86\u8865\u507f\u8fd9\u4e00\u70b9\uff0c\u6211\u4eec\u5fc5\u987b\u5728\u4e0b\u4e00\u4e2a\u66f4\u9ad8\u7684\u5217\u4e2d\u63d2\u5165\\(\u2212 a_4\\)\u3002\u53ef\u4ee5\u5bf9 \\(a_4 \\bar{x}_1\\)\u3001\\(a_4 \\bar{x}_2\\) \u548c \\(a_4 \\bar{x}_3\\) \u91cd\u590d\u76f8\u540c\u7684\u53c2\u6570\u3002\u9664\u4e86\u7b2c\u4e00\u5217\u4e4b\u5916\uff0c\u6bcf\u4e00\u5217\u90fd\u5f97\u5230 \\(a_4\\) \u548c \\(\u2212 a_4\\)\uff0c\u5b83\u4eec\u76f8\u4e92\u62b5\u6d88\u3002 \\(p 8\\) \u5217\u83b7\u53d6 \\(\u2212 a_4\\) \u6761\u76ee\uff0c\u53ef\u4ee5\u5c06\u5176\u66ff\u6362\u4e3a \\(\\bar{a}_4 \u2212 1\\)\u3002\u53ef\u4ee5\u5bf9 \\(\\bar{a}_ix_4\\) \u6761\u76ee\u91cd\u590d\u76f8\u540c\u7684\u505a\u6cd5\uff0c\u4ece\u800c\u5bfc\u81f4\u5728 \\(p_4\\) \u5217\u4e2d\u63d2\u5165 \\(x_4\\)\u548c \\(p8\\) \u5217\u4e2d\u7684 \\(\\bar{x}_4 \u2212 1\\) \u3002\u8fd9\u6837\u5728\u7b2c\u516b\u5217\u4e2d\u4ea7\u751f\u7684\u4e24\u4e2a -1 \u76f8\u5f53\u4e8e \\(p_9\\) \u5217\u4e2d\u7684\u4e00\u4e2a -1 \u6761\u76ee\uff0c\u5b83\u53c8\u53ef\u4ee5\u7528 1 \u66ff\u6362\u5e76\u501f\u7528\u4e86\u4e0d\u5b58\u5728\u7684\uff08\u4e14\u65e0\u5173\u7d27\u8981\u7684\uff09\u7b2c\u5341\u680f\u3002</p> <p>Another way to justify the Baugh\u2013Wooley method is to transfer all negatively weighted \\(a_4 x_i\\) terms, \\(0 \u2264 i \u2264 3\\), to the bottom row, thus leading to two negative numbers (the preceding number and the one formed by the \\(a_ix_4\\) bits, \\(0 \u2264 i \u2264 3\\)) in the last two rows. Now, the two numbers x 4 a and a 4 x must be subtracted from the sum of all the positive elements. Instead of subtracting x 4 \u00d7 a, we add x 4 times the 2\u2019s complement of a, which consists of 1\u2019s complement of a plus x 4 (similarly for a 4 x). The reader should be able to supply the other details.</p> <p>\u8bc1\u660e Baugh-Wooley \u65b9\u6cd5\u5408\u7406\u6027\u7684\u53e6\u4e00\u79cd\u65b9\u6cd5\u662f\u5c06\u6240\u6709\u8d1f\u6743\u91cd \\(a_4 x_i\\)  \u9879, \\(0 \u2264 i \u2264 3\\), \u8f6c\u79fb\u5230\u5e95\u884c\uff0c\u4ece\u800c\u4ea7\u751f\u4e24\u4e2a\u8d1f\u6570\uff08\u524d\u4e00\u4e2a\u6570\u548c\u540e\u4e00\u4e2a \u7531\u6700\u540e\u4e24\u884c\u4e2d\u7684 \\(a_ix_4\\) \u4f4d \\(0 \u2264 i \u2264 3\\)\u7ec4\u6210\u7684\u6570\uff09\u3002 \u73b0\u5728\uff0c\u5fc5\u987b\u4ece\u6240\u6709\u6b63\u5143\u7d20\u7684\u603b\u548c\u4e2d\u51cf\u53bb \\(x_4a\\) \u548c \\(a_4 x\\) \u8fd9\u4e24\u4e2a\u6570\u5b57\u3002 \u6211\u4eec\u4e0d\u662f\u51cf\u53bb \\(x_4 \u00d7 a\\)\uff0c\u800c\u662f\u52a0\u4e0a \\(x_4\\) \u4e58\u4ee5 a \u7684 2 \u8865\u7801\uff0c\u5176\u4e2d\u5305\u62ec a \u7684 1 \u8865\u7801\u52a0\u4e0a \\(x_4\\)\uff08\u4e0e \\(a_4x\\) \u7c7b\u4f3c\uff09 \u3002 \u8bfb\u8005\u5e94\u8be5\u80fd\u591f\u63d0\u4f9b\u5176\u4ed6\u7ec6\u8282\u3002</p> <p>A modified form of the Baugh\u2013Wooley method, (Fig. 11.8d) is preferable because it does not lead to an increase in the maximum column height. Justifying this modified form is left as an exercise.</p> <p>Baugh-Wooley \u65b9\u6cd5\u7684\u4fee\u6539\u5f62\u5f0f\uff08\u56fe 11.8d\uff09\u66f4\u53ef\u53d6\uff0c\u56e0\u4e3a\u5b83\u4e0d\u4f1a\u5bfc\u81f4\u6700\u5927\u67f1\u9ad8\u5ea6\u7684\u589e\u52a0\u3002\u8bc1\u660e\u8fd9\u4e2a\u4fee\u6539\u540e\u7684\u5f62\u5f0f\u7684\u5408\u7406\u6027\u7559\u4f5c\u7ec3\u4e60\u3002</p>"},{"location":"Part_03/11/#114","title":"11.4 \u622a\u65ad\u4e58\u6cd5\u5668\u4e0e\u6811\u578b\u4e58\u6cd5\u5668","text":"<p>If the cost of a full-tree multiplier is unacceptably high for a particular application, then a variety of mixed serial-parallel designs can be considered. Let  h  be a number smaller than  k. One idea is to perform the  k-operand addition needed for  k \u00d7  k  multiplication via   k/h passes through a smaller CSA tree. Figure 11.9 shows the resulting design that includes an ( h + 2)-input CSA tree for adding the cumulative partial product (in stored-carry form) and  h  new operands, feeding back the resulting sum and carry to be combined with the next batch of  h  operands. </p> <p>\u5982\u679c\u5168\u6811\u4e58\u6cd5\u5668\u7684\u6210\u672c\u5bf9\u4e8e\u7279\u5b9a\u5e94\u7528\u800c\u8a00\u9ad8\u5f97\u4ee4\u4eba\u65e0\u6cd5\u63a5\u53d7\uff0c\u5219\u53ef\u4ee5\u8003\u8651\u5404\u79cd\u6df7\u5408\u4e32\u884c\u5e76\u884c\u8bbe\u8ba1\u3002\u4ee4\\(h\\)\u4e3a\u5c0f\u4e8e\\(k\\)\u7684\u6570\u3002\u4e00\u79cd\u60f3\u6cd5\u662f\u901a\u8fc7 \\(\\left \\lceil k/h \\right \\rceil\\) \u904d\u5386\u8f83\u5c0f\u7684 CSA \u6811\u6765\u6267\u884c \\(k \u00d7 k\\) \u4e58\u6cd5\u6240\u9700\u7684 \\(k\\) \u64cd\u4f5c\u6570\u52a0\u6cd5\u3002\u56fe 11.9 \u663e\u793a\u4e86\u6700\u7ec8\u7684\u8bbe\u8ba1\uff0c\u5176\u4e2d\u5305\u62ec\u4e00\u4e2a$ ( h + 2) $\u8f93\u5165 CSA \u6811\uff0c\u7528\u4e8e\u6dfb\u52a0\u7d2f\u79ef\u90e8\u5206\u79ef\uff08\u4ee5\u5b58\u50a8\u8fdb\u4f4d\u5f62\u5f0f\uff09\u548c \\(h\\) \u4e2a\u65b0\u64cd\u4f5c\u6570\uff0c\u53cd\u9988\u7ed3\u679c\u603b\u548c\u548c\u8fdb\u4f4d\u4ee5\u4e0e\u4e0b\u4e00\u6279 \\(h\\) \u64cd\u4f5c\u9635\u5217\u5408\u3002</p> <p>Since the next batch of  h  operands will be shifted by  h  bits with respect to the current batch,  h  bits of the derived sum and  h \u2212 1 bits of the carry can be relaxed after each pass. These are combined using an  h-bit adder to yield  h  bits of the final product, with the carry-out kept in a flip-flop to be combined with the next inputs. Alternatively, these relaxed bits can be kept in carry-save form by simply shifting them to the right in their respective registers and postponing the conversion to standard binary format to the very end. This is why parts of Fig. 11.9 are rendered in light gray. The latter approach might be followed if a fast double-width adder is already available in the arithmetic/logic unit for other reasons. </p> <p>\u7531\u4e8e\u4e0b\u4e00\u6279\u7684 \\(h\\) \u64cd\u4f5c\u6570\u5c06\u76f8\u5bf9\u4e8e\u5f53\u524d\u6279\u6b21\u79fb\u4f4d \\(h\\) \u4f4d\uff0c\u56e0\u6b64\u6bcf\u6b21\u4f20\u9012\u540e\u53ef\u4ee5\u653e\u5bbd\u5bfc\u51fa\u548c\u7684 \\(h\\) \u4f4d\u548c\u8fdb\u4f4d\u7684 \\(h \u2212 1\\) \u4f4d\u3002\u4f7f\u7528 \\(h\\) \u4f4d\u52a0\u6cd5\u5668\u5c06\u5b83\u4eec\u7ec4\u5408\u8d77\u6765\uff0c\u4ea7\u751f\u6700\u7ec8\u4e58\u79ef\u7684 h \u4f4d\uff0c\u5e76\u5c06\u8fdb\u4f4d\u4fdd\u7559\u5728\u89e6\u53d1\u5668\u4e2d\u4ee5\u4e0e\u4e0b\u4e00\u4e2a\u8f93\u5165\u7ec4\u5408\u3002\u6216\u8005\uff0c\u901a\u8fc7\u7b80\u5355\u5730\u5c06\u8fd9\u4e9b\u5bbd\u677e\u4f4d\u5728\u5404\u81ea\u7684\u5bc4\u5b58\u5668\u4e2d\u53f3\u79fb\u5e76\u5c06\u5230\u6807\u51c6\u4e8c\u8fdb\u5236\u683c\u5f0f\u7684\u8f6c\u6362\u63a8\u8fdf\u5230\u6700\u540e\uff0c\u53ef\u4ee5\u5c06\u8fd9\u4e9b\u5bbd\u677e\u4f4d\u4fdd\u6301\u4e3a\u8fdb\u4f4d\u4fdd\u5b58\u5f62\u5f0f\u3002\u8fd9\u5c31\u662f\u56fe 11.9 \u7684\u90e8\u5206\u90e8\u5206\u5448\u73b0\u4e3a\u6d45\u7070\u8272\u7684\u539f\u56e0\u3002\u5982\u679c\u7531\u4e8e\u5176\u4ed6\u539f\u56e0\u5728\u7b97\u672f/\u903b\u8f91\u5355\u5143\u4e2d\u5df2\u7ecf\u53ef\u4ee5\u4f7f\u7528\u5feb\u901f\u53cc\u5bbd\u5ea6\u52a0\u6cd5\u5668\uff0c\u5219\u53ef\u4ee5\u91c7\u7528\u540e\u4e00\u79cd\u65b9\u6cd5\u3002</p> <p>Note that the design depicted in Fig. 11.9 corresponds to radix-2 h  multiplication. Thus, our discussions in Sections 10.3 and 10.4 are relevant here as well. In fact, the difference between high-radix and partial-tree multipliers is quantitative rather than qualitative (see Fig. 10.13). When  h  is relatively small, say up to 8 bits, we tend to view the multiplier of Fig. 11.9 as a high-radix multiplier. On the other hand, when  h is a significant fraction of  k, say  k/2 or  k/4, then we view the design as a partial-tree multiplier. In Section 11.6, we will see that a pipelined variant of the design in Fig. 11.9 can be considerably faster when h is large.</p> <p>\u8bf7\u6ce8\u610f\uff0c\u56fe 11.9 \u4e2d\u63cf\u8ff0\u7684\u8bbe\u8ba1\u5bf9\u5e94\u4e8e radix-\\(2^h\\) \u4e58\u6cd5\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u5728\u7b2c 10.3 \u8282\u548c\u7b2c 10.4 \u8282\u4e2d\u7684\u8ba8\u8bba\u4e5f\u4e0e\u6b64\u76f8\u5173\u3002\u4e8b\u5b9e\u4e0a\uff0c\u9ad8\u57fa\u4e58\u6570\u548c\u90e8\u5206\u6811\u4e58\u6570\u4e4b\u95f4\u7684\u5dee\u5f02\u662f\u5b9a\u91cf\u7684\u800c\u4e0d\u662f\u5b9a\u6027\u7684\uff08\u89c1\u56fe 10.13\uff09\u3002\u5f53 h \u76f8\u5bf9\u8f83\u5c0f\u65f6\uff0c\u6bd4\u5982\u6700\u591a 8 \u4f4d\uff0c\u6211\u4eec\u503e\u5411\u4e8e\u5c06\u56fe 11.9 \u7684\u4e58\u6cd5\u5668\u89c6\u4e3a\u9ad8\u57fa\u6570\u4e58\u6cd5\u5668\u3002\u53e6\u4e00\u65b9\u9762\uff0c\u5f53 h \u662f k \u7684\u91cd\u8981\u5206\u6570\uff08\u4f8b\u5982 \\(k/2\\) \u6216 \\(k/4\\)\uff09\u65f6\uff0c\u6211\u4eec\u5c06\u8bbe\u8ba1\u89c6\u4e3a\u90e8\u5206\u6811\u4e58\u6cd5\u5668\u3002\u5728\u7b2c 11.6 \u8282\u4e2d\uff0c\u6211\u4eec\u5c06\u770b\u5230\u56fe 11.9 \u4e2d\u8bbe\u8ba1\u7684\u6d41\u6c34\u7ebf\u53d8\u4f53\u5f53 h \u5f88\u5927\u65f6\uff0c\u901f\u5ea6\u4f1a\u5feb\u5f97\u591a\u3002</p> <p></p> <p>Figure 11.9 has been drawn with the assumption of radix-2 multiplication. If radix-2 b Booth\u2019s recoding is applied first to produce one multiple for every b bits of the multiplier, then b times fewer passes are needed and bh bits can be relaxed after each pass. In this case, the small adder in Fig. 11.9 will be bh bits wide.</p> <p>\u56fe 11.9 \u662f\u5728\u57fa\u6570 2 \u4e58\u6cd5\u7684\u5047\u8bbe\u4e0b\u7ed8\u5236\u7684\u3002\u5982\u679c\u9996\u5148\u5e94\u7528 radix-\\(2^b\\) Booth \u91cd\u65b0\u7f16\u7801\u6765\u4e3a\u4e58\u6cd5\u5668\u7684\u6bcf b \u4f4d\u751f\u6210\u4e00\u4e2a\u500d\u6570\uff0c\u5219\u9700\u8981 b \u500d\u7684\u901a\u8fc7\u6b21\u6570\uff0c\u5e76\u4e14\u5728\u6bcf\u6b21\u901a\u8fc7\u540e\u53ef\u4ee5\u653e\u5bbd \\(bh\\) \u4f4d\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u56fe 11.9 \u4e2d\u7684\u5c0f\u52a0\u6cd5\u5668\u5c06\u4e3a \\(bh\\) \u4f4d\u5bbd\u3002</p> <p>Thus far, our multipliers were all designed to produce double-width, or full-precision, products. In many applications, a single-width product might be sufficient. Consider, for example, k-bit fractional operands a and x, whose exact product has 2 k bits. A k-bit fractional result can be obtained by truncating or rounding the double-width result to k bits. However, this might be viewed as wasteful, given that all the bits on the right half of the partial products bit-matrix of Fig. 11.10, to the right of the vertical dashed line, have only a slight impact on the final result. Why not simply drop all those bits to save on the AND gates that produce them and the CSAs that combine and reduce them? Let us see what would happen if we do decide to drop the said bits in the 8 \u00d7 8 multiplication depicted in Fig. 11.10. In the worst case, when all the dropped bits are 1s, we would lose a value equal to 8 / 2 + 7 / 4 + 6 / 8 + 5 / 16 + 4 / 32 + 3 / 64 + 2 / 128 + 1 / 256 \u2248 7.004 ulp, where ulp is the weight or worth of the least-significant bit of each operand. If this maximum error of \u22127 ulp is tolerable, then the multiplier can be greatly simplified.</p> <p>\u5230\u76ee\u524d\u4e3a\u6b62\uff0c\u6211\u4eec\u7684\u4e58\u6cd5\u5668\u90fd\u662f\u4e3a\u4ea7\u751f\u53cc\u5bbd\u5ea6\u6216\u5168\u7cbe\u5ea6\u4e58\u79ef\u800c\u8bbe\u8ba1\u7684\u3002\u5728\u8bb8\u591a\u5e94\u7528\u4e2d\uff0c\u5355\u5bbd\u5ea6\u4e58\u79ef\u53ef\u80fd\u5c31\u8db3\u591f\u4e86\u3002\u4f8b\u5982\uff0c\u8003\u8651 k \u4f4d\u5c0f\u6570\u64cd\u4f5c\u6570 a \u548c x\uff0c\u5176\u7cbe\u786e\u4e58\u79ef\u6709 2 k \u4f4d\u3002\u901a\u8fc7\u5c06\u53cc\u500d\u5bbd\u5ea6\u7ed3\u679c\u622a\u65ad\u6216\u56db\u820d\u4e94\u5165\u4e3ak\u4f4d\uff0c\u53ef\u4ee5\u83b7\u5f97k\u4f4d\u5c0f\u6570\u7ed3\u679c\u3002\u7136\u800c\uff0c\u8fd9\u53ef\u80fd\u88ab\u89c6\u4e3a\u6d6a\u8d39\uff0c\u56e0\u4e3a\u56fe 11.10 \u7684\u90e8\u5206\u4e58\u79ef\u4f4d\u77e9\u9635\u7684\u53f3\u534a\u90e8\u5206\uff08\u5782\u76f4\u865a\u7ebf\u53f3\u4fa7\uff09\u4e0a\u7684\u6240\u6709\u4f4d\u5bf9\u6700\u7ec8\u7ed3\u679c\u4ec5\u4ea7\u751f\u8f7b\u5fae\u5f71\u54cd\u3002\u4e3a\u4ec0\u4e48\u4e0d\u7b80\u5355\u5730\u4e22\u5f03\u6240\u6709\u8fd9\u4e9b\u4f4d\u4ee5\u8282\u7701\u4ea7\u751f\u5b83\u4eec\u7684 AND \u95e8\u4ee5\u53ca\u7ec4\u5408\u548c\u51cf\u5c11\u5b83\u4eec\u7684 CSA\uff1f\u8ba9\u6211\u4eec\u770b\u770b\u5982\u679c\u6211\u4eec\u51b3\u5b9a\u5728\u56fe 11.10 \u6240\u793a\u7684 8 \u00d7 8 \u4e58\u6cd5\u4e2d\u5220\u9664\u8fd9\u4e9b\u4f4d\uff0c\u4f1a\u53d1\u751f\u4ec0\u4e48\u3002\u5728\u6700\u574f\u7684\u60c5\u51b5\u4e0b\uff0c\u5f53\u6240\u6709\u4e22\u5f03\u7684\u4f4d\u90fd\u662f 1 \u65f6\uff0c\u6211\u4eec\u5c06\u4e22\u5931\u7b49\u4e8e \\(8 / 2 + 7 / 4 + 6 / 8 + 5 / 16 + 4 / 32 + 3 / 64 + 2 / 128 + 1 / 256 \u2248 7.004 \\text{ ulp}\\) </p> <p>\u7684\u503c\uff0c\u5176\u4e2d ulp \u662f\u6bcf\u4e2a\u64cd\u4f5c\u6570\u6700\u4f4e\u6709\u6548\u4f4d\u7684\u6743\u91cd\u6216\u503c\u3002\u5982\u679c\u22127 ulp \u7684\u6700\u5927\u8bef\u5dee\u662f\u53ef\u4ee5\u5bb9\u5fcd\u7684\uff0c\u90a3\u4e48\u4e58\u6cd5\u5668\u5c31\u53ef\u4ee5\u5927\u5927\u7b80\u5316\u3002</p> <p>However, we can do substantially better, will little additional cost. One way to reduce the error of our truncated multiplier is to keep the first column of dots to the right of the vertical dashed line in Fig. 11.10, dropping only the dots in columns indexed \u221210 to \u221216. This modification will improve the error bound computed above by 8 / 2 = 4 ulp in the partial products accumulation phase, but introduces a possible error of ulp/ 2 when the extra product bit p\u22129 is dropped to form a k-bit final product. Thus, the maximum error is reduced from 7 ulp to 3.5 ulp, at the expense of more circuitry to generate and process the eight previously ignored dots. Another possibility is to drop columns \u22129 and beyond as before, but introduce a compensating 1 term in column \u22126. The error now ranges from about \u22123 ulp, when all the dropped bits are 1s, to 4 ulp, when all the dropped bits are 0s. The latter error is comparable in magnitude to that of the preceding method, but it is achieved at a much lower cost. This constant compensation method can be further refined to produce better results. Finally, we can resort to variable compensation, exemplified by the insertion of two dots with values a\u22121 and x\u22121 (leading bits of the two operands) in column \u22127. The idea here is to provide greater compensation for the value of the dropped bits when they are more likely to be 1s. Error analysis for this approach is left as an exercise.</p> <p>\u7136\u800c\uff0c\u6211\u4eec\u53ef\u4ee5\u505a\u5f97\u66f4\u597d\uff0c\u4e14\u51e0\u4e4e\u4e0d\u9700\u8981\u989d\u5916\u7684\u6210\u672c\u3002\u51cf\u5c11\u622a\u65ad\u4e58\u6cd5\u5668\u8bef\u5dee\u7684\u4e00\u79cd\u65b9\u6cd5\u662f\u5c06\u7b2c\u4e00\u5217\u70b9\u4fdd\u6301\u5728\u56fe 11.10 \u4e2d\u5782\u76f4\u865a\u7ebf\u7684\u53f3\u4fa7\uff0c\u4ec5\u5220\u9664\u7d22\u5f15\u4e3a -10 \u5230 -16 \u7684\u5217\u4e2d\u7684\u70b9\u3002\u6b64\u4fee\u6539\u5c06\u5728\u90e8\u5206\u4e58\u79ef\u7d2f\u79ef\u9636\u6bb5\u5c06\u4e0a\u9762\u8ba1\u7b97\u7684\u8bef\u5dee\u8303\u56f4\u63d0\u9ad8 \\(8 / 2 = 4\\) ulp\uff0c\u4f46\u662f\u5f53\u4e22\u5f03\u989d\u5916\u4e58\u79ef\u4f4d \\(p_{\u22129}\\) \u4ee5\u5f62\u6210 k \u4f4d\u6700\u7ec8\u4e58\u79ef\u65f6\uff0c\u4f1a\u5f15\u5165 ulp/ 2 \u7684\u53ef\u80fd\u9519\u8bef\u3002\u56e0\u6b64\uff0c\u6700\u5927\u8bef\u5dee\u4ece 7 ulp \u51cf\u5c11\u5230 3.5 ulp\uff0c\u4f46\u4ee3\u4ef7\u662f\u9700\u8981\u66f4\u591a\u7535\u8def\u6765\u751f\u6210\u548c\u5904\u7406\u5148\u524d\u5ffd\u7565\u7684\u516b\u4e2a\u70b9\u3002\u53e6\u4e00\u79cd\u53ef\u80fd\u6027\u662f\u50cf\u4ee5\u524d\u4e00\u6837\u5220\u9664\u22129 \u5217\u53ca\u4e4b\u540e\u7684\u5217\uff0c\u4f46\u5728\u22126 \u5217\u4e2d\u5f15\u5165\u8865\u507f1\u7684\u9879\u3002\u73b0\u5728\uff0c\u5f53\u6240\u6709\u4e22\u5f03\u7684\u4f4d\u5747\u4e3a 1 \u65f6\uff0c\u8bef\u5dee\u8303\u56f4\u7ea6\u4e3a -3 ulp\uff0c\u5f53\u6240\u6709\u4e22\u5f03\u7684\u4f4d\u5747\u4e3a 0 \u65f6\uff0c\u8bef\u5dee\u8303\u56f4\u4e3a 4 ulp\u3002\u540e\u4e00\u79cd\u8bef\u5dee\u7684\u5927\u5c0f\u4e0e\u524d\u4e00\u79cd\u65b9\u6cd5\u7684\u8bef\u5dee\u76f8\u5f53\uff0c\u4f46\u5176\u5b9e\u73b0\u6210\u672c\u8981\u4f4e\u5f97\u591a\u3002\u8fd9\u79cd\u6052\u5b9a\u8865\u507f\u65b9\u6cd5\u53ef\u4ee5\u8fdb\u4e00\u6b65\u7ec6\u5316\u4ee5\u4ea7\u751f\u66f4\u597d\u7684\u7ed3\u679c\u3002\u6700\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u8bc9\u8bf8\u53d8\u91cf\u8865\u507f\uff0c\u4f8b\u5982\u5728 -7 \u5217\u4e2d\u63d2\u5165\u503c\u4e3a \\(a_{\u22121}\\) \u548c \\(x_{\u22121}\\)\uff08\u4e24\u4e2a\u64cd\u4f5c\u6570\u7684\u524d\u5bfc\u4f4d\uff09\u7684\u4e24\u4e2a\u70b9\u3002\u8fd9\u91cc\u7684\u60f3\u6cd5\u662f\uff0c\u5f53\u4e22\u5f03\u7684\u4f4d\u66f4\u6709\u53ef\u80fd\u4e3a 1 \u65f6\uff0c\u4e3a\u5b83\u4eec\u7684\u503c\u63d0\u4f9b\u66f4\u5927\u7684\u8865\u507f\u3002\u8fd9\u79cd\u65b9\u6cd5\u7684\u9519\u8bef\u5206\u6790\u7559\u4f5c\u7ec3\u4e60\u3002</p> <p></p>"},{"location":"Part_03/11/#115","title":"11.5 \u9635\u5217\u4e58\u6cd5\u5668","text":"<p>Consider a full-tree multiplier (Fig. 11.1) in which the reduction tree is one-sided and the final adder has a ripple-carry design, as depicted in Fig. 11.11. Such a tree multiplier, which is composed of the slowest possible CSA tree and the slowest possible CPA, is known as an array multiplier.</p> <p>\u8003\u8651\u4e00\u4e2a\u5168\u6811\u4e58\u6cd5\u5668\uff08\u56fe 11.1\uff09\uff0c\u5176\u4e2d\u7ea6\u7b80\u6811\u662f\u5355\u4fa7\u7684\uff0c\u5e76\u4e14\u6700\u7ec8\u52a0\u6cd5\u5668\u5177\u6709\u7eb9\u6ce2\u8fdb\u4f4d\u8bbe\u8ba1\uff0c\u5982\u56fe 11.11 \u6240\u793a\u3002\u8fd9\u79cd\u7531\u6700\u6162\u7684 CSA \u6811\u548c\u6700\u6162\u7684 CPA \u7ec4\u6210\u7684\u6811\u4e58\u6cd5\u5668\u79f0\u4e3a\u9635\u5217\u4e58\u6cd5\u5668\u3002</p> <p></p> <p>But why would anyone be interested in such a slow multiplier? The answer is that an array multiplier is very regular in its structure and uses only short wires that go from one FA to horizontally, vertically, or diagonally adjacent FAs. Thus, it has a very simple and efficient layout in VLSI. Furthermore, it can be easily and efficiently pipelined by inserting latches after every CSAor after every few rows (the last row must be handled differently, as discussed in Section 11.6, because its latency is much larger than the others).</p> <p>\u4f46\u4e3a\u4ec0\u4e48\u6709\u4eba\u4f1a\u5bf9\u5982\u6b64\u7f13\u6162\u7684\u4e58\u6570\u611f\u5174\u8da3\u5462\uff1f\u7b54\u6848\u662f\uff0c\u9635\u5217\u4e58\u6cd5\u5668\u7684\u7ed3\u6784\u975e\u5e38\u89c4\u5219\uff0c\u4ec5\u4f7f\u7528\u4ece\u4e00\u4e2a FA \u5230\u6c34\u5e73\u3001\u5782\u76f4\u6216\u5bf9\u89d2\u76f8\u90bb FA \u7684\u77ed\u7ebf\u3002\u56e0\u6b64\uff0c\u5b83\u5728 VLSI \u4e2d\u5177\u6709\u975e\u5e38\u7b80\u5355\u4e14\u9ad8\u6548\u7684\u5e03\u5c40\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5728\u6bcf\u4e2a CSA \u4e4b\u540e\u6216\u6bcf\u9694\u51e0\u884c\u4e4b\u540e\u63d2\u5165\u9501\u5b58\u5668\uff0c\u53ef\u4ee5\u8f7b\u677e\u9ad8\u6548\u5730\u8fdb\u884c\u6d41\u6c34\u7ebf\u5904\u7406\uff08\u6700\u540e\u4e00\u884c\u5fc5\u987b\u4ee5\u4e0d\u540c\u65b9\u5f0f\u5904\u7406\uff0c\u5982\u7b2c 11.6 \u8282\u4e2d\u6240\u8ff0\uff0c\u56e0\u4e3a\u5b83\u7684\u5ef6\u8fdf\u6bd4\u5176\u4ed6\u884c\u5927\u5f97\u591a\uff09\u3002</p> <p>The free input of the topmost CSA in the array multiplier of Fig. 11.11 can be used to realize a multiply-add module yielding p = ax + y. This is useful in a variety of applications involving convolution or inner-product computation. When only the computation of ax is desired, the topmost CSA in the array multiplier of Fig. 11.11 can be removed, with x 0 a and x 1 a input to the second CSA directly.</p> <p>\u56fe11.11\u7684\u9635\u5217\u4e58\u6cd5\u5668\u4e2d\u6700\u9876\u5c42CSA\u7684\u81ea\u7531\u8f93\u5165\u53ef\u4ee5\u7528\u4e8e\u5b9e\u73b0\u4e58\u52a0\u6a21\u5757\uff0c\u4ea7\u751f p = ax + y\u3002\u8fd9\u5728\u6d89\u53ca\u5377\u79ef\u6216\u5185\u79ef\u8ba1\u7b97\u7684\u5404\u79cd\u5e94\u7528\u4e2d\u975e\u5e38\u6709\u7528\u3002\u5f53\u53ea\u9700\u8981\u8ba1\u7b97 ax\uff0c\u5219\u53ef\u4ee5\u5220\u9664\u56fe 11.11 \u7684\u9635\u5217\u4e58\u6cd5\u5668\u4e2d\u6700\u4e0a\u9762\u7684 CSA\uff0c\u5c06 \\(x_0 a\\) \u548c \\(x_1 a\\) \u76f4\u63a5\u8f93\u5165\u5230\u7b2c\u4e8c\u4e2a CSA\u3002</p> <p></p> <p>Figure 11.12 shows the design of a 5 \u00d7 5 array multiplier in terms of FA cells and two-input AND gates. The sum outputs are connected diagonally, while the carry outputs are linked vertically, except in the last row, where they are chained from right to left.  The design in Fig. 11.12 assumes unsigned numbers, but it can be easily converted to a 2\u2019s-complement array multiplier using the Baugh\u2013Wooley method. This involves adding a FA at the right end of the ripple-carry adder, to take in the a 4 and x 4 terms, and a couple of FAs at the lower left edge to accommodate the a 4, x 4, and 1 terms of Fig. 11.8C (see Fig. 11.13). Most of the connections between FA blocks in Fig. 11.13 have been removed to avoid clutter. The modified diagonal connections in Fig. 11.13 will be described shortly.</p> <p>\u56fe 11.12 \u663e\u793a\u4e86 5 \u00d7 5 \u9635\u5217\u4e58\u6cd5\u5668\u7684 FA \u5355\u5143\u548c\u4e24\u8f93\u5165\u4e0e\u95e8\u7684\u8bbe\u8ba1\u3002\u548c\u8f93\u51fa\u5bf9\u89d2\u8fde\u63a5\uff0c\u800c\u8fdb\u4f4d\u8f93\u51fa\u5782\u76f4\u8fde\u63a5\uff0c\u9664\u4e86\u6700\u540e\u4e00\u884c\uff0c\u5b83\u4eec\u4ece\u53f3\u5230\u5de6\u94fe\u63a5\u3002\u56fe 11.12 \u4e2d\u7684\u8bbe\u8ba1\u5047\u8bbe\u65e0\u7b26\u53f7\u6570\uff0c\u4f46\u53ef\u4ee5\u4f7f\u7528 Baugh-Wooley \u65b9\u6cd5\u8f7b\u677e\u5c06\u5176\u8f6c\u6362\u4e3a 2 \u8865\u7801\u9635\u5217\u4e58\u6cd5\u5668\u3002\u8fd9\u6d89\u53ca\u5230\u5728\u7eb9\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\u7684\u53f3\u7aef\u6dfb\u52a0\u4e00\u4e2a FA\uff0c\u4ee5\u63a5\u6536 \\(a_4\\) \u548c \\(x_4\\) \u9879\uff0c\u5e76\u5728\u5de6\u4e0b\u8fb9\u7f18\u6dfb\u52a0\u51e0\u4e2a FA \u4ee5\u5bb9\u7eb3\u56fe 11.8C\uff08\u89c1\u56fe11.13\uff09 \u4e2d\u7684 \\(\\bar{a}_4\u3001\\bar{x}_4\\) \u548c 1 \u9879\u3002\u56fe 11.13 \u4e2d FA \u5757\u4e4b\u95f4\u7684\u5927\u90e8\u5206\u8fde\u63a5\u5df2\u88ab\u5220\u9664\u4ee5\u907f\u514d\u6df7\u4e71\u3002\u4e0b\u9762\u7b80\u8981\u63cf\u8ff0\u56fe 11.13 \u4e2d\u4fee\u6539\u7684\u5bf9\u89d2\u7ebf\u8fde\u63a5\u3002</p> <p></p> <p>In view of the simplicity of an array multiplier for 2\u2019s-complement numbers based on the Baugh\u2013Wooley method, we no longer use techniques proposed by Pezaris [Peza71] and others that required in some of the array positions variants of an FA cell capable of accommodating some negatively weighted input bits and producing one or both outputs with negative weight(s). </p> <p>\u9274\u4e8e\u57fa\u4e8e Baugh-Wooley \u65b9\u6cd5\u7684 2 \u8865\u7801\u9635\u5217\u4e58\u6cd5\u5668\u7684\u7b80\u5355\u6027\uff0c\u6211\u4eec\u4e0d\u518d\u4f7f\u7528 Pezaris [Peza71] \u4ee5\u53ca\u5176\u4ed6\u4eba\u63d0\u51fa\u7684\u6280\u672f\uff0c\u90a3\u9700\u8981\u5728 FA \u5355\u5143\u7684\u67d0\u4e9b\u9635\u5217\u4f4d\u7f6e\u53d8\u4f53\u4e2d\u80fd\u591f\u5bb9\u7eb3\u4e00\u4e9b\u8d1f\u6743\u91cd\u8f93\u5165\u4f4d\u5e76\u4ea7\u751f\u4e00\u4e2a\u6216\u4e24\u4e2a\u5177\u6709\u8d1f\u6743\u91cd\u7684\u8f93\u51fa\u7684\u60c5\u51b5\u3002</p> <p>If we build a cell containing an FA and an AND gate to internally form the term ajxi, the unsigned array multiplier of Fig. 11.12 turns into Fig. 11.14. Here, the  xi  and  aj bits are broadcast to rows and columns of cells, with the row- i, column- j  cell, forming the term  ajxi  and using it as an input to its FA. If desired, one can make the design less complex by replacing the cells in the first row, or the first two rows, by AND gates. </p> <p>\u5982\u679c\u6211\u4eec\u6784\u5efa\u4e00\u4e2a\u5305\u542b FA \u548c AND \u95e8\u7684\u5355\u5143\u6765\u5728\u5185\u90e8\u5f62\u6210\u9879 \\(a_jx_i\\)\uff0c\u5219\u56fe 11.12 \u7684\u65e0\u7b26\u53f7\u9635\u5217\u4e58\u6cd5\u5668\u5c06\u53d8\u6210\u56fe 11.14\u3002\u8fd9\u91cc\uff0c\\(x_i\\) \u548c \\(a_j\\) \u4f4d\u88ab\u5e7f\u64ad\u5230\u5355\u5143\u7684\u884c\u548c\u5217\uff0c\u5176\u4e2d\u7b2c i \u884c\u3001\u7b2c j \u5217\u7684\u5355\u5143\u5f62\u6210\u672f\u8bed \\(a_jx_i\\)\u5e76\u5c06\u5176\u7528\u4f5c FA \u7684\u8f93\u5165\u3002\u5982\u679c\u9700\u8981\uff0c\u53ef\u4ee5\u901a\u8fc7\u7528\u201c\u4e0e\u201d\u95e8\u66ff\u6362\u7b2c\u4e00\u884c\u6216\u524d\u4e24\u884c\u4e2d\u7684\u5355\u5143\u6765\u964d\u4f4e\u8bbe\u8ba1\u7684\u590d\u6742\u6027\u3002</p> <p></p> <p>The critical path through a  k \u00d7  k  array multiplier, when the sum generation logic of an FA block has a longer delay than the carry-generation circuit, goes through the main (top left to bottom rigt) diagonal in Fig. 11.13 and proceeds horizontally in the last row to the  p 9 output. The overall delay of the array multiplier can thus be reduced by rearranging the FA inputs such that some of the sum signals skip rows (they go from row  i  to row  i +  h  for some  h &gt;  1). Figure 11.13 shows the modified connections on the main diagonal for  h = 2. The lower right cell now has one too many inputs, but we can redirect one of them to the second cell on the main diagonal, which now has one free input. Note, however, that such skipping of levels makes for a less regular layout, which also requires longer wires, and hence may not be a worthwhile modification in practice. </p> <p>\u5f53 FA \u6a21\u5757\u7684\u6c42\u548c\u751f\u6210\u903b\u8f91\u6bd4\u8fdb\u4f4d\u751f\u6210\u7535\u8def\u5177\u6709\u66f4\u957f\u7684\u5ef6\u8fdf\u65f6\uff0c\u901a\u8fc7 \\(k \u00d7 k\\) \u9635\u5217\u4e58\u6cd5\u5668\u7684\u5173\u952e\u8def\u5f84\u4f1a\u7a7f\u8fc7\u56fe 11.13 \u4e2d\u7684\u4e3b\u5bf9\u89d2\u7ebf\uff08\u4ece\u5de6\u4e0a\u5230\u53f3\u4e0b\uff09\uff0c\u5e76\u5728\u6700\u540e\u4e00\u884c\u4e2d\u6c34\u5e73\u524d\u8fdb\u5230 \\(p_9\\) \u8f93\u51fa\u3002\u56e0\u6b64\uff0c\u53ef\u4ee5\u901a\u8fc7\u91cd\u65b0\u6392\u5217 FA \u8f93\u5165\u6765\u51cf\u5c11\u9635\u5217\u4e58\u6cd5\u5668\u7684\u6574\u4f53\u5ef6\u8fdf\uff0c\u4f7f\u5f97\u4e00\u4e9b\u548c\u4fe1\u53f7\u8df3\u8fc7\u884c\uff08\u5bf9\u4e8e\u67d0\u4e9b \\(h &gt; 1\\)\uff0c\u5b83\u4eec\u4ece\u884c \\(i\\) \u5230\u884c \\(i + h\\)\uff09\u3002\u56fe 11.13 \u663e\u793a\u4e86 \\(h = 2\\) \u65f6\u4e3b\u5bf9\u89d2\u7ebf\u4e0a\u7684\u4fee\u6539\u540e\u7684\u8fde\u63a5\u3002\u53f3\u4e0b\u89d2\u5355\u5143\u73b0\u5728\u6709\u592a\u591a\u8f93\u5165\uff0c\u4f46\u6211\u4eec\u53ef\u4ee5\u5c06\u5176\u4e2d\u4e4b\u4e00\u91cd\u5b9a\u5411\u5230\u4e3b\u5bf9\u89d2\u7ebf\u4e0a\u7684\u7b2c\u4e8c\u4e2a\u5355\u5143\uff0c\u8be5\u5355\u5143\u73b0\u5728\u6709\u4e00\u4e2a\u7a7a\u95f2\u8f93\u5165\u3002\u4f46\u8bf7\u6ce8\u610f\uff0c\u8fd9\u79cd\u7ea7\u522b\u7684\u8df3\u8fc7\u4f1a\u5bfc\u81f4\u5e03\u5c40\u4e0d\u592a\u89c4\u5219\uff0c\u8fd9\u4e5f\u9700\u8981\u66f4\u957f\u7684\u7535\u7ebf\uff0c\u56e0\u6b64\u5728\u5b9e\u8df5\u4e2d\u53ef\u80fd\u4e0d\u662f\u503c\u5f97\u8fdb\u884c\u7684\u4fee\u6539\u3002</p> <p>Since almost half the latency of an array multiplier is due to the cells in the last row, it is interesting to speculate about whether we can do the final addition faster. Obviously, it is possible to replace the last row of cells with a fast adder, but this would adversely affect the regularity of the design. Besides, even a fast adder is still much slower than the other rows, making pipelining more difficult. </p> <p>\u7531\u4e8e\u9635\u5217\u4e58\u6cd5\u5668\u7684\u5ef6\u8fdf\u51e0\u4e4e\u6709\u4e00\u534a\u662f\u7531\u6700\u540e\u4e00\u884c\u4e2d\u7684\u5355\u5143\u5f15\u8d77\u7684\uff0c\u56e0\u6b64\u63a8\u6d4b\u6211\u4eec\u662f\u5426\u53ef\u4ee5\u66f4\u5feb\u5730\u8fdb\u884c\u6700\u7ec8\u52a0\u6cd5\u662f\u5f88\u6709\u8da3\u7684\u3002\u663e\u7136\uff0c\u53ef\u4ee5\u7528\u5feb\u901f\u52a0\u6cd5\u5668\u66ff\u6362\u6700\u540e\u4e00\u884c\u5355\u5143\u683c\uff0c\u4f46\u8fd9\u4f1a\u4ea7\u751f\u5f71\u54cd\u8bbe\u8ba1\u89c4\u5f8b\u6027\u7684\u4e0d\u5229\u5f71\u54cd\u3002\u6b64\u5916\uff0c\u5373\u4f7f\u662f\u5feb\u901f\u52a0\u6cd5\u5668\u4ecd\u7136\u6bd4\u5176\u4ed6\u884c\u6162\u5f97\u591a\uff0c\u8fd9\u4f7f\u5f97\u6d41\u6c34\u7ebf\u66f4\u52a0\u56f0\u96be\u3002</p> <p>To see how the ripple-carry portion of an array multiplier can be eliminated, let us arrange the  \\(k^2\\) terms  \\(a_jx_i\\)  in a triangle, with bits distributed in \\(2 k \u2212 1\\) columns according to the pattern</p> <p>\u4e3a\u4e86\u4e86\u89e3\u5982\u4f55\u6d88\u9664\u9635\u5217\u4e58\u6cd5\u5668\u7684\u7eb9\u6ce2\u8fdb\u4f4d\u90e8\u5206\uff0c\u8ba9\u6211\u4eec\u5c06 \\(k^2\\) \u9879 \\(a_jx_i\\) \u6392\u5217\u5728\u4e00\u4e2a\u4e09\u89d2\u5f62\u4e2d\uff0c\u6839\u636e\u6a21\u5f0f\u5c06\u4f4d\u5206\u5e03\u5728 \\(2 k \u2212 1\\) \u5217\u4e2d</p> <p>\u200b          <code>1  2  3   \u00b7 \u00b7 \u00b7   k\u22121   k    k\u22121    \u00b7 \u00b7 \u00b7    3  2  1</code></p> <p></p> <p>The least-significant bit of the product is output directly, and the other bits are reduced gradually by rows of FAs and HAs (rectangular boxes in Fig. 11.15). Let us focus on the i th level and assume that the first i \u2212 1 levels have already yielded two versions of the final product bits past the Bi boundary, one assuming that the next carry-save addition will produce a carry across Bi and another assuming no carry (Fig. 11.16).</p> <p>\u4e58\u79ef\u7684\u6700\u4f4e\u6709\u6548\u4f4d\u76f4\u63a5\u8f93\u51fa\uff0c\u5176\u4ed6\u4f4d\u6309FA\u548cHA\u7684\u884c\u9010\u6e10\u51cf\u5c11\uff08\u56fe11.15\u4e2d\u7684\u77e9\u5f62\u6846\uff09\u3002\u8ba9\u6211\u4eec\u5173\u6ce8\u7b2c \\(i\\) \u4e2a\u7ea7\u522b\uff0c\u5e76\u5047\u8bbe\u524d \\(i\u22121\\) \u4e2a\u7ea7\u522b\u5df2\u7ecf\u4ea7\u751f\u4e86\u8d85\u8fc7 \\(B_i\\) \u8fb9\u754c\u7684\u6700\u7ec8\u4e58\u79ef\u4f4d\u7684\u4e24\u4e2a\u7248\u672c\uff0c\u4e00\u4e2a\u5047\u8bbe\u4e0b\u4e00\u4e2a\u8fdb\u4f4d\u4fdd\u5b58\u52a0\u6cd5\u5c06\u4ea7\u751f\u8de8 \\(B_i\\) \u7684\u8fdb\u4f4d\uff0c\u53e6\u4e00\u4e2a\u5047\u8bbe\u6ca1\u6709\u8fdb\u4f4d\uff08\u56fe 11.16\uff09\u3002</p> <p></p> <p>At the i th level, the shaded block in Fig. 11.15 produces two versions of its sum and carry, conditional upon a future carry or no carry across Bi+1. The conditional sum bits from the shaded block are simply appended to the i bits coming from above. So, two versions of the upper i + 1 bits of the product are obtained, conditional upon the future carry across the Bi+1 boundary. The process is then repeated in the lower levels, with each level extending the length of the conditional portion by 1 bit and the lowermost multiplexer (mux) providing the last k bits of the end product in nonredundant form.</p> <p>\u5728\u7b2c \\(i\\) \u5c42\uff0c\u56fe 11.15 \u4e2d\u7684\u9634\u5f71\u5757\u4ea7\u751f\u5176\u548c\u548c\u8fdb\u4f4d\u7684\u4e24\u4e2a\u7248\u672c\uff0c\u6761\u4ef6\u662f \\(B_{i+1}\\) \u4e0a\u672a\u6765\u8fdb\u4f4d\u6216\u65e0\u8fdb\u4f4d\u3002\u6765\u81ea\u9634\u5f71\u5757\u7684\u6761\u4ef6\u548c\u4f4d\u7b80\u5355\u5730\u9644\u52a0\u5230\u6765\u81ea\u4e0a\u9762\u7684 \\(i\\) \u4f4d\u3002\u56e0\u6b64\uff0c\u6839\u636e\u672a\u6765\u8de8\u8d8a \\(B_{i+1}\\) \u8fb9\u754c\u7684\u8fdb\u4f4d\uff0c\u83b7\u5f97\u4e58\u79ef\u7684\u9ad8 \\(i+1\\) \u4f4d\u7684\u4e24\u4e2a\u7248\u672c\u3002\u7136\u540e\u5728\u8f83\u4f4e\u7ea7\u522b\u91cd\u590d\u8be5\u8fc7\u7a0b\uff0c\u6bcf\u4e2a\u7ea7\u522b\u5c06\u6761\u4ef6\u90e8\u5206\u7684\u957f\u5ea6\u6269\u5c55 1 \u4f4d\uff0c\u5e76\u4e14\u6700\u4e0b\u9762\u7684\u591a\u8def\u590d\u7528\u5668 (mux) \u4ee5\u975e\u5197\u4f59\u5f62\u5f0f\u63d0\u4f9b\u7ed3\u679c\u4e58\u79ef\u7684\u6700\u540e k \u4f4d\u3002</p> <p>The conceptual design of Fig. 11.15 can be translated to an actual multiplier circuit after certain optimizations to remove redundant elements [Cimi96], [Erce90].</p> <p>\u7ecf\u8fc7\u67d0\u4e9b\u4f18\u5316\u4ee5\u5220\u9664\u5197\u4f59\u5143\u7d20\u540e\uff0c\u56fe 11.15 \u7684\u6982\u5ff5\u8bbe\u8ba1\u53ef\u4ee5\u8f6c\u5316\u4e3a\u5b9e\u9645\u7684\u4e58\u6cd5\u5668\u7535\u8def [Cimi96]\u3001[Erce90]\u3002</p>"},{"location":"Part_03/11/#116","title":"11.6 \u6d41\u6c34\u5316\u4e58\u6cd5\u5668\u4e0e\u9635\u5217\u4e58\u6cd5\u5668","text":"<p>A full-tree multiplier can be easily pipelined. The partial products reduction tree of a full-tree multiplier is a combinational circuit that can be sliced into pipeline stages. A new set of inputs cannot be applied to the partial-tree multiplier of Fig. 11.9, however, until the sum and carry for the preceding set have been latched. Given that for large h, the depth of the tree can be significant, the rate of the application of inputs to the tree, and thus the speed of the multiplier, is limited.</p> <p>\u5168\u6811\u4e58\u6cd5\u5668\u53ef\u4ee5\u8f7b\u677e\u5730\u6d41\u6c34\u7ebf\u5316\u3002\u5168\u6811\u4e58\u6cd5\u5668\u7684\u90e8\u5206\u79ef\u5f52\u7ea6\u6811\u662f\u4e00\u4e2a\u53ef\u4ee5\u5206\u5272\u6210\u6d41\u6c34\u7ebf\u7ea7\u7684\u7ec4\u5408\u7535\u8def\u3002\u7136\u800c\uff0c\u5728\u524d\u4e00\u7ec4\u8f93\u5165\u7684\u548c\u548c\u8fdb\u4f4d\u88ab\u9501\u5b58\u4e4b\u524d\uff0c\u4e00\u7ec4\u65b0\u7684\u8f93\u5165\u4e0d\u80fd\u5e94\u7528\u4e8e\u56fe 11.9 \u7684\u90e8\u5206\u6811\u4e58\u6cd5\u5668\u3002\u8003\u8651\u5230\u5bf9\u4e8e\u8f83\u5927\u7684 h\uff0c\u6811\u7684\u6df1\u5ea6\u53ef\u80fd\u5f88\u5927\uff0c\u56e0\u6b64\u6811\u7684\u8f93\u5165\u5e94\u7528\u7387\u4ee5\u53ca\u4e58\u6cd5\u5668\u7684\u901f\u5ea6\u53d7\u5230\u9650\u5236\u3002</p> <p>Now, if instead of feeding back the tree outputs to its inputs, we feed them back into the middle of the ( h + 2)-input tree, as shown in Fig. 11.17, the pipeline rate will be dictated by the delay through only two CSA levels rather than by the depth of the entire tree. This leads to much faster multiplication.</p> <p>\u73b0\u5728\uff0c\u5982\u679c\u6211\u4eec\u4e0d\u5c06\u6811\u8f93\u51fa\u53cd\u9988\u5230\u5176\u8f93\u5165\uff0c\u800c\u662f\u5c06\u5b83\u4eec\u53cd\u9988\u5230 \\((h + 2)\\) \u8f93\u5165\u6811\u7684\u4e2d\u95f4\uff0c\u5982\u56fe 11.17 \u6240\u793a\uff0c\u5219\u7ba1\u9053\u901f\u7387\u5c06\u7531\u4ec5\u901a\u8fc7\u4e24\u4e2a CSA \u7ea7\u522b\u7684\u5ef6\u8fdf\u51b3\u5b9a\uff0c\u800c\u4e0d\u662f\u7531\u6574\u4e2a\u6811\u7684\u6df1\u5ea6\u51b3\u5b9a\u3002\u8fd9\u5bfc\u81f4\u4e58\u6cd5\u901f\u5ea6\u66f4\u5feb\u3002</p> <p></p> <p>Figure 11.18 shows one way to pipeline an array multiplier. Inputs are applied from above and the product emerges from below after 9 clock cycles (2 k \u2212 1 in general). All FA blocks used are assumed to have output latches for both sum and carry. Note how the xi inputs needed for the various rows of the array multiplier are delayed through the insertion of latches in their paths and how the 4-bit ripple-carry adder at the bottom row of Fig. 11.14 has been pipelined in Fig. 11.18.</p> <p>\u56fe 11.18 \u663e\u793a\u4e86\u4e00\u79cd\u6d41\u6c34\u7ebf\u6570\u7ec4\u4e58\u6cd5\u5668\u7684\u65b9\u6cd5\u3002\u8f93\u5165\u4ece\u4e0a\u65b9\u5e94\u7528\uff0c\u4e58\u79ef\u5728 9 \u4e2a\u65f6\u949f\u5468\u671f\uff08\u4e00\u822c\u4e3a \\(2 k \u2212 1\\)\uff09\u540e\u4ece\u4e0b\u65b9\u51fa\u73b0\u3002\u5047\u5b9a\u4f7f\u7528\u7684\u6240\u6709 FA \u5757\u90fd\u5177\u6709\u7528\u4e8e\u6c42\u548c\u548c\u8fdb\u4f4d\u7684\u8f93\u51fa\u9501\u5b58\u5668\u3002\u8bf7\u6ce8\u610f\u9635\u5217\u4e58\u6cd5\u5668\u5404\u884c\u6240\u9700\u7684 \\(x_i\\) \u8f93\u5165\u5982\u4f55\u901a\u8fc7\u5728\u5176\u8def\u5f84\u4e2d\u63d2\u5165\u9501\u5b58\u5668\u6765\u5ef6\u8fdf\uff0c\u4ee5\u53ca\u56fe 11.14 \u5e95\u884c\u7684 4 \u4f4d\u7eb9\u6ce2\u8fdb\u4f4d\u52a0\u6cd5\u5668\u5982\u4f55\u5728\u56fe 11.18 \u4e2d\u8fdb\u884c\u6d41\u6c34\u7ebf\u5904\u7406\u3002</p> <p></p>"},{"location":"Part_03/11/#_1","title":"\u95ee\u9898\uff08\u7565\uff09","text":""},{"location":"Part_03/11/#_2","title":"\u53c2\u8003\u6587\u732e\u548c\u8fdb\u4e00\u6b65\u9605\u8bfb","text":"<pre><code>[Baug73] Baugh, C. R., and B. A. Wooley, \u201cA Two\u2019s Complement Parallel Array Multiplication\n         Algorithm,\u201d IEEE Trans. Computers, Vol. 22, pp. 1045\u20131047, 1973.\n[Bewi94] Bewick, G. W., \u201cFast Multiplication: Algorithms and Implementation,\u201d PhD\n         dissertation, Stanford University, 1994.\n[Blan74] Blankenship, P. E., \u201cComments on \u2018A Two\u2019s Complement Parallel Array\n         Multiplication Algorithm,\u2019\u201d IEEE Trans. Computers, Vol. 23, p. 1327, 1974.\n[Cimi96] Ciminiera, L., and P. Montuschi, \u201cCarry-Save Multiplication Schemes Without Final\n         Addition,\u201d IEEE Trans. Computers, Vol. 45, No. 9, pp. 1050\u20131055, 1996.\n[Dadd65] Dadda, L., \u201cSome Schemes for Parallel Multipliers,\u201d Alta Frequenza, Vol. 34,\n         pp. 349\u2013356, 1965.\n[Erce90] Ercegovac, M. D., and T. Lang, \u201cFast Multiplication Without Carry-Propagate\n         Addition,\u201d IEEE Trans. Computers, Vol. 39, No. 11, pp. 1385\u20131390, 1990.\n[Gok06]  Gok, M., M. J. Schulte, and M. G. Arnold, \u201cInteger Multipliers with Overflow\n         Detection,\u201d IEEE Trans. Computers, Vol. 55, No. 8, pp. 1062\u20131066, 2006.\n[Mou92]  Mou, Z.-J., and F. Jutand, \u201c \u2018Overturned-Stairs\u2019Adder Trees and Multiplier Design,\u201d\n         IEEE Trans. Computers, Vol. 41, No. 8, pp. 940\u2013948, 1992.\n[Parh96] Parhami, B., \u201cComments on \u2018High-Speed Area-Efficient Multiplier Design Using\n         Multiple-Valued Current Mode Circuits,\u2019\u201d IEEE Trans. Computers, Vol. 45, No. 5,\n         pp. 637\u2013638, 1996.\n[Peza71] Pezaris, S. D., \u201cA 40-ns 17-Bit by 17-Bit Array Multiplier,\u201d IEEE Trans. Computers,\n         Vol. 20, pp. 442\u2013447, 1971.\n[Robi98] Robinson, M. E., and E. Swartzlander Jr., \u201cA Reduction Scheme to Optimize the\n         Wallace Multiplier,\u201d Proc. Int\u2019l Conf. Computer Design, pp. 122\u2013127, 1998.\n[Schu93] Schulte, M. J., and E. E. Swartzlander, Jr., \u201cTruncated Multiplication with Correction\n         Constant,\u201d in VLSI Signal Processing VI, pp. 388\u2013396, 1993.\n[Swar99] Swartzlander, E. E., \u201cTruncated Multiplication with Approximate Rounding,\u201d Proc.\n         33rd Asilomar Conf. Signals Systems and Computers, pp. 1480\u20131483, 1999.\n[Taka85] Takagi, N., H. Yasuura, and S. Yajima, \u201cHigh-Speed VLSI Multiplication Algorithm\n         with a Redundant Binary Addition Tree,\u201d IEEE Trans. Computers, Vol. 34, No. 9,\n         pp. 789\u2013796, 1985.\n[Town03] Townsend, W. J., E. E. Swartzlander, and J. A. Abraham, \u201cA Comparison of Dadda\n         and Wallace Multiplier Delays,\u201d Proc. SPIE Conf. Advanced Signal Processing:\n         Algorithms, Architectures, and Implementations, pp. 552\u2013560, 2003.\n[Vill93] Villager, D., and V. G. Oklobdzija, \u201cAnalysis of Booth Encoding Efficiency in Parallel\n         Multipliers Using Compressors for Reduction of Partial Products,\u201d Proc. Asilomar\n         Conf. Signals, Systems, and Computers, pp. 781\u2013784, 1993.\n[Vuil83] Vuillemin, J., \u201cA Very Fast Multiplication Algorithm for VLSI Implementation,\u201d\n         Integration: The VLSI Journal, Vol. 1, pp. 39\u201352, 1983.\n[Wall64] Wallace, C. S., \u201cA Suggestion for a Fast Multiplier,\u201d IEEE Trans. Electronic\n         Computers, Vol. 13, pp. 14\u201317, 1964.\n[Zura86] Zuras, D., and W. H. McAllister, \u201cBalanced Delay Trees and Combinatorial Division\n         in VLSI,\u201d IEEE J. Solid-State Circuits, Vol. 21, pp. 814\u2013819, 1986.\n</code></pre>"},{"location":"Part_03/12/","title":"12. \u5176\u5b83\u4e58\u6cd5\u5668","text":"<p>Variations in Multipliers</p> <p>\u201cIf it\u2019s zero degrees outside today and it\u2019s supposed to be twice as cold tomorrow, how cold is it going to be?\u201d STEPHEN WRIGHT</p> <p>\u201c\u5982\u679c\u4eca\u5929\u5916\u9762\u7684\u6c14\u6e29\u4e3a\u96f6\u5ea6\uff0c\u660e\u5929\u7684\u6e29\u5ea6\u5e94\u8be5\u662f\u539f\u6765\u7684\u4e24\u500d\uff0c\u90a3\u4e48\u4f1a\u6709\u591a\u51b7\uff1f\u201d \u65af\u8482\u82ac\u00b7\u8d56\u7279</p> <p>We do not always synthesize our multipliers from scratch but may desire, or be required, to use building blocks such as adders, small multipliers, or lookup tables. Furthermore, limited chip area and/or pin availability may dictate the use of bit-serial designs. In this chapter, we discuss such variations and also deal with modular multipliers,the special case of squaring,and multiply-accumulators. Chapter topics include:</p> <p>\u6211\u4eec\u5e76\u4e0d\u603b\u662f\u4ece\u5934\u5f00\u59cb\u5408\u6210\u4e58\u6cd5\u5668\uff0c\u4f46\u53ef\u80fd\u5e0c\u671b\u6216\u88ab\u8981\u6c42\u4f7f\u7528\u52a0\u6cd5\u5668\u3001\u5c0f\u578b\u4e58\u6cd5\u5668\u6216\u67e5\u627e\u8868\u7b49\u6784\u5efa\u5757\u3002 \u6b64\u5916\uff0c\u6709\u9650\u7684\u82af\u7247\u9762\u79ef\u548c/\u6216\u5f15\u811a\u53ef\u7528\u6027\u53ef\u80fd\u51b3\u5b9a\u4f7f\u7528\u4f4d\u4e32\u884c\u8bbe\u8ba1\u3002 \u5728\u672c\u7ae0\u4e2d\uff0c\u6211\u4eec\u8ba8\u8bba\u8fd9\u4e9b\u53d8\u5316\uff0c\u5e76\u8ba8\u8bba\u6a21\u4e58\u6cd5\u5668\u3001\u5e73\u65b9\u7684\u7279\u6b8a\u60c5\u51b5\u548c\u4e58\u6cd5\u7d2f\u52a0\u5668\u3002 \u7ae0\u8282\u4e3b\u9898\u5305\u62ec\uff1a</p> <ul> <li>12.1 \u5206\u6cbb\u7b97\u6cd5 DIVIDE AND CONQUER DESIGNS</li> <li>12.2 \u4e58\u52a0\u6a21\u5757 ADDITIVE MULTIPLY MODULES</li> <li>12.3 \u4f4d\u4e32\u884c\u4e58\u6cd5\u5668 BIT-SERIAL MULTIPLIERS</li> <li>12.4 \u6a21\u4e58\u6cd5\u5668 MODUL AR MULTIPLIERS</li> <li>12.5 \u5e73\u65b9\u8fd0\u7b97\u5668 THE SPECIAL CASE OF SQUARING</li> <li>12.6 \u4e58\u52a0\u6df7\u5408\u5355\u5143 COMBINED MULTIPLY-ADD UNITS</li> </ul>"},{"location":"Part_03/12/#121","title":"12.1 \u5206\u6cbb\u7b97\u6cd5","text":"<p>Suppose you have b \u00d7 b multipliers and would like to use them to synthesize a 2 b \u00d7 2 b multiplier. Denoting the high and low halves of the multiplicand (multiplier) by a H and a L (x H and x L), we can use four b \u00d7 b multipliers to compute the four partial products a L x L, a L x H, a H x L, and a H x H as shown in Fig. 12.1a. These four values must then be added to obtain the final product. Actually, as shown in Fig. 12.1b, only three values need to be added, since the nonoverlapping partial products a H x H and a L x L can be viewed as a single 4 b-bit number.</p> <p>\u5047\u8bbe\u60a8\u6709 \\(b \u00d7 b\\) \u4e58\u6cd5\u5668\uff0c\u5e76\u60f3\u7528\u5b83\u4eec\u5408\u6210 \\(2 b \u00d7 2 b\\) \u4e58\u6cd5\u5668\u3002\u7528\\(a_H\\)\u548c\\(a_L\\)\uff08\\(x_H\\)\u548c\\(x_L\\)\uff09\u8868\u793a\u88ab\u4e58\u6570\uff08\u4e58\u6570\uff09\u7684\u9ad8\u534a\u90e8\u5206\u548c\u4f4e\u534a\u90e8\u5206\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u56db\u4e2a\\(b \u00d7 b\\)\u4e58\u6570\u6765\u8ba1\u7b97\u56db\u4e2a\u90e8\u5206\u79ef\\(a_L x_L\\)\uff0c\\(a_L x_H\\)\uff0c\\(a_H x_L\\)\u548c\\(a_H x_H\\)\uff0c\u5982\u56fe12.1a\u6240\u793a\u3002\u7136\u540e\u5fc5\u987b\u5c06\u8fd9\u56db\u4e2a\u503c\u76f8\u52a0\u4ee5\u83b7\u5f97\u6700\u7ec8\u4e58\u79ef\u3002\u5b9e\u9645\u4e0a\uff0c\u5982\u56fe 12.1b \u6240\u793a\uff0c\u53ea\u9700\u8981\u52a0\u4e09\u4e2a\u503c\uff0c\u56e0\u4e3a\u4e0d\u91cd\u53e0\u7684\u90e8\u5206\u79ef \\(a_H x_H\\) \u548c \\(a_L x_L\\) \u53ef\u4ee5\u88ab\u89c6\u4e3a\u5355\u4e2a \\(4 b\\) \u4f4d\u6570\u5b57\u3002</p> <p></p> <p>We see that our original 2 b \u00d7 2 b  multiplication problem has been reduced to four b \u00d7  b  multiplications and a three-operand addition problem. The  b \u00d7  b  multiplications can be performed by smaller hardware multipliers or via table lookup. Then, we can compute the 4 b-bit product by means of a single level of carry-save addition, followed by a 3 b-bit carry-propagate addition. Note that  b  bits of the product are directly available following the  b \u00d7  b  multiplications. </p> <p>\u6211\u4eec\u770b\u5230\u539f\u6765\u7684 \\(2 b \u00d7 2 b\\) \u4e58\u6cd5\u95ee\u9898\u5df2\u7b80\u5316\u4e3a\u56db\u4e2a \\(b \u00d7 b\\) \u4e58\u6cd5\u548c\u4e00\u4e2a\u4e09\u64cd\u4f5c\u6570\u52a0\u6cd5\u95ee\u9898\u3002 \\(b \u00d7 b\\) \u4e58\u6cd5\u53ef\u4ee5\u901a\u8fc7\u8f83\u5c0f\u7684\u786c\u4ef6\u4e58\u6cd5\u5668\u6216\u901a\u8fc7\u67e5\u8868\u6765\u6267\u884c\u3002\u7136\u540e\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u5355\u7ea7\u8fdb\u4f4d\u4fdd\u5b58\u52a0\u6cd5\uff0c\u7136\u540e\u662f \\(3 b\\) \u4f4d\u8fdb\u4f4d\u4f20\u64ad\u52a0\u6cd5\u6765\u8ba1\u7b97 \\(4 b\\) \u4f4d\u4e58\u79ef\u3002\u8bf7\u6ce8\u610f\uff0c\u5728 \\(b \u00d7 b\\) \u4e58\u6cd5\u4e4b\u540e\uff0c\u4e58\u79ef\u7684 \\(b\\) \u4f4d\u53ef\u76f4\u63a5\u83b7\u5f97\u3002</p> <p>Larger multipliers, such as 3 b \u00d7 3 b  or 4 b \u00d7 4 b, can be similarly synthesized from b \u00d7  b  multiplier building blocks. Figure 12.2 shows that 3 b \u00d7 3 b  multiplication leads to five numbers, while 4 b \u00d7 4 b  multiplication produces seven numbers. Hence, we can complete the multiplication process in these two cases by using a row of (5; 2)- or (7; 2)-counters, followed by a 5 b- or 7 b-bit fast adder, respectively. Note that  b  bits of the product are obtained directly from a small multiplier in each case. </p> <p>\u66f4\u5927\u7684\u4e58\u6cd5\u5668\uff0c\u4f8b\u5982 \\(3 b \u00d7 3 b\\) \u6216 \\(4 b \u00d7 4 b\\)\uff0c\u53ef\u4ee5\u7c7b\u4f3c\u5730\u4ece \\(b \u00d7 b\\) \u4e58\u6cd5\u5668\u6784\u5efa\u5757\u5408\u6210\u3002\u56fe 12.2 \u663e\u793a \\(3 b \u00d7 3 b\\) \u4e58\u6cd5\u4ea7\u751f 5 \u4e2a\u6570\u5b57\uff0c\u800c \\(4 b \u00d7 4 b\\) \u4e58\u6cd5\u4ea7\u751f 7 \u4e2a\u6570\u5b57\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528\u4e00\u884c \\((5; 2)\\) \u6216 \\((7; 2)\\) \u8ba1\u6570\u5668\uff0c\u7136\u540e\u5206\u522b\u8ddf\u968f\u4e00\u4e2a \\(5 b\\) \u4f4d\u6216 \\(7 b\\) \u4f4d\u5feb\u901f\u52a0\u6cd5\u5668\u6765\u5b8c\u6210\u8fd9\u4e24\u79cd\u60c5\u51b5\u4e0b\u7684\u4e58\u6cd5\u8fc7\u7a0b\u3002\u8bf7\u6ce8\u610f\uff0c\u5728\u6bcf\u79cd\u60c5\u51b5\u4e0b\uff0c\u4e58\u79ef\u7684 b \u4f4d\u90fd\u662f\u76f4\u63a5\u4ece\u5c0f\u4e58\u6cd5\u5668\u83b7\u5f97\u7684\u3002</p> <p></p> <p>For example, given 4 \u00d7 4 multipliers as building blocks, we can synthesize a 16 \u00d7 16multiplier using 16 of the small multipliers, along with 24 (7; 2)-counters and a 28-bit fast adder. The structure of a 32 \u00d7 32 multiplier built of 8 \u00d7 8-multiplier building blocks is identical to the one just discussed. </p> <p>\u4f8b\u5982\uff0c\u7ed9\u5b9a 4 \u00d7 4 \u4e58\u6cd5\u5668\u4f5c\u4e3a\u6784\u5efa\u5757\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 16 \u4e2a\u5c0f\u578b\u4e58\u6cd5\u5668\uff0c\u4ee5\u53ca 24 \u4e2a (7; 2) \u8ba1\u6570\u5668\u548c\u4e00\u4e2a 28 \u4f4d\u5feb\u901f\u52a0\u6cd5\u5668, \u5408\u6210\u4e00\u4e2a 16 \u00d7 16 \u4e58\u6cd5\u5668\u3002\u7531 8 \u00d7 8 \u4e58\u6cd5\u5668\u6784\u5efa\u5757\u6784\u5efa\u7684 32 \u00d7 32 \u4e58\u6cd5\u5668\u7684\u7ed3\u6784\u4e0e\u521a\u624d\u8ba8\u8bba\u7684\u7ed3\u6784\u76f8\u540c\u3002</p> <p>One can view the preceding divide-and-conquer scheme, depicted in Figs. 12.1 and 12.2, as radix-2 b  multiplication, except that each radix-2 b  digit of the multiplier produces several partial products, one for each radix-2 b  digit of the multiplicand, instead just one. </p> <p>\u4eba\u4eec\u53ef\u4ee5\u67e5\u770b\u524d\u9762\u7684\u5206\u800c\u6cbb\u4e4b\u65b9\u6848\uff0c\u5982\u56fe 12.1 \u548c 12.2 \u6240\u793a\u3002 \u4f5c\u4e3a\u57fa \\(2^b\\) \u4e58\u6cd5\uff0c\u4e0d\u540c\u4e4b\u5904\u5728\u4e8e\u4e58\u6570\u7684\u6bcf\u4e2a\u57fa \\(2^b\\) \u6570\u5b57\u4ea7\u751f\u591a\u4e2a\u90e8\u5206\u4e58\u79ef\uff0c\u88ab\u4e58\u6570\u7684\u6bcf\u4e2a\u57fa \\(2^b\\) \u6570\u5b57\u4ea7\u751f\u4e00\u4e2a\u90e8\u5206\u79ef\uff0c\u800c\u4e0d\u662f\u4ec5\u4ea7\u751f\u4e00\u4e2a\u3002</p> <p>For 2 b \u00d7 2 b  multiplication, one can use  b-bit adders exclusively to accumulate the partial products, as shown in Fig. 12.3 for  b = 4. The pair [ i,  j] of numbers shown next to a solid line in Fig. 12.3 indicates that the 4-bit bundle of wires represented by that line spans bit positions i through j. A gray line represents 1 bit, with its positions given by a single integer. We need five b-bit adder blocks, arranged in a circuit of depth 4, to perform the accumulation. This is attractive if b-bit adders are available as economical, off-the-shelf components. The resulting design is not much slower than the design based on carry-save adder (CSA) reduction if the latter design uses a cascade of three b-bit adders for the final 3 b-bit addition.</p> <p>\u5bf9\u4e8e \\(2 b \u00d7 2 b\\) \u4e58\u6cd5\uff0c\u53ef\u4ee5\u4e13\u95e8\u4f7f\u7528 b \u4f4d\u52a0\u6cd5\u5668\u6765\u7d2f\u52a0\u90e8\u5206\u79ef\uff0c\u5982\u56fe 12.3\uff08b = 4\uff09\u6240\u793a\u3002\u63a5\u4e0b\u6765\u56fe 12.3 \u4e2d\u7684\u5b9e\u7ebf\u663e\u793a\u7684\u6570\u5b57\u5bf9 \\([ i, j]\\) \u8868\u793a\u8be5\u7ebf\u4ee3\u8868\u7684 4 \u4f4d\u7ebf\u675f\u8de8\u8d8a\u4f4d\u4f4d\u7f6e \\(i\\) \u5230 \\(j\\)\u3002\u7070\u7ebf\u4ee3\u8868 1 \u6bd4\u7279\u4f4d\uff0c\u5176\u4f4d\u7f6e\u7531\u5355\u4e2a\u6574\u6570\u7ed9\u51fa\u3002\u6211\u4eec\u9700\u8981\u4e94\u4e2a b \u4f4d\u52a0\u6cd5\u5668\u5757\uff0c\u6392\u5217\u5728\u6df1\u5ea6 4 \u7684\u7535\u8def\u4e2d\u6765\u6267\u884c\u7d2f\u52a0\u3002\u5982\u679c b \u4f4d\u52a0\u6cd5\u5668\u53ef\u4f5c\u4e3a\u7ecf\u6d4e\u7684\u3001\u73b0\u6210\u7684\u7ec4\u4ef6\uff0c\u90a3\u4e48\u8fd9\u5c06\u662f\u5f88\u6709\u5438\u5f15\u529b\u7684\u3002\u5982\u679c\u57fa\u4e8e\u8fdb\u4f4d\u4fdd\u5b58\u52a0\u6cd5\u5668 (CSA) \u7f29\u51cf\u7684\u8bbe\u8ba1\u4f7f\u7528\u7ea7\u8054\u7684\u4e09\u4e2a b \u4f4d\u52a0\u6cd5\u5668\u8fdb\u884c\u6700\u7ec8\u7684 3 b \u4f4d\u52a0\u6cd5\uff0c\u5219\u6240\u5f97\u8bbe\u8ba1\u4e0d\u4f1a\u6162\u5f88\u591a\u3002</p> <p></p> <p>Instead of b \u00d7 b multipliers, one can use b \u00d7 c multipliers. For example, with 8 \u00d7 4 multipliers as building blocks, a 16 \u00d7 16 multiplier can be synthesized from eight such units, followed by a 5-to-2 reduction circuit and a 28-bit adder.</p> <p>\u53ef\u4ee5\u4f7f\u7528 \\(b \u00d7 c\\) \u4e58\u6cd5\u5668\u6765\u4ee3\u66ff \\(b \u00d7 b\\) \u4e58\u6cd5\u5668\u3002\u4f8b\u5982\uff0c8 \u00d7 4 \u4e58\u6cd5\u5668\u4f5c\u4e3a\u6784\u5efa\u5757\uff0c\u53ef\u4ee5\u7531\u516b\u4e2a\u8fd9\u6837\u7684\u5355\u5143\u5408\u6210\u4e00\u4e2a \\(16 \u00d7 16\\) \u4e58\u6cd5\u5668\uff0c\u540e\u9762\u662f\u4e00\u4e2a 5 \u6bd4 2 \u7f29\u51cf\u7535\u8def\u548c\u4e00\u4e2a 28 \u4f4d\u52a0\u6cd5\u5668\u3002</p> <p>Note that we can perform a double-width multiplication using only three single-width multiplications, as indicated by the following identity attributed to Karatsuba [Mont05]: </p> <p>\u8bf7\u6ce8\u610f\uff0c\u6211\u4eec\u53ef\u4ee5\u4ec5\u4f7f\u7528\u4e09\u4e2a\u5355\u5bbd\u4e58\u6cd5\u6765\u6267\u884c\u53cc\u5bbd\u4e58\u6cd5\uff0c\u5982 Karatsuba [Mont05] \u7684\u4ee5\u4e0b\u6052\u7b49\u5f0f\u6240\u793a\uff1a</p> \\[ (2^ba_H + a_L)(2^bx_H + x_L) = 2^{2 b}a_H x_H + 2^b[ (a_H + a_L)(x_H + x_L) \u2212 a_H x_H \u2212 a_L x_L] + a_L x_L \\] <p>By contrast, our four-multiplication scheme was based on the identity:</p> <p>\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u6211\u4eec\u7684\u56db\u4e58\u6cd5\u65b9\u6848\u57fa\u4e8e\u4ee5\u4e0b\u6052\u7b49\u5f0f\uff1a</p> <p>\u200b     \\((2^ba_H + a_L)(2^bx_H + x_L) = 2^{2 b}a_H x_H + 2^b[ a_H x_L + a_L x_H] + a_L x_L\\)</p> <p>The three single-width multiplications in Karatsuba\u2019s algorithm compute a H x H, a L x L, and ( a H + a L )(x H + x L). So, Karatsuba\u2019s modified multiplication method removes one multiplication and introduces three extra additions/subtractions. This constitutes a good tradeoff in the case of extremely wide numbers, when the method is applied recursively.</p> <p>Karatsuba \u7b97\u6cd5\u4e2d\u7684\u4e09\u4e2a\u5355\u5bbd\u5ea6\u4e58\u6cd5\u8ba1\u7b97 \\(a_Hx_H\\)\u3001\\(a_L  x_L\\) \u548c \\((a_H + a_L )(x_H + x_L)\\)\u3002\u56e0\u6b64\uff0cKaatsuba \u7684\u6539\u8fdb\u4e58\u6cd5\u65b9\u6cd5\u5220\u9664\u4e86\u4e00\u9879\u4e58\u6cd5\uff0c\u5e76\u5f15\u5165\u4e86\u4e09\u9879\u989d\u5916\u7684\u52a0\u6cd5/\u51cf\u6cd5\u3002\u5f53\u9012\u5f52\u5e94\u7528\u8be5\u65b9\u6cd5\u65f6\uff0c\u5728\u6781\u5bbd\u7684\u6570\u5b57\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd9\u6784\u6210\u4e86\u4e00\u4e2a\u5f88\u597d\u7684\u6743\u8861\u3002</p>"},{"location":"Part_03/12/#122","title":"12.2 \u4e58\u52a0\u6a21\u5757","text":"<p>We note from the discussion in Section 12.1, and Fig. 12.3 in particular, that synthesizing large multipliers from smaller ones requires both multiplier and adder units. If we can combine the multiplication and addition functions into one unit, then perhaps a single module type will suffice for implementing such multipliers. This is the idea behind additive multiply modules (AMMs).</p> <p>\u6211\u4eec\u4ece\u7b2c 12.1 \u8282\u7684\u8ba8\u8bba\u4e2d\u6ce8\u610f\u5230\uff0c\u7279\u522b\u662f\u56fe 12.3\uff0c\u4ece\u8f83\u5c0f\u7684\u4e58\u6cd5\u5668\u5408\u6210\u8f83\u5927\u7684\u4e58\u6cd5\u5668\u9700\u8981\u4e58\u6cd5\u5668\u548c\u52a0\u6cd5\u5668\u5355\u5143\u3002\u5982\u679c\u6211\u4eec\u53ef\u4ee5\u5c06\u4e58\u6cd5\u548c\u52a0\u6cd5\u51fd\u6570\u7ec4\u5408\u5230\u4e00\u4e2a\u5355\u5143\u4e2d\uff0c\u90a3\u4e48\u4e5f\u8bb8\u5355\u4e2a\u6a21\u5757\u7c7b\u578b\u5c31\u8db3\u4ee5\u5b9e\u73b0\u6b64\u7c7b\u4e58\u6cd5\u5668\u3002\u8fd9\u5c31\u662f\u52a0\u6cd5\u4e58\u6cd5\u6a21\u5757 (AMM) \u80cc\u540e\u7684\u60f3\u6cd5\u3002</p> <p></p> <p>The AMM in Fig. 12.4a, performs the computation p = ax + y + z, where a and y are 4-bit numbers and x and z are 2-bit numbers. The maximum value of the result p is ( 15 \u00d7 3 ) + 15 + 3 = 63, which can be represented with 6 bits. Figure 12.4b shows an implementation of this AMM using four full adders (FAs), depicted as boxes enclosing three dots, and a 4-bit adder.</p> <p>\u56fe 12.4a \u4e2d\u7684 AMM \u6267\u884c\u8ba1\u7b97 \\(p = ax + y + z\\)\uff0c\u5176\u4e2d a \u548c y \u662f 4 \u4f4d\u6570\u5b57\uff0cx \u548c z \u662f 2 \u4f4d\u6570\u5b57\u3002\u7ed3\u679cp\u7684\u6700\u5927\u503c\u4e3a(15\u00d73)+15+3=63\uff0c\u53ef\u4ee5\u75286\u4f4d\u6765\u8868\u793a\u3002\u56fe 12.4b \u663e\u793a\u4e86\u8be5 AMM \u7684\u5b9e\u73b0\uff0c\u8be5\u5b9e\u73b0\u4f7f\u7528\u56db\u4e2a\u5168\u52a0\u5668 (FA)\uff08\u63cf\u7ed8\u4e3a\u5305\u542b\u4e09\u4e2a\u70b9\u7684\u6846\uff09\u548c\u4e00\u4e2a 4 \u4f4d\u52a0\u6cd5\u5668\u3002</p> <p></p> <p>Figure 12.5 shows how the 8 \u00d7 8 multiplier example of Fig. 12.3 can be built from eight AMMs of the type depicted in Fig. 12.4. Note that eight 4 \u00d7 2 multipliers would have been needed for this design; so the number of modules is kept to a minimum. Each AMM is slower than a 4 \u00d7 2 multiplier by at most one FA level. So, the delay in Fig. 12.5 that is attributable to the addition function is no more than six FA delays (the critical path goes through six AMMs). Thus, given that the cost of a 4 \u00d7 2 AMM is less than the combined costs of a 4 \u00d7 2 multiplier and a 4-bit adder, the design shown in Fig. 12.5 is very cost-effective.</p> <p>\u56fe 12.5 \u663e\u793a\u4e86\u5982\u4f55\u5229\u7528\u56fe 12.4 \u6240\u793a\u7c7b\u578b\u7684\u516b\u4e2a AMM \u6784\u5efa\u56fe 12.3 \u7684 8 \u00d7 8 \u4e58\u6cd5\u5668\u793a\u4f8b\u3002\u8bf7\u6ce8\u610f\uff0c\u6b64\u8bbe\u8ba1\u9700\u8981\u516b\u4e2a 4 \u00d7 2 \u4e58\u6cd5\u5668\uff1b\u56e0\u6b64\u6a21\u5757\u7684\u6570\u91cf\u4fdd\u6301\u5728\u6700\u4f4e\u9650\u5ea6\u3002\u6bcf\u4e2a AMM \u6bd4 4 \u00d7 2 \u4e58\u6cd5\u5668\u6700\u591a\u6162 1 \u4e2a FA \u7ea7\u522b\u3002\u6240\u4ee5\uff0c\u5982\u56fe12.5\u6240\u793a\u7684\u5ef6\u8fdf\u3002\u5f52\u56e0\u4e8e\u52a0\u6cd5\u529f\u80fd\u7684 FA \u5ef6\u8fdf\u4e0d\u8d85\u8fc7 6 \u4e2a\uff08\u5173\u952e\u8def\u5f84\u7ecf\u8fc7 6 \u4e2a AMM\uff09\u3002\u56e0\u6b64\uff0c\u8003\u8651\u5230 4 \u00d7 2 AMM \u7684\u6210\u672c\u4f4e\u4e8e 4 \u00d7 2 \u4e58\u6cd5\u5668\u548c 4 \u4f4d\u52a0\u6cd5\u5668\u7684\u603b\u6210\u672c\uff0c\u56fe 12.5 \u6240\u793a\u7684\u8bbe\u8ba1\u975e\u5e38\u7ecf\u6d4e\u9ad8\u6548\u3002</p> <p></p> <p>Figure 12.6 depicts an alternate design for an 8 \u00d7 8 multiplier using the same number and type of 4 \u00d7 2 AMMs as in Fig. 12.5 (as well as the same notational conventions). This latter design is slower than the design of Fig. 12.5 because its critical path goes through all eight modules. However, it is more regular and, thus, readily generalizable to any 4 h 2 \u00d7 2 h 1 multiplier with compact layout.</p> <p>\u56fe 12.6 \u63cf\u8ff0\u4e86 8 \u00d7 8 \u4e58\u6cd5\u5668\u7684\u66ff\u4ee3\u8bbe\u8ba1\uff0c\u4f7f\u7528\u4e0e\u56fe 12.5 \u76f8\u540c\u6570\u91cf\u548c\u7c7b\u578b\u7684 4 \u00d7 2 AMM\uff08\u4ee5\u53ca\u76f8\u540c\u7684\u7b26\u53f7\u7ea6\u5b9a\uff09\u3002\u540e\u4e00\u79cd\u8bbe\u8ba1\u6bd4\u56fe 12.5 \u7684\u8bbe\u8ba1\u6162\uff0c\u56e0\u4e3a\u5b83\u7684\u5173\u952e\u8def\u5f84\u7ecf\u8fc7\u6240\u6709\u516b\u4e2a\u6a21\u5757\u3002\u7136\u800c\uff0c\u5b83\u66f4\u52a0\u89c4\u5219\uff0c\u56e0\u6b64\u5f88\u5bb9\u6613\u63a8\u5e7f\u5230\u4efb\u4f55\u5177\u6709\u7d27\u51d1\u5e03\u5c40\u7684 4 h 2 \u00d7 2 h 1 \u4e58\u6cd5\u5668\u3002</p> <p>In general, a b \u00d7 c AMM will have a pair of b-bit and c-bit multiplicative inputs, two b-bit and c-bit additive inputs, and a ( b + c)-bit output. The number of bits in the output is just adequate to represent the largest possible output value, as is evident from the following identity:</p> <p>\u4e00\u822c\u6765\u8bf4\uff0c\\(b \u00d7 c\\) AMM \u5c06\u5177\u6709\u4e00\u5bf9 \\(b\\) \u4f4d\u548c \\(c\\) \u4f4d\u4e58\u6cd5\u8f93\u5165\u3001\u4e24\u4e2a \\(b\\) \u4f4d\u548c \\(c\\) \u4f4d\u52a0\u6cd5\u8f93\u5165\u4ee5\u53ca\u4e00\u4e2a \\(( b + c)\\) \u4f4d\u8f93\u51fa\u3002\u8f93\u51fa\u4e2d\u7684\u4f4d\u6570\u8db3\u4ee5\u8868\u793a\u6700\u5927\u53ef\u80fd\u7684\u8f93\u51fa\u503c\uff0c\u4ece\u4ee5\u4e0b\u6052\u7b49\u5f0f\u53ef\u4ee5\u660e\u663e\u770b\u51fa\uff1a</p> <p>$$ (2^b \u2212 1)(2^c \u2212 1) + (2^b \u2212 1) + (2^c \u2212 1) = 2^{b+c} \u2212 1 $$ In designing larger multipliers based on b \u00d7 c AMMs, the ( b + c)-bit output of each AMM is divided into a b-bit upper part and a c-bit lower part that are supplied as additive inputs to other AMMs or serve as primary outputs. An AMM that receives a[ j, j+ b\u22121] and x[ i, i+ c\u22121] as its multiplicative inputs should have values spanning the bit positions [ i + j, i + j + b \u2212 1] and [ i + j, i + j + c \u2212 1] as its additive inputs (why?). To design a k \u00d7 l multiplier, where b and c divide both k and l, one can organize the kl/( bc) AMMs as a ( k/ b) \u00d7 ( l/ c) or a ( k/ c) \u00d7 ( l/ b) array. This provides some flexibility in fitting the design to the available chip area. However, the choice may have nontrivial implications for speed.</p> <p>\u5728\u8bbe\u8ba1\u57fa\u4e8e \\(b \u00d7 c\\) AMM \u7684\u8f83\u5927\u4e58\u6cd5\u5668\u65f6\uff0c\u6bcf\u4e2a AMM \u7684 \\((b + c)\\) \u4f4d\u8f93\u51fa\u88ab\u5206\u4e3a b \u4f4d\u4e0a\u90e8\u548c c \u4f4d\u4e0b\u90e8\uff0c\u5b83\u4eec\u4f5c\u4e3a\u9644\u52a0\u8f93\u5165\u63d0\u4f9b\u7ed9\u5176\u4ed6 AMM \u6216\u7528\u4f5c\u4e3b\u8981\u8f93\u51fa\u3002\u63a5\u6536 \\(a_{[ j, j+ b\u22121]}\\) \u548c \\(x_{[ i, i+ c\u22121]}\\) \u4f5c\u4e3a\u5176\u4e58\u6cd5\u8f93\u5165\u7684 AMM \u5e94\u8be5\u5177\u6709\u8de8\u8d8a\u4f4d\u4f4d\u7f6e \\([ i + j, i + j + b \u2212 1]\\) \u548c \\([ i + j, i + j + c \u2212 1]\\) \u7684\u503c\u4f5c\u4e3a\u5176\u52a0\u6cd5\u8f93\u5165\uff08\u4e3a\u4ec0\u4e48\uff1f\uff09\u3002\u8981\u8bbe\u8ba1\u4e00\u4e2a k \u00d7 l \u4e58\u6cd5\u5668\uff0c\u5176\u4e2d b \u548c c \u5747\u9664 k \u548c l\uff0c\u53ef\u4ee5\u5c06 \\(kl/( bc)\\) AMM \u7ec4\u7ec7\u4e3a \\(( k/ b) \u00d7 ( l/ c)\\) \u6216 \\(( k/ c) \u00d7 ( l/ b)\\) \u9635\u5217\u3002\u8fd9\u4e3a\u5c06\u8bbe\u8ba1\u9002\u5e94\u53ef\u7528\u82af\u7247\u533a\u57df\u63d0\u4f9b\u4e86\u4e00\u5b9a\u7684\u7075\u6d3b\u6027\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u9009\u62e9\u53ef\u80fd\u4f1a\u5bf9\u901f\u5ea6\u4ea7\u751f\u91cd\u5927\u5f71\u54cd\u3002</p>"},{"location":"Part_03/12/#123","title":"12.3 \u4f4d\u4e32\u884c\u4e58\u6cd5\u5668","text":"<p>Bit-serial arithmetic is attractive in view of its smaller pin count, reduced wire length, and lower floor space requirements in very large-scale integration. In fact, the compactness of the design may allow us to run a bit-serial multiplier at a clock rate high enough to make the unit almost competitive with much more complex designs with regard to speed.</p> <p>\u4f4d\u4e32\u884c\u7b97\u6cd5\u56e0\u5176\u5728\u8d85\u5927\u89c4\u6a21\u96c6\u6210\u4e2d\u5177\u6709\u8f83\u5c11\u7684\u5f15\u811a\u6570\u3001\u8f83\u77ed\u7684\u5bfc\u7ebf\u957f\u5ea6\u548c\u8f83\u4f4e\u7684\u5360\u5730\u9762\u79ef\u800c\u5177\u6709\u5438\u5f15\u529b\u3002\u4e8b\u5b9e\u4e0a\uff0c\u8bbe\u8ba1\u7684\u7d27\u51d1\u6027\u53ef\u80fd\u5141\u8bb8\u6211\u4eec\u4ee5\u8db3\u591f\u9ad8\u7684\u65f6\u949f\u901f\u7387\u8fd0\u884c\u4f4d\u4e32\u884c\u4e58\u6cd5\u5668\uff0c\u4ece\u800c\u4f7f\u8be5\u5355\u5143\u5728\u901f\u5ea6\u65b9\u9762\u51e0\u4e4e\u53ef\u4ee5\u4e0e\u66f4\u590d\u6742\u7684\u8bbe\u8ba1\u7ade\u4e89\u3002</p> <p>In addition, in certain application contexts, inputs are supplied bit-serially anyway. In such a case, using a parallel multiplier would be quite wasteful, since the parallelism may not lead to any speed benefit. Furthermore, in applications that call for a large number of independent multiplications, multiple bit-serial multipliers may be more cost-effective than a complex highly pipelined unit.</p> <p>\u6b64\u5916\uff0c\u5728\u67d0\u4e9b\u5e94\u7528\u7a0b\u5e8f\u73af\u5883\u4e2d\uff0c\u8f93\u5165\u65e0\u8bba\u5982\u4f55\u90fd\u662f\u6309\u4f4d\u4e32\u884c\u63d0\u4f9b\u7684\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u4f7f\u7528\u5e76\u884c\u4e58\u6cd5\u5668\u5c06\u975e\u5e38\u6d6a\u8d39\uff0c\u56e0\u4e3a\u5e76\u884c\u6027\u53ef\u80fd\u4e0d\u4f1a\u5e26\u6765\u4efb\u4f55\u901f\u5ea6\u4f18\u52bf\u3002\u6b64\u5916\uff0c\u5728\u9700\u8981\u5927\u91cf\u72ec\u7acb\u4e58\u6cd5\u7684\u5e94\u7528\u4e2d\uff0c\u591a\u4e2a\u4f4d\u4e32\u884c\u4e58\u6cd5\u5668\u53ef\u80fd\u6bd4\u590d\u6742\u7684\u9ad8\u5ea6\u6d41\u6c34\u7ebf\u5355\u5143\u66f4\u5177\u6210\u672c\u6548\u76ca\u3002</p> <p>Bit-serial multipliers can be designed as systolic arrays: synchronous arrays of processing elements that are interconnected by only short, local wires thus allowing very high clock rates. Let us begin by introducing a semisystolic multiplier, so named because its design involves broadcasting a single bit of the multiplier x to a number of circuit elements, thus violating the \u201cshort, local wires\u201d requirement of pure systolic design [Kung82].</p> <p>\u4f4d\u4e32\u884c\u4e58\u6cd5\u5668\u53ef\u4ee5\u8bbe\u8ba1\u4e3a\u8109\u52a8\u9635\u5217\uff1a\u4ec5\u901a\u8fc7\u77ed\u7684\u672c\u5730\u7535\u7ebf\u4e92\u8fde\u7684\u5904\u7406\u5143\u4ef6\u7684\u540c\u6b65\u9635\u5217\uff0c\u4ece\u800c\u5141\u8bb8\u975e\u5e38\u9ad8\u7684\u65f6\u949f\u901f\u7387\u3002\u8ba9\u6211\u4eec\u9996\u5148\u4ecb\u7ecd\u4e00\u4e2a\u534a\u8109\u52a8\u4e58\u6cd5\u5668\uff0c\u4e4b\u6240\u4ee5\u5982\u6b64\u547d\u540d\uff0c\u662f\u56e0\u4e3a\u5b83\u7684\u8bbe\u8ba1\u6d89\u53ca\u5c06\u4e58\u6cd5\u5668 x \u7684\u5355\u4e2a\u4f4d\u5e7f\u64ad\u5230\u591a\u4e2a\u7535\u8def\u5143\u4ef6\uff0c\u4ece\u800c\u8fdd\u53cd\u4e86\u7eaf\u8109\u52a8\u8bbe\u8ba1\u7684\u201c\u77ed\u5c40\u90e8\u7ebf\u8def\u201d\u8981\u6c42 [Kung82].</p> <p></p> <p>Figure 12.7 shows a semisystolic 4 \u00d7 4 multiplier. The multiplicand a is supplied in parallel from above and the multiplier x is supplied bit-serially from the right, with its least-significant bit (LSB) arriving first. Each bit xi of the multiplier is multiplied by a and the result added to the cumulative partial product, kept in carry-save form in the carry and sum latches. The carry bit stays in its current position, while the sum bit is passed on to the neighboring cell on the right. This corresponds to shifting the partial product to the right before the next addition step (normally the sum bit would stay put and the carry bit would be shifted to the left). Bits of the result emerge serially from the right as they become available.</p> <p>\u56fe 12.7 \u663e\u793a\u4e86\u534a\u6536\u7f29 4 \u00d7 4 \u4e58\u6cd5\u5668\u3002\u88ab\u4e58\u6570 a \u4ece\u4e0a\u65b9\u5e76\u884c\u63d0\u4f9b\uff0c\u4e58\u6570 x \u4ece\u53f3\u4fa7\u6309\u4f4d\u4e32\u884c\u63d0\u4f9b\uff0c\u5176\u6700\u4f4e\u6709\u6548\u4f4d (LSB) \u9996\u5148\u5230\u8fbe\u3002\u4e58\u6cd5\u5668\u7684\u6bcf\u4e00\u4f4d \\(x_i\\) \u4e0e\\(a\\)\u76f8\u4e58\u5e76\u5c06\u7ed3\u679c\u52a0\u5230\u7d2f\u79ef\u90e8\u5206\u79ef\u4e2d\uff0c\u4ee5\u8fdb\u4f4d\u4fdd\u5b58\u5f62\u5f0f\u4fdd\u5b58\u5728\u8fdb\u4f4d\u9501\u5b58\u5668\u548c\u6c42\u548c\u9501\u5b58\u5668\u4e2d\u3002\u8fdb\u4f4d\u4f4d\u4fdd\u7559\u5728\u5176\u5f53\u524d\u4f4d\u7f6e\uff0c\u800c\u548c\u4f4d\u5219\u4f20\u9012\u5230\u53f3\u4fa7\u7684\u76f8\u90bb\u5355\u5143\u3002\u8fd9\u5bf9\u5e94\u4e8e\u5728\u4e0b\u4e00\u4e2a\u52a0\u6cd5\u6b65\u9aa4\u4e4b\u524d\u5c06\u90e8\u5206\u79ef\u5411\u53f3\u79fb\u52a8\uff08\u901a\u5e38\u548c\u4f4d\u5c06\u4fdd\u6301\u4e0d\u53d8\uff0c\u8fdb\u4f4d\u4f4d\u5c06\u5411\u5de6\u79fb\u52a8\uff09\u3002\u7ed3\u679c\u7684\u5404\u4e2a\u4f4d\u5728\u53ef\u7528\u65f6\u4ece\u53f3\u4fa7\u8fde\u7eed\u51fa\u73b0\u3002</p> <p>A k-bit unsigned multiplier x must be padded with k zeros to allow the carries to propagate to the output, yielding the correct 2 k-bit product. Thus, the semisystolic multiplier of Fig. 12.7 can perform one k \u00d7 k unsigned integer multiplication every 2 k clock cycles. If k-bit fractions need to be multiplied, the first k output bits are discarded or used to properly round the most-significant k bits. Such a multiplier is useful in designing a cell that must multiply a bit-serial input by a constant chosen from among a set of values stored in its local memory. The chosen constant a is read out from the cell\u2019s random-access memory, stored in a register, and used for 1 operating cycle (2 k clock cycles) to perform the multiplication by x. Different constants may be used in different operating cycles, hence the need for a general multiplier, rather than a constant multiplier of the types discussed in Section 9.5.</p> <p>k \u4f4d\u65e0\u7b26\u53f7\u4e58\u6cd5\u5668 x \u5fc5\u987b\u7528 k \u4e2a\u96f6\u586b\u5145\uff0c\u4ee5\u5141\u8bb8\u8fdb\u4f4d\u4f20\u64ad\u5230\u8f93\u51fa\uff0c\u4ece\u800c\u4ea7\u751f\u6b63\u786e\u7684 \\(2 k\\) \u4f4d\u4e58\u79ef\u3002\u56e0\u6b64\uff0c\u56fe 12.7 \u7684\u534a\u8109\u52a8\u4e58\u6cd5\u5668\u53ef\u4ee5\u6bcf \\(2 k\\) \u4e2a\u65f6\u949f\u5468\u671f\u6267\u884c\u4e00\u6b21 \\(k \u00d7 k\\) \u65e0\u7b26\u53f7\u6574\u6570\u4e58\u6cd5\u3002\u5982\u679c\u9700\u8981\u4e58\u4ee5 k \u4f4d\u5206\u6570\uff0c\u5219\u524d k \u4e2a\u8f93\u51fa\u4f4d\u5c06\u88ab\u4e22\u5f03\u6216\u7528\u4e8e\u6b63\u786e\u820d\u5165\u6700\u9ad8\u6709\u6548 k \u4f4d\u3002\u8fd9\u79cd\u4e58\u6cd5\u5668\u5728\u8bbe\u8ba1\u5fc5\u987b\u5c06\u4f4d\u4e32\u884c\u8f93\u5165\u4e58\u4ee5\u4ece\u5b58\u50a8\u5728\u5176\u672c\u5730\u5b58\u50a8\u5668\u4e2d\u7684\u4e00\u7ec4\u503c\u4e2d\u9009\u62e9\u7684\u5e38\u6570\u7684\u5355\u5143\u65f6\u975e\u5e38\u6709\u7528\u3002\u6240\u9009\u5e38\u6570 a \u4ece\u5355\u5143\u7684\u968f\u673a\u5b58\u53d6\u5b58\u50a8\u5668\u4e2d\u8bfb\u51fa\uff0c\u5b58\u50a8\u5728\u5bc4\u5b58\u5668\u4e2d\uff0c\u5e76\u7528\u4e8e 1 \u4e2a\u64cd\u4f5c\u5468\u671f\uff082 k \u65f6\u949f\u5468\u671f\uff09\u6765\u6267\u884c x \u4e58\u6cd5\u3002\u4e0d\u540c\u7684\u5e38\u6570\u53ef\u4ee5\u7528\u5728\u4e0d\u540c\u7684\u64cd\u4f5c\u5468\u671f\u4e2d\uff0c\u56e0\u6b64\u9700\u8981\u901a\u7528\u4e58\u6cd5\u5668\uff0c\u800c\u4e0d\u662f\u7b2c 9.5 \u8282\u4e2d\u8ba8\u8bba\u7684\u7c7b\u578b\u7684\u5e38\u6570\u4e58\u6cd5\u5668\u3002</p> <p>To make the multiplier of Fig. 12.7 fully systolic, we must remove the broadcasting of the multiplier bits. This can be accomplished by a process known as systolic retiming, which is briefly explained below.</p> <p>\u4e3a\u4e86\u4f7f\u56fe 12.7 \u7684\u4e58\u6cd5\u5668\u5b8c\u5168\u8109\u52a8\uff0c\u6211\u4eec\u5fc5\u987b\u5220\u9664\u4e58\u6cd5\u5668\u4f4d\u7684\u5e7f\u64ad\u3002\u8fd9\u53ef\u4ee5\u901a\u8fc7\u79f0\u4e3a\u8109\u52a8\u91cd\u65b0\u5b9a\u65f6\u7684\u8fc7\u7a0b\u6765\u5b8c\u6210\uff0c\u4e0b\u9762\u5bf9\u6b64\u8fdb\u884c\u7b80\u8981\u8bf4\u660e\u3002</p> <p>Consider a synchronous (clocked) circuit, with each line between two functional parts having an integral number of unit delays (possibly 0). Then, if we cut the circuit into two parts cL and cR, we can delay (advance) all the signals going in one direction and advance (delay) the ones going in the opposite direction by the same amount without affecting the correct functioning or external timing relations of the circuit. For this claim to hold, the primary inputs and outputs to the two parts cL and cR must be correspondingly advanced or delayed too (see Fig. 12.8).</p> <p>\u8003\u8651\u4e00\u4e2a\u540c\u6b65\uff08\u65f6\u949f\uff09\u7535\u8def\uff0c\u4e24\u4e2a\u529f\u80fd\u90e8\u5206\u4e4b\u95f4\u7684\u6bcf\u6761\u7ebf\u8def\u90fd\u5177\u6709\u6574\u6570\u4e2a\u5355\u4f4d\u5ef6\u8fdf\uff08\u53ef\u80fd\u4e3a 0\uff09\u3002\u7136\u540e\uff0c\u5982\u679c\u6211\u4eec\u5c06\u7535\u8def\u5206\u6210\u4e24\u90e8\u5206 \\(c_L\\) \u548c \\(c_R\\)\uff0c\u6211\u4eec\u53ef\u4ee5\u5ef6\u8fdf\uff08\u63d0\u524d\uff09\u671d\u4e00\u4e2a\u65b9\u5411\u4f20\u64ad\u7684\u6240\u6709\u4fe1\u53f7\uff0c\u5e76\u63d0\u524d\uff08\u5ef6\u8fdf\uff09\u76f8\u53cd\u65b9\u5411\u4f20\u64ad\u7684\u4fe1\u53f7\u76f8\u540c\u7684\u91cf\uff0c\u800c\u4e0d\u4f1a\u5f71\u54cd\u7535\u8def\u7684\u6b63\u786e\u529f\u80fd\u6216\u5916\u90e8\u65f6\u5e8f\u5173\u7cfb\u3002\u4e3a\u4e86\u4f7f\u8fd9\u4e00\u4e3b\u5f20\u6210\u7acb\uff0c\\(c_L\\) \u548c \\(c_R\\) \u4e24\u4e2a\u90e8\u5206\u7684\u4e3b\u8981\u8f93\u5165\u548c\u8f93\u51fa\u4e5f\u5fc5\u987b\u76f8\u5e94\u5730\u63d0\u524d\u6216\u5ef6\u8fdf\uff08\u89c1\u56fe 12.8\uff09\u3002</p> <p></p> <p>For the retiming shown in Fig. 12.8 to be possible, all the signals that are advanced by d must have had original delays of d or more (negative delays are not allowed). Note that all the signals going into cL have been delayed by d time units. Thus, cL will work as before, except that everything, including output production, occurs d time units later than before retiming. Advancing the outputs by d time units will keep the external view of the circuit unchanged.</p> <p>\u4e3a\u4e86\u4f7f\u56fe 12.8 \u4e2d\u6240\u793a\u7684\u91cd\u5b9a\u65f6\u6210\u4e3a\u53ef\u80fd\uff0c\u63d0\u524d d \u7684\u6240\u6709\u4fe1\u53f7\u5fc5\u987b\u5177\u6709 d \u6216\u66f4\u591a\u7684\u539f\u59cb\u5ef6\u8fdf\uff08\u4e0d\u5141\u8bb8\u8d1f\u5ef6\u8fdf\uff09\u3002\u8bf7\u6ce8\u610f\uff0c\u8fdb\u5165 \\(c_L\\) \u7684\u6240\u6709\u4fe1\u53f7\u5747\u5df2\u5ef6\u8fdf d \u4e2a\u65f6\u95f4\u5355\u4f4d\u3002\u56e0\u6b64\uff0c\\(c_L\\) \u5c06\u50cf\u4ee5\u524d\u4e00\u6837\u5de5\u4f5c\uff0c\u53ea\u662f\u4e00\u5207\uff08\u5305\u62ec\u8f93\u51fa\u4ea7\u751f\uff09\u53d1\u751f\u7684\u65f6\u95f4\u6bd4\u91cd\u5b9a\u65f6\u4e4b\u524d\u665a d \u4e2a\u65f6\u95f4\u5355\u4f4d\u3002\u5c06\u8f93\u51fa\u63d0\u524d d \u4e2a\u65f6\u95f4\u5355\u4f4d\u5c06\u4f7f\u7535\u8def\u7684\u5916\u90e8\u89c6\u56fe\u4fdd\u6301\u4e0d\u53d8\u3002</p> <p>We apply the preceding process to the multiplier circuit of Fig. 12.7 in three successive steps corresponding to cuts 1, 2, and 3 in Fig. 12.9, each time delaying the left-moving signal by one unit and advancing the right-moving signal by one unit. Verifying that the multiplier in Fig. 12.9 works correctly is left as an exercise. This new version of our multiplier does not have the fan-out problem of the design in Fig. 12.7, but it suffers from long signal propagation delay through the four FAs in each clock cycle, leading to inferior operating speed. Note that the culprits are zero-delay lines that lead to signal propagation through multiple circuit elements.</p> <p>\u6211\u4eec\u5c06\u524d\u9762\u7684\u8fc7\u7a0b\u5e94\u7528\u5230\u56fe12.7\u7684\u4e58\u6cd5\u5668\u7535\u8def\u4e2d\uff0c\u5206\u4e09\u4e2a\u8fde\u7eed\u6b65\u9aa4\uff0c\u5bf9\u5e94\u4e8e\u56fe12.9\u4e2d\u7684\u5207\u5206\u59041\u30012\u548c3\uff0c\u6bcf\u6b21\u5c06\u5411\u5de6\u79fb\u52a8\u7684\u4fe1\u53f7\u5ef6\u8fdf\u4e00\u4e2a\u5355\u4f4d\uff0c\u5e76\u5c06\u5411\u53f3\u79fb\u52a8\u7684\u4fe1\u53f7\u63d0\u524d\u4e00\u4e2a\u5355\u4f4d\u3002\u9a8c\u8bc1\u56fe 12.9 \u4e2d\u7684\u4e58\u6cd5\u5668\u662f\u5426\u6b63\u5e38\u5de5\u4f5c\u7559\u4f5c\u7ec3\u4e60\u3002\u6211\u4eec\u7684\u4e58\u6cd5\u5668\u7684\u8fd9\u4e2a\u65b0\u7248\u672c\u4e0d\u5b58\u5728\u56fe12.7\u4e2d\u8bbe\u8ba1\u7684\u6247\u51fa\u95ee\u9898\uff0c\u4f46\u5b83\u5728\u6bcf\u4e2a\u65f6\u949f\u5468\u671f\u5185\u901a\u8fc7\u56db\u4e2aFA\u7684\u4fe1\u53f7\u4f20\u64ad\u5ef6\u8fdf\u5f88\u957f\uff0c\u5bfc\u81f4\u8fd0\u884c\u901f\u5ea6\u8f83\u5dee\u3002\u8bf7\u6ce8\u610f\uff0c\u7f6a\u9b41\u7978\u9996\u662f\u5bfc\u81f4\u4fe1\u53f7\u901a\u8fc7\u591a\u4e2a\u7535\u8def\u5143\u4ef6\u4f20\u64ad\u7684\u96f6\u5ef6\u8fdf\u7ebf\u3002</p> <p></p> <p>One way of avoiding zero-delay lines in our design is to begin by doubling all the delays in Fig. 12.7. This is done by simply replacing each of the sum and carry flip-flops with two cascaded flip-flops before retiming is applied. Since the circuit is now operating at half its original speed, the multiplier x must also be applied on alternate clock cycles. The resulting design in Fig. 12.10 is fully systolic, inasmuch as signals move only between adjacent cells in each clock cycle. However, twice as many cycles are needed.</p> <p>\u5728\u6211\u4eec\u7684\u8bbe\u8ba1\u4e2d\u907f\u514d\u96f6\u5ef6\u8fdf\u7ebf\u7684\u4e00\u79cd\u65b9\u6cd5\u662f\u9996\u5148\u5c06\u56fe 12.7 \u4e2d\u7684\u6240\u6709\u5ef6\u8fdf\u52a0\u500d\u3002\u8fd9\u662f\u901a\u8fc7\u5728\u5e94\u7528\u91cd\u5b9a\u65f6\u4e4b\u524d\u7b80\u5355\u5730\u7528\u4e24\u4e2a\u7ea7\u8054\u89e6\u53d1\u5668\u66ff\u6362\u6bcf\u4e2a\u6c42\u548c\u89e6\u53d1\u5668\u548c\u8fdb\u4f4d\u89e6\u53d1\u5668\u6765\u5b8c\u6210\u7684\u3002\u7531\u4e8e\u7535\u8def\u73b0\u5728\u4ee5\u539f\u59cb\u901f\u5ea6\u7684\u4e00\u534a\u8fd0\u884c\uff0c\u56e0\u6b64\u4e58\u6cd5\u5668 x \u4e5f\u5fc5\u987b\u5e94\u7528\u4e8e\u4ea4\u66ff\u7684\u65f6\u949f\u5468\u671f\u3002\u56fe 12.10 \u4e2d\u7684\u6700\u7ec8\u8bbe\u8ba1\u662f\u5b8c\u5168\u8109\u52a8\u7684\uff0c\u56e0\u4e3a\u4fe1\u53f7\u5728\u6bcf\u4e2a\u65f6\u949f\u5468\u671f\u4e2d\u4ec5\u5728\u76f8\u90bb\u5355\u5143\u4e4b\u95f4\u79fb\u52a8\u3002\u7136\u800c\uff0c\u9700\u8981\u4e24\u500d\u7684\u5468\u671f\u3002</p> <p></p> <p>The easiest way to derive a multiplier with both inputs entering bit-serially is to allow k clock ticks for the multiplicand bits to be put into place in a shift register and then use the design of Fig. 12.7 (or its fully systolic counterpart in Fig. 12.10) to compute the product. This increases the total delay by k cycles.</p> <p>\u5bfc\u51fa\u4e24\u4e2a\u8f93\u5165\u5747\u6309\u4f4d\u4e32\u884c\u8f93\u5165\u7684\u4e58\u6cd5\u5668\u7684\u6700\u7b80\u5355\u65b9\u6cd5\u662f\u5141\u8bb8\u5c06\u88ab\u4e58\u6570\u4f4d\u7684 k \u4e2a\u65f6\u949f\u5468\u671f\u653e\u5165\u79fb\u4f4d\u5bc4\u5b58\u5668\u4e2d\uff0c\u7136\u540e\u4f7f\u7528\u56fe 12.7 \u7684\u8bbe\u8ba1\uff08\u6216\u56fe 12.10 \u4e2d\u7684\u5b8c\u5168\u8109\u52a8\u5bf9\u5e94\u90e8\u5206\uff09\u6765\u8ba1\u7b97\u4e58\u79ef\u3002\u8fd9\u4f1a\u4f7f\u603b\u5ef6\u8fdf\u589e\u52a0 k \u4e2a\u5468\u671f\u3002</p> <p>An alternative bit-serial input/output design is obtained by writing the relationship between the output and inputs in the form of a recurrence and then implementing it in hardware. Let a(i) and x(i) denote the values of a and x up to bit position i ( a( 0 ) = a 0, a( 1 ) = (a 1 a 0 ) two, etc.). Assume that the k-bit, 2\u2019s-complement inputs are sign-extended to 2 k bits. Define the partial product p(i) as follows: p(i) = 2\u2212 (i+1 )a(i)x(i)</p> <p>\u53e6\u4e00\u79cd\u4f4d\u4e32\u884c\u8f93\u5165/\u8f93\u51fa\u8bbe\u8ba1\u662f\u901a\u8fc7\u4ee5\u9012\u5f52\u5f62\u5f0f\u7f16\u5199\u8f93\u51fa\u548c\u8f93\u5165\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u7136\u540e\u5728\u786c\u4ef6\u4e2d\u5b9e\u73b0\u5b83\u6765\u83b7\u5f97\u7684\u3002\u4ee4 \\(a^{(i)}\\) \u548c \\(x^{(i)}\\) \u8868\u793a\u4f4d\u7f6e \\(i\\) \u7684 \\(a\\) \u548c \\(x\\) \u7684\u503c ( \\(a^{(0)} =a_0\\)\u3001\\(a^{(1)} = (a_1 a_0)_2\\) \u7b49\uff09\u3002\u5047\u8bbe k\u6bd4\u7279 2 \u7684\u8865\u7801\u8f93\u5165\u88ab\u7b26\u53f7\u6269\u5c55\u4e3a \\(2 k\\) \u4f4d\u3002\u5b9a\u4e49\u90e8\u5206\u79ef p(i) \u5982\u4e0b\uff1a </p> <p>\\(p^{(i)} = 2^{\u2212(i+1)}a^{(i)}x^{(i)}\\)</p> <p>Then, given that a(i) = 2 iai + a(i\u22121 ) and x(i) = 2 ixi + x(i\u22121 ), we have: </p> <p>\u7136\u540e\uff0c\u5047\u8bbe \\(a^{(i)} = 2^ia_i + a^{(i\u22121)}\\) \u548c \\(x^{(i)} = 2^ix_i + x^{(i\u22121)}\\)\uff0c\u6211\u4eec\u6709\uff1a </p> \\[ \\begin{array}{l} 2 p^{(i)} &amp;= 2^{\u2212 i}( 2^ia_i + a^{(i\u22121 )})( 2^ix_i + x^{(i\u22121 )}) \\\\           &amp;= p^{(i\u22121)} + a_ix^{(i\u22121)} + x_ia^{(i\u22121)} + 2^ia_ix_i \\end{array} \\] <p>Thus, if p(i\u22121 ) is stored in double\u2013carry-save form (three rows of dots in dot notation, as opposed to two for ordinary carry-save), it can be combined with the terms aix(i\u22121 ) and xia(i\u22121 ) using a (5; 3)-counter to yield a double\u2013carry-save result for the next step. The final term 2 iaixi has a single 1 in the i th position where all the other terms have 0s. Thus it can be handled by using a multiplexer (mux) (Fig. 12.11). In cycle i, ai and xi are input and stored in the i th cell (the correct timing is achieved by a \u201ctoken\u201d t, which is provided to cell 0 at time 0 and is then shifted leftward with each clock tick). The terms a(i\u22121 ) and x(i\u22121 ), which are already available in registers, are ANDed with xi and ai, respectively, and supplied along with the three bits of p(i\u22121 ) as inputs to the (5; 3)-counter. Figures 12.11 and 12.12 show the complete cell design and cell interconnection [Ienn94]. The AND gate computing aixi is replicated in each cell for the sake of uniformity. A single copy of this gate could be placed outside the cells, with its output broadcast to all cells.</p> <p>\u56e0\u6b64\uff0c\u5982\u679c \\(p^{(i\u22121)}\\) \u4ee5\u53cc\u8fdb\u4f4d\u4fdd\u5b58\u5f62\u5f0f\u5b58\u50a8\uff08\u70b9\u8868\u793a\u6cd5\u4e2d\u7684\u4e09\u884c\u70b9\uff0c\u800c\u4e0d\u662f\u666e\u901a\u8fdb\u4f4d\u4fdd\u5b58\u7684\u4e24\u884c\uff09\uff0c\u5219\u53ef\u4ee5\u4f7f\u7528 (5; 3) \u8ba1\u6570\u5668\u5c06\u5176\u4e0e\u9879 \\(a_ix^{(i\u22121)}\\) \u548c \\(x_ia^{(i\u22121)}\\) \u7ec4\u5408\uff0c\u4ee5\u4ea7\u751f\u53cc\u8fdb\u4f4d\u4fdd\u5b58\u7ed3\u679c\u4e0b\u4e00\u6b65\u3002\u6700\u540e\u4e00\u9879 \\(2^ia_ix_i\\) \u5728\u7b2c \\(i\\) \u4e2a\u4f4d\u7f6e\u6709\u4e00\u4e2a 1\uff0c\u800c\u6240\u6709\u5176\u4ed6\u9879\u90fd\u662f 0\u3002\u56e0\u6b64\u5b83\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528\u591a\u8def\u590d\u7528\u5668\uff08mux\uff09\u6765\u5904\u7406\uff08\u56fe12.11\uff09\u3002\u5728\u5468\u671f \\(i\\) \u4e2d\uff0c\\(a_i\\) \u548c \\(x_i\\) \u88ab\u8f93\u5165\u5e76\u5b58\u50a8\u5728\u7b2c \\(i\\) \u4e2a\u5355\u5143\u4e2d\uff08\u6b63\u786e\u7684\u65f6\u5e8f\u662f\u901a\u8fc7\u201c\u4ee4\u724c\u201dt \u5b9e\u73b0\u7684\uff0c\u8be5\u4ee4\u724c\u5728\u65f6\u95f4 0 \u5904\u63d0\u4f9b\u7ed9\u5355\u5143 0\uff0c\u7136\u540e\u5728\u6bcf\u4e2a\u65f6\u949f\u5468\u671f\u5185\u5411\u5de6\u79fb\u52a8\uff09\u3002\u5bc4\u5b58\u5668\u4e2d\u5df2\u7ecf\u5b58\u5728\u7684\u9879 \\(a^{(i\u22121)}\\) \u548c \\(x^{(i\u22121)}\\) \u5206\u522b\u4e0e \\(x_i\\) \u548c \\(a_i\\) \u8fdb\u884c AND \u8fd0\u7b97\uff0c\u5e76\u4e0e \\(p^{(i\u22121)}\\) \u7684\u4e09\u4f4d\u4e00\u8d77\u4f5c\u4e3a (5; 3) \u8ba1\u6570\u5668\u7684\u8f93\u5165\u63d0\u4f9b\u3002\u56fe 12.11 \u548c 12.12 \u663e\u793a\u4e86\u5b8c\u6574\u7684\u5355\u5143\u8bbe\u8ba1\u548c\u5355\u5143\u4e92\u8fde [Ienn94]\u3002\u4e3a\u4e86\u7edf\u4e00\u8d77\u89c1\uff0c\u4e0e\u95e8\u8ba1\u7b97 \\(a_ix_i\\) \u5728\u6bcf\u4e2a\u5355\u5143\u4e2d\u590d\u5236\u3002\u8be5\u95e8\u7684\u5355\u4e2a\u526f\u672c\u53ef\u4ee5\u653e\u7f6e\u5728\u5355\u5143\u5916\u90e8\uff0c\u5176\u8f93\u51fa\u5e7f\u64ad\u5230\u6240\u6709\u5355\u5143\u3002</p> <p></p> <p></p> <p>Note that the 3-bit sum of the five inputs to the (5; 3)-counter is shifted rightward before being stored in latches by connecting its LSB to the right neighboring cell, keeping its middle bit in place, and shifting its most-significant bit to the left. The product becomes available bit-serially at the s out output of the rightmost cell. Only k \u2212 1 such cells are needed to compute the full 2 k-bit product of two k-bit numbers. The reason is that the largest intermediate partial product is 2 k \u2212 1 bits wide, but by the time we get to this partial product, k bits of the product have already been produced and shifted out.</p> <p>\u8bf7\u6ce8\u610f\uff0c(5; 3) \u8ba1\u6570\u5668\u7684\u4e94\u4e2a\u8f93\u5165\u7684 3 \u4f4d\u603b\u548c\u5728\u5b58\u50a8\u5230\u9501\u5b58\u5668\u4e2d\u4e4b\u524d\u4f1a\u5411\u53f3\u79fb\u52a8\uff0c\u65b9\u6cd5\u662f\u5c06\u5176 LSB \u8fde\u63a5\u5230\u53f3\u4fa7\u76f8\u90bb\u5355\u5143\uff0c\u4fdd\u6301\u5176\u4e2d\u95f4\u4f4d\u4e0d\u53d8\uff0c\u5e76\u5c06\u5176\u6700\u9ad8\u6709\u6548\u4f4d\u5411\u5de6\u79fb\u52a8\u3002\u8be5\u4ea7\u54c1\u5728\u6700\u53f3\u4fa7\u5355\u5143\u7684 \\(s_{out}\\) \u8f93\u51fa\u5904\u4ee5\u4f4d\u4e32\u884c\u65b9\u5f0f\u53ef\u7528\u3002\u53ea\u9700 \\(k \u2212 1\\) \u4e2a\u8fd9\u6837\u7684\u5355\u5143\u5373\u53ef\u8ba1\u7b97\u4e24\u4e2a k \u4f4d\u6570\u5b57\u7684\u5b8c\u6574 \\(2 k\\) \u4f4d\u4e58\u79ef\u3002\u539f\u56e0\u662f\u6700\u5927\u7684\u4e2d\u95f4\u90e8\u5206\u79ef\u7684\u5bbd\u5ea6\u4e3a \\(2 k \u2212 1\\) \u4f4d\uff0c\u4f46\u662f\u5f53\u6211\u4eec\u5f97\u5230\u8fd9\u4e2a\u90e8\u5206\u79ef\u65f6\uff0c\u8be5\u4e58\u79ef\u7684 k \u4f4d\u5df2\u7ecf\u88ab\u751f\u6210\u5e76\u79fb\u51fa\u3002</p> <p>Figure 12.13 uses dot notation to show the justification for the bit-serial multiplier design in Figs. 12.11 and 12.12. Figure 12.13a depicts the meanings of the various partial operands and results, while Fig. 12.13b represents the operation of the (5; 3)-counters. Note, in particular, how the dot representing aixi is transferred to the s out output by the cell holding the token (refer to the lower right corner of Fig. 12.11).</p> <p>\u56fe 12.13 \u4f7f\u7528\u70b9\u8868\u793a\u6cd5\u663e\u793a\u4e86\u56fe 12.11 \u548c 12.12 \u4e2d\u4f4d\u4e32\u884c\u4e58\u6cd5\u5668\u8bbe\u8ba1\u7684\u5408\u7406\u6027\u3002  \u56fe 12.13a \u63cf\u8ff0\u4e86\u5404\u4e2a\u90e8\u5206\u64cd\u4f5c\u6570\u548c\u7ed3\u679c\u7684\u542b\u4e49\uff0c\u800c\u56fe 12.13b \u8868\u793a (5; 3) \u8ba1\u6570\u5668\u7684\u64cd\u4f5c\u3002 \u8bf7\u7279\u522b\u6ce8\u610f\uff0c\u4ee3\u8868 \\(a_ix_i\\) \u7684\u70b9\u5982\u4f55\u901a\u8fc7\u6301\u6709\u4ee4\u724c\u7684\u5355\u5143\u4f20\u8f93\u5230 \\(s_{out}\\)\uff08\u53c2\u89c1\u56fe 12.11 \u7684\u53f3\u4e0b\u89d2\uff09\u3002</p> <p></p>"},{"location":"Part_03/12/#124","title":"12.4 \u6a21\u4e58\u6cd5\u5668","text":"<p>A modular multiplier is one that produces the product of two (unsigned) integers modulo some fixed constant  m. It is useful, for example, for implementing the multiplication operation for residue number systems. A modular multiplier could be implemented by attaching a modular reduction circuit to the output of an ordinary binary multiplier. However, simpler designs are often possible if the modular reduction is intertwined with the accumulation of partial products. In particular, this approach obviates the need for keeping wider intermediate values. </p> <p>\u6a21\u4e58\u6cd5\u5668\u662f\u4e00\u79cd\u4ea7\u751f\u4e24\u4e2a\uff08\u65e0\u7b26\u53f7\uff09\u6574\u6570\u4ee5\u67d0\u4e2a\u56fa\u5b9a\u5e38\u6570 m \u4e3a\u6a21\u7684\u4e58\u79ef\u7684\u4e58\u6cd5\u5668\u3002\u4f8b\u5982\uff0c\u5b83\u5bf9\u4e8e\u5b9e\u73b0\u4f59\u6570\u7cfb\u7edf\u7684\u4e58\u6cd5\u8fd0\u7b97\u5f88\u6709\u7528\u3002\u6a21\u5757\u5316\u4e58\u6cd5\u5668\u53ef\u4ee5\u901a\u8fc7\u5c06\u6a21\u5757\u5316\u7f29\u51cf\u7535\u8def\u9644\u52a0\u5230\u666e\u901a\u4e8c\u8fdb\u5236\u4e58\u6cd5\u5668\u7684\u8f93\u51fa\u6765\u5b9e\u73b0\u3002\u7136\u800c\uff0c\u5982\u679c\u6a21\u5757\u5316\u7b80\u5316\u4e0e\u90e8\u5206\u4ea7\u54c1\u7684\u79ef\u7d2f\u4ea4\u7ec7\u5728\u4e00\u8d77\uff0c\u5219\u901a\u5e38\u53ef\u4ee5\u5b9e\u73b0\u66f4\u7b80\u5355\u7684\u8bbe\u8ba1\u3002\u7279\u522b\u662f\uff0c\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u9700\u8981\u4fdd\u7559\u66f4\u5bbd\u7684\u4e2d\u95f4\u503c\u3002</p> <p>The two special cases of  m = 2 b  and  m = 2 b \u2212 1 are, as usual, simpler to deal with (see Section 8.6). For example, if the partial products are accumulated through carry-save addition, then for  m = 2 b, the modular version simply ignores the carry output of the FA in position  b \u2212 1 and for  m = 2 b \u2212 1, the carry out of position  b \u2212 1 is combined with bits in column 0 (Fig. 12.14). </p> <p>\u50cf\u5f80\u5e38\u4e00\u6837\uff0c\\(m = 2^b\\) \u548c \\(m = 2^b \u2212 1\\) \u7684\u4e24\u79cd\u7279\u6b8a\u60c5\u51b5\u66f4\u5bb9\u6613\u5904\u7406\uff08\u53c2\u89c1\u7b2c 8.6 \u8282\uff09\u3002\u4f8b\u5982\uff0c\u5982\u679c\u90e8\u5206\u4e58\u79ef\u901a\u8fc7\u8fdb\u4f4d\u4fdd\u5b58\u52a0\u6cd5\u8fdb\u884c\u7d2f\u52a0\uff0c\u5219\u5bf9\u4e8e \\(m = 2^b\\)\uff0c\u6a21\u5757\u5316\u7248\u672c\u7b80\u5355\u5730\u5ffd\u7565\u4f4d\u7f6e \\(b \u2212 1\\) \u4e2d FA \u7684\u8fdb\u4f4d\u8f93\u51fa\uff0c\u800c\u5bf9\u4e8e \\(m = 2^b \u2212 1\\)\uff0c\u4f4d\u7f6e \\(b \u2212 1\\) \u7684\u8fdb\u4f4d\u8f93\u51fa\u4e0e\u7b2c 0 \u5217\u4e2d\u7684\u4f4d\u7ec4\u5408\uff08\u56fe 12.14\uff09\u3002</p> <p></p> <p>As an example, consider the design of a modulo-15 multiplier for 4-bit operands. Since 16 = 1 mod 15, the six heavy dots enclosed by the gray triangle in the upper left corner of Fig. 12.15 can be moved as shown, leading to the square partial products matrix on the lower left. The four 4-bit values can then be reduced by two levels of CSA (with wraparound links, as in Fig. 12.14) followed by a 4-bit adder (again with end-around carry). We see that this particular modular multiplier is in fact simpler than an ordinary 4 \u00d7 4 binary multiplier.</p> <p>\u4f8b\u5982\uff0c\u8003\u8651 4 \u4f4d\u64cd\u4f5c\u6570\u7684\u6a21 15 \u4e58\u6cd5\u5668\u7684\u8bbe\u8ba1\u3002\u7531\u4e8e 16 = 1 mod 15\uff0c\u56fe 12.15 \u5de6\u4e0a\u89d2\u7070\u8272\u4e09\u89d2\u5f62\u5305\u56f4\u7684\u516d\u4e2a\u9ed1\u70b9\u53ef\u4ee5\u5982\u56fe\u6240\u793a\u79fb\u52a8\uff0c\u4ece\u800c\u5f97\u5230\u5de6\u4e0b\u89d2\u7684\u65b9\u5f62\u90e8\u5206\u4e58\u79ef\u77e9\u9635\u3002\u7136\u540e\u53ef\u4ee5\u5c06\u56db\u4e2a 4 \u4f4d\u503c\u51cf\u5c11\u4e24\u4e2a\u7ea7\u522b\uff0cCSA\uff08\u5e26\u6709\u73af\u7ed5\u94fe\u63a5\uff0c\u5982\u56fe 12.14 \u6240\u793a\uff09\uff0c\u540e\u9762\u8ddf\u7740\u4e00\u4e2a 4 \u4f4d\u52a0\u6cd5\u5668\uff08\u540c\u6837\u5e26\u6709\u7ed3\u675f\u8fdb\u4f4d\uff09\u3002\u6211\u4eec\u770b\u5230\u8fd9\u4e2a\u7279\u5b9a\u7684\u6a21\u4e58\u6cd5\u5668\u5b9e\u9645\u4e0a\u6bd4\u666e\u901a\u7684 4 \u00d7 4 \u4e8c\u8fdb\u5236\u4e58\u6cd5\u5668\u66f4\u7b80\u5355\u3002</p> <p></p> <p>The special case of m = 2^b + 1 is also worth discussing, as it finds applications in low-cost residue number system designs. Assuming diminished-1 representation of nonzero mod- ( 2^b +1 ) inputs, we simply need to multiply each bit of x by the diminished-1 representation of a, adding all the terms. Some adjustments are required to compensate for the 0 terms resulting from the 0 digits of x, as these are not in the diminished-1 format, and for the representation of x being 1 less than its true value. These adjustments are not difficult to derive, and they do not significantly increase the cost or latency of the multiplier [Verg07].</p> <p>\\(m = 2^b + 1\\) \u7684\u7279\u6b8a\u60c5\u51b5\u4e5f\u503c\u5f97\u8ba8\u8bba\uff0c\u56e0\u4e3a\u5b83\u5728\u4f4e\u6210\u672c\u4f59\u6570\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u627e\u5230\u4e86\u5e94\u7528\u3002\u5047\u8bbe\u975e\u96f6 mod-\\((2^b +1 )\\) \u8f93\u5165\u7684\u51cf 1 \u8868\u793a\uff0c\u6211\u4eec\u53ea\u9700\u5c06 x \u7684\u6bcf\u4e00\u4f4d\u4e58\u4ee5 a \u7684\u51cf 1 \u8868\u793a\uff0c\u5e76\u5c06\u6240\u6709\u9879\u76f8\u52a0\u3002\u9700\u8981\u8fdb\u884c\u4e00\u4e9b\u8c03\u6574\u6765\u8865\u507f\u7531 x \u7684 0 \u4f4d\u4ea7\u751f\u7684 0 \u9879\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u9879\u4e0d\u662f\u51cf 1 \u683c\u5f0f\uff0c\u5e76\u4e14 x \u7684\u8868\u793a\u5f62\u5f0f\u6bd4\u5176\u771f\u5b9e\u503c\u5c0f 1\u3002\u8fd9\u4e9b\u8c03\u6574\u5e76\u4e0d\u96be\u63a8\u5bfc\uff0c\u5e76\u4e14\u5b83\u4eec\u4e0d\u4f1a\u663e\u7740\u589e\u52a0\u4e58\u6cd5\u5668\u7684\u6210\u672c\u6216\u5ef6\u8fdf[Verg07]\u3002</p> <p>Similar techniques can be used to handle modular multiplication in the general case. For example, a modulo-13 multiplier can be designed by using the identities 16 = 3 mod 13, 32 = 6 mod 13, and 64 = 12 mod 13. Each dot inside the triangle in Fig. 12.15 must now be replaced with two dots in the four lower-order columns (Fig. 12.16). Thus, some complexity is added in view of the larger number of dots to be reduced and the need for the final adjustment of the result to be in [0, 12].</p> <p>\u7c7b\u4f3c\u7684\u6280\u672f\u53ef\u7528\u4e8e\u5904\u7406\u4e00\u822c\u60c5\u51b5\u4e0b\u7684\u6a21\u4e58\u6cd5\u3002\u4f8b\u5982\uff0c\u53ef\u4ee5\u4f7f\u7528\u6052\u7b49\u5f0f \\(16=3 \\mod 13\\) \u3001\\(32 = 6 \\mod 13\\) \u548c \\(64 = 12 \\mod 13\\)\u3002\u56fe 12.15 \u4e2d\u4e09\u89d2\u5f62\u5185\u7684\u6bcf\u4e2a\u70b9\u73b0\u5728\u5fc5\u987b\u66ff\u6362\u4e3a\u56db\u4e2a\u8f83\u4f4e\u987a\u5e8f\u5217\u4e2d\u7684\u4e24\u4e2a\u70b9\uff08\u56fe 12.16\uff09\u3002\u56e0\u6b64\uff0c\u8003\u8651\u5230\u9700\u8981\u51cf\u5c11\u7684\u70b9\u6570\u8f83\u591a\u4ee5\u53ca\u9700\u8981\u5c06\u7ed3\u679c\u6700\u7ec8\u8c03\u6574\u5728[0, 12]\u4e4b\u95f4\uff0c\u56e0\u6b64\u589e\u52a0\u4e86\u4e00\u5b9a\u7684\u590d\u6742\u5ea6\u3002</p> <p></p> <p>To complete the design of our 4 \u00d7 4 modulo-13 multiplier, the values shown on the right-hand side of Fig. 12.16 must be added modulo 13. After a minor simplification, consisting of removing one dot from column 1 and replacing it with two dots in column 0, a variety of methods can be used for the required modular multioperand addition as discussed at the end of Section 8.6.</p> <p>\u4e3a\u4e86\u5b8c\u6210\u6211\u4eec\u7684 4 \u00d7 4 \u6a21 13 \u4e58\u6cd5\u5668\u7684\u8bbe\u8ba1\uff0c\u56fe 12.16 \u53f3\u4fa7\u6240\u793a\u7684\u503c\u5fc5\u987b\u5bf9 13 \u8fdb\u884c\u52a0\u6cd5\u3002\u7ecf\u8fc7\u8f7b\u5fae\u7b80\u5316\uff08\u5305\u62ec\u4ece\u7b2c 1 \u5217\u4e2d\u5220\u9664\u4e00\u4e2a\u70b9\u5e76\u7528\u7b2c 0 \u5217\u4e2d\u7684\u4e24\u4e2a\u70b9\u66ff\u6362\u5b83\uff09\uff0c\u53ef\u4ee5\u4f7f\u7528\u591a\u79cd\u65b9\u6cd5\u6765\u5b9e\u73b0\u6240\u9700\u7684\u6a21\u591a\u64cd\u4f5c\u6570\u52a0\u6cd5\uff0c\u5982\u7b2c 8.6 \u8282\u672b\u5c3e\u6240\u8ff0\u3002</p> <p>For example, one can use a CSA tree in which carries into column 4 are reinserted into columns 0 and 1. However, this scheme will not work toward the end of the process and must thus be supplemented with a different modular reduction scheme. Another approach is to keep some of the bits emerging from the left end (e.g., those that cannot be accommodated in the dot matrix without increasing its height) and reduce them modulo 13 by means of a lookup table or specially designed logic circuit. Supplying the details is left as an exercise. Figure 12.17 shows a general method for converting an n-input modulo- m addition problem to a three-input problem.</p> <p>\u4f8b\u5982\uff0c\u53ef\u4ee5\u4f7f\u7528 CSA \u6811\uff0c\u5176\u4e2d\u5c06\u8fdb\u5165\u7b2c 4 \u5217\u7684\u8fdb\u4f4d\u91cd\u65b0\u63d2\u5165\u5230\u7b2c 0 \u5217\u548c\u7b2c 1 \u5217\u3002\u4f46\u662f\uff0c\u8be5\u65b9\u6848\u5728\u8fc7\u7a0b\u7ed3\u675f\u65f6\u5c06\u4e0d\u8d77\u4f5c\u7528\uff0c\u56e0\u6b64\u5fc5\u987b\u7528\u4e0d\u540c\u7684\u6a21\u6570\u7f29\u51cf\u65b9\u6848\u8fdb\u884c\u8865\u5145\u3002\u53e6\u4e00\u79cd\u65b9\u6cd5\u662f\u4fdd\u7559\u4e00\u4e9b\u4ece\u5de6\u7aef\u51fa\u73b0\u7684\u4f4d\uff08\u4f8b\u5982\uff0c\u90a3\u4e9b\u5728\u4e0d\u589e\u52a0\u70b9\u9635\u9ad8\u5ea6\u7684\u60c5\u51b5\u4e0b\u65e0\u6cd5\u5bb9\u7eb3\u5728\u70b9\u9635\u4e2d\u7684\u4f4d\uff09\uff0c\u5e76\u901a\u8fc7\u67e5\u627e\u8868\u6216\u4e13\u95e8\u8bbe\u8ba1\u7684\u903b\u8f91\u7535\u8def\u5bf9\u5b83\u4eec\u8fdb\u884c\u6a2113\u51cf\u5c11\u3002\u63d0\u4f9b\u8be6\u7ec6\u4fe1\u606f\u7559\u4f5c\u7ec3\u4e60\u3002\u56fe 12.17 \u663e\u793a\u4e86\u5c06 n \u8f93\u5165\u6a21\u52a0\u6cd5\u95ee\u9898\u8f6c\u6362\u4e3a\u4e09\u8f93\u5165\u95ee\u9898\u7684\u901a\u7528\u65b9\u6cd5\u3002</p> <p></p> <p>When dealing with very large numbers, say having widths of the order of hundreds of bits, a modular multiplication algorithm known as Montgomery multiplication is quite efficient. Such multiplications are used extensively in cryptographic applications. We postpone discussion of this algorithm to Section 15.4, where we describe it along with Montgomery modular reduction.</p> <p>\u5f53\u5904\u7406\u975e\u5e38\u5927\u7684\u6570\u5b57\u65f6\uff0c\u4f8b\u5982\u5bbd\u5ea6\u4e3a\u6570\u767e\u4f4d\u7684\u6570\u5b57\uff0c\u79f0\u4e3a\u8499\u54e5\u9a6c\u5229\u4e58\u6cd5\u7684\u6a21\u4e58\u7b97\u6cd5\u975e\u5e38\u6709\u6548\u3002\u8fd9\u79cd\u4e58\u6cd5\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5bc6\u7801\u5b66\u5e94\u7528\u4e2d\u3002\u6211\u4eec\u5c06\u8be5\u7b97\u6cd5\u7684\u8ba8\u8bba\u63a8\u8fdf\u5230\u7b2c 15.4 \u8282\uff0c\u6211\u4eec\u5728\u5176\u4e2d\u63cf\u8ff0\u4e86\u5b83\u4ee5\u53ca\u8499\u54e5\u9a6c\u5229\u6a21\u7ea6\u7b80\u3002</p>"},{"location":"Part_03/12/#125","title":"12.5 \u5e73\u65b9\u8fd0\u7b97\u5668","text":"<p>Any ordinary or modular multiplier can be used for computing p = x 2 if both its inputs are connected to x. However, a special-purpose k-bit squarer, if built in hardware, will be significantly lower in cost and delay than a k \u00d7 k multiplier.</p> <p>\u5982\u679c\u4efb\u4f55\u666e\u901a\u6216\u6a21\u4e58\u6cd5\u5668\u7684\u4e24\u4e2a\u8f93\u5165\u90fd\u8fde\u63a5\u5230 x\uff0c\u5219\u53ef\u4ee5\u4f7f\u7528\u5b83\u6765\u8ba1\u7b97 \\(p = x^2\\)\u3002\u7136\u800c\uff0c\u4e13\u7528\u7684 k \u4f4d\u5e73\u65b9\u5668\u5982\u679c\u5185\u7f6e\u4e8e\u786c\u4ef6\u4e2d\uff0c\u5176\u6210\u672c\u548c\u5ef6\u8fdf\u5c06\u660e\u663e\u4f4e\u4e8e \\(k \u00d7 k\\) \u4e58\u6cd5\u5668\u3002</p> <p>To see why, consider the problem of squaring a 5-bit unsigned binary integer \\(( x_4 x_3 x_2 x_1 x_0 )_{two}\\). As shown in Fig. 12.18a, the partial products matrix can be considerably simplified before performing multioperand addition. A term xixi reduces to xi and a pair of terms xixj and xjxi in any given column can be replaced by xixj in the next higher column. The resulting simplified partial products matrix for our 5-bit example is shown in Fig. 12.18b. We see that the two LSBs of the square are obtained with no effort and that computing the remaining bits involves a three-operand addition as opposed to a five-operand addition needed for 5 \u00d7 5 multiplication.</p> <p>\u8981\u4e86\u89e3\u539f\u56e0\uff0c\u8bf7\u8003\u8651\u5bf9 5 \u4f4d\u65e0\u7b26\u53f7\u4e8c\u8fdb\u5236\u6574\u6570\\(( x_4 x_3 x_2 x_1 x_0 )_2\\) \u8fdb\u884c\u5e73\u65b9\u7684\u95ee\u9898\u3002\u5982\u56fe 12.18a \u6240\u793a\uff0c\u5728\u6267\u884c\u591a\u64cd\u4f5c\u6570\u52a0\u6cd5\u4e4b\u524d\uff0c\u53ef\u4ee5\u5927\u5927\u7b80\u5316\u90e8\u5206\u4e58\u79ef\u77e9\u9635\u3002\u9879 \\(x_ix_i\\) \u7b80\u5316\u4e3a \\(x_i\\)\uff0c\u5e76\u4e14\u4efb\u4f55\u7ed9\u5b9a\u5217\u4e2d\u7684\u4e00\u5bf9\u9879 \\(x_ix_j\\) \u548c \\(x_jx_i\\) \u53ef\u4ee5\u88ab\u4e0b\u4e00\u4e2a\u66f4\u9ad8\u5217\u4e2d\u7684 \\(x_ix_j\\) \u66ff\u6362\u3002\u6211\u4eec\u7684 5 \u4f4d\u793a\u4f8b\u7684\u7b80\u5316\u90e8\u5206\u4e58\u79ef\u77e9\u9635\u5982\u56fe 12.18b \u6240\u793a\u3002\u6211\u4eec\u770b\u5230\uff0c\u5e73\u65b9\u7684\u4e24\u4e2a LSB \u662f\u6beb\u4e0d\u8d39\u529b\u5730\u83b7\u5f97\u7684\uff0c\u5e76\u4e14\u8ba1\u7b97\u5269\u4f59\u4f4d\u6d89\u53ca\u4e09\u64cd\u4f5c\u6570\u52a0\u6cd5\uff0c\u800c\u4e0d\u662f 5 \u00d7 5 \u4e58\u6cd5\u6240\u9700\u7684\u4e94\u64cd\u4f5c\u6570\u52a0\u6cd5\u3002</p> <p></p> <p>Further simplifications and fine-tuning are often possible. For example, based on the identities</p> <p>\u901a\u5e38\u53ef\u4ee5\u8fdb\u884c\u8fdb\u4e00\u6b65\u7684\u7b80\u5316\u548c\u5fae\u8c03\u3002\u4f8b\u5982\uff0c\u6839\u636e\u7b49\u5f0f</p> \\[ \\begin{array}{l} x_1x_0 + x_1 &amp;= 2x_1x_0 + x_1 \u2212 x_1x_0 \\\\              &amp;= 2x_1x_0 + x_1(1 \u2212 x_0) \\\\              &amp;= 2x_1x_0 + x_1x_0 \\end{array} \\] <p>we can remove the two terms x 1 x 0 and x 1 from column 2, replacing them by x 1 x 0 in column 2 and x 1 x 0 in column 3. This transformation reduces the width of the final carry-propagate adder from 7 to 6 bits. Similar substitutions can be made for the terms in columns 4 and 6, but they do not lead to any simplification or speedup in this particular example. The design of truncated and modular squarers will be explored in the end-of-chapter problems.</p> <p>\u6211\u4eec\u53ef\u4ee5\u4ece\u7b2c 2 \u5217\u4e2d\u5220\u9664\u4e24\u9879 x 1 x 0 \u548c x 1\uff0c\u5e76\u7528\u7b2c 2 \u5217\u4e2d\u7684 x 1 x 0 \u548c\u7b2c 3 \u5217\u4e2d\u7684 x 1 x 0 \u66ff\u6362\u5b83\u4eec\u3002\u6b64\u8f6c\u6362\u5c06\u6700\u7ec8\u8fdb\u4f4d\u4f20\u64ad\u52a0\u6cd5\u5668\u7684\u5bbd\u5ea6\u4ece 7 \u4f4d\u51cf\u5c11\u5230 6 \u4f4d\u3002\u53ef\u4ee5\u5bf9\u7b2c 4 \u5217\u548c\u7b2c 6 \u5217\u4e2d\u7684\u672f\u8bed\u8fdb\u884c\u7c7b\u4f3c\u7684\u66ff\u6362\uff0c\u4f46\u5b83\u4eec\u4e0d\u4f1a\u5bfc\u81f4\u6b64\u7279\u5b9a\u793a\u4f8b\u4e2d\u7684\u4efb\u4f55\u7b80\u5316\u6216\u52a0\u901f\u3002\u622a\u65ad\u548c\u6a21\u5757\u5316\u5e73\u65b9\u5668\u7684\u8bbe\u8ba1\u5c06\u5728\u672c\u7ae0\u672b\u5c3e\u7684\u95ee\u9898\u4e2d\u63a2\u8ba8\u3002</p> <p>For a small word width k, the square of a k-bit number can be easily obtained from a 2 k \u00d7 ( 2 k \u2212 2 ) lookup table, whereas a much larger table would be needed for multiplying two k-bit numbers. In fact, two numbers can be multiplied based on two table-lookup evaluations of the square function, and three additions, using the identity ax = [ (a +  x) 2 \u2212  (a \u2212  x) 2] / 4. Chapter 24 contains a comprehensive discussion of table-lookup methods for performing, or facilitating, arithmetic computations. </p> <p>\u5bf9\u4e8e\u8f83\u5c0f\u7684\u5b57\u5bbd \\(k\\)\uff0c\u53ef\u4ee5\u4ece \\(2^k \u00d7 (2 k \u2212 2)\\) \u67e5\u627e\u8868\u8f7b\u677e\u83b7\u5f97 \\(k\\) \u4f4d\u6570\u5b57\u7684\u5e73\u65b9\uff0c\u800c\u5c06\u4e24\u4e2a \\(k\\) \u4f4d\u6570\u5b57\u76f8\u4e58\u5219\u9700\u8981\u66f4\u5927\u7684\u8868\u3002\u4e8b\u5b9e\u4e0a\uff0c\u4e24\u4e2a\u6570\u76f8\u4e58\u53ef\u4ee5\u901a\u8fc7\u4e24\u4e2a\u5e73\u65b9\u51fd\u6570\u7684\u67e5\u8868\u6c42\u503c\uff0c\u4ee5\u53ca\u4e09\u4e2a\u52a0\u6cd5\uff0c\u4f7f\u7528\u6052\u7b49\u5f0f \\(ax = [ (a + x)^2 \u2212 (a \u2212 x)^2] / 4\\)  \u5b8c\u6210\u3002\u7b2c 24 \u7ae0\u5168\u9762\u8ba8\u8bba\u4e86\u7528\u4e8e\u6267\u884c\u6216\u4fc3\u8fdb\u7b97\u672f\u8ba1\u7b97\u7684\u67e5\u8868\u65b9\u6cd5\u3002</p> <p>Finally, exponentiation can be performed by a sequence of squaring or square-multiply steps. For example, based on the identity</p> <p>\u6700\u540e\uff0c\u6c42\u5e42\u53ef\u4ee5\u901a\u8fc7\u4e00\u7cfb\u5217\u5e73\u65b9\u6216\u5e73\u65b9-\u4e58\u6b65\u9aa4\u6765\u6267\u884c\u3002\u4f8b\u5982\uff0c\u6839\u636e\u7b49\u5f0f</p> <p>\\(x^{13} = x((x(x^2)) ^2 ) ^2\\)</p> <p>we can compute  x 13 by squaring  x, multiplying the result by  x, squaring twice, and finally multiplying the result by  x. We discuss exponentiation for both real and integer operands in greater detail in Section 23.3. </p> <p>\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u5bf9 x \u8fdb\u884c\u5e73\u65b9\u3001\u5c06\u7ed3\u679c\u4e58\u4ee5 x\u3001\u5e73\u65b9\u4e24\u6b21\u3001\u6700\u540e\u5c06\u7ed3\u679c\u4e58\u4ee5 x \u6765\u8ba1\u7b97 x 13\u3002\u6211\u4eec\u5728\u7b2c 23.3 \u8282\u4e2d\u66f4\u8be6\u7ec6\u5730\u8ba8\u8bba\u4e86\u5b9e\u6570\u548c\u6574\u6570\u64cd\u4f5c\u6570\u7684\u6c42\u5e42\u3002</p>"},{"location":"Part_03/12/#126","title":"12.6 \u4e58\u52a0\u6df7\u5408\u5355\u5143","text":"<p>In certain computations, such as vector inner-product, convolution, or fast Fourier transform, multiplications are commonly followed by additions. In such cases, implementing a multiply-add unit in hardware to compute  p =  ax +  y  might be cost-effective. Since the preceding computations are commonplace in signal processing applications, most modern digital signal processors have built-in hardware capability for multiply-add, or multiply-accumulate, operations. </p> <p>\u5728\u67d0\u4e9b\u8ba1\u7b97\u4e2d\uff0c\u4f8b\u5982\u5411\u91cf\u5185\u79ef\u3001\u5377\u79ef\u6216\u5feb\u901f\u5085\u7acb\u53f6\u53d8\u6362\uff0c\u4e58\u6cd5\u540e\u901a\u5e38\u7d27\u63a5\u7740\u52a0\u6cd5\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u5728\u786c\u4ef6\u4e2d\u5b9e\u73b0\u4e58\u52a0\u5355\u5143\u6765\u8ba1\u7b97 \\(p = ax + y\\) \u53ef\u80fd\u5177\u6709\u6210\u672c\u6548\u76ca\u3002\u7531\u4e8e\u4e0a\u8ff0\u8ba1\u7b97\u5728\u4fe1\u53f7\u5904\u7406\u5e94\u7528\u4e2d\u5f88\u5e38\u89c1\uff0c\u56e0\u6b64\u5927\u591a\u6570\u73b0\u4ee3\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u5668\u90fd\u5177\u6709\u7528\u4e8e\u4e58\u52a0\u6216\u4e58\u7d2f\u52a0\u8fd0\u7b97\u7684\u5185\u7f6e\u786c\u4ef6\u529f\u80fd\u3002</p> <p>We have already discussed AMMs (Section 12.2) that add one or two numbers to the product of their multiplicative inputs. Similarly, at several points in this and the preceding three chapters we have hinted at a means of incorporating an additive input into the multiplication process (e.g., by initializing the cumulative partial product to a nonzero value or by entering a nonzero value to the top row of an array multiplier). In all cases, however, the additive inputs are comparable in width to the multiplicative inputs. </p> <p>\u6211\u4eec\u5df2\u7ecf\u8ba8\u8bba\u8fc7 AMM\uff08\u7b2c 12.2 \u8282\uff09\uff0c\u5b83\u5c06\u4e00\u6216\u4e24\u4e2a\u6570\u5b57\u52a0\u5230\u8f93\u5165\u7684\u4e58\u79ef\u4e0a\u3002\u7c7b\u4f3c\u5730\uff0c\u5728\u672c\u7ae0\u548c\u524d\u4e09\u7ae0\u7684\u4e00\u4e9b\u5730\u65b9\uff0c\u6211\u4eec\u6697\u793a\u4e86\u5c06\u52a0\u6cd5\u8f93\u5165\u5408\u5e76\u5230\u4e58\u6cd5\u8fc7\u7a0b\u4e2d\u7684\u65b9\u6cd5\uff08\u4f8b\u5982\uff0c\u901a\u8fc7\u5c06\u7d2f\u79ef\u90e8\u5206\u79ef\u521d\u59cb\u5316\u4e3a\u975e\u96f6\u503c\u6216\u901a\u8fc7\u5728\u6570\u7ec4\u4e58\u6cd5\u5668\u7684\u9876\u884c\u8f93\u5165\u975e\u96f6\u503c\uff09\u3002\u7136\u800c\uff0c\u5728\u6240\u6709\u60c5\u51b5\u4e0b\uff0c\u52a0\u6cd5\u8f93\u5165\u7684\u5bbd\u5ea6\u4e0e\u4e58\u6cd5\u8f93\u5165\u7684\u5bbd\u5ea6\u76f8\u5f53\u3002</p> <p>The type of multiply-add operation of interest to us here involves an additive input that is significantly wider than the multiplicative inputs (perhaps even wider than their product). For example, we might have 24-bit multiplicative inputs, yielding a 48-bit product, that is then added to a 64-bit running sum. The wider running sum may be required to avoid overflow in the intermediate computation steps or to provide greater precision to counter the accumulation of errors when dealing with fractional values. </p> <p>\u6211\u4eec\u5728\u8fd9\u91cc\u611f\u5174\u8da3\u7684\u4e58\u52a0\u8fd0\u7b97\u7c7b\u578b\u6d89\u53ca\u52a0\u6cd5\u8f93\u5165\uff0c\u8be5\u52a0\u6cd5\u8f93\u5165\u660e\u663e\u5bbd\u4e8e\u4e58\u6cd5\u8f93\u5165\uff08\u751a\u81f3\u53ef\u80fd\u6bd4\u5b83\u4eec\u7684\u4e58\u79ef\u66f4\u5bbd\uff09\u3002\u4f8b\u5982\uff0c\u6211\u4eec\u53ef\u80fd\u6709 24 \u4f4d\u4e58\u6cd5\u8f93\u5165\uff0c\u4ea7\u751f 48 \u4f4d\u4e58\u79ef\uff0c\u7136\u540e\u5c06\u5176\u6dfb\u52a0\u5230 64 \u4f4d\u8fd0\u884c\u548c\u4e2d\u3002\u53ef\u80fd\u9700\u8981\u66f4\u5bbd\u7684\u8fd0\u884c\u603b\u548c\u4ee5\u907f\u514d\u4e2d\u95f4\u8ba1\u7b97\u6b65\u9aa4\u4e2d\u7684\u6ea2\u51fa\u6216\u63d0\u4f9b\u66f4\u9ad8\u7684\u7cbe\u5ea6\u4ee5\u5728\u5904\u7406\u5206\u6570\u503c\u65f6\u62b5\u6d88\u8bef\u5dee\u7684\u7d2f\u79ef\u3002</p> <p>Figure 12.19 depicts several methods for incorporating a wide additive input into the multiplication process. First, we might use a CSA tree to find the product of the multiplicative inputs in carry-save form and then add the result to the additive input using a CSA followed by a fast adder (Fig. 12.19a). To avoid a carry-propagate addition in every step, the running sum may itself be kept in carry-save form, leading to the requirement for two CSA levels (Fig. 12.19b). The resulting hardware implementation for this latter scheme is quite similar to the partial-tree multiplier of Fig. 11.9. </p> <p>\u56fe 12.19 \u63cf\u8ff0\u4e86\u5c06\u5bbd\u52a0\u6cd5\u8f93\u5165\u5408\u5e76\u5230\u4e58\u6cd5\u8fc7\u7a0b\u4e2d\u7684\u51e0\u79cd\u65b9\u6cd5\u3002\u9996\u5148\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528 CSA \u6811\u4ee5\u8fdb\u4f4d\u4fdd\u5b58\u5f62\u5f0f\u67e5\u627e\u4e58\u6cd5\u8f93\u5165\u7684\u4e58\u79ef\uff0c\u7136\u540e\u4f7f\u7528 CSA \u548c\u5feb\u901f\u52a0\u6cd5\u5668\u5c06\u7ed3\u679c\u52a0\u5230\u52a0\u6cd5\u8f93\u5165\uff08\u56fe 12.19a\uff09\u3002\u4e3a\u4e86\u907f\u514d\u5728\u6bcf\u4e2a\u6b65\u9aa4\u4e2d\u8fdb\u884c\u8fdb\u4f4d\u4f20\u64ad\u52a0\u6cd5\uff0c\u8fd0\u884c\u548c\u672c\u8eab\u53ef\u4ee5\u4fdd\u6301\u8fdb\u4f4d\u4fdd\u5b58\u5f62\u5f0f\uff0c\u4ece\u800c\u5bfc\u81f4\u9700\u8981\u4e24\u4e2a CSA \u7ea7\u522b\uff08\u56fe 12.19b\uff09\u3002\u540e\u4e00\u79cd\u65b9\u6848\u7684\u6700\u7ec8\u786c\u4ef6\u5b9e\u73b0\u4e0e\u56fe 11.9 \u7684\u90e8\u5206\u6811\u4e58\u6cd5\u5668\u975e\u5e38\u76f8\u4f3c\u3002</p> <p>Alternatively, the two-step process of computing the product in carry-save form and adding it to the running sum can be replaced by a merged multiply-add operation that directly operates on the dots from the additive input(s) and the partial products bit matrix (Figs. 12.19c and 12.19d). In the latter case, the speed and cost penalties for including the additive input in a parallel tree multiplier are fairly small, thus leading to a cost-effective design. We will revisit this notion of merged arithmetic in Section 23.6.</p> <p>\u6216\u8005\uff0c\u4ee5\u8fdb\u4f4d\u4fdd\u5b58\u5f62\u5f0f\u8ba1\u7b97\u4e58\u79ef\u5e76\u5c06\u5176\u52a0\u5230\u8fd0\u884c\u548c\u4e2d\u7684\u4e24\u6b65\u8fc7\u7a0b\u53ef\u4ee5\u7531\u76f4\u63a5\u5bf9\u6765\u81ea\u52a0\u6cd5\u8f93\u5165\u548c\u90e8\u5206\u4e58\u79ef\u7684\u70b9\u8fdb\u884c\u64cd\u4f5c\u7684\u5408\u5e76\u4e58\u52a0\u8fd0\u7b97\u6765\u4ee3\u66ff \u4f4d\u77e9\u9635\uff08\u56fe 12.19c \u548c 12.19d\uff09\u3002 \u5728\u540e\u4e00\u79cd\u60c5\u51b5\u4e0b\uff0c\u5c06\u52a0\u6027\u8f93\u5165\u5305\u542b\u5728\u5e76\u884c\u6811\u4e58\u6cd5\u5668\u4e2d\u7684\u901f\u5ea6\u548c\u6210\u672c\u635f\u5931\u76f8\u5f53\u5c0f\uff0c\u4ece\u800c\u5b9e\u73b0\u5177\u6709\u6210\u672c\u6548\u76ca\u7684\u8bbe\u8ba1\u3002 \u6211\u4eec\u5c06\u5728 23.6 \u8282\u4e2d\u91cd\u65b0\u8ba8\u8bba\u5408\u5e76\u7b97\u672f\u7684\u6982\u5ff5\u3002</p> <p></p> <p>Multiply-add and multiply-accumulate units are particularly useful when dealing with floating-point operands. Merging the two steps, so that a single rounding operation is used just before producing the final result, leads to a fused multiply-add or fused multiply-accumulate operation. Such a fused operation saves time and reduces computation errors. These notions will be further discussed in Section 18.5.</p> <p>\u4e58\u52a0\u548c\u4e58\u52a0\u5355\u5143\u5728\u5904\u7406\u6d6e\u70b9\u64cd\u4f5c\u6570\u65f6\u7279\u522b\u6709\u7528\u3002\u5408\u5e76\u8fd9\u4e24\u4e2a\u6b65\u9aa4\uff0c\u4ee5\u4fbf\u5728\u751f\u6210\u6700\u7ec8\u7ed3\u679c\u4e4b\u524d\u4f7f\u7528\u5355\u4e2a\u820d\u5165\u8fd0\u7b97\uff0c\u4ece\u800c\u4ea7\u751f\u878d\u5408\u4e58\u52a0\u6216\u878d\u5408\u4e58\u7d2f\u52a0\u8fd0\u7b97\u3002\u8fd9\u79cd\u878d\u5408\u64cd\u4f5c\u53ef\u4ee5\u8282\u7701\u65f6\u95f4\u5e76\u51cf\u5c11\u8ba1\u7b97\u9519\u8bef\u3002\u8fd9\u4e9b\u6982\u5ff5\u5c06\u5728 18.5 \u8282\u4e2d\u8fdb\u4e00\u6b65\u8ba8\u8bba\u3002</p>"},{"location":"Part_03/12/#_1","title":"\u95ee\u9898\uff08\u7565\uff09","text":""},{"location":"Part_03/12/#_2","title":"\u53c2\u8003\u6587\u732e\u548c\u8fdb\u4e00\u6b65\u9605\u8bfb","text":"<pre><code>[Alia91] Alia, G., and E. Martinelli, \u201cA VLSI Modulo m Multiplier,\u201d IEEE Trans. Computers,\n         Vol. 40, No. 7, pp. 873\u2013878, 1991.\n[Chen79] Chen, I.-N., and R. Willowner, \u201cAn O(n) Parallel Multiplier with Bit-Sequential\n         Input and Output,\u201d IEEE Trans. Computers, Vol. 28, No. 10, pp. 721\u2013727, 1979.\n[Dany05] Danysh, A., and D. Tan, \u201cArchitecture and Implementation of a Vector/SIMD\n         Multiply-Accumulate Unit,\u201d IEEE Trans. Computers, Vol. 54, No. 3, pp. 284\u2013293,\n         2005.\n[Ghes71] Ghest, C., \u201cMultiplying Made Easy for Digital Assemblies,\u201d Electronics, Vol. 44,\n         pp. 56\u201361, 22 November, 1971.\n[Hakk01] Hakkennes, E., and S. Vassiliadis, \u201cMultimedia Execution Hardware Accelerator,\u201d\n         J. VLSI Signal Processing, Vol. 28, No. 3, pp. 221\u2013234, 2001.\n[Hayn96] Haynal, S., and B. Parhami, \u201cArithmetic Structures for Inner-Product and Other\n         Computations Based on a Latency-Free Bit-Serial Multiplier Design,\u201d Proc. 30th\n         Asilomar Conf. Signals, Systems, and Computers, pp. 197\u2013201, 1996.\n[Hwan79] Hwang, K., Computer Arithmetic: Principles, Architecture, and Design, Wiley,\n         1979.\n[Ienn94] Ienne, P., and M. A. Viredaz, \u201cBit-Serial Multipliers and Squarers,\u201d IEEE Trans.\n         Computers, Vol. 43, No. 12, pp. 1445\u20131450, 1994.\n[Kung82] Kung, H. T., \u201cWhy Systolic Architectures?\u201d Computer, Vol. 15, No. 1, pp. 37\u201346,\n         1982.\n[Lidd00] Liddicoat, A. A., and M. J. Flynn, \u201cParallel Square and Cube Computations,\u201d Proc.\n         34th Asilomar Conf. Signals, Systems, and Computers, pp. 1325\u20131329, 2000.\n[Mont05] Montgomery, P., \u201cFive, Six, and Seven-Term Karatsuba-Like Formulae,\u201d IEEE\n         Trans. Computers, Vol. 54, No. 3, pp. 362\u2013369, 2005.\n[Parh93] Parhami, B., and H.-F. Lai, \u201cAlternate Memory Compression Schemes for Modular\n         Multiplication,\u201d IEEE Trans. Signal Processing, Vol. 41, No. 3, pp. 1378\u20131385,\n         1993.\n[Pies94] Piestrak, S. J., \u201cDesign of Residue Generators and Multioperand Modular Adders\n         Using Carry-Save Adders,\u201d IEEE Trans. Computers, Vol. 43, No. 1, pp. 68\u201377,\n         1994.\n[Stro03] Strollo, A. G. M., and D. De Caro, \u201cBooth Folding Encoding for High Performance\n         Squarer Circuits,\u201d IEEE Trans. Circuits and Systems II, Vol. 50, No. 5, pp. 250\u2013254,\n         2003.\n[Verg07] Vergos, H. T., and C. Efstathiou, \u201cDesign of Efficient Modulo 2n + 1 Multipliers,\u201d\n         IET Computers and Digital Techniques, Vol. 1, No. 1, pp. 49\u201357, 2007.\n[Walt04] Walters, E. G. III, M. J. Schulte, and M. G. Arnold, \u201cTruncated Squarers with\n         Constant and Variable Correction,\u201d Advanced Signal Processing Algorithms,\n         Architectures, and Implementations XIV (Proc. SPIE Conf. 5559), pp. 40\u201350, 2004.\n[Wire99] Wires, K. E., M. J. Schulte, L. P. Marquette, and P. I. Balzola, \u201cCombined Unsigned\n         and Two\u2019s Complement Squarers,\u201d Proc. 33rd Asilomar Conf. Signals Systems and\n         Computers, pp. 1215\u20131219, 1999.\n</code></pre>"},{"location":"Part_04/","title":"\u9664\u6cd5","text":"<p>DIVISION</p> <p>\u201cProbably nothing in the modern world could have more astonished a Greek mathematician than to learn that . . . a large proportion of the population of Western Europe could perform the operation of division for the largest numbers.\u201d               \u2014 ALFRED WHITEHEAD , AN INTRODUCTION TO MATHEMATICS , 1911</p> <p>\u201cTo divide one\u2019s life by years is of course to tumble into a trap set by our own arithmetic.\u201d               \u2014 CLIFTON FADIMAN</p> <p>\u201c\u5728\u73b0\u4ee3\u4e16\u754c\u4e2d\uff0c\u4e5f\u8bb8\u6ca1\u6709\u4ec0\u4e48\u6bd4\u5f97\u77e5\u8fd9\u4e00\u70b9\u66f4\u8ba9\u5e0c\u814a\u6570\u5b66\u5bb6\u611f\u5230\u60ca\u8bb6\u7684\u4e86\u2026\u2026 \u897f\u6b27\u7684\u5f88\u5927\u4e00\u90e8\u5206\u4eba\u53e3\u53ef\u4ee5\u8fdb\u884c\u6700\u5927\u6570\u7684\u9664\u6cd5\u8fd0\u7b97\u3002\u201d           \u2014 \u963f\u5c14\u5f17\u96f7\u5fb7\u00b7\u6000\u7279\u6d77\u5fb7\uff0c\u300a\u6570\u5b66\u5bfc\u8bba\u300b\uff0c1911</p> <p>\u201c\u7528\u5c81\u6708\u6765\u5212\u5206\u4e00\u4e2a\u4eba\u7684\u751f\u547d\uff0c\u5f53\u7136\u4f1a\u9677\u5165\u6211\u4eec\u81ea\u5df1\u7b97\u672f\u8bbe\u7f6e\u7684\u9677\u9631\u3002\u201d           \u2014 \u514b\u5229\u592b\u987f\u00b7\u6cd5\u8fea\u66fc</p> <p>DIVISION IS THE MOST COMPLEX OF THE FOUR BASIC ARITHMETIC OPERATIONS and the hardest one to speed up. Thus, dividers are more expensive and/or slower than multipliers. Fortunately, division operations are also less common than multiplications.Two classes of dividers are discussed here. In digit-recurrence schemes, the quotient is generated one digit at a time, beginning at the mostsignificant end. Binary versions of digit-recurrence division can be implemented through shifting and addition, in much the same way as shift/add multiplication schemes. Determining the digits of the quotient from the most-significant end allows us to\u201cconverge\u201d to a k-digit quotient in k cycles. Speeding up of division via reducing the number of shift/add cycles leads to high-radix dividers. Array dividers as well as convergence methods that require far fewer than k iterations, with each iteration being more complex, are also discussed. This part is composed of the following four chapters:</p> <p>\u9664\u6cd5\u662f\u56db\u79cd\u57fa\u672c\u7b97\u672f\u8fd0\u7b97\u4e2d\u6700\u590d\u6742\u7684\u8fd0\u7b97\uff0c\u4e5f\u662f\u6700\u96be\u52a0\u901f\u7684\u8fd0\u7b97\u3002 \u56e0\u6b64\uff0c\u9664\u6cd5\u5668\u6bd4\u4e58\u6cd5\u5668\u66f4\u6602\u8d35\u548c/\u6216\u66f4\u6162\u3002 \u5e78\u8fd0\u7684\u662f\uff0c\u9664\u6cd5\u8fd0\u7b97\u4e5f\u4e0d\u5982\u4e58\u6cd5\u5e38\u89c1\u3002\u8fd9\u91cc\u8ba8\u8bba\u4e24\u7c7b\u9664\u6cd5\u5668\u3002 \u5728\u6570\u5b57\u5faa\u73af\u65b9\u6848\u4e2d\uff0c\u5546\u4ece\u6700\u9ad8\u6709\u6548\u7aef\u5f00\u59cb\u4e00\u6b21\u751f\u6210\u4e00\u4f4d\u6570\u5b57\u3002 \u4e8c\u8fdb\u5236\u7248\u672c\u7684\u6570\u5b57\u5faa\u73af\u9664\u6cd5\u53ef\u4ee5\u901a\u8fc7\u79fb\u4f4d\u548c\u52a0\u6cd5\u6765\u5b9e\u73b0\uff0c\u5176\u65b9\u5f0f\u4e0e\u79fb\u4f4d/\u52a0\u6cd5\u4e58\u6cd5\u65b9\u6848\u975e\u5e38\u76f8\u4f3c\u3002\u4ece\u6700\u9ad8\u6709\u6548\u7aef\u786e\u5b9a\u5546\u7684\u6570\u5b57\u4f7f\u6211\u4eec\u80fd\u591f\u7528 k \u5468\u671f\u201c\u6536\u655b\u201d\u4e3a k \u4f4d\u6570\u5b57\u7684\u5546\u3002 \u901a\u8fc7\u51cf\u5c11\u79fb\u4f4d/\u52a0\u6cd5\u5468\u671f\u7684\u6570\u91cf\u6765\u52a0\u901f\u9664\u6cd5\uff0c\u5c31\u662f\u9ad8\u57fa\u6570\u9664\u6cd5\u5668\u3002 \u8fd8\u8ba8\u8bba\u4e86\u6570\u7ec4\u9664\u6cd5\u5668\u4ee5\u53ca\u9700\u8981\u8fdc\u5c11\u4e8e k \u6b21\u8fed\u4ee3\u7684\u6536\u655b\u65b9\u6cd5\uff0c\u5e76\u4e14\u6bcf\u6b21\u8fed\u4ee3\u90fd\u66f4\u52a0\u590d\u6742\u3002 \u672c\u90e8\u5206\u7531\u4ee5\u4e0b\u56db\u7ae0\u7ec4\u6210\uff1a</p> <ul> <li>\u7b2c\u5341\u4e09\u7ae0 \u57fa\u7840\u9664\u6cd5\u65b9\u6848 Basic Division Schemes</li> <li>\u7b2c\u5341\u56db\u7ae0 \u9ad8\u57fa\u9664\u6cd5\u5668 High-Radix Dividers</li> <li>\u7b2c\u5341\u4e94\u7ae0 \u5176\u5b83\u9664\u6cd5\u5668 Variations in Dividers</li> <li>\u7b2c\u5341\u516d\u7ae0 \u9664\u6cd5\u7684\u6536\u655b\u7b97\u6cd5 Division by Convergence</li> </ul>"},{"location":"Part_04/13/","title":"13. \u57fa\u7840\u9664\u6cd5\u65b9\u6848","text":"<p>Basic Division Schemes</p> <ul> <li>13.1 \u79fb\u4f4d\u76f8\u51cf\u9664\u6cd5\u7b97\u6cd5 SHIFT/SUBTRACT DIVISION ALGORITHMS</li> <li>13.2 \u7a0b\u5e8f\u5b9e\u73b0\u7684\u9664\u6cd5\u7b97\u6cd5 PROGRAMMED DIVISION</li> <li>13.3 \u6062\u590d\u4f59\u6570\u9664\u6cd5\u5668 RESTORING HARDWARE DIVIDERS</li> <li>13.4 \u4e0d\u6062\u590d\u4f59\u6570\u9664\u6cd5\u5668\u4e0e\u6709\u7b26\u53f7\u6570\u9664\u6cd5 NONRESTORING AND SIGNED DIVISION</li> <li>13.5 \u9664\u4ee5\u4e00\u4e2a\u5e38\u6570 DIVISION BY CONSTANTS</li> <li>13.6 \u57fa2 SRT\u9664\u6cd5 RADIX-2 SRT DIVISION</li> </ul>"},{"location":"Part_04/14/","title":"14. \u9ad8\u57fa\u9664\u6cd5\u5668","text":"<p>High-Radix Dividers</p> <ul> <li>14.1 \u57fa\u7840\u9ad8\u57fa\u9664\u6cd5\u5668 BASICS OF HIGH-RADIX DIVISION</li> <li>14.2 \u8fd0\u7528\u8fdb\u4f4d\u4fdd\u7559\u52a0\u6cd5\u5668 USING CARRY SAVE ADDERS</li> <li>14.3 \u57fa4 SRT\u9664\u6cd5 RADIX-4 SRT DIVISION</li> <li>14.4 \u4e00\u822c\u9ad8\u57fa\u9664\u6cd5\u5668 GENERAL HIGH-RADIX DIVIDERS</li> <li>14.5 \u5546\u4f4d\u9009\u62e9 QUOTIENT DIGIT SELECTION</li> <li>14.5 p-d\u56fe\u7684\u5e94\u7528 USING p-d PLOTS IN PRACTICE</li> </ul>"},{"location":"Part_04/15/","title":"15. \u5176\u5b83\u9664\u6cd5\u5668","text":"<p>Variations in Dividers</p> <ul> <li>15.1 \u7f29\u653e\u540e\u7684\u9664\u6cd5 DIVISION WITH PRESCALING</li> <li>15.2 \u91cd\u53e0\u5546\u4f4d\u9009\u62e9 OVERLAPPED QUOTIENT DIGIT SELECTION</li> <li>15.3 \u7ec4\u5408\u4e0e\u9635\u5217\u9664\u6cd5\u5668 COMBINATIONAL AND ARRAY DIVMIDERS</li> <li>15.4 \u6a21\u9664\u6cd5\u5668\u4e0e\u538b\u7f29\u5668 MODULAR DIVIDERS AND REDUCERS</li> <li>15.5 \u5012\u6570\u8fd0\u7b97\u5668 THE SPECIAL CASE OF RECIPROCATION</li> <li>15.6 \u4e58\u9664\u6df7\u5408\u5355\u5143 COMBINED MULTIPLY/DIVIDE UNITS</li> </ul>"},{"location":"Part_04/16/","title":"16. \u9664\u6cd5\u7684\u6536\u655b\u7b97\u6cd5","text":"<p>Division by Convergence</p> <ul> <li>16.1 \u4e00\u822c\u6536\u655b\u7b97\u6cd5 GENERAL CONVERGENCE METHODS</li> <li>16.2 \u9664\u6cd5\u7684\u91cd\u590d\u76f8\u4e58\u7b97\u6cd5 DIVISION BY REPEATED MULTIPLICATIONS</li> <li>16.3 \u9664\u6cd5\u7684\u8fed\u4ee3\u7b97\u6cd5 DIVISION BY RECIPROCATION</li> <li>16.4 \u52a0\u901f\u9664\u6cd5\u6536\u655b SPEEDUP OF CONVERGENCE DIVISION</li> <li>16.5 \u786c\u4ef6\u5b9e\u73b0 HARDWARE IMPLEMENTATION</li> <li>16.6 \u67e5\u627e\u8868\u5c3a\u5bf8\u5206\u6790 ANALYSIS OF LOOKUP TABLE SIZE</li> </ul>"},{"location":"Part_05/","title":"\u5b9e\u6570\u7b97\u6570","text":"<p>REAL ARITHMETIC </p> <p>\u201cIt is the mark of an educated man to look for precision in each class of things just so far as the nature of the subject admits.\u201d               \u2014 ARISTOTLE</p> <p>\u201cAll exact science is dominated by the idea of approximation.\u201d               \u2014 BERTRANDA . RUSSELL</p> <p>\u201c\u53d7\u8fc7\u6559\u80b2\u7684\u4eba\u7684\u6807\u5fd7\u662f\u5728\u6bcf\u4e00\u7c7b\u4e8b\u7269\u7684\u672c\u8d28\u5141\u8bb8\u7684\u8303\u56f4\u5185\u5bfb\u6c42\u7cbe\u786e\u6027\u3002\u201d               \u2014 \u4e9a\u91cc\u58eb\u591a\u5fb7 \u201c\u6240\u6709\u7cbe\u786e\u79d1\u5b66\u90fd\u53d7\u8fd1\u4f3c\u601d\u60f3\u7684\u652f\u914d\u3002\u201d               \u2014 \u8d1d\u7279\u5170\u8fbe.\u7f57\u7d20</p> <p>IN MANY SCIENTIFIC AND ENGINEERING COMPUTATIONS, NUMBERS IN A WIDE RANGE, from very small to extremely large, are processed. Fixed-point number representations and arithmetic are ill-suited to such applications. For example, a fixed-point decimal number system capable of representing both \\(10^{\u221220}\\) and \\(10^{20}\\) would require at least 40 decimal digits and even then, would not offer much precision with numbers close to \\(10^{\u221220}\\).Thus,we need special number representations that possess both a wide range and acceptable precision. Floating-point numbers constitute the primary mode of real arithmetic in most digital systems. In this part, we discuss key topics in floating-point number representation, arithmetic, and computational errors.Additionally,we cover alternative representations,such as logarithmic and rational number systems,that can offer certain advantages in range and/or accuracy. This part is composed of the following four chapters:</p> <p>\u5728\u8bb8\u591a\u79d1\u5b66\u548c\u5de5\u7a0b\u8ba1\u7b97\u4e2d\uff0c\u90fd\u4f1a\u5904\u7406\u4ece\u975e\u5e38\u5c0f\u5230\u6781\u5927\u7684\u5404\u79cd\u6570\u5b57\u3002 \u5b9a\u70b9\u6570\u8868\u793a\u548c\u7b97\u672f\u4e0d\u9002\u5408\u6b64\u7c7b\u5e94\u7528\u3002 \u4f8b\u5982\uff0c\u80fd\u591f\u8868\u793a \\(10^{\u221220}\\) \u548c \\(10^{20}\\) \u7684\u5b9a\u70b9\u5341\u8fdb\u5236\u6570\u5b57\u7cfb\u7edf\u5c06\u9700\u8981\u81f3\u5c11 40 \u4f4d\u5341\u8fdb\u5236\u6570\u5b57\uff0c\u5373\u4f7f\u5982\u6b64\uff0c\u4e5f\u65e0\u6cd5\u4e3a\u63a5\u8fd1 \\(10^{\u221220}\\) \u7684\u6570\u5b57\u63d0\u4f9b\u592a\u591a\u7cbe\u5ea6\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u9700\u8981\u7279\u6b8a\u7684\u6570\u5b57\u8868\u793a\u5f62\u5f0f\u53ef\u4ee5\u540c\u65f6\u8868\u8fbe\u5f88\u5927\u7684\u8303\u56f4\u548c\u53ef\u63a5\u53d7\u7684\u7cbe\u5ea6\u3002\u6d6e\u70b9\u6570\u6784\u6210\u4e86\u5927\u591a\u6570\u6570\u5b57\u7cfb\u7edf\u4e2d\u5b9e\u9645\u7b97\u672f\u7684\u4e3b\u8981\u6a21\u5f0f\u3002 \u5728\u8fd9\u4e00\u90e8\u5206\u4e2d\uff0c\u6211\u4eec\u8ba8\u8bba\u6d6e\u70b9\u6570\u8868\u793a\u3001\u7b97\u672f\u548c\u8ba1\u7b97\u8bef\u5dee\u65b9\u9762\u7684\u5173\u952e\u4e3b\u9898\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u4ecb\u7ecd\u4e86\u5176\u4ed6\u53d8\u79cd\u8868\u793a\uff0c\u4f8b\u5982\u5bf9\u6570\u548c\u6709\u7406\u6570\u7cfb\u7edf\uff0c\u5b83\u4eec\u53ef\u4ee5\u5728\u8303\u56f4\u548c/\u6216\u7cbe\u5ea6\u65b9\u9762\u63d0\u4f9b\u4e00\u5b9a\u7684\u4f18\u52bf\u3002 \u672c\u90e8\u5206\u7531\u4ee5\u4e0b\u56db\u7ae0\u7ec4\u6210\uff1a</p> <ul> <li>\u7b2c\u5341\u4e03\u7ae0 \u6d6e\u70b9\u6570\u8868\u793a Floating-Point Representations</li> <li>\u7b2c\u5341\u516b\u7ae0 \u6d6e\u70b9\u6570\u8fd0\u7b97 Floating-Point Operations</li> <li>\u7b2c\u5341\u4e5d\u7ae0 \u8bef\u5dee\u4e0e\u8bef\u5dee\u63a7\u5236 Errors and Error Control</li> <li>\u7b2c\u4e8c\u5341\u7ae0 \u7cbe\u786e\u53ef\u9760\u7684\u7b97\u672f Precise and Certifiable Arithmetic</li> </ul>"},{"location":"Part_05/17/","title":"17. \u6d6e\u70b9\u6570\u8868\u793a","text":"<p>Floating-Point Representations</p> <ul> <li>17.1 \u6d6e\u70b9\u6570 FLOATING POINT NUMBERS</li> <li>17.2 IEEE\u6d6e\u70b9\u6570\u6807\u51c6 THE IEEE FLOATING POINT STANDARD</li> <li>17.3 \u57fa\u7840\u6d6e\u70b9\u6570\u7b97\u672f BASIC FLOATING POINT ALGORITHMS</li> <li>17.4 \u820d\u5165\u4e0e\u5f02\u5e38 CONVERSIONS AND EXCEPTIONS</li> <li>17.5 \u820d\u5165\u65b9\u6cd5 ROUNDING SCHEMES</li> <li>17.6 \u5bf9\u6570\u8868\u793a\u7cfb\u7edf LOGARITHMIC NUMBER SYSTEMS</li> </ul>"},{"location":"Part_05/18/","title":"18. \u6d6e\u70b9\u6570\u8fd0\u7b97","text":"<p>Floating-Point Operations</p> <ul> <li>18.1 \u6d6e\u70b9\u6570\u52a0\u51cf\u6cd5 FLOATING-POINT ADDERS/SUBTRACTORS</li> <li>18.2 \u6d6e\u70b9\u6570\u7684\u9884\u3001\u540e\u79fb\u4f4d PRE- AND POSTSHIFTING</li> <li>18.3 \u8f6c\u6362\u4e0e\u5f02\u5e38 ROUNDING AND EXCEPTIONS</li> <li>18.4 \u6d6e\u70b9\u4e58\u6cd5\u5668\u4e0e\u9664\u6cd5\u5668 FLOATING-POINT MULTIPLIERS AND DIVIDERS</li> <li>18.5 \u4e58\u52a0\u5355\u5143(p=ax+b) FUSED MULTIPLY-ADD UNITS</li> <li>18.6 \u5bf9\u6570\u8868\u793a\u7cfb\u7edf\u7684\u8fd0\u7b97\u5355\u5143 OGARITHMIC ARITHMETIC UNT</li> </ul>"},{"location":"Part_05/19/","title":"19. \u8bef\u5dee\u4e0e\u8bef\u5dee\u63a7\u5236","text":"<p>Errors and Error Control</p> <ul> <li>19.1 \u8ba1\u7b97\u8bef\u5dee\u7684\u6765\u6e90 SOURCES OF COMPUTATIONAL ERRORS</li> <li>19.2 \u4ee3\u6570\u6cd5\u5219\u5931\u6548\u7684\u60c5\u51b5 INVALIDATED LAWS OF ALGEBRA</li> <li>19.3 \u6700\u574f\u8bef\u5dee\u7d2f\u8ba1 WORST-CASE ERROR ACCUMULATION</li> <li>19.4 \u8bef\u5dee\u5206\u5e03\u4e0e\u671f\u671b\u8bef\u5dee ERROR DISTRIBUTION AND EXPECTED ERRORS</li> <li> <p>19.5 \u524d\u5411\u8bef\u5dee\u5206\u6790 FORWARD ERROR ANALYSIS</p> <ul> <li>\u81ea\u52a8\u9519\u8bef\u5206\u6790 Automatic error analysis</li> <li>\u5c3e\u6570\u7b97\u672f Significance arithmetic</li> <li>\u566a\u58f0\u6a21\u5f0f\u8ba1\u7b97 Noisy mode computation</li> <li>\u533a\u95f4\u7b97\u6570 Interval arithmetic</li> </ul> </li> <li> <p>19.6 \u540e\u5411\u8bef\u5dee\u5206\u6790 BACKWARD ERROR ANALYSIS</p> </li> </ul>"},{"location":"Part_05/20/","title":"20. \u7cbe\u786e\u53ef\u9760\u7684\u7b97\u672f","text":"<p>Precise and Certifiable Arithmetic</p> <ul> <li>20.1 \u9ad8\u7cbe\u5ea6\u4e0e\u9ad8\u53ef\u9760\u6027 HIGH PRECISION AND CERTIFIABILITY</li> <li> <p>20.2 \u7cbe\u786e\u7b97\u6570 EXACT ARITHMETIC</p> <ul> <li>\u8fde\u5206\u6570 Continued fractions</li> <li>\u5b9a\u5206\u6570\u8868\u793a\u7cfb\u7edf Fixed-slash number systems</li> <li>\u6d6e\u5206\u6570\u8868\u793a\u7cfb\u7edf Floating-slash number systems</li> </ul> </li> <li> <p>20.3 \u591a\u500d\u7cbe\u5ea6\u7684\u7b97\u672f MULTIPRECISION ARITHMETIC</p> </li> <li>20.4 \u7cbe\u5ea6\u53ef\u53d8\u7684\u7b97\u672f VARIABLE PRECISION ARITHMETIC</li> <li>20.5 \u8bef\u5dee\u8fb9\u754c\u4e0e\u533a\u95f4\u7b97\u672f ERROR BOUNDING VIA INTERVAL ARITHMETIC</li> <li>20.6 \u81ea\u9002\u5e94\u4e0e\u60c5\u6027\u7b97\u672f ADAPTIVE AND LAZY ARITHMETIC</li> </ul>"},{"location":"Part_06/","title":"\u7279\u6b8a\u51fd\u6570\u6c42\u503c","text":"<p>FUNCTION EVALUATION</p> <p>\u201cI wrote this book and compiled in it everything that is necessary for the computer, avoiding both boring verbosity and misleading brevity.\u201d               \u2014 GHIYATH AL-DIN JAMSHID AL-KASHI, THE KEY TO COMPUTING (MIFTAH AL-HISABI ) , 1427</p> <p>\u201cSomeone told me that each equation I included in the book would halve the sales.\u201d               \u2014 STEPHEN HAWKING , A BRIEF HISTORY OF TIME , 1988</p> <p>\u201c\u6211\u5199\u4e86\u8fd9\u672c\u4e66\uff0c\u5e76\u5728\u5176\u4e2d\u6c47\u7f16\u4e86\u8ba1\u7b97\u673a\u6240\u9700\u7684\u6240\u6709\u5185\u5bb9\uff0c\u907f\u514d\u4e86\u65e0\u804a\u7684\u5197\u957f\u548c\u8bef\u5bfc\u6027\u7684\u7b80\u6d01\u3002\u201d               \u2014 GHIYATH AL-DIN JAMSHID AL-KASHI\uff0c\u8ba1\u7b97\u7684\u5173\u952e (MIFTAH AL-HISABI)\uff0c1427</p> <p>\u201c\u6709\u4eba\u544a\u8bc9\u6211\uff0c\u6211\u5728\u4e66\u4e2d\u5305\u542b\u7684\u6bcf\u4e2a\u65b9\u7a0b\u5f0f\u90fd\u4f1a\u4f7f\u9500\u552e\u989d\u51cf\u534a\u3002\u201d               \u2014 \u53f2\u8482\u82ac\u00b7\u970d\u91d1\uff0c\u300a\u65f6\u95f4\u7b80\u53f2\u300b\uff0c1988</p> <p>ONE WAY OF COMPUTING FUNCTIONS SUCH AS  \u221ax, SIN x, TANH x, LN x, AND \\(e^x\\) IS to evaluate their series expansions by means of addition, multiplication, and division operations. Another is through convergence computations of the type used for evaluating the  functions z/d and 1/d in Chapter 16. In this part, we introduce several methods for evaluating elementary and other functions.We begin by examining the important operation of extracting the square root of a number, covering both digit-recurrence and convergence square-rooting methods. We then devote two chapters to coordinate rotation digital computer (CORDIC) algorithms, other convergence methods, approximations, and merged arithmetic. We conclude by discussing versatile, and highly flexible, tablelookup schemes,which are assuming increasingly important roles as advances in digital technology lead to ever cheaper and denser memories.This part is composed of the following four chapters:</p> <p>\u8ba1\u7b97 \u221ax\u3001SIN x\u3001TANH x\u3001LN x \u548c \\(e^x\\) \u7b49\u51fd\u6570\u7684\u4e00\u79cd\u65b9\u6cd5\u662f\u901a\u8fc7\u52a0\u6cd5\u3001\u4e58\u6cd5\u548c\u9664\u6cd5\u8fd0\u7b97\u6765\u8ba1\u7b97\u5b83\u4eec\u7684\u7ea7\u6570\u5c55\u5f00\u5f0f\u3002 \u53e6\u4e00\u79cd\u65b9\u6cd5\u662f\u901a\u8fc7\u7b2c 16 \u7ae0\u4e2d\u7528\u4e8e\u6c42\u51fd\u6570 \\(z/d\\) \u548c \\(1/d\\) \u7684\u7c7b\u578b\u7684\u6536\u655b\u8ba1\u7b97\u3002\u5728\u8fd9\u4e00\u90e8\u5206\u4e2d\uff0c\u6211\u4eec\u4ecb\u7ecd\u51e0\u79cd\u8bc4\u4f30\u521d\u7b49\u51fd\u6570\u548c\u5176\u4ed6\u51fd\u6570\u7684\u65b9\u6cd5\u3002\u6211\u4eec\u9996\u5148\u68c0\u67e5\u63d0\u53d6\u5e73\u65b9\u7684\u91cd\u8981\u64cd\u4f5c \u6570\u5b57\u7684\u6839\uff0c\u6db5\u76d6\u6570\u5b57\u9012\u5f52\u548c\u6536\u655b\u5e73\u65b9\u6839\u65b9\u6cd5\u3002 \u7136\u540e\uff0c\u6211\u4eec\u7528\u4e24\u7ae0\u6765\u4ecb\u7ecd\u5750\u6807\u65cb\u8f6c\u6570\u5b57\u8ba1\u7b97\u673a\uff08CORDIC\uff09\u7b97\u6cd5\u3001\u5176\u4ed6\u6536\u655b\u65b9\u6cd5\u3001\u8fd1\u4f3c\u548c\u5408\u5e76\u7b97\u6cd5\u3002 \u6700\u540e\uff0c\u6211\u4eec\u8ba8\u8bba\u4e86\u901a\u7528\u4e14\u9ad8\u5ea6\u7075\u6d3b\u7684\u67e5\u8868\u65b9\u6848\uff0c\u968f\u7740\u6570\u5b57\u6280\u672f\u7684\u8fdb\u6b65\u5bfc\u81f4\u5b58\u50a8\u5668\u53d8\u5f97\u66f4\u52a0\u4fbf\u5b9c\u548c\u5bc6\u96c6\uff0c\u8fd9\u4e9b\u65b9\u6848\u6b63\u5728\u53d1\u6325\u8d8a\u6765\u8d8a\u91cd\u8981\u7684\u4f5c\u7528\u3002\u8fd9\u90e8\u5206\u7531\u4ee5\u4e0b\u56db\u7ae0\u7ec4\u6210\uff1a</p> <ul> <li>\u7b2c\u4e8c\u5341\u4e00\u7ae0 \u5e73\u65b9\u6839\u7b97\u6cd5 Square Rooting Methods</li> <li>\u7b2c\u4e8c\u5341\u4e8c\u7ae0 CORDIC\u7b97\u6cd5 The CORDIC Algorithms</li> <li>\u7b2c\u4e8c\u5341\u4e09\u7ae0 \u5176\u5b83\u51fd\u6570\u6c42\u503c\u65b9\u6cd5 Variations in Function Evaluation</li> <li>\u7b2c\u4e8c\u5341\u56db\u7ae0 \u67e5\u8868\u6cd5\u7b97\u672f Arithmetic by Table Lookup</li> </ul>"},{"location":"Part_06/21/","title":"21. \u5e73\u65b9\u6839\u7b97\u6cd5","text":"<p>Square Rooting Methods</p> <ul> <li>21.1 \u7eb8\u7b14\u7b97\u6cd5 THE PENCIL-AND PAPER ALGORITHM</li> <li>21.2 \u6062\u590d\u4f59\u6570\u79fb\u4f4d\u76f8\u51cf\u7b97\u6cd5 RESTORING SHIFT/SUBTRACT ALGORITHM</li> <li>21.3 \u4e8c\u8fdb\u5236\u4e0d\u6062\u590d\u4f59\u6570\u7b97\u6cd5 BINARY NONRESTORING ALGORITHM</li> <li>21.4 \u9ad8\u57fa\u5e73\u65b9\u6839\u7b97\u6cd5 HIGH-RADIX SQUARE ROOTING</li> <li>21.5 \u5e73\u65b9\u6839\u7684\u6536\u655b\u7b97\u6cd5 SQUARE ROOTING BY CONVERGENCE</li> <li>21.6 \u9ad8\u901f\u5e73\u65b9\u6839\u8fd0\u7b97\u5668 FAST HARDWARE SQUARE ROOTERS</li> </ul>"},{"location":"Part_06/22/","title":"22. CORDIC\u7b97\u6cd5","text":"<p>The CORDIC Algorithms</p> <ul> <li>22.1 \u65cb\u8f6c\u4e0e\u4f2a\u65cb\u8f6c ROTATIONS AND PSEUDOROTATIONS</li> <li>22.2 CORDIC\u7684\u57fa\u672c\u8fed\u4ee3\u8fc7\u7a0b BASIC CORDIC ITERATIONS</li> <li>22.3 CORDIC\u7684\u786c\u4ef6\u5b9e\u73b0 CORDIC HARDWARE</li> <li>22.4 \u5e7f\u4e49CORDIC\u7b97\u6cd5 GENERALIZED CORDIC</li> <li>22.5 CORDIC\u7684\u5e94\u7528 USING THE CORDIC METHOD</li> <li>22.6 \u4e00\u4e9b\u4ee3\u6570\u516c\u5f0f AN ALGEBRAIC FORMULATION</li> </ul>"},{"location":"Part_06/23/","title":"23. \u5176\u5b83\u51fd\u6570\u6c42\u503c\u65b9\u6cd5","text":"<p>Variations in Function Evaluation</p> <ul> <li>23.1 \u7ea6\u5316\u4e0e\u7f29\u5c0f\u8303\u56f4 NORMALIZATION AND RANGE REDUCTION</li> <li>23.2 \u5bf9\u6570\u6c42\u503c COMPUTING LOGARITHMS</li> <li>23.3 \u6307\u6570\u6c42\u503c EXPONENTIATION</li> <li>23.4 \u518d\u8bba\u9664\u6cd5\u4e0e\u5e73\u65b9\u6839 DIVISION AND SQUARE ROOTING,AGAIN</li> <li>23.5 \u8fd1\u4f3c\u51fd\u6570 USE OF APPROXIMATING FUNCTIONS</li> <li>23.6 \u878d\u5408\u7b97\u672f MERGED ARITHMETIC</li> </ul>"},{"location":"Part_06/24/","title":"24. \u67e5\u8868\u6cd5\u7b97\u672f","text":"<p>Arithmetic by Table Lookup</p> <ul> <li>24.1 \u76f4\u63a5\u67e5\u8868\u4e0e\u95f4\u63a5\u67e5\u8868 DIRECT AND INDIRECT TABLE LOOKUP</li> <li>24.2 \u53cc\u53d8\u91cf\u7ea6\u5316\u4e3a\u4e3a\u5355\u53d8\u91cf BINARY-TO-UNARY REDUCTION</li> <li>24.3 \u4f4d\u4e32\u884c\u7b97\u6570\u4e2d\u7684\u67e5\u627e\u8868 TABLES IN BIT-SERIAL ARITHMETIC</li> <li>24.4 \u63d2\u503c\u5b58\u50a8 INTERPOL ATING MEMORY</li> <li>24.5 \u5206\u6bb5\u67e5\u8868 PIECEWISE LOOKUP TABLES</li> <li>24.6 \u591a\u90e8\u8868 MULTIPARTITE TABLE METHODS</li> </ul>"},{"location":"Part_07/","title":"\u5b9e\u73b0\u76f8\u5173\u4e3b\u9898","text":"<p>IMPLEMENTATION TOPICS</p> <p>\u201cThe scientist describes what is; the engineer creates what never was.\u201d               \u2014 THEODORE VON KARMAN</p> <p>\u201cAlways design a thing by considering it in its next larger context \u2014 a chair in a room,a room in a house, a house in an environment,an environment in a city plan.\u201d               \u2014 ELIEL SAARINEN</p> <p>\u201c\u79d1\u5b66\u5bb6\u63cf\u8ff0\u4e86\u73b0\u5728\u6709\u7684\u4e1c\u897f\uff1b \u5de5\u7a0b\u5e08\u521b\u9020\u4e86\u4ee5\u524d\u6ca1\u6709\u7684\u4e1c\u897f\u3002\u201d               \u2014 \u897f\u5965\u591a\u00b7\u51af\u00b7\u5361\u95e8</p> <p>\u201c\u8bbe\u8ba1\u4e00\u4ef6\u4e1c\u897f\u65f6\uff0c\u603b\u662f\u8981\u8003\u8651\u5b83\u7684\u4e0b\u4e00\u4e2a\u66f4\u5927\u7684\u80cc\u666f\u2014\u2014\u623f\u95f4\u91cc\u7684\u6905\u5b50\u3001\u623f\u5b50\u91cc\u7684\u623f\u95f4\u3001\u73af\u5883\u4e2d\u7684\u623f\u5b50\u3001\u57ce\u5e02\u89c4\u5212\u4e2d\u7684\u73af\u5883\u3002\u201d               \u2014 \u57c3\u5229\u5c14\u00b7\u8428\u91cc\u5b81</p> <p>WE HAVE THUS FAR IGNORED SEVERAL IMPORTANT TOPICS THAT BEAR ON THE usefulness and overall quality of computer arithmetic units. In some contexts\u2014say, when we want the hardware to support two floating-point arithmetic operations per cycle on the average and do not mind that the result of each operation becomes available after many cycles\u2014throughput might be more important than latency. Pipelining is the mechanism used to achieve high throughput while keeping the cost and size of the circuits in check. In other contexts, the size or power requirements of the arithmetic circuits are of primary concern. In some critical applications,or in harsh operating environments,tolerance to permanent and transient hardware faults might be required. Finally, ease of implementation with flexible hardware components,such as fieldprogrammable gate arrays, rests upon certain special provisions in the design. Our discussions in this part should be viewed as windows into advanced implementation techniques. Each of the following four chapters could be expanded into a book.</p> <p>\u5230\u76ee\u524d\u4e3a\u6b62\uff0c\u6211\u4eec\u5ffd\u7565\u4e86\u4e0e\u8ba1\u7b97\u673a\u7b97\u672f\u5355\u5143\u7684\u5b9e\u7528\u6027\u548c\u6574\u4f53\u8d28\u91cf\u6709\u5173\u7684\u51e0\u4e2a\u91cd\u8981\u4e3b\u9898\u3002 \u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u4f8b\u5982\uff0c\u5f53\u6211\u4eec\u5e0c\u671b\u786c\u4ef6\u5e73\u5747\u6bcf\u4e2a\u5468\u671f\u652f\u6301\u4e24\u4e2a\u6d6e\u70b9\u7b97\u672f\u8fd0\u7b97\uff0c\u5e76\u4e14\u4e0d\u4ecb\u610f\u6bcf\u4e2a\u8fd0\u7b97\u7684\u7ed3\u679c\u5728\u591a\u4e2a\u5468\u671f\u540e\u624d\u53ef\u7528\u65f6\uff0c\u541e\u5410\u91cf\u53ef\u80fd\u6bd4\u5ef6\u8fdf\u66f4\u91cd\u8981\u3002 \u6d41\u6c34\u7ebf\u662f\u4e00\u79cd\u7528\u4e8e\u5b9e\u73b0\u9ad8\u541e\u5410\u91cf\u540c\u65f6\u63a7\u5236\u7535\u8def\u6210\u672c\u548c\u5c3a\u5bf8\u7684\u673a\u5236\u3002 \u5728\u5176\u4ed6\u60c5\u51b5\u4e0b\uff0c\u8fd0\u7b97\u7535\u8def\u7684\u5c3a\u5bf8\u6216\u529f\u7387\u8981\u6c42\u662f\u9996\u8981\u8003\u8651\u7684\u95ee\u9898\u3002 \u5728\u67d0\u4e9b\u5173\u952e\u5e94\u7528\u7a0b\u5e8f\u6216\u6076\u52a3\u7684\u64cd\u4f5c\u73af\u5883\u4e2d\uff0c\u53ef\u80fd\u9700\u8981\u5bb9\u5fcd\u6c38\u4e45\u6027\u548c\u6682\u65f6\u6027\u786c\u4ef6\u6545\u969c\u3002 \u6700\u540e\uff0c\u7075\u6d3b\u7684\u786c\u4ef6\u7ec4\u4ef6\uff08\u4f8b\u5982\u73b0\u573a\u53ef\u7f16\u7a0b\u95e8\u9635\u5217\uff09\u7684\u6613\u4e8e\u5b9e\u73b0\u53d6\u51b3\u4e8e\u8bbe\u8ba1\u4e2d\u7684\u67d0\u4e9b\u7279\u6b8a\u89c4\u5b9a\u3002 \u6211\u4eec\u5728\u8fd9\u4e00\u90e8\u5206\u7684\u8ba8\u8bba\u5e94\u88ab\u89c6\u4e3a\u4e86\u89e3\u9ad8\u7ea7\u5b9e\u73b0\u6280\u672f\u7684\u7a97\u53e3\u3002 \u4ee5\u4e0b\u56db\u7ae0\u6bcf\u4e00\u7ae0\u90fd\u53ef\u4ee5\u6269\u5145\u6210\u4e00\u672c\u4e66\u3002</p> <ul> <li>\u7b2c\u4e8c\u5341\u4e94\u7ae0 \u9ad8\u541e\u5410\u91cf\u7b97\u672f High-Throughput Arithmetic</li> <li>\u7b2c\u4e8c\u5341\u516d\u7ae0 \u4f4e\u529f\u8017\u7b97\u672f Low Power Arithmetic</li> <li>\u7b2c\u4e8c\u5341\u4e03\u7ae0 \u5bb9\u9519\u7b97\u672f Fault-Tolerant Arithmetic</li> <li>\u7b2c\u4e8c\u5341\u516b\u7ae0 \u53ef\u91cd\u6784\u7b97\u672f Reconfigurable Arithmetic</li> </ul>"},{"location":"Part_07/25/","title":"25. \u9ad8\u541e\u5410\u91cf\u7b97\u672f","text":"<p>High-Throughput Arithmetic</p> <ul> <li> <p>25.1 \u7b97\u672f\u529f\u80fd\u7684\u6d41\u6c34\u5316 PIPELINING OF ARITHMETIC FUNCTIONS</p> </li> <li> <p>25.2 \u65f6\u949f\u9891\u7387\u4e0e\u541e\u5410\u91cf CLOCK RATE AND THROUGHPUT</p> </li> <li> <p>25.3 \u5384\u5c14\u9501\u5b58\u5668 THE EARLE LATCH</p> </li> <li> <p>25.4 \u5e76\u884c\u6d41\u6c34\u7ebf\u4e0e\u4e32\u884c\u6d41\u6c34\u7ebf PARALLEL AND DIGIT SERIAL PIPELINES</p> </li> <li> <p>25.5 \u5373\u65f6\u7b97\u672f\u4e0e\u6570\u4f4d\u6d41\u6c34\u7ebf ON-LINE OR DIGIT-PIPELINED ARITHMETIC</p> </li> <li> <p>25.6 \u8109\u52a8\u7b97\u672f\u5355\u5143 SYSTOLIC ARITHMETIC UNITS</p> </li> </ul>"},{"location":"Part_07/26/","title":"26. \u4f4e\u529f\u8017\u7b97\u672f","text":"<p>Low Power Arithmetic</p> <ul> <li>26.1 \u4f4e\u529f\u8017\u8bbe\u8ba1\u7684\u9700\u6c42 THE NEED FOR LOW-POWER DESIGN</li> <li>26.2 \u529f\u8017\u5f00\u9500\u7684\u6765\u6e90 SOURCES OF POWER CONSUMPTION</li> <li>26.3 \u51cf\u5c11\u80fd\u6e90\u6d6a\u8d39 REDUCTION OF POWERWASTE</li> <li>26.4 \u51cf\u5c11\u6d3b\u52a8 REDUCTION OF ACTIVITY</li> <li>26.5 \u8f6c\u53d8\u4e0e\u6743\u6a2a TRANSFORMATIONS AND TRADE-OFFS</li> <li>26.6 \u65b0\u5174\u65b9\u6cd5 NEW AND EMERGING METHODS</li> </ul>"},{"location":"Part_07/27/","title":"27. \u5bb9\u9519\u7b97\u672f","text":"<p>Fault-Tolerant Arithmetic</p> <ul> <li>27.1 \u6545\u969c\u3001\u68c0\u9519\u4e0e\u7ea0\u9519\u7f16\u7801 FAULTS, ERRORS, AND ERROR CODES</li> <li> <p>27.2 \u7b97\u6570\u9519\u8bef\u68c0\u6d4b\u4ee3\u7801 ARITHMETIC ERROR DETECTING CODES</p> <ul> <li>\u4e58\u79ef\u7f16\u7801 Product codes</li> <li>\u4f59\u6570\u7f16\u7801 Residue codes</li> </ul> </li> <li> <p>27.3 \u7b97\u672f\u7ea0\u9519\u7801 ARITHMETIC ERROR-CORRECTING CODES</p> </li> <li>27.4 \u81ea\u68c0\u529f\u80fd\u5355\u5143 SELF-CHECKING FUNCTION UNITS</li> <li>27.5 \u5bb9\u9519\u7b97\u6cd5 ALGORITHM-BASED FAULT TOLERANCE</li> <li>27.5 \u5bb9\u9519RNS\u7b97\u672f FAULT-TOLERANT RNS ARITHMETIC</li> </ul>"},{"location":"Part_07/28/","title":"28. \u53ef\u91cd\u6784\u7b97\u672f","text":"<p>Reconfigurable Arithmetic</p> <ul> <li>28.1 \u53ef\u7f16\u7a0b\u903b\u8f91\u5668\u4ef6 PROGRAMMABLE LOGIC DEVICES</li> <li>28.2 FPGAs\u7684\u52a0\u6cd5\u5668\u8bbe\u8ba1 ADDER DESIGNS FOR FPGAS</li> <li>28.3 \u4e58\u6cd5\u5668\u4e0e\u9664\u6cd5\u5668\u7684\u8bbe\u8ba1 MULTIPLIER AND DIVIDER DESIGNS</li> <li>28.4 \u67e5\u8868\u6cd5\u4e0e\u5206\u5e03\u5f0f\u7b97\u672f TABULAR AND DISTRIBUTED ARITHMETIC</li> <li>28.5 FPGAs\u4e0a\u7684\u51fd\u6570\u6c42\u503c FUNCTION EVALUATION ON FPGAS</li> <li>28.6 \u7ec6\u7c92\u5ea6\u8bbe\u5907\u4e4b\u4e0a BEYOND FINE-GRAINED DEVICES</li> </ul>"}]}